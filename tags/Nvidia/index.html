<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: Nvidia - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.1.1"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Nvidia</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-11T16:00:00.000Z" title="5/11/2023, 4:00:00 PM">2023-05-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-03T05:41:20.008Z" title="2/3/2024, 5:41:20 AM">2024-02-03</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">18 minutes read (About 2681 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/11/Work/software/perf/nvidiaNsight/">Nvidia Nsight</a></p><div class="content"><h2 id="Nsight-system-compute-Graph-的关系"><a href="#Nsight-system-compute-Graph-的关系" class="headerlink" title="Nsight system compute &amp; Graph 的关系"></a>Nsight system compute &amp; Graph 的关系</h2><p><img src="https://pic.shaojiemike.top/img/20220513195618.png"></p>
<h3 id="Nsight-Systems"><a href="#Nsight-Systems" class="headerlink" title="Nsight Systems"></a>Nsight Systems</h3><p>All developers should start with Nsight Systems to identify the largest optimization opportunities. Nsight Systems provides developers a <strong>system-wide visualization</strong> of an applications performance. Developers can optimize <strong>bottlenecks</strong> to scale efficiently across any number or size of CPUs and GPUs; from large servers to our smallest SoC. For <strong>further optimizations to compute kernels developers should use Nsight Compute</strong> or to further optimize a graphics workloads, use Nsight Graphics.</p>
<h3 id="Nsight-Compute"><a href="#Nsight-Compute" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h3><p>Nsight Compute is an interactive <strong>kernel</strong> profiler for <strong>CUDA</strong> applications. It provides detailed performance metrics and API debugging via a user interface and command line tool. Nsight Compute also provides customizable and data-driven user interface and metric collection that can be extended with analysis scripts for post-processing results.</p>
<h3 id="Nsight-Graphics"><a href="#Nsight-Graphics" class="headerlink" title="Nsight Graphics"></a>Nsight Graphics</h3><p>Nsight Graphics is a standalone application for the debugging, profiling, and analysis of <strong>graphics applications</strong> on Microsoft Windows and Linux. It allows you to optimize the performance of your Direct3D 11, Direct3D 12, DirectX Raytracing 1.1, <strong>OpenGL</strong>, Vulkan, and KHR Vulkan <strong>Ray Tracing</strong> Extension based applications.</p>
<h2 id="Install-Nsight-local"><a href="#Install-Nsight-local" class="headerlink" title="Install Nsight local"></a>Install Nsight local</h2><ol>
<li>check the perf config To collect thread scheduling data and IP (instruction pointer) samples<ol>
<li><code>cat /proc/sys/kernel/perf_event_paranoid</code></li>
<li>如果大于2，临时改变 <code>sudo sh -c &#39;echo 2 &gt;/proc/sys/kernel/perf_event_paranoid&#39;</code>重启会重置</li>
<li>永久修改 <code>sudo sh -c &#39;echo kernel.perf_event_paranoid=2 &gt; /etc/sysctl.d/local.conf&#39;</code></li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/gameworksdownload#?dn=nsight-systems-2022-2">下载Nsight</a><ol>
<li>但是单独下载要会员</li>
<li>下载cuda toolkit,有集成</li>
</ol>
</li>
</ol>
<h2 id="Nsight-System"><a href="#Nsight-System" class="headerlink" title="Nsight System"></a>Nsight System</h2><h3 id="目标与功能"><a href="#目标与功能" class="headerlink" title="目标与功能"></a>目标与功能</h3><p>运行 <code>nsight-sys</code>，可以从整体上看GPU,CPU资源的使用情况，和分辨出热点函数和kernel，但是对于为什么是热点给不出具体分析。</p>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>勾选了CUDA-trace, GPU Metrics选项</p>
<p>??? tip “GPU Metrics 需要 sudo”</p>
<pre><code>否则会报错。一般情况下使用sudo能保证`0 error`

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GPU Metrics [0]: The user running Nsight Systems does not have permission to access NVIDIA GPU Performance Counters on the target device. For more details, please visit https://developer.nvidia.com/ERR_NVGPUCTRPERM</span><br><span class="line">  - API <span class="keyword">function</span>: NVPW_GPU_PeriodicSampler_GetCounterAvailability(&amp;params)</span><br><span class="line">  - Error code: 17</span><br><span class="line">  - Source <span class="keyword">function</span>: static std::vector&lt;unsigned char&gt; QuadDDaemon::EventSource::GpuMetricsBackend::Impl::CounterConfig::GetCounterAvailabilityImage(uint32_t)</span><br><span class="line">  - Source location: /dvs/p4/build/sw/devtools/Agora/Rel/DTC_F/QuadD/Target/quadd_d/quadd_d/jni/EventSource/GpuMetricsBackend.cpp:609</span><br></pre></td></tr></table></figure>
</code></pre>
<h3 id="Profile-速度"><a href="#Profile-速度" class="headerlink" title="Profile 速度"></a>Profile 速度</h3><p>大致2到3倍时间：默认采样率，单独运行52s, Nsight-sys模拟需要135s。</p>
<h3 id="HPC-APP-PCIE-GPU-DRAM-Bandwidth-Warp"><a href="#HPC-APP-PCIE-GPU-DRAM-Bandwidth-Warp" class="headerlink" title="HPC APP : PCIE, GPU DRAM Bandwidth, Warp"></a>HPC APP : PCIE, GPU DRAM Bandwidth, Warp</h3><p> GPU Metrics选项能看出 PCIE, GPU DRAM Bandwidth, Warp的使用情况。</p>
<p><img src="https://pic.shaojiemike.top/img/20220521143324.png"></p>
<h4 id="Compute-Warps-in-Flight"><a href="#Compute-Warps-in-Flight" class="headerlink" title="Compute Warps in Flight"></a>Compute Warps in Flight</h4><p>将鼠标放在上面会有<strong>具体</strong>的数值或者名称的解释，(正在使用的Warps)</p>
<p><img src="https://pic.shaojiemike.top/img/20220521143753.png"><br><img src="https://pic.shaojiemike.top/img/20220521144435.png"></p>
<h4 id="Unallocated-Warps-in-Active-SMs"><a href="#Unallocated-Warps-in-Active-SMs" class="headerlink" title="Unallocated Warps in Active SMs"></a>Unallocated Warps in Active SMs</h4><ul>
<li><strong>Definition:</strong> This metric represents the number of warps that are not actively executing but are assigned to an active Streaming Multiprocessor (SM).</li>
<li><strong>Interpretation:</strong> In CUDA, SMs are the fundamental processing units on the GPU. Each SM can execute multiple warps concurrently. “Unallocated Warps in Active SMs” indicates the number of warps that are ready to be scheduled on an SM but are currently waiting due to resource contention or other factors. <strong>A high number</strong> may suggest that there is room for additional work but available resources are <strong>not fully utilized</strong>.</li>
</ul>
<h4 id="NVTX"><a href="#NVTX" class="headerlink" title="NVTX"></a>NVTX</h4><p>由于没有根据kernel function区分，很难读。为此提供了NVTX来给代码打标签</p>
<p>??? note “The NVIDIA Tools Extension Library (NVTX)”</p>
<pre><code>使用NVTX可以在C代码里插入标记，使得Nvsight能有效监控区域代码。

头文件：[^1]

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;nvToolsExt.h&gt;</span></span></span><br></pre></td></tr></table></figure>

需要标记代码前后加入：

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvtxRangePush(<span class="string">&quot;checkResult&quot;</span>); <span class="comment">//nvtxRangePushA,nvtxRangePushW,nvtxRangePushEx 好像都差不多</span></span><br><span class="line">checkResult&lt;&lt;&lt;dim3(row_num / TPBX, col_num / TPBY, <span class="number">1</span>), dim3(TPBX, TPBY, <span class="number">1</span>)&gt;&gt;&gt;(row_num, col_num, result);</span><br><span class="line">cudaDeviceSynchronize(); </span><br><span class="line">nvtxRangePop();</span><br></pre></td></tr></table></figure>

注意NVTX是作用在**CPU线程**上的，无法在GPU里用。

注意需要 `g++ -o testnv -I/usr/local/cuda/include -L/usr/local/cuda/lib64 -lnvToolsExt testnv.cpp`。或者修改cmake来实现同样的效果

NVTX问题：怎么不在同一竖直方向上？GPU还先跑是什么情况[^2]

![](https://pic.shaojiemike.top/img/20220521153540.png)
</code></pre>
<h3 id="AI-APP-Stable-Diffusion-XL"><a href="#AI-APP-Stable-Diffusion-XL" class="headerlink" title="AI APP: Stable Diffusion XL"></a>AI APP: Stable Diffusion XL</h3><p><img src="https://pic.shaojiemike.top/shaojiemike/2023/12/1a1f45bbc4293f22a0b26305dc74c220.png"></p>
<p>具体分析见 Deploy Stable Diffusion to A100</p>
<h2 id="Nsight-Compute-1"><a href="#Nsight-Compute-1" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h2><ul>
<li>Nsight Systems 就是nvprof的继任者，NVIDIA最新的用于监测 kernel timeline的工具。</li>
<li>NVIDIA 计算能力7.5及以上的GPU设备(从A100开始)不再支持nvprof工具进行性能剖析，提示使用Nsight Compute作为替代品.</li>
</ul>
<h3 id="目标与功能-1"><a href="#目标与功能-1" class="headerlink" title="目标与功能"></a>目标与功能</h3><p>默认kernel模式，会根据 function的调度关系，将程序划分为kernel</p>
<ol>
<li>Summary： 给出in-order执行的每个kernel的参数，时间，资源占用(寄存器，计算访存单元)信息。<ol>
<li>Detail: 对于<strong>被选择的kernel</strong>给出， NV的优化建议</li>
<li>Source：对于<strong>被选择的kernel</strong>给出， 给出源代码</li>
</ol>
</li>
</ol>
<h3 id="基本使用-1"><a href="#基本使用-1" class="headerlink" title="基本使用"></a>基本使用</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># recommand running under sudo</span></span><br><span class="line">ncu <span class="comment"># 命令行 Nsight Compute CLI(ncu)</span></span><br><span class="line">ncu-ui <span class="comment"># GUI</span></span><br></pre></td></tr></table></figure>

<h3 id="Profile速度"><a href="#Profile速度" class="headerlink" title="Profile速度"></a>Profile速度</h3><p>目测模拟时间慢百倍。</p>
<h3 id="使用Nsight-Compute-CLI-nv-nsight-cu-cli-ncu-输出数据"><a href="#使用Nsight-Compute-CLI-nv-nsight-cu-cli-ncu-输出数据" class="headerlink" title="使用Nsight Compute CLI (nv-nsight-cu-cli &#x2F; ncu) 输出数据"></a>使用Nsight Compute CLI (nv-nsight-cu-cli &#x2F; ncu) 输出数据</h3><p><code>nv-nsight-cu-cli -&gt; ncu</code></p>
<p>下面是一个使用样例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/NVIDIA-Nsight-Compute/nv-nsight-cu-cli -o mnist -f --csv --profile-from-start off /usr/bin/python3 mnist.py</span><br></pre></td></tr></table></figure>

<p>其中-o是为了输出.nsight-cuprof-report文件用于后续的可视化查看，-f为强制覆盖原有文件，–csv可是在console输出除 timeline 以外数据的时候以逗号分隔数据，方便拷贝至csv文件， –profile-from-start的使用方法和Nsight System以及nvprof一样。其余flag选项可见<a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">文档</a>。</p>
<p>上面的例子会生成mnist.nsight-cuprof-report文件。</p>
<p>注意</p>
<p>最前面的可执行文件需要绝对路径，如上面的python3需要使用 &#x2F;usr&#x2F;bin&#x2F;python3。<br>生成过程中可能会产生很大的临时文件（几十G）。如果本次磁盘空间不够，可以设置如下环境变量来调整存储临时文件的地址。没有找到能直接使用 Nsight Compute 修改临时文件地址的方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export /TMPDIR=/path/for/tmp</span><br></pre></td></tr></table></figure>

<h3 id="ncu与nvprof命令行抓取参数的映射表"><a href="#ncu与nvprof命令行抓取参数的映射表" class="headerlink" title="ncu与nvprof命令行抓取参数的映射表"></a>ncu与nvprof命令行抓取参数的映射表</h3><p><a target="_blank" rel="noopener" href="https://www.freesion.com/article/34871449930/">https://www.freesion.com/article/34871449930/</a></p>
<h3 id="ncu-ui教程"><a href="#ncu-ui教程" class="headerlink" title="ncu-ui教程"></a>ncu-ui教程</h3><p>为了显示原代码makefile添加 <code>-g -G</code>选项<br>对应CmakeList.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">target_compile_options(better PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:--extended-lambda</span><br><span class="line">    -G -src-in-ptx</span><br><span class="line">    &gt;)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yan31415/article/details/109491749">https://blog.csdn.net/yan31415/article/details/109491749</a></p>
<h3 id="ncu-ui表格-图"><a href="#ncu-ui表格-图" class="headerlink" title="ncu-ui表格&amp;图"></a>ncu-ui表格&amp;图</h3><p><img src="https://pic.shaojiemike.top/img/20220521160243.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220521161200.png"><br>我不明白我的SMEM怎么不是从DRAM来的， 而且峰值怎么这么低？</p>
<p>这个错误也是令人迷惑<br>The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 3.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.</p>
<p><img src="https://pic.shaojiemike.top/img/20220521163326.png"></p>
<p>不知道为什么有1%和2% 的bank conflict</p>
<p>可以看到 SMEM， Register，Block Size是怎么影响GPU Warp的分配调度的。<br><img src="https://pic.shaojiemike.top/img/20220521163505.png"><br>上图没有拖累，吃满了64个warp。</p>
<p>关于if语句<br><img src="https://pic.shaojiemike.top/img/20220521163918.png"><br>if语句只要warp里执行相同就行。</p>
<p>可以提示出不连续访问的地方。(这里是这样设计的，已经避免了绝大部分的不连续访问)<br><img src="https://pic.shaojiemike.top/img/20220521164456.png"></p>
<p>显示stall最多的指令是什么以及在等待什么。还有执行最多的指令<br><img src="https://pic.shaojiemike.top/img/20220521164627.png"></p>
<p>假如 file mismatched 手动选择文件就行<br><img src="https://pic.shaojiemike.top/img/20220521165836.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220521170004.png"></p>
<p>stall的信息，感觉就这些有点用。(其中sb是scoreboard的意思)</p>
<h2 id="ncu-ui-分析汇编"><a href="#ncu-ui-分析汇编" class="headerlink" title="ncu-ui 分析汇编"></a>ncu-ui 分析汇编</h2><h3 id="PTX-SASS汇编说明"><a href="#PTX-SASS汇编说明" class="headerlink" title="PTX&amp;SASS汇编说明"></a>PTX&amp;SASS汇编说明</h3><p>有两种汇编</p>
<p>请看PTX SASS一文</p>
<h3 id="基本说明"><a href="#基本说明" class="headerlink" title="基本说明"></a>基本说明</h3><p><img src="https://pic.shaojiemike.top/img/20220522095802.png"></p>
<p>可以通过指令执行数或者采样率来得知，执行最多的指令。</p>
<p>鼠标悬停可以知道具体命令的含义</p>
<h3 id="Ex1-for循环头"><a href="#Ex1-for循环头" class="headerlink" title="Ex1: for循环头"></a>Ex1: for循环头</h3><p><img src="https://pic.shaojiemike.top/img/20220522101042.png"></p>
<h3 id="Ex2-for-loop-kernel"><a href="#Ex2-for-loop-kernel" class="headerlink" title="Ex2: for-loop kernel"></a>Ex2: for-loop kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sdata[Regular_local_index]=arr_data[Regular_global_index];</span><br></pre></td></tr></table></figure>

<p>该从DRAM里读取到SMEM的指令对应的PTX和SASS代码<br><img src="https://pic.shaojiemike.top/img/20220522105005.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cvt.f32.u16 d, a;   // convert 16-bit unsigned to 32-bit float</span><br></pre></td></tr></table></figure>

<h3 id="问题：无效self-mov？"><a href="#问题：无效self-mov？" class="headerlink" title="问题：无效self-mov？"></a>问题：无效self-mov？</h3><p><img src="https://pic.shaojiemike.top/img/20220522101410.png"></p>
<p>为了隐藏延迟？</p>
<p>直接原因是PTX翻译成SASS。一条mov变多条了</p>
<p><img src="https://pic.shaojiemike.top/img/20220522103503.png"></p>
<h2 id="CUDA-Visual-Profiler"><a href="#CUDA-Visual-Profiler" class="headerlink" title="CUDA Visual Profiler"></a>CUDA Visual Profiler</h2><p>老一代debugger工具，逐渐被Nsight淘汰</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof # 命令行,nsys 之前的名称叫做 nvprof</span><br><span class="line">nvvp</span><br></pre></td></tr></table></figure>

<p>在more里有建议</p>
<h3 id="nvprof捕获信息存储"><a href="#nvprof捕获信息存储" class="headerlink" title="nvprof捕获信息存储"></a>nvprof捕获信息存储</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./nbody --benchmark -numdevices=2 -i=1</span><br><span class="line"><span class="comment"># 下面输出 .qdrep 文件</span></span><br><span class="line">nsys profile --stats=<span class="literal">true</span> --force-overwrite=<span class="literal">true</span>  -o baseline-report ./single-thread-vector-add</span><br></pre></td></tr></table></figure>

<h2 id="CUDA-Visual-Profiler-问题"><a href="#CUDA-Visual-Profiler-问题" class="headerlink" title="CUDA Visual Profiler 问题"></a>CUDA Visual Profiler 问题</h2><p>??? failure “&#x3D;&#x3D;7196&#x3D;&#x3D; Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.”</p>
<pre><code>解决方法在程序末尾加cudaDeviceReset()或者cudaProfilerStop()
</code></pre>
<h2 id="Nsight-Compute-问题"><a href="#Nsight-Compute-问题" class="headerlink" title="Nsight Compute 问题"></a>Nsight Compute 问题</h2><h3 id="OpenGL-没有安装"><a href="#OpenGL-没有安装" class="headerlink" title="OpenGL 没有安装"></a>OpenGL 没有安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Warning: Failed to get OpenGL version. OpenGL version 2.0 or higher is required.</span><br><span class="line">OpenGL version is too low (0). Falling back to Mesa software rendering.</span><br><span class="line">qt.qpa.plugin: Could not load the Qt platform plugin <span class="string">&quot;xcb&quot;</span> <span class="keyword">in</span> <span class="string">&quot;&quot;</span> even though it was found.</span><br><span class="line">This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.</span><br><span class="line"></span><br><span class="line">Available platform plugins are: offscreen, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, xcb.</span><br></pre></td></tr></table></figure>

<p>解决办法</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libxcb-xinerama0</span><br><span class="line">sudo apt install libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0</span><br></pre></td></tr></table></figure>

<h3 id="Qt插件缺失"><a href="#Qt插件缺失" class="headerlink" title="Qt插件缺失"></a>Qt插件缺失</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.</span><br><span class="line">This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.</span><br><span class="line"></span><br><span class="line">Available platform plugins are: xcb.</span><br><span class="line"></span><br><span class="line">Application could not be initialized!</span><br><span class="line">    This is likely due to missing Qt platform dependencies.</span><br><span class="line">    For a list of dependencies, please refer to https://doc.qt.io/qt-5/linux-requirements.html</span><br><span class="line">    To view missing libraries, set QT_DEBUG_PLUGINS=1 and re-run the application.</span><br></pre></td></tr></table></figure>

<p>按照说明 <code>export QT_DEBUG_PLUGINS=1</code>再次运行, 显示具体问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot load library /staff/shaojiemike/Install/cuda_11.7.0_515.43.04_linux/nsight-compute-2022.2.0/host/linux-desktop-glibc_2_11_3-x64/Plugins/platforms/libqxcb.so: (libxcb-xinput.so.0: cannot open shared object file: No such file or directory)</span><br></pre></td></tr></table></figure>

<p>解决 <code>sudo apt-get install libxcb-xinput0</code></p>
<h3 id="kernel没权限profile"><a href="#kernel没权限profile" class="headerlink" title="kernel没权限profile"></a>kernel没权限profile</h3><p><code>ERR_NVGPUCTRPERM - The user does not have permission to profile on the target device</code></p>
<p>要用sudo，或者最新的NV</p>
<h3 id="could-not-connect-to-display-localhost-10-0-under-sudo"><a href="#could-not-connect-to-display-localhost-10-0-under-sudo" class="headerlink" title="could not connect to display localhost:10.0 under sudo"></a>could not connect to display localhost:10.0 <strong>under sudo</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ncu-ui</span><br><span class="line">MobaXterm X11 proxy: Authorisation not recognised</span><br><span class="line">qt.qpa.xcb: could not connect to display localhost:10.0</span><br><span class="line"></span><br><span class="line">MobaXterm X11 proxy: Unsupported authorisation protocol</span><br><span class="line">Error: Can<span class="string">&#x27;t open display: localhost:10.0</span></span><br></pre></td></tr></table></figure>

<p>解决办法(原因是sudo相当于切换到root用户，丢失了xauth信息)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ xauth list</span><br><span class="line">snode0/unix:12  MIT-MAGIC-COOKIE-1  84941f1f8be97d19436356685f75b884</span><br><span class="line">snode0/unix:13  MIT-MAGIC-COOKIE-1  5172ee2c7364b055cd37538b460f7741</span><br><span class="line">snode0/unix:11  MIT-MAGIC-COOKIE-1  589f3b5ab852f24ca3710c53e6439260</span><br><span class="line">hades1/unix:10  MIT-MAGIC-COOKIE-1  9346adec202bd65250f3d21239025750</span><br><span class="line">snode0/unix:10  MIT-MAGIC-COOKIE-1  52285c563f1688741fa1b434ed2b7b2c</span><br><span class="line"></span><br><span class="line">sudo -s <span class="comment"># 切换</span></span><br><span class="line">xauth add snode0/unix:10  MIT-MAGIC-COOKIE-1  52285c563f1688741fa1b434ed2b7b2c <span class="comment"># 补全xauth</span></span><br><span class="line"><span class="comment"># 正常执行 xauth有用的总是最后一个</span></span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220606170556.png"></p>
<h3 id="GPU-Metrics-0-Sampling-buffer-overflow"><a href="#GPU-Metrics-0-Sampling-buffer-overflow" class="headerlink" title="GPU Metrics [0]: Sampling buffer overflow."></a>GPU Metrics [0]: Sampling buffer overflow.</h3><ol>
<li>只勾选CUDA Metrics 和 GPU Metrics</li>
<li>降低采样频率</li>
</ol>
<h3 id="Error-0-UnsupportedGpu"><a href="#Error-0-UnsupportedGpu" class="headerlink" title="Error 0: UnsupportedGpu"></a>Error 0: UnsupportedGpu</h3><p>原因是 <a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/nsight-unsupported-gpu/163617">软件对GPU的支持是逐步</a>的需要安装最新的。</p>
<p>不支持的Nsight的可以尝试老的debugger工具 CUDA Visual Profiler</p>
<h3 id="Error-Profiling-is-not-supported-on-this-device"><a href="#Error-Profiling-is-not-supported-on-this-device" class="headerlink" title="Error: Profiling is not supported on this device"></a>Error: Profiling is not supported on this device</h3><p>Pascal support was deprecated, then dropped from Nsight Compute after Nsight Compute 2019.5.1.</p>
<p>The profiling tools that support Pascal in the CUDA Toolkit 11.1 and later are <code>nvprof</code> and <code>visual profiler</code>.</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>NVTX问题</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/tools-overview">https://developer.nvidia.com/tools-overview</a></p>
<p><a target="_blank" rel="noopener" href="https://www.365seal.com/y/zyn1yxJQn3.html">https://www.365seal.com/y/zyn1yxJQn3.html</a></p>
<p>[^1]: <a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-visual-studio-edition/2020.1/nvtx/index.html">Usage of NVTX</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-14T16:00:00.000Z" title="5/14/2022, 4:00:00 PM">2022-05-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-03T05:41:19.992Z" title="2/3/2024, 5:41:19 AM">2024-02-03</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">18 minutes read (About 2659 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/14/Work/HPC/cuda/CudaOptimize/">Cuda Optimize</a></p><div class="content"><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ol>
<li>General optimization guidance<ol>
<li>Coalescing memory operations</li>
<li>Occupancy and latency hiding</li>
<li>Using shared memory</li>
</ol>
</li>
<li>Example 1: transpose<ol>
<li>Coalescing and bank conflict avoidance</li>
</ol>
</li>
<li>Example 2: efficient parallel reductions<ol>
<li>Using peak performance metrics to guide optimization</li>
<li>Avoiding SIMD divergence &amp; bank conflicts</li>
<li>Loop unrolling</li>
<li>Using template parameters to write general-yet-optimized code</li>
<li>Algorithmic strategy: Cost efficiency</li>
</ol>
</li>
</ol>
<h2 id="CUDA-优化策略"><a href="#CUDA-优化策略" class="headerlink" title="CUDA 优化策略"></a>CUDA 优化策略</h2><h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><ol>
<li>最大化并行独立性</li>
<li>最大化计算密度</li>
</ol>
<h3 id="减少数据传输"><a href="#减少数据传输" class="headerlink" title="减少数据传输"></a>减少数据传输</h3><ol>
<li>数据可以直接在GPU生成。</li>
<li>一次大传输也比分开的小批次快</li>
</ol>
<h4 id="zerocopy"><a href="#zerocopy" class="headerlink" title="zerocopy"></a>zerocopy</h4><p>如果我们数据只会在 GPU 产生和使用，我们不需要来回进行拷贝。</p>
<p><a target="_blank" rel="noopener" href="https://migocpp.wordpress.com/2018/06/08/cuda-memory-access-global-zero-copy-unified/">https://migocpp.wordpress.com/2018/06/08/cuda-memory-access-global-zero-copy-unified/</a></p>
<p>简而言之，在 host 使用命令：cudaHostRegisterMapped<br>之后用 cudaHostGetDevicePointer 进行映射<br>最后解除绑定 cudaHostUnregister</p>
<p>即，</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// First, pin the memory (or cudaHostAlloc instead)</span></span><br><span class="line">cudaHostRegister(h_a, …, cudaHostRegisterMapped);</span><br><span class="line">cudaHostRegister(h_b, …, cudaHostRegisterMapped);</span><br><span class="line">cudaHostRegister(h_c, …, cudaHostRegisterMapped);</span><br><span class="line"></span><br><span class="line">cudaHostGetDevicePointer(&amp;a, h_a, <span class="number">0</span>);</span><br><span class="line">cudaHostGetDevicePointer(&amp;b, h_b, <span class="number">0</span>);</span><br><span class="line">cudaHostGetDevicePointer(&amp;c, h_c, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">kernel&lt;&lt;&lt;...&gt;&gt;&gt;(a, b, c);</span><br><span class="line">cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line"><span class="comment">// unpin/release host memory</span></span><br><span class="line">cudaHostUnregister(h_a);</span><br><span class="line">cudaHostUnregister(h_b);</span><br><span class="line">cudaHostUnregister(h_c);</span><br></pre></td></tr></table></figure>

<h4 id="cuda-warp-shuffle"><a href="#cuda-warp-shuffle" class="headerlink" title="cuda warp shuffle"></a>cuda warp shuffle</h4><p>只要两个thread在 同一个warp中，允许thread直接读其他thread的寄存器值，这种比通过shared Memory进行thread间的通讯效果更好，latency更低，同时也不消耗额外的内存资源来执行数据交换。<a target="_blank" rel="noopener" href="https://blog.csdn.net/Bruce_0712/article/details/64926471">ref</a></p>
<h3 id="访存连续性"><a href="#访存连续性" class="headerlink" title="访存连续性"></a>访存连续性</h3><ol start="2">
<li><strong>Optimize for spatial locality in cached texture memory</strong> ???</li>
<li>避免bank conflict： 如果没有bank冲突的话，共享内存的访存速度将会非常的快，大约比全局内存的访问延迟低100多倍，但是速度没有寄存器快。然而，如果在使用共享内存时发生了bank冲突的话，性能将会降低很多很多。</li>
</ol>
<h4 id="Global-Memory：coalesced-access"><a href="#Global-Memory：coalesced-access" class="headerlink" title="Global Memory：coalesced access"></a>Global Memory：coalesced access</h4><p>对齐(Starting address for a region must be a multiple of region size)集体访问，有数量级的差异Coalesced</p>
<p>利用好每个block里的thread，全部每个线程各自读取自己对齐(Starting address for a region must be a multiple of region size 不一定是自己用的)数据到shared memory开辟的总空间。由于需要的数据全部合力读取进来了，计算时正常使用需要的读入的数据。</p>
<p>特别是对于结构体使用SoA(structure of arrays)而不是AoS（array of structures），<br>如果结构体实在不能对齐, 可以使用 <code>__align(X)</code>, where X &#x3D; 4, 8, or 16.强制对齐。</p>
<p>??? example “对齐读取 float3 code”</p>
<pre><code>对于small Kernel和访存瓶颈的Kernel影响很大

![](https://pic.shaojiemike.top/img/20220505203920.png)

由于需要对齐读取，3float是12字节，所以只能拆成三份。

![](https://pic.shaojiemike.top/img/20220519000548.png)

有无采用对齐shared读取，有10倍的加速。
</code></pre>
<h3 id="利用好Shared-Memory"><a href="#利用好Shared-Memory" class="headerlink" title="利用好Shared Memory"></a>利用好Shared Memory</h3><ol>
<li>比globalMemory快百倍</li>
<li>可以来避免 non-Coalesced access</li>
<li>SM的线程可以共享</li>
<li><strong>Use one &#x2F; a few threads to load &#x2F; compute data shared by all threads</strong></li>
</ol>
<h3 id="隐藏延迟的方法"><a href="#隐藏延迟的方法" class="headerlink" title="隐藏延迟的方法"></a>隐藏延迟的方法</h3><ol>
<li>增加SM上线程数量，</li>
<li>block数&gt; SM数，这样所有的multiprocessors至少有一个block执行</li>
<li>threads&#x2F;block&gt;128 。原因：机器上一般有最多4个Warp调度器&#x3D;4*32&#x3D;128</li>
<li>threadsInblock&#x3D;N*WarpSize&#x3D;N*32</li>
<li>在 SM 上的 TB 越多越好，让 Thread Block 不停的跑我们的利用率就会高。</li>
<li>但是如果 Thread Block 太多，我们每一个 SM 能分配的寄存器就会变少，所以就会发生 Register Spill, 使用更高级的 L1、L2 Cache 去代替 Registers。所以 TB 不能太多，需要减少 Register Spill 的次数。<ol>
<li>资源占用率不要太高（最多一半？</li>
</ol>
</li>
<li>多使用 <code>__syncthreads</code></li>
<li>最好的参数需要<code>self-tuning</code>出来</li>
</ol>
<h3 id="占用率高不一定是好事"><a href="#占用率高不一定是好事" class="headerlink" title="占用率高不一定是好事"></a>占用率高不一定是好事</h3><p>占用率是指每个多处理器（Streaming Multiprocessor，SM）的实际的活动warps数量与最大理论的warps数量的比率。<br>高的占用率不一定能提升性能，因为这一般意味着每个线程分配的寄存器和shared memory变少。但低的占用率会导致内存延迟无法隐藏。</p>
<p>实际需要计算每个线程大概需要的shared memory和register数量</p>
<h4 id="实际例子测试-待研究"><a href="#实际例子测试-待研究" class="headerlink" title="实际例子测试-待研究"></a>实际例子测试-待研究</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4541313.html">https://www.cnblogs.com/1024incn/p/4541313.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4545265.html">https://www.cnblogs.com/1024incn/p/4545265.html</a></p>
<h2 id="优化实例1-矩阵转置"><a href="#优化实例1-矩阵转置" class="headerlink" title="优化实例1 - 矩阵转置"></a>优化实例1 - 矩阵转置</h2><p>通过SMEM实现coalescing access</p>
<p>原本代码</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">_global__ <span class="type">void</span> <span class="title function_">transpose_naive</span><span class="params">(<span class="type">float</span> *odata, <span class="type">float</span> *idata, <span class="type">int</span> width, <span class="type">int</span> height)</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> xIndex = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> yIndex = blockDim.y * blockIdx.y + threadIdx.y;</span><br><span class="line">   <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="type">unsigned</span> <span class="type">int</span> index_in = xIndex + width * yIndex;</span><br><span class="line">      <span class="type">unsigned</span> <span class="type">int</span> index_out = yIndex + height * xIndex;</span><br><span class="line">      odata[index_out] = idata[index_in]; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>思想：将大矩阵划分成方块，并且存储在SMEM里。不仅SMEM速度更快，而且每行元素个数变少，跨行访问的间距变小，局部性增强。而且对于大矩阵加速效果会更明显。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">transpose</span><span class="params">(<span class="type">float</span> *odata, <span class="type">float</span> *idata, <span class="type">int</span> width, <span class="type">int</span> height)</span></span><br><span class="line">&#123;</span><br><span class="line">   __shared__ <span class="type">float</span> block[BLOCK_DIM*BLOCK_DIM];</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> xBlock = blockDim.x * blockIdx.x;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> yBlock = blockDim.y * blockIdx.y;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> xIndex = xBlock + threadIdx.x;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> yIndex = yBlock + threadIdx.y;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> index_out, index_transpose;</span><br><span class="line">   <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="type">unsigned</span> <span class="type">int</span> index_in = width * yIndex + xIndex;</span><br><span class="line">      <span class="type">unsigned</span> <span class="type">int</span> index_block = threadIdx.y * BLOCK_DIM + threadIdx.x;</span><br><span class="line">      block[index_block] = idata[index_in];</span><br><span class="line">      index_transpose = threadIdx.x * BLOCK_DIM + threadIdx.y;</span><br><span class="line">      index_out = height * (xBlock + threadIdx.y) + yBlock + threadIdx.x;</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">   <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">      odata[index_out] = block[index_transpose]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="coalescing-access"><a href="#coalescing-access" class="headerlink" title="coalescing access"></a>coalescing access</h3><p>when Block&#x2F;tile dimensions are multiples of 16 ???</p>
<h3 id="关于bank-conflict"><a href="#关于bank-conflict" class="headerlink" title="关于bank conflict"></a>关于bank conflict</h3><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/">https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/</a></p>
<p>对于一个32 × 32个元素的共享内存块，一列数据中的所有元素都映射到相同的SMEM bank ，导致bank conflict 的最坏情况:读取一列数据会导致32路的存储库冲突。</p>
<p>幸运的是，只需要将tile的元素宽度改为33，而不是32就行。</p>
<h2 id="优化实例2-数据归约"><a href="#优化实例2-数据归约" class="headerlink" title="优化实例2 - 数据归约"></a>优化实例2 - 数据归约</h2><p>具体问题：将长数组的所有元素，归约求和为一个结果。[^1][^2]</p>
<p><img src="https://pic.shaojiemike.top/img/20220511211558.png"></p>
<h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3><p>为了避免全局同步的巨大开销，采取分级归约<br><img src="https://pic.shaojiemike.top/img/20220515105630.png"></p>
<p>由于归约的计算密度低<br>1 flop per element loaded (bandwidth-optimal)</p>
<p>所以优化目标是将访存带宽用满。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">384-bit memory interface, 900 MHz DDR</span><br><span class="line">384 * 1800 / 8 = 86.4 GB/s</span><br></pre></td></tr></table></figure>

<h3 id="step0-baseline-Interleaved-Addressing-交错-间隔寻址"><a href="#step0-baseline-Interleaved-Addressing-交错-间隔寻址" class="headerlink" title="step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址"></a>step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce0(int *g_idata, int *g_odata) &#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   // each thread loads one element from global to shared mem</span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">   sdata[tid] = g_idata[i];</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   // do reduction in shared mem</span><br><span class="line">   for(unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">      if (tid % (s) == 0) &#123;</span><br><span class="line">         sdata[tid] += sdata[tid + s];</span><br><span class="line">      &#125;</span><br><span class="line">      __syncthreads();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   // write result for this block to global mem</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220515150953.png"><br>工作的线程越来越少。一开始是全部，最后一次只有thread0.</p>
<h3 id="Step1-使用连续的index"><a href="#Step1-使用连续的index" class="headerlink" title="Step1 : 使用连续的index"></a>Step1 : 使用连续的index</h3><p>Just replace divergent branch With strided index and non-divergent branch，但是会带来bank conflict。</p>
<p>原理和Warp发射有关，假如在这里每个Warp并行的线程是2。一个Warp运行耗时为T.</p>
<p>Step0: 4+4+2+1&#x3D;11T</p>
<p>Step1: 4+2+1+1&#x3D;8T</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">   <span class="type">int</span> index = <span class="number">2</span> * s * tid;</span><br><span class="line">   <span class="keyword">if</span> (index &lt; blockDim.x) &#123;</span><br><span class="line">      sdata[index] += sdata[index + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220515144525.png"><br><img src="https://pic.shaojiemike.top/img/20220515151516.png"></p>
<h3 id="Step2-连续寻址"><a href="#Step2-连续寻址" class="headerlink" title="Step2: 连续寻址"></a>Step2: 连续寻址</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> s=blockDim.x/<span class="number">2</span>; s&gt;<span class="number">0</span>; s&gt;&gt;=<span class="number">1</span>) &#123;</span><br><span class="line">   <span class="keyword">if</span> (tid &lt; s) &#123;</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>原本寻址<img src="https://pic.shaojiemike.top/img/20220515151840.png"></p>
<p>现在寻址有一边连续了<br><img src="https://pic.shaojiemike.top/img/20220515151937.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220515152034.png"></p>
<h3 id="Step3-弥补浪费的线程"><a href="#Step3-弥补浪费的线程" class="headerlink" title="Step3 : 弥补浪费的线程"></a>Step3 : 弥补浪费的线程</h3><p>方法： 在load SMEM的时候提前做一次规约加法，通过减少一半的block数，将原本两个block里的值load+add存储在sum里。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// perform first level of reduction,</span></span><br><span class="line"><span class="comment">// reading from global memory, writing to shared memory</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x*(blockDim.x*<span class="number">2</span>) + threadIdx.x;</span><br><span class="line">sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220515152704.png"></p>
<h3 id="step4-Unrolling-the-Last-Warp"><a href="#step4-Unrolling-the-Last-Warp" class="headerlink" title="step4 : Unrolling the Last Warp"></a>step4 : Unrolling the Last Warp</h3><p>当s&lt; 32的时候，就只有一个Warp工作了。</p>
<p>使用warp的SIMD还省去了<code>__syncthreads()</code>的麻烦</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> s=blockDim.x/<span class="number">2</span>; s&gt;<span class="number">32</span>; s&gt;&gt;=<span class="number">1</span>) </span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">if</span> (tid &lt; s)</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">32</span>)</span><br><span class="line">&#123;</span><br><span class="line">   sdata[tid] += sdata[tid + <span class="number">32</span>]; </span><br><span class="line">   sdata[tid] += sdata[tid + <span class="number">16</span>]; </span><br><span class="line">   sdata[tid] += sdata[tid + <span class="number">8</span>]; </span><br><span class="line">   sdata[tid] += sdata[tid + <span class="number">4</span>]; </span><br><span class="line">   sdata[tid] += sdata[tid + <span class="number">2</span>]; </span><br><span class="line">   sdata[tid] += sdata[tid + <span class="number">1</span>]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为了保持整洁，最后一个if还做了无效的计算。eg, Warp里的最后一个线程只有第一句命令有用。<br><img src="https://pic.shaojiemike.top/img/20220515162352.png"></p>
<h3 id="Step5-根据blockSize完全展开for和去除代码"><a href="#Step5-根据blockSize完全展开for和去除代码" class="headerlink" title="Step5 : 根据blockSize完全展开for和去除代码"></a>Step5 : 根据blockSize完全展开for和去除代码</h3><p>由于for循环里是二分的，而且小于32的单独处理了，导致for循环里实际运行代码最多就3句。</p>
<p>利用代码模板和编译器的自动优化实现：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">template &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">reduce5</span><span class="params">(<span class="type">int</span> *g_idata, <span class="type">int</span> *g_odata)</span></span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220515163110.png"></p>
<p>红色代码会在编译时自动优化。<br><img src="https://pic.shaojiemike.top/img/20220515163243.png"></p>
<h3 id="step6-：归并算法优化"><a href="#step6-：归并算法优化" class="headerlink" title="step6 ：归并算法优化"></a>step6 ：归并算法优化</h3><p>加速级联？？</p>
<p>Cost&#x3D; processors × time complexity</p>
<p>我们知道N个元素直接二叉树归约是O(log N)<br>时间 Cost&#x3D;N*O(log N).</p>
<p>但是假如只有P个线程先做N&#x2F;P的串行加法, 然后是log(P)的归约。<br>总cost&#x3D;P(N&#x2F;P+log(P))</p>
<p>当P&#x3D;N&#x2F;log(N), cost&#x3D;O(N)</p>
<p>each thread should sum O(log n) elements来设置</p>
<p>比如，1024 or 2048 elements per block vs. 256 线程。每个sum n&#x3D;4个元素。 具体参数要perf</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x*(blockSize*<span class="number">2</span>) + threadIdx.x;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> gridSize = blockSize*<span class="number">2</span>*gridDim.x;</span><br><span class="line">sdata[tid] = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; n) &#123;</span><br><span class="line">   sdata[tid] += g_idata[i] + g_idata[i+blockSize];</span><br><span class="line">   i += gridSize;</span><br><span class="line">&#125;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220515171758.png"></p>
<h3 id="final-code"><a href="#final-code" class="headerlink" title="final code"></a>final code</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">template &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">reduce6</span><span class="params">(<span class="type">int</span> *g_idata, <span class="type">int</span> *g_odata, <span class="type">unsigned</span> <span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">extern</span> __shared__ <span class="type">int</span> sdata[];</span><br><span class="line"></span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x*(blockSize*<span class="number">2</span>) + tid;</span><br><span class="line">   <span class="type">unsigned</span> <span class="type">int</span> gridSize = blockSize*<span class="number">2</span>*gridDim.x;</span><br><span class="line">   sdata[tid] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">do</span> &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; <span class="keyword">while</span> (i &lt; n);</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (blockSize &gt;= <span class="number">512</span>) &#123; <span class="keyword">if</span> (tid &lt; <span class="number">256</span>) &#123; sdata[tid] += sdata[tid + <span class="number">256</span>]; &#125; __syncthreads(); &#125;</span><br><span class="line">   <span class="keyword">if</span> (blockSize &gt;= <span class="number">256</span>) &#123; <span class="keyword">if</span> (tid &lt; <span class="number">128</span>) &#123; sdata[tid] += sdata[tid + <span class="number">128</span>]; &#125; __syncthreads(); &#125;</span><br><span class="line">   <span class="keyword">if</span> (blockSize &gt;= <span class="number">128</span>) &#123; <span class="keyword">if</span> (tid &lt; <span class="number">64</span>) &#123; sdata[tid] += sdata[tid + <span class="number">64</span>]; &#125; __syncthreads(); &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (tid &lt; <span class="number">32</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (blockSize &gt;= <span class="number">64</span>) sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">      <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>) sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">      <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>) sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">      <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>) sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">      <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>) sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">      <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>) sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (tid == <span class="number">0</span>) g_odata[blockIdx.x] = sdata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="关于if语句的补充"><a href="#关于if语句的补充" class="headerlink" title="关于if语句的补充"></a>关于if语句的补充</h2><p>有if语句是没问题的，只要运行的时候全部执行if或者else就行。不要有些执行if，有些执行else，这才会等待。<img src="https://pic.shaojiemike.top/img/20220515153440.png"></p>
<p>说不定也不是全部执行if或者else就行，只需要连续32个Thread Index，是相同的执行就行。（猜想，需要测试。</p>
<h2 id="关于延迟隐藏"><a href="#关于延迟隐藏" class="headerlink" title="关于延迟隐藏"></a>关于延迟隐藏</h2><p>通过增加block里的线程数，并且同时读取来隐藏延迟。 不仅可以隐藏Global Memory的延迟，还可以隐藏写后读的延迟</p>
<p><img src="https://pic.shaojiemike.top/img/20220515181043.png"></p>
<h3 id="线程资源查看"><a href="#线程资源查看" class="headerlink" title="线程资源查看"></a>线程资源查看</h3><p>线程太多会导致分配到每一个的寄存器和SMEM变少</p>
<p>通过编译时加<code>-cubin</code>选项，<code>.cubin</code>文件前几行会显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">architecture &#123;sm_10&#125;</span><br><span class="line">abiversion &#123;0&#125;</span><br><span class="line">modname &#123;cubin&#125;</span><br><span class="line">code &#123;</span><br><span class="line">   name = BlackScholesGPU</span><br><span class="line">   lmem = 0    # per thread local memory</span><br><span class="line">   smem = 68   # per thread block shared memory</span><br><span class="line">   reg = 20    # per thread registers</span><br></pre></td></tr></table></figure>


<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[^1]: <a target="_blank" rel="noopener" href="https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf">SC07 Optimizing Parallel Reduction in CUDA - Mark Harris</a></p>
<p>[^2]: <a target="_blank" rel="noopener" href="https://download.csdn.net/download/yujia269/4203734">2009 清华 邓仰东 cuda lecture pdf</a> 注意也是参考的SC07 Nvidia。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-12T01:18:42.000Z" title="5/12/2022, 1:18:42 AM">2022-05-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-03T05:41:20.008Z" title="2/3/2024, 5:41:20 AM">2024-02-03</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">3 minutes read (About 424 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/12/Work/software/perf/nvprof/">Nvprof</a></p><div class="content"><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ which nvprof </span><br><span class="line">/usr/local/cuda/bin/nvprof</span><br></pre></td></tr></table></figure>

<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="摘要模式"><a href="#摘要模式" class="headerlink" title="摘要模式"></a>摘要模式</h3><p>命令行直接运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="跟踪API"><a href="#跟踪API" class="headerlink" title="跟踪API"></a>跟踪API</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --print-gpu-trace ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="保存在log里"><a href="#保存在log里" class="headerlink" title="保存在log里"></a>保存在log里</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/nvprof --log-file a.log --metrics achieved_occupancy /staff/shaojiemike/github/cutests/22-commonstencil/common</span><br></pre></td></tr></table></figure>

<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ol>
<li>nsight可以直接在远程机器上运行<ol>
<li>ssh -X host</li>
<li>.ssh&#x2F;config<ol>
<li>add</li>
<li>XAuthLocation &#x2F;opt&#x2F;X11&#x2F;bin&#x2F;xauth #for macbookAir</li>
<li>ForwardX11Trusted yes</li>
<li>ForwardX11 yes</li>
</ol>
</li>
</ol>
</li>
<li>Visual Profiler也可以ssh直接连接远程机器</li>
<li>或者导出分析结果以便可视化, 在Visual Profiler使用</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof --export-profile timeline.prof &lt;app&gt; &lt;app args&gt;</span><br><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="profile-kernel"><a href="#profile-kernel" class="headerlink" title="profile kernel"></a>profile kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/ncu -k stencil_kernel -s 0 -c 1 /staff/shaojiemike/github/cutests/22-commonstencil/best</span><br></pre></td></tr></table></figure>

<p>ncu-ui是可视化界面，但是没弄懂</p>
<h2 id="带宽profile"><a href="#带宽profile" class="headerlink" title="带宽profile"></a>带宽profile</h2><h3 id="上限测量"><a href="#上限测量" class="headerlink" title="上限测量"></a>上限测量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:02:08]                                                                                                                                                                      $ ./bin/x86_64/linux/release/bandwidthTest                                                                                                                                                                                           [CUDA Bandwidth Test] - Starting...                                                                                                                                                                                                  Running on...                                                                                                                                                                                                                                                                                                                                                                                                                                                              Device 0: Tesla P40                                                                                                                                                                                                                  Quick Mode                                                                                                                                                                                                                                                                                                                                                                                                                                                                Host to Device Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     11.8                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Host Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     13.0                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Device Bandwidth, 1 Device(s)                                                                                                                                                                                              PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     244.3                                                                                                                                                                                                                                                                                                                                                                                                                                     Result = PASS                                                                                                                                                                                                                                                                                                                                                                                                                                                             NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.                                                                                                                                                                                       # shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:03:24]                                                                                                                                                                      $ ./bin/x86_64/linux/release/p2pBandwidthLatencyTest        </span><br></pre></td></tr></table></figure>

<h3 id="实际值"><a href="#实际值" class="headerlink" title="实际值"></a>实际值</h3><p>nvprof通过指定与dram，L1或者L2 的metrics来实现。具体解释可以参考<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">官网</a></p>
<p>在 Maxwell 和之后的架构中 L1 和 SMEM 合并</p>
<table>
<thead>
<tr>
<th>Metric Name</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>achieved_occupancy</td>
<td>活跃cycle是 Warps 活跃的比例</td>
</tr>
<tr>
<td>dram_read_throughput</td>
<td></td>
</tr>
<tr>
<td>dram_utilization</td>
<td>在0到10的范围内，相对于峰值利用率，设备内存的利用率水平</td>
</tr>
<tr>
<td>shared_load_throughput</td>
<td></td>
</tr>
<tr>
<td>shared_utilization</td>
<td></td>
</tr>
<tr>
<td>l2_utilization</td>
<td></td>
</tr>
</tbody></table>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-01-23T16:00:00.000Z" title="1/23/2022, 4:00:00 PM">2022-01-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-03T05:41:20.000Z" title="2/3/2024, 5:41:20 AM">2024-02-03</time></span><span class="level-item"><a class="link-muted" href="/categories/Overview/">Overview</a></span><span class="level-item">22 minutes read (About 3226 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/23/Work/info/Nvidia/">Nvidia</a></p><div class="content"><p>Nvidia 的系列产品的基本参数</p></div><a class="article-more button is-small is-size-7" href="/2022/01/23/Work/info/Nvidia/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-18T14:03:30.000Z" title="9/18/2021, 2:03:30 PM">2021-09-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-03T05:41:19.984Z" title="2/3/2024, 5:41:19 AM">2024-02-03</time></span><span class="level-item"><a class="link-muted" href="/categories/Overview/">Overview</a></span><span class="level-item">2 minutes read (About 295 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/18/Work/Architecture/GPU/GPU/">GPU</a></p><div class="content"><p>这篇聚焦于 GPU 发展的起源，目的和历史。（看历史真好玩）</p></div><a class="article-more button is-small is-size-7" href="/2021/09/18/Work/Architecture/GPU/GPU/#more">Read more</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">388</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">487</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">39</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Thinking/"><span class="level-start"><span class="level-item">Thinking</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">51</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-29T12:58:53.000Z">2024-01-29</time></p><p class="title"><a href="/2024/01/29/OutOfWork/5-VideoEntertainment/AnimeAutoChineseSubtitle/">Anime Auto add Chinese Subtitle</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-25T03:20:42.000Z">2024-01-25</time></p><p class="title"><a href="/2024/01/25/OutOfWork/5-VideoEntertainment/AnimeSuperResolutionFrame/">Anime Super Resolution to 4K &amp; Interpolation to 120 fps</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-13T14:32:40.000Z">2024-01-13</time></p><p class="title"><a href="/2024/01/13/Thinking/2-courage2move/SocialScience/">Social Science</a></p><p class="categories"><a href="/categories/Thinking/">Thinking</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-13T12:15:22.000Z">2024-01-13</time></p><p class="title"><a href="/2024/01/13/Work/Architecture/FPGA/">FPGA</a></p><p class="categories"><a href="/categories/toLearn/">toLearn</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-13T08:02:52.000Z">2024-01-13</time></p><p class="title"><a href="/2024/01/13/Work/Architecture/workloadPriority/">Workload Characterization &amp; Priority &amp; Scheduler to CPU/GPU/PIM</a></p><p class="categories"><a href="/categories/Architecture/">Architecture</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">235</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2024 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>