<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: Nvidia - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Nvidia</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-11T16:00:00.000Z" title="5/11/2023, 4:00:00 PM">2023-05-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T10:53:14.799Z" title="12/20/2023, 10:53:14 AM">2023-12-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">14 minutes read (About 2170 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/11/Work/software/perf/nvidiaNsight/">Nvidia Nsight</a></p><div class="content"><h2 id="Nsight-system-compute-Graph-的关系"><a href="#Nsight-system-compute-Graph-的关系" class="headerlink" title="Nsight system compute &amp; Graph 的关系"></a>Nsight system compute &amp; Graph 的关系</h2><p><img src="https://pic.shaojiemike.top/img/20220513195618.png"></p>
<h3 id="Nsight-Systems"><a href="#Nsight-Systems" class="headerlink" title="Nsight Systems"></a>Nsight Systems</h3><p>All developers should start with Nsight Systems to identify the largest optimization opportunities. Nsight Systems provides developers a <strong>system-wide visualization</strong> of an applications performance. Developers can optimize <strong>bottlenecks</strong> to scale efficiently across any number or size of CPUs and GPUs; from large servers to our smallest SoC. For <strong>further optimizations to compute kernels developers should use Nsight Compute</strong> or to further optimize a graphics workloads, use Nsight Graphics.</p>
<h3 id="Nsight-Compute"><a href="#Nsight-Compute" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h3><p>Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool. Nsight Compute also provides customizable and data-driven user interface and metric collection that can be extended with analysis scripts for post-processing results.</p>
<h3 id="Nsight-Graphics"><a href="#Nsight-Graphics" class="headerlink" title="Nsight Graphics"></a>Nsight Graphics</h3><p>Nsight Graphics is a standalone application for the debugging, profiling, and analysis of <strong>graphics applications</strong> on Microsoft Windows and Linux. It allows you to optimize the performance of your Direct3D 11, Direct3D 12, DirectX Raytracing 1.1, <strong>OpenGL</strong>, Vulkan, and KHR Vulkan <strong>Ray Tracing</strong> Extension based applications.</p>
<h2 id="Install-Nsight-local"><a href="#Install-Nsight-local" class="headerlink" title="Install Nsight local"></a>Install Nsight local</h2><ol>
<li>check the perf config To collect thread scheduling data and IP (instruction pointer) samples<ol>
<li><code>cat /proc/sys/kernel/perf_event_paranoid</code></li>
<li>如果大于2，临时改变 <code>sudo sh -c &#39;echo 2 &gt;/proc/sys/kernel/perf_event_paranoid&#39;</code>重启会重置</li>
<li>永久修改 <code>sudo sh -c &#39;echo kernel.perf_event_paranoid=2 &gt; /etc/sysctl.d/local.conf&#39;</code></li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/gameworksdownload#?dn=nsight-systems-2022-2">下载Nsight</a><ol>
<li>但是单独下载要会员</li>
<li>下载cuda toolkit,有集成</li>
</ol>
</li>
</ol>
<h2 id="Nsight-System"><a href="#Nsight-System" class="headerlink" title="Nsight System"></a>Nsight System</h2><p>运行 <code>nsight-sys</code></p>
<h3 id="使用基本说明"><a href="#使用基本说明" class="headerlink" title="使用基本说明"></a>使用基本说明</h3><p>勾选了CUDA-trace等选项<br><img src="https://pic.shaojiemike.top/img/20220521143324.png"></p>
<p>可以从整体上看资源的使用情况，</p>
<p>将鼠标放在上面会有<strong>具体</strong>的数值或者名称的解释</p>
<p><img src="https://pic.shaojiemike.top/img/20220521143753.png"><br><img src="https://pic.shaojiemike.top/img/20220521144435.png"></p>
<p>比较有用的是能看出 PCIE, GPU DRAM Bandwidth, Warp的使用情况。</p>
<p>由于没有根据kernel function区分，很难读。为此提供了NVTX来给代码打标签</p>
<h3 id="The-NVIDIA-Tools-Extension-Library-NVTX-使用"><a href="#The-NVIDIA-Tools-Extension-Library-NVTX-使用" class="headerlink" title="The NVIDIA Tools Extension Library (NVTX)使用"></a>The NVIDIA Tools Extension Library (NVTX)使用</h3><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-visual-studio-edition/2020.1/nvtx/index.html">https://docs.nvidia.com/nsight-visual-studio-edition/2020.1/nvtx/index.html</a><br>头文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;nvToolsExt.h&gt;</span><br></pre></td></tr></table></figure>

<p>需要标记代码前后加入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvtxRangePush(&quot;checkResult&quot;); //nvtxRangePushA,nvtxRangePushW,nvtxRangePushEx 好像都差不多</span><br><span class="line">checkResult&lt;&lt;&lt;dim3(row_num / TPBX, col_num / TPBY, 1), dim3(TPBX, TPBY, 1)&gt;&gt;&gt;(row_num, col_num, result);</span><br><span class="line">cudaDeviceSynchronize(); </span><br><span class="line">nvtxRangePop();</span><br></pre></td></tr></table></figure>

<p>注意NVTX是作用在<strong>CPU线程</strong>上的，无法在GPU里用。</p>
<p>注意需要 <code>g++ -o testnv -I/usr/local/cuda/include -L/usr/local/cuda/lib64 -lnvToolsExt testnv.cpp</code>。或者修改cmake来实现同样的效果</p>
<h3 id="NVTX问题"><a href="#NVTX问题" class="headerlink" title="NVTX问题"></a>NVTX问题</h3><p><img src="https://pic.shaojiemike.top/img/20220521153540.png"></p>
<p>怎么不在同一竖直方向上？GPU还先跑是什么情况</p>
<h2 id="Nsight-Compute-1"><a href="#Nsight-Compute-1" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h2><p>Nsight Systems 就是nvprof的继任者，NVIDIA最新的用于监测 kernel timeline的工具。NVIDIA 计算能力7.5及以上的GPU设备不再支持nvprof工具进行性能剖析，提示使用Nsight Compute作为替代品.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ncu # 命令行</span><br><span class="line">ncu-ui</span><br></pre></td></tr></table></figure>

<h3 id="使用Nsight-Compute-CLI-nv-nsight-cu-cli-ncu-输出数据"><a href="#使用Nsight-Compute-CLI-nv-nsight-cu-cli-ncu-输出数据" class="headerlink" title="使用Nsight Compute CLI (nv-nsight-cu-cli &#x2F; ncu) 输出数据"></a>使用Nsight Compute CLI (nv-nsight-cu-cli &#x2F; ncu) 输出数据</h3><p><code>nv-nsight-cu-cli -&gt; ncu</code><br>下面是一个使用样例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/NVIDIA-Nsight-Compute/nv-nsight-cu-cli -o mnist -f --csv --profile-from-start off /usr/bin/python3 mnist.py</span><br></pre></td></tr></table></figure>

<p>其中-o是为了输出.nsight-cuprof-report文件用于后续的可视化查看，-f为强制覆盖原有文件，–csv可是在console输出除 timeline 以外数据的时候以逗号分隔数据，方便拷贝至csv文件， –profile-from-start的使用方法和Nsight System以及nvprof一样。其余flag信息可见<a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html</a> 。</p>
<p>上面的例子会生成mnist.nsight-cuprof-report文件。</p>
<p>注意</p>
<p>最前面的可执行文件需要绝对路径，如上面的python3需要使用 &#x2F;usr&#x2F;bin&#x2F;python3。<br>生成过程中可能会产生很大的临时文件（几十G）。如果本次磁盘空间不够，可以设置如下环境变量来调整存储临时文件的地址。没有找到能直接使用 Nsight Compute 修改临时文件地址的方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export /TMPDIR=/path/for/tmp</span><br></pre></td></tr></table></figure>

<h3 id="ncu与nvprof命令行抓取参数的映射表"><a href="#ncu与nvprof命令行抓取参数的映射表" class="headerlink" title="ncu与nvprof命令行抓取参数的映射表"></a>ncu与nvprof命令行抓取参数的映射表</h3><p><a target="_blank" rel="noopener" href="https://www.freesion.com/article/34871449930/">https://www.freesion.com/article/34871449930/</a></p>
<h3 id="ncu-ui教程"><a href="#ncu-ui教程" class="headerlink" title="ncu-ui教程"></a>ncu-ui教程</h3><p>为了显示原代码makefile添加 <code>-g -G</code>选项<br>对应CmakeList.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">target_compile_options(better PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:--extended-lambda</span><br><span class="line">    -G -src-in-ptx</span><br><span class="line">    &gt;)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yan31415/article/details/109491749">https://blog.csdn.net/yan31415/article/details/109491749</a></p>
<h3 id="ncu-ui表格-图"><a href="#ncu-ui表格-图" class="headerlink" title="ncu-ui表格&amp;图"></a>ncu-ui表格&amp;图</h3><p><img src="https://pic.shaojiemike.top/img/20220521160243.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220521161200.png"><br>我不明白我的SMEM怎么不是从DRAM来的， 而且峰值怎么这么低？</p>
<p>这个错误也是令人迷惑<br>The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 3.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.</p>
<p><img src="https://pic.shaojiemike.top/img/20220521163326.png"></p>
<p>不知道为什么有1%和2% 的bank conflict</p>
<p>可以看到 SMEM， Register，Block Size是怎么影响GPU Warp的分配调度的。<br><img src="https://pic.shaojiemike.top/img/20220521163505.png"><br>上图没有拖累，吃满了64个warp。</p>
<p>关于if语句<br><img src="https://pic.shaojiemike.top/img/20220521163918.png"><br>if语句只要warp里执行相同就行。</p>
<p>可以提示出不连续访问的地方。(这里是这样设计的，已经避免了绝大部分的不连续访问)<br><img src="https://pic.shaojiemike.top/img/20220521164456.png"></p>
<p>显示stall最多的指令是什么以及在等待什么。还有执行最多的指令<br><img src="https://pic.shaojiemike.top/img/20220521164627.png"></p>
<p>假如 file mismatched 手动选择文件就行<br><img src="https://pic.shaojiemike.top/img/20220521165836.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220521170004.png"></p>
<p>stall的信息，感觉就这些有点用。(其中sb是scoreboard的意思)</p>
<h2 id="ncu-ui-分析汇编"><a href="#ncu-ui-分析汇编" class="headerlink" title="ncu-ui 分析汇编"></a>ncu-ui 分析汇编</h2><h3 id="PTX-SASS汇编说明"><a href="#PTX-SASS汇编说明" class="headerlink" title="PTX&amp;SASS汇编说明"></a>PTX&amp;SASS汇编说明</h3><p>有两种汇编</p>
<p>请看PTX SASS一文</p>
<h3 id="基本说明"><a href="#基本说明" class="headerlink" title="基本说明"></a>基本说明</h3><p><img src="https://pic.shaojiemike.top/img/20220522095802.png"></p>
<p>可以通过指令执行数或者采样率来得知，执行最多的指令。</p>
<p>鼠标悬停可以知道具体命令的含义</p>
<h3 id="Ex1-for循环头"><a href="#Ex1-for循环头" class="headerlink" title="Ex1: for循环头"></a>Ex1: for循环头</h3><p><img src="https://pic.shaojiemike.top/img/20220522101042.png"></p>
<h3 id="Ex2-for-loop-kernel"><a href="#Ex2-for-loop-kernel" class="headerlink" title="Ex2: for-loop kernel"></a>Ex2: for-loop kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sdata[Regular_local_index]=arr_data[Regular_global_index];</span><br></pre></td></tr></table></figure>

<p>该从DRAM里读取到SMEM的指令对应的PTX和SASS代码<br><img src="https://pic.shaojiemike.top/img/20220522105005.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cvt.f32.u16 d, a;   // convert 16-bit unsigned to 32-bit float</span><br></pre></td></tr></table></figure>

<h3 id="问题：无效self-mov？"><a href="#问题：无效self-mov？" class="headerlink" title="问题：无效self-mov？"></a>问题：无效self-mov？</h3><p><img src="https://pic.shaojiemike.top/img/20220522101410.png"></p>
<p>为了隐藏延迟？</p>
<p>直接原因是PTX翻译成SASS。一条mov变多条了</p>
<p><img src="https://pic.shaojiemike.top/img/20220522103503.png"></p>
<h2 id="CUDA-Visual-Profiler"><a href="#CUDA-Visual-Profiler" class="headerlink" title="CUDA Visual Profiler"></a>CUDA Visual Profiler</h2><p>老一代debugger工具，逐渐被Nsight淘汰</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof # 命令行,nsys 之前的名称叫做 nvprof</span><br><span class="line">nvvp</span><br></pre></td></tr></table></figure>

<p>在more里有建议</p>
<h3 id="nvprof捕获信息存储"><a href="#nvprof捕获信息存储" class="headerlink" title="nvprof捕获信息存储"></a>nvprof捕获信息存储</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./nbody --benchmark -numdevices=2 -i=1</span><br><span class="line"># 下面输出 .qdrep 文件</span><br><span class="line">nsys profile --stats=true --force-overwrite=true  -o baseline-report ./single-thread-vector-add</span><br></pre></td></tr></table></figure>

<h2 id="CUDA-Visual-Profiler-问题"><a href="#CUDA-Visual-Profiler-问题" class="headerlink" title="CUDA Visual Profiler 问题"></a>CUDA Visual Profiler 问题</h2><p>&#x3D;&#x3D;7196&#x3D;&#x3D; Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.<br>解决方法在程序末尾加cudaDeviceReset()或者cudaProfilerStop()</p>
<h2 id="Nsight-Compute-问题"><a href="#Nsight-Compute-问题" class="headerlink" title="Nsight Compute 问题"></a>Nsight Compute 问题</h2><h3 id="OpenGL-没有安装"><a href="#OpenGL-没有安装" class="headerlink" title="OpenGL 没有安装"></a>OpenGL 没有安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Warning: Failed to get OpenGL version. OpenGL version 2.0 or higher is required.</span><br><span class="line">OpenGL version is too low (0). Falling back to Mesa software rendering.</span><br><span class="line">qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.</span><br><span class="line">This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.</span><br><span class="line"></span><br><span class="line">Available platform plugins are: offscreen, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, xcb.</span><br></pre></td></tr></table></figure>

<p>解决办法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libxcb-xinerama0</span><br><span class="line">sudo apt install libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0</span><br></pre></td></tr></table></figure>

<h3 id="Qt插件缺失"><a href="#Qt插件缺失" class="headerlink" title="Qt插件缺失"></a>Qt插件缺失</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.</span><br><span class="line">This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.</span><br><span class="line"></span><br><span class="line">Available platform plugins are: xcb.</span><br><span class="line"></span><br><span class="line">Application could not be initialized!</span><br><span class="line">    This is likely due to missing Qt platform dependencies.</span><br><span class="line">    For a list of dependencies, please refer to https://doc.qt.io/qt-5/linux-requirements.html</span><br><span class="line">    To view missing libraries, set QT_DEBUG_PLUGINS=1 and re-run the application.</span><br></pre></td></tr></table></figure>

<p>按照说明 <code>export QT_DEBUG_PLUGINS=1</code>再次运行, 显示具体问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot load library /staff/shaojiemike/Install/cuda_11.7.0_515.43.04_linux/nsight-compute-2022.2.0/host/linux-desktop-glibc_2_11_3-x64/Plugins/platforms/libqxcb.so: (libxcb-xinput.so.0: cannot open shared object file: No such file or directory)</span><br></pre></td></tr></table></figure>

<p>解决 <code>sudo apt-get install libxcb-xinput0</code></p>
<h3 id="kernel没权限profile"><a href="#kernel没权限profile" class="headerlink" title="kernel没权限profile"></a>kernel没权限profile</h3><p>mobaXterm打开，每个核函数都会出现ERR_NVGPUCTRPERM - The user does not have permission to profile on the target device这个错误</p>
<ol>
<li>说要用sudo，或者最新的NV</li>
</ol>
<h3 id="sudo-ncu-ui-不能远程打开"><a href="#sudo-ncu-ui-不能远程打开" class="headerlink" title="sudo ncu-ui 不能远程打开"></a>sudo ncu-ui 不能远程打开</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ncu-ui</span><br><span class="line">MobaXterm X11 proxy: Authorisation not recognised</span><br><span class="line">qt.qpa.xcb: could not connect to display localhost:10.0</span><br></pre></td></tr></table></figure>

<p>解决办法(原因是sudo相当于切换到root用户，丢失了xauth信息)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ xauth list</span><br><span class="line">snode0/unix:12  MIT-MAGIC-COOKIE-1  84941f1f8be97d19436356685f75b884</span><br><span class="line">snode0/unix:13  MIT-MAGIC-COOKIE-1  5172ee2c7364b055cd37538b460f7741</span><br><span class="line">snode0/unix:11  MIT-MAGIC-COOKIE-1  589f3b5ab852f24ca3710c53e6439260</span><br><span class="line">hades1/unix:10  MIT-MAGIC-COOKIE-1  9346adec202bd65250f3d21239025750</span><br><span class="line">snode0/unix:10  MIT-MAGIC-COOKIE-1  52285c563f1688741fa1b434ed2b7b2c</span><br><span class="line"></span><br><span class="line">sudo -s # 切换</span><br><span class="line">xauth add snode0/unix:10  MIT-MAGIC-COOKIE-1  52285c563f1688741fa1b434ed2b7b2c # 补全xauth</span><br><span class="line"># 正常执行 xauth有用的总是最后一个</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220606170556.png"></p>
<h3 id="Error-0-UnsupportedGpu"><a href="#Error-0-UnsupportedGpu" class="headerlink" title="Error 0: UnsupportedGpu"></a>Error 0: UnsupportedGpu</h3><p>原因是 <a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/nsight-unsupported-gpu/163617">软件对GPU的支持是逐步</a>的需要安装最新的。</p>
<p>不支持的Nsight的可以尝试老的debugger工具 CUDA Visual Profiler</p>
<h3 id="Error-Profiling-is-not-supported-on-this-device"><a href="#Error-Profiling-is-not-supported-on-this-device" class="headerlink" title="Error: Profiling is not supported on this device"></a>Error: Profiling is not supported on this device</h3><p>Pascal support was deprecated, then dropped from Nsight Compute after Nsight Compute 2019.5.1.</p>
<p>The profiling tools that support Pascal in the CUDA Toolkit 11.1 and later are <code>nvprof</code> and <code>visual profiler</code>.</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>NVTX问题</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/tools-overview">https://developer.nvidia.com/tools-overview</a></p>
<p><a target="_blank" rel="noopener" href="https://www.365seal.com/y/zyn1yxJQn3.html">https://www.365seal.com/y/zyn1yxJQn3.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-14T16:00:00.000Z" title="5/14/2022, 4:00:00 PM">2022-05-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T10:53:14.783Z" title="12/20/2023, 10:53:14 AM">2023-12-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">14 minutes read (About 2081 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/14/Work/HPC/cuda/nvidiaOptimize/">Nvidia Optimize</a></p><div class="content"><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ol>
<li>General optimization guidance<ol>
<li>Coalescing memory operations</li>
<li>Occupancy and latency hiding</li>
<li>Using shared memory</li>
</ol>
</li>
<li>Example 1: transpose<ol>
<li>Coalescing and bank conflict avoidance</li>
</ol>
</li>
<li>Example 2: efficient parallel reductions<ol>
<li>Using peak performance metrics to guide optimization</li>
<li>Avoiding SIMD divergence &amp; bank conflicts</li>
<li>Loop unrolling</li>
<li>Using template parameters to write general-yet-optimized code</li>
<li>Algorithmic strategy: Cost efficiency</li>
</ol>
</li>
</ol>
<h2 id="专业术语-terminology"><a href="#专业术语-terminology" class="headerlink" title="专业术语 terminology"></a>专业术语 terminology</h2><ol>
<li>Thread : 并行的基本单位<ol>
<li>但是创建和切换的成本比CPU小多了</li>
</ol>
</li>
<li>Warp: 一堆能硬件物理支持并行的线程(SIMD)</li>
<li>Thread Block: 在一个SM(multiprocessor) 里共享shared memory的一堆线程</li>
</ol>
<h2 id="CUDA-优化策略"><a href="#CUDA-优化策略" class="headerlink" title="CUDA 优化策略"></a>CUDA 优化策略</h2><h3 id="GPU的优化算法"><a href="#GPU的优化算法" class="headerlink" title="GPU的优化算法"></a>GPU的优化算法</h3><ol>
<li>最大化并行独立性</li>
<li>最大化计算密度</li>
<li>减少数据传输<ol>
<li>数据可以直接在GPU生成。</li>
<li>一次大传输也比分开的小批次快</li>
</ol>
</li>
</ol>
<h3 id="访存连续性"><a href="#访存连续性" class="headerlink" title="访存连续性"></a>访存连续性</h3><ol>
<li>对齐(Starting address for a region must be a multiple of region size)集体访问，有数量级的差异Coalesced</li>
<li><strong>Optimize for spatial locality in cached texture memory</strong> ???</li>
<li>避免bank conflict</li>
</ol>
<h3 id="利用好Shared-Memory"><a href="#利用好Shared-Memory" class="headerlink" title="利用好Shared Memory"></a>利用好Shared Memory</h3><ol>
<li>比globalMemory快百倍</li>
<li>可以来避免 non-Coalesced access</li>
<li>SM的线程可以共享</li>
<li><strong>Use one &#x2F; a few threads to load &#x2F; compute data shared by all threads</strong></li>
</ol>
<h3 id="占用率高不一定是好事"><a href="#占用率高不一定是好事" class="headerlink" title="占用率高不一定是好事"></a>占用率高不一定是好事</h3><p>占用率是指每个多处理器（Streaming Multiprocessor，SM）的实际的活动warps数量与最大理论的warps数量的比率。<br>高的占用率不一定能提升性能，因为这一般意味着每个线程分配的寄存器和shared memory变少。但低的占用率会导致内存延迟无法隐藏。</p>
<p>实际需要计算每个线程大概需要的shared memory和register数量</p>
<h4 id="实际例子测试-待研究"><a href="#实际例子测试-待研究" class="headerlink" title="实际例子测试-待研究"></a>实际例子测试-待研究</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4541313.html">https://www.cnblogs.com/1024incn/p/4541313.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4545265.html">https://www.cnblogs.com/1024incn/p/4545265.html</a></p>
<h2 id="优化实例1-矩阵转置"><a href="#优化实例1-矩阵转置" class="headerlink" title="优化实例1 - 矩阵转置"></a>优化实例1 - 矩阵转置</h2><p>通过SMEM实现coalescing access</p>
<p>原本代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">_global__ void transpose_naive(float *odata, float *idata, int width, int height)</span><br><span class="line">&#123;</span><br><span class="line">   unsigned int xIndex = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">   unsigned int yIndex = blockDim.y * blockIdx.y + threadIdx.y;</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      unsigned int index_in = xIndex + width * yIndex;</span><br><span class="line">      unsigned int index_out = yIndex + height * xIndex;</span><br><span class="line">      odata[index_out] = idata[index_in]; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思想：将大矩阵划分成方块，并且存储在SMEM里。不仅SMEM速度更快，而且每行元素个数变少，跨行访问的间距变小，局部性增强。而且对于大矩阵加速效果会更明显。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void transpose(float *odata, float *idata, int width, int height)</span><br><span class="line">&#123;</span><br><span class="line">   __shared__ float block[BLOCK_DIM*BLOCK_DIM];</span><br><span class="line">   unsigned int xBlock = blockDim.x * blockIdx.x;</span><br><span class="line">   unsigned int yBlock = blockDim.y * blockIdx.y;</span><br><span class="line">   unsigned int xIndex = xBlock + threadIdx.x;</span><br><span class="line">   unsigned int yIndex = yBlock + threadIdx.y;</span><br><span class="line">   unsigned int index_out, index_transpose;</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      unsigned int index_in = width * yIndex + xIndex;</span><br><span class="line">      unsigned int index_block = threadIdx.y * BLOCK_DIM + threadIdx.x;</span><br><span class="line">      block[index_block] = idata[index_in];</span><br><span class="line">      index_transpose = threadIdx.x * BLOCK_DIM + threadIdx.y;</span><br><span class="line">      index_out = height * (xBlock + threadIdx.y) + yBlock + threadIdx.x;</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">      odata[index_out] = block[index_transpose]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="coalescing-access"><a href="#coalescing-access" class="headerlink" title="coalescing access"></a>coalescing access</h3><p>when Block&#x2F;tile dimensions are multiples of 16 ???</p>
<h3 id="关于bank-conflict"><a href="#关于bank-conflict" class="headerlink" title="关于bank conflict"></a>关于bank conflict</h3><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/">https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/</a></p>
<p>对于一个32 × 32个元素的共享内存块，一列数据中的所有元素都映射到相同的SMEM bank ，导致bank conflict 的最坏情况:读取一列数据会导致32路的存储库冲突。</p>
<p>幸运的是，只需要将tile的元素宽度改为33，而不是32就行。</p>
<h2 id="优化实例2-数据归约"><a href="#优化实例2-数据归约" class="headerlink" title="优化实例2 - 数据归约"></a>优化实例2 - 数据归约</h2><p>具体问题：将长数组的所有元素，归约求和为一个结果</p>
<h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3><p>为了避免全局同步的巨大开销，采取分级归约<br><img src="https://pic.shaojiemike.top/img/20220515105630.png"></p>
<p>由于归约的计算密度低<br>1 flop per element loaded (bandwidth-optimal)</p>
<p>所以优化目标是将访存带宽用满。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">384-bit memory interface, 900 MHz DDR</span><br><span class="line">384 * 1800 / 8 = 86.4 GB/s</span><br></pre></td></tr></table></figure>

<h3 id="step0-baseline-Interleaved-Addressing-交错-间隔寻址"><a href="#step0-baseline-Interleaved-Addressing-交错-间隔寻址" class="headerlink" title="step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址"></a>step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce0(int *g_idata, int *g_odata) &#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   // each thread loads one element from global to shared mem</span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">   sdata[tid] = g_idata[i];</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   // do reduction in shared mem</span><br><span class="line">   for(unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">      if (tid % (s) == 0) &#123;</span><br><span class="line">         sdata[tid] += sdata[tid + s];</span><br><span class="line">      &#125;</span><br><span class="line">      __syncthreads();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   // write result for this block to global mem</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515150953.png"><br>工作的线程越来越少。一开始是全部，最后一次只有thread0.</p>
<h3 id="Step1-使用连续的index"><a href="#Step1-使用连续的index" class="headerlink" title="Step1 : 使用连续的index"></a>Step1 : 使用连续的index</h3><p>Just replace divergent branch With strided index and non-divergent branch，但是会带来bank conflict。</p>
<p>原理和Warp发射有关，假如在这里每个Warp并行的线程是2。一个Warp运行耗时为T.</p>
<p>Step0: 4+4+2+1&#x3D;11T</p>
<p>Step1: 4+2+1+1&#x3D;8T</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">   int index = 2 * s * tid;</span><br><span class="line">   if (index &lt; blockDim.x) &#123;</span><br><span class="line">      sdata[index] += sdata[index + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515144525.png"><br><img src="https://pic.shaojiemike.top/img/20220515151516.png"></p>
<h3 id="Step2-连续寻址"><a href="#Step2-连续寻址" class="headerlink" title="Step2: 连续寻址"></a>Step2: 连续寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=blockDim.x/2; s&gt;0; s&gt;&gt;=1) &#123;</span><br><span class="line">   if (tid &lt; s) &#123;</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原本寻址<img src="https://pic.shaojiemike.top/img/20220515151840.png"></p>
<p>现在寻址有一边连续了<br><img src="https://pic.shaojiemike.top/img/20220515151937.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220515152034.png"></p>
<h3 id="Step3-弥补浪费的线程"><a href="#Step3-弥补浪费的线程" class="headerlink" title="Step3 : 弥补浪费的线程"></a>Step3 : 弥补浪费的线程</h3><p>方法： 在load SMEM的时候提前做一次规约加法，通过减少一半的block数，将原本两个block里的值load+add存储在sum里。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// perform first level of reduction,</span><br><span class="line">// reading from global memory, writing to shared memory</span><br><span class="line">unsigned int tid = threadIdx.x;</span><br><span class="line">unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;</span><br><span class="line">sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515152704.png"></p>
<h3 id="step4-Unrolling-the-Last-Warp"><a href="#step4-Unrolling-the-Last-Warp" class="headerlink" title="step4 : Unrolling the Last Warp"></a>step4 : Unrolling the Last Warp</h3><p>当s&lt; 32的时候，就只有一个Warp工作了。</p>
<p>使用warp的SIMD还省去了<code>__syncthreads()</code>的麻烦</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=blockDim.x/2; s&gt;32; s&gt;&gt;=1) </span><br><span class="line">&#123;</span><br><span class="line">   if (tid &lt; s)</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line">if (tid &lt; 32)</span><br><span class="line">&#123;</span><br><span class="line">   sdata[tid] += sdata[tid + 32]; </span><br><span class="line">   sdata[tid] += sdata[tid + 16]; </span><br><span class="line">   sdata[tid] += sdata[tid + 8]; </span><br><span class="line">   sdata[tid] += sdata[tid + 4]; </span><br><span class="line">   sdata[tid] += sdata[tid + 2]; </span><br><span class="line">   sdata[tid] += sdata[tid + 1]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了保持整洁，最后一个if还做了无效的计算。eg, Warp里的最后一个线程只有第一句命令有用。<br><img src="https://pic.shaojiemike.top/img/20220515162352.png"></p>
<h3 id="Step5-根据blockSize完全展开for和去除代码"><a href="#Step5-根据blockSize完全展开for和去除代码" class="headerlink" title="Step5 : 根据blockSize完全展开for和去除代码"></a>Step5 : 根据blockSize完全展开for和去除代码</h3><p>由于for循环里是二分的，而且小于32的单独处理了，导致for循环里实际运行代码最多就3句。</p>
<p>利用代码模板和编译器的自动优化实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce5(int *g_idata, int *g_odata)</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515163110.png"></p>
<p>红色代码会在编译时自动优化。<br><img src="https://pic.shaojiemike.top/img/20220515163243.png"></p>
<h3 id="step6-：归并算法优化"><a href="#step6-：归并算法优化" class="headerlink" title="step6 ：归并算法优化"></a>step6 ：归并算法优化</h3><p>加速级联？？</p>
<p>Cost&#x3D; processors × time complexity</p>
<p>我们知道N个元素直接二叉树归约是O(log N)<br>时间 Cost&#x3D;N*O(log N).</p>
<p>但是假如只有P个线程先做N&#x2F;P的串行加法, 然后是log(P)的归约。<br>总cost&#x3D;P(N&#x2F;P+log(P))</p>
<p>当P&#x3D;N&#x2F;log(N), cost&#x3D;O(N)</p>
<p>each thread should sum O(log n) elements来设置</p>
<p>比如，1024 or 2048 elements per block vs. 256 线程。每个sum n&#x3D;4个元素。 具体参数要perf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">unsigned int tid = threadIdx.x;</span><br><span class="line">unsigned int i = blockIdx.x*(blockSize*2) + threadIdx.x;</span><br><span class="line">unsigned int gridSize = blockSize*2*gridDim.x;</span><br><span class="line">sdata[tid] = 0;</span><br><span class="line">while (i &lt; n) &#123;</span><br><span class="line">   sdata[tid] += g_idata[i] + g_idata[i+blockSize];</span><br><span class="line">   i += gridSize;</span><br><span class="line">&#125;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515171758.png"></p>
<h3 id="final-code"><a href="#final-code" class="headerlink" title="final code"></a>final code</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce6(int *g_idata, int *g_odata, unsigned int n)</span><br><span class="line">&#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*(blockSize*2) + tid;</span><br><span class="line">   unsigned int gridSize = blockSize*2*gridDim.x;</span><br><span class="line">   sdata[tid] = 0;</span><br><span class="line"></span><br><span class="line">   do &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; while (i &lt; n);</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   if (blockSize &gt;= 512) &#123; if (tid &lt; 256) &#123; sdata[tid] += sdata[tid + 256]; &#125; __syncthreads(); &#125;</span><br><span class="line">   if (blockSize &gt;= 256) &#123; if (tid &lt; 128) &#123; sdata[tid] += sdata[tid + 128]; &#125; __syncthreads(); &#125;</span><br><span class="line">   if (blockSize &gt;= 128) &#123; if (tid &lt; 64) &#123; sdata[tid] += sdata[tid + 64]; &#125; __syncthreads(); &#125;</span><br><span class="line"></span><br><span class="line">   if (tid &lt; 32) &#123;</span><br><span class="line">      if (blockSize &gt;= 64) sdata[tid] += sdata[tid + 32];</span><br><span class="line">      if (blockSize &gt;= 32) sdata[tid] += sdata[tid + 16];</span><br><span class="line">      if (blockSize &gt;= 16) sdata[tid] += sdata[tid + 8];</span><br><span class="line">      if (blockSize &gt;= 8) sdata[tid] += sdata[tid + 4];</span><br><span class="line">      if (blockSize &gt;= 4) sdata[tid] += sdata[tid + 2];</span><br><span class="line">      if (blockSize &gt;= 2) sdata[tid] += sdata[tid + 1];</span><br><span class="line">   &#125;</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="关于if语句的补充"><a href="#关于if语句的补充" class="headerlink" title="关于if语句的补充"></a>关于if语句的补充</h2><p>有if语句是没问题的，只要运行的时候全部执行if或者else就行。不要有些执行if，有些执行else，这才会等待。<img src="https://pic.shaojiemike.top/img/20220515153440.png"></p>
<p>说不定也不是全部执行if或者else就行，只需要连续32个Thread Index，是相同的执行就行。（猜想，需要测试。</p>
<h2 id="关于延迟隐藏"><a href="#关于延迟隐藏" class="headerlink" title="关于延迟隐藏"></a>关于延迟隐藏</h2><p>通过增加block里的线程数，并且同时读取来隐藏延迟。 不仅可以隐藏Global Memory的延迟，还可以隐藏写后读的延迟</p>
<p><img src="https://pic.shaojiemike.top/img/20220515181043.png"></p>
<h3 id="线程资源查看"><a href="#线程资源查看" class="headerlink" title="线程资源查看"></a>线程资源查看</h3><p>线程太多会导致分配到每一个的寄存器和SMEM变少</p>
<p>通过编译时加<code>-cubin</code>选项，<code>.cubin</code>文件前几行会显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">architecture &#123;sm_10&#125;</span><br><span class="line">abiversion &#123;0&#125;</span><br><span class="line">modname &#123;cubin&#125;</span><br><span class="line">code &#123;</span><br><span class="line">   name = BlackScholesGPU</span><br><span class="line">   lmem = 0    # per thread local memory</span><br><span class="line">   smem = 68   # per thread block shared memory</span><br><span class="line">   reg = 20    # per thread registers</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf">https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf</a></p>
<p>类似的cuda优化资料有09年的， 清华 邓仰东 cuda lecture pdf <a target="_blank" rel="noopener" href="https://download.csdn.net/download/yujia269/4203734%E3%80%82">https://download.csdn.net/download/yujia269/4203734。</a> 注意也是参考的上面Nvidia的这个。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-12T01:18:42.000Z" title="5/12/2022, 1:18:42 AM">2022-05-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T10:53:14.799Z" title="12/20/2023, 10:53:14 AM">2023-12-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">3 minutes read (About 424 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/12/Work/software/perf/nvprof/">Nvprof</a></p><div class="content"><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ which nvprof </span><br><span class="line">/usr/local/cuda/bin/nvprof</span><br></pre></td></tr></table></figure>

<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="摘要模式"><a href="#摘要模式" class="headerlink" title="摘要模式"></a>摘要模式</h3><p>命令行直接运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="跟踪API"><a href="#跟踪API" class="headerlink" title="跟踪API"></a>跟踪API</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --print-gpu-trace ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="保存在log里"><a href="#保存在log里" class="headerlink" title="保存在log里"></a>保存在log里</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/nvprof --log-file a.log --metrics achieved_occupancy /staff/shaojiemike/github/cutests/22-commonstencil/common</span><br></pre></td></tr></table></figure>

<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ol>
<li>nsight可以直接在远程机器上运行<ol>
<li>ssh -X host</li>
<li>.ssh&#x2F;config<ol>
<li>add</li>
<li>XAuthLocation &#x2F;opt&#x2F;X11&#x2F;bin&#x2F;xauth #for macbookAir</li>
<li>ForwardX11Trusted yes</li>
<li>ForwardX11 yes</li>
</ol>
</li>
</ol>
</li>
<li>Visual Profiler也可以ssh直接连接远程机器</li>
<li>或者导出分析结果以便可视化, 在Visual Profiler使用</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof --export-profile timeline.prof &lt;app&gt; &lt;app args&gt;</span><br><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="profile-kernel"><a href="#profile-kernel" class="headerlink" title="profile kernel"></a>profile kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/ncu -k stencil_kernel -s 0 -c 1 /staff/shaojiemike/github/cutests/22-commonstencil/best</span><br></pre></td></tr></table></figure>

<p>ncu-ui是可视化界面，但是没弄懂</p>
<h2 id="带宽profile"><a href="#带宽profile" class="headerlink" title="带宽profile"></a>带宽profile</h2><h3 id="上限测量"><a href="#上限测量" class="headerlink" title="上限测量"></a>上限测量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:02:08]                                                                                                                                                                      $ ./bin/x86_64/linux/release/bandwidthTest                                                                                                                                                                                           [CUDA Bandwidth Test] - Starting...                                                                                                                                                                                                  Running on...                                                                                                                                                                                                                                                                                                                                                                                                                                                              Device 0: Tesla P40                                                                                                                                                                                                                  Quick Mode                                                                                                                                                                                                                                                                                                                                                                                                                                                                Host to Device Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     11.8                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Host Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     13.0                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Device Bandwidth, 1 Device(s)                                                                                                                                                                                              PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     244.3                                                                                                                                                                                                                                                                                                                                                                                                                                     Result = PASS                                                                                                                                                                                                                                                                                                                                                                                                                                                             NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.                                                                                                                                                                                       # shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:03:24]                                                                                                                                                                      $ ./bin/x86_64/linux/release/p2pBandwidthLatencyTest        </span><br></pre></td></tr></table></figure>

<h3 id="实际值"><a href="#实际值" class="headerlink" title="实际值"></a>实际值</h3><p>nvprof通过指定与dram，L1或者L2 的metrics来实现。具体解释可以参考<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">官网</a></p>
<p>在 Maxwell 和之后的架构中 L1 和 SMEM 合并</p>
<table>
<thead>
<tr>
<th>Metric Name</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>achieved_occupancy</td>
<td>活跃cycle是 Warps 活跃的比例</td>
</tr>
<tr>
<td>dram_read_throughput</td>
<td></td>
</tr>
<tr>
<td>dram_utilization</td>
<td>在0到10的范围内，相对于峰值利用率，设备内存的利用率水平</td>
</tr>
<tr>
<td>shared_load_throughput</td>
<td></td>
</tr>
<tr>
<td>shared_utilization</td>
<td></td>
</tr>
<tr>
<td>l2_utilization</td>
<td></td>
</tr>
</tbody></table>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-01-23T16:00:00.000Z" title="1/23/2022, 4:00:00 PM">2022-01-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T10:53:14.795Z" title="12/20/2023, 10:53:14 AM">2023-12-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Overview/">Overview</a></span><span class="level-item">12 minutes read (About 1830 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/23/Work/info/Nvidia/">Nvidia</a></p><div class="content"><h1 id="what-is-RTX-GTX-RX"><a href="#what-is-RTX-GTX-RX" class="headerlink" title="what is RTX GTX RX"></a>what is RTX GTX RX</h1><h2 id="GTX"><a href="#GTX" class="headerlink" title="GTX"></a>GTX</h2><p>在NVIDIA显卡中，从2004年的Geforce 6800系列开始就有“GT”的代号，GT：频率提升版本”GeForce Technology”的缩写,代表着中高端显卡或者是加强版显卡，比如6600GT和6800GT，到了2005年的7800系列之后便引入了“GTX”的代号，直接代表着高端或者顶级显卡。进入GTX400系列以后，当时还有象征中低端的“GTS”命名，后来就连“GTS”也没有了，全部的独立显卡统称为“GTX”，仅用后面的数字大小来区分性能等级，至今GTX1000系列显卡一直延续着这样的命名方式。</p>
<p>   对于已经沿用了多年的GTX前缀，NVIDIA终于在最新的GTX20系列有所改变了，高端的2080和2080TI统称为“RTX”，这里的“RT”就代表着光线追踪（ray tracing的缩写），象征着RTX2080显卡拥有非常强大的光线追踪性能。其实光线追踪技术本身并不新鲜，但是由于计算量需求庞大，往往为了渲染一帧图片都需要传统电脑消耗数个小时乃至数天的时间，但是RTX20显卡采用的“图灵”架构引入了RT计算单元，使其光线追踪性能超越上一代显卡的六倍，拥有了即时处理游戏光追的条件，NVIDIA认为这是一个划时代的进化，于是果断把沿用多年的“GTX”改名为“RTX”。</p>
<h2 id="RTX"><a href="#RTX" class="headerlink" title="RTX"></a>RTX</h2><ol>
<li>NVIDIA RTX显卡是首个包含RT Core的图形卡。这种专用光线追踪硬件每秒可以投射超过10 gigarays的光线，从而可以在游戏中提供类似电影的实时照明。RTX显卡的光线追踪性能最高可提高6倍，因而可以实现实时光线追踪效果。</li>
<li>RTX显卡也是首个提供Tensor Core的设备，这些Tensor Core能够提供超过100 teraflop的AI处理，以利用NVIDIA DLSS提高游戏性能。</li>
</ol>
<h1 id="Nvidia"><a href="#Nvidia" class="headerlink" title="Nvidia"></a>Nvidia</h1><h2 id="产品"><a href="#产品" class="headerlink" title="产品"></a>产品</h2><ol>
<li>GeForce 提供家庭娱乐<ol>
<li>PC,与AMD（原ATi）的Radeon系列显卡竞争</li>
</ol>
</li>
<li>Tegra 移动端 SOC system on chip<ol>
<li><p>基于ARM架构的通用处理器(CPU)。Tegra是一种采用单片机系统设计（system-on-a-chip）芯片，它集成了ARM架构处理器和NVIDIA的GeforceGPU，并内置了其它功能，产品主要面向小型设备。和Intel以PC为起点的x86架构相比，ARM架构的Tegra更像是以手机处理器为起点做出的发展。它不能运行x86 PC上的Windows XP等操作系统，但在手机上应用多年的ARM架构轻量级操作系统更能适应它高速低功耗的需求</p>
</li>
<li><p>2008年2月11日，NVIDIA发布了用于智能手机与PDA平台的Tegra APX 2500</p>
</li>
<li><p>Tegra APX 2500</p>
<pre><code>  65 nm
  600 MHz
  ARM11 MP Core
  FWVGA
   720p
</code></pre>
</li>
<li><p>Tegra X1的分数几乎是Tegra K1,再之前是Tegra 1&#x2F;2&#x2F;3&#x2F;4</p>
<ol>
<li>Switch采用了Nvidia Tegra T210处理器，属于Tegra X1系列。目前各类主机以及手机、平板都是将CPU与GPU整合在一块芯片上，并不像电脑还需有个独显。而Tegra系列便是Nvidia专门为手持设备开发的系统芯片，Tegra为Nvidia自产主机SHIELD以及Google手机Nexus、小米平板等设备提供过技术支持，图像处理性能介于A8X与A9X之间，是的，Tegra常拿来与移动端处理器对比，感情Switch就是用的一手机CPU啊，还是三年前的！</li>
<li>Tegra X1整合了四颗Cortex-A57核心和四颗Cortex-A53核心，和骁龙810以及三星Exynos 7系列相同。而GPU部分则采用了Maxwell架构，共计256个流处理器，堪比入门独显了</li>
</ol>
</li>
<li><p>Super Switch有望搭载一块1080P OLED&#x2F;mini LED显示屏，处理器升级为Tegra X1+&#x2F;Xavier，配备64GB存储空间。</p>
</li>
</ol>
</li>
<li>ION 低端上网本，集成 </li>
<li>Quadro （视觉计算平台）</li>
<li>Tesla用于大规模的并联电脑运算<ol>
<li>NVIDIA推出了CUDA。开发者利用C语言，再通过CUDA编译器，就能利用显核运算。开发者可忽略图形处理技术，而直接利用熟悉的C语言。开发者和科学家，就可以利用显示核心，研究物理、生化和勘探等领域。</li>
<li>可实现极高精度</li>
<li>最大的差别是特斯拉计算卡（Tesla ）属于运算卡，没有图形输出功能</li>
</ol>
</li>
</ol>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><ol>
<li>Maxwell 老<ol>
<li>GTX 980</li>
</ol>
</li>
<li>Pascal 2016年<ol>
<li>Pascal的GPC有6个SM，每个SM只含有64个CUDA Core，但是拥有64个FP32单元32个FP64单元，FP64与FP32比例达到了1：2，双精度性能大幅度提高，而Pascal的FP32单元可以同时执行2个FP16半精度运算，因此FP16浮点性能也同样获得极大提升</li>
<li>GTX1080, Tesla P100</li>
</ol>
</li>
<li>Turing 2018年<ol>
<li>RT core 硬件光追</li>
<li>Tensor core 加速深度学习 DLSS</li>
<li>VR + 采样 光栅性能</li>
</ol>
</li>
<li>Ampere 2020年<ol>
<li>7nm + NVIDIA第八代GPU提供了迄今为止最大的性能飞跃，集AI训练和推理于一身</li>
<li>新的Turing RT核心和Tensor核心</li>
<li>Ampere可能是Turing的平稳升级</li>
</ol>
</li>
</ol>
<h3 id="Ampere架构"><a href="#Ampere架构" class="headerlink" title="Ampere架构"></a>Ampere架构</h3><ol>
<li>在GTC 2020主题演讲中，NVIDIA宣布推出Ampere架构，这是NVIDIA发布的第八代GPU架构，包含超过540亿个晶体管，性能相较于前代提升了高达20倍，也是NVIDIA 8代GPU历史上最大的一次性能飞跃。  NVIDIA A100是首款基于NVIDIA Ampere架构的GPU。作为一款通用型工作负载加速器，A100还被设计用于数据分析、科学计算和云图形。</li>
</ol>
<h2 id="经典产品"><a href="#经典产品" class="headerlink" title="经典产品"></a>经典产品</h2><ol>
<li>GTX1070 和 GTX1080 的 GPU 芯片均为 GP104</li>
<li>GeForce GTX TITAN X 28nm Maxwell架构 GM200</li>
<li>RTX3090<ol>
<li>10496 &#x3D;  cuda cores 24GB GDDR6X PCIe 4.0 350W 1.73GHz 384位显存位宽 </li>
<li>GA102</li>
</ol>
</li>
<li>RTX2080Ti<ol>
<li>Turing 架构</li>
<li>4352 &#x3D;  cuda cores 11GB GDDR6 PCIe 4.0 260W 1.63GHz 352位显存位宽</li>
</ol>
</li>
<li>RTX2060<br> 1. 1920 cuda cores 6GB GDDR6  160W 1680MHz 192位显存位宽 336GB&#x2F;s显存带宽</li>
<li>TESLA P100 2016<ol>
<li>Pascal 架构 GP100</li>
<li>双单 5&#x2F;10 Tflops</li>
<li>NVIDIA NVLink</li>
<li>3584 &#x3D; 640 *5.6 cuda cores 12&#x2F;16GB 250W</li>
</ol>
</li>
<li>TESLA V100 2017-2019<ol>
<li>Volta架构 GP100</li>
<li>5120 cuda cores + 640 tensor cores + 16&#x2F;32GB HBM2 250W </li>
<li>双单Tensor 7&#x2F;14&#x2F;112 Tflops</li>
</ol>
</li>
<li>TESLA A100 2020<ol>
<li>6912 CUDA Cores 40&#x2F;80GB 250W </li>
<li>GA100-883AA-A1 核心 <ol>
<li>a full GA100 GPU with 128 SMs. The A100 is based on GA100 and has 108 SMs. </li>
<li>64 FP32 CUDA Cores&#x2F;SM, 8192 FP32 CUDA Cores per full GPU</li>
</ol>
</li>
<li>双单Tensor 9.7&#x2F;19.5&#x2F;152 Tflops</li>
</ol>
</li>
</ol>
<h2 id="平时用显卡"><a href="#平时用显卡" class="headerlink" title="平时用显卡"></a>平时用显卡</h2><ol>
<li>GTX1650<ol>
<li>Turing 架构，浮点整数并发 </li>
<li>896 cuda cores 4GB GDDR5&#x2F;6 PCIe 3.0 75W 1665MHz 128位显存位宽 128GB&#x2F;s显存带宽</li>
</ol>
</li>
<li>GTX1080Ti snode4<ol>
<li>16nm Pascal</li>
<li>3584 &#x3D; 640 *5.6 cuda cores 11GB GDDR5X PCIe 3.0 250W 1582MHz 352位显存位宽 484GB&#x2F;s显存带宽</li>
<li>GP102 8+6pin</li>
</ol>
</li>
<li>Tesla P40 snode0 2019<ol>
<li>GP100 全</li>
<li>3840 &#x3D;  640 *6 cuda cores 24GB GDDR5 250W </li>
<li>双单 6&#x2F;12 Tflops</li>
</ol>
</li>
<li>RTX3070<ol>
<li>7nm Ampere 架构 + DLSS AI Tensor core 动态精度 + 2代 RT core</li>
<li>5888 &#x3D;  cuda cores 8GB GDDR6 PCIe 4.0 220W 1.73GHz 256位显存位宽</li>
</ol>
</li>
</ol>
<h1 id="AMD-原ATi"><a href="#AMD-原ATi" class="headerlink" title="AMD(原ATi)"></a>AMD(原ATi)</h1><ol>
<li>PS4 PRO与Xbox One X两大主机皆是采用了AMD公司的捷豹（Jaguar）处理器</li>
<li>PS4Pro 的APU GPU部分大概是RX470D？（或者1050Ti）</li>
</ol>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无

</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-18T14:03:30.000Z" title="9/18/2021, 2:03:30 PM">2021-09-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T10:53:14.775Z" title="12/20/2023, 10:53:14 AM">2023-12-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Overview/">Overview</a></span><span class="level-item">2 minutes read (About 240 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/18/Work/Architecture/GPU/GPU/">GPU</a></p><div class="content"><h2 id="GPU-papers-is-All-you-need"><a href="#GPU-papers-is-All-you-need" class="headerlink" title="GPU papers is All  you need"></a>GPU papers is All  you need</h2><p><a target="_blank" rel="noopener" href="https://github.com/Jokeren/Awesome-GPU">https://github.com/Jokeren/Awesome-GPU</a></p>
<h2 id="GPU-起源"><a href="#GPU-起源" class="headerlink" title="GPU 起源"></a>GPU 起源</h2><p>1985年 8月20日 ATi公司成立，同年10月ATi使用ASIC技术开发出了第一款图形芯片和图形卡，1992年 4月 ATi发布了 Mach32 图形卡集成了图形加速功能，1998年 4月 ATi被IDC评选为图形芯片工业的市场领导者，但那时候这种芯片还没有GPU的称号，很长的一段时间ATI都是把图形处理器称为VPU，直到AMD收购ATI之后其图形芯片才正式采用GPU的名字。</p>
<p>NVIDIA公司在1999年发布GeForce 256图形处理芯片时首先提出GPU的概念。从此NVIDIA显卡的芯片就用这个新名字GPU来称呼。</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>看历史真好玩</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81675479">https://zhuanlan.zhihu.com/p/81675479</a></p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">372</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">30</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">482</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">49</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-20T10:32:37.000Z">2023-12-20</time></p><p class="title"><a href="/2023/12/20/Work/Artificial%20Intelligence/AIHardware/">AI Hardware &amp; Accelerators</a></p><p class="categories"><a href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-20T02:19:24.000Z">2023-12-20</time></p><p class="title"><a href="/2023/12/20/Work/Artificial%20Intelligence/Model/CV/Idea2StableDiffusion/">Idea to StableDiffusion</a></p><p class="categories"><a href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-19T02:59:59.000Z">2023-12-19</time></p><p class="title"><a href="/2023/12/19/Work/math/TuringMachinePversusNPproblem/">Turing Machine &amp; P versus NP problem</a></p><p class="categories"><a href="/categories/Math/">Math</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-18T20:59:04.000Z">2023-12-18</time></p><p class="title"><a href="/2023/12/18/Work/Artificial%20Intelligence/Model/AIModelDesignEffectiveness/">AI Model Design Effectiveness</a></p><p class="categories"><a href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-18T08:47:31.000Z">2023-12-18</time></p><p class="title"><a href="/2023/12/18/Work/Artificial%20Intelligence/Model/CV/DeployStableDiffusionTOA100/">Deploy Stable Diffusion to A100</a></p><p class="categories"><a href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">233</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>