<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: PyG - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">PyG</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-13T13:39:29.000Z" title="4/13/2022, 1:39:29 PM">2022-04-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-27T08:29:27.882Z" title="11/27/2023, 8:29:27 AM">2023-11-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">22 minutes read (About 3279 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/13/Work/Artificial%20Intelligence/PyTorchGeometric/">PyTorchGeometric</a></p><div class="content"><h2 id="PyTorch-Geometric-Liberty"><a href="#PyTorch-Geometric-Liberty" class="headerlink" title="PyTorch Geometric Liberty"></a>PyTorch Geometric Liberty</h2><p>PyG是一个基于PyTorch的用于处理不规则数据（比如图）的库，或者说是一个用于在图等数据上快速实现表征学习的框架。它的运行速度很快，训练模型速度可以达到DGL（Deep Graph Library ）v0.2 的40倍（数据来自论文）。除了出色的运行速度外，PyG中也集成了很多论文中提出的方法（GCN,SGC,GAT,SAGE等等）和常用数据集。因此对于复现论文来说也是相当方便。</p>
<p>经典的库才有函数可以支持，自己的模型，自己根据自动微分实现。还要自己写GPU并行。</p>
<p>MessagePassing 是网络交互的核心</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="数据怎么存储"><a href="#数据怎么存储" class="headerlink" title="数据怎么存储"></a>数据怎么存储</h3><p>torch_geometric.data.Data (下面简称Data) 用于构建图</p>
<ol>
<li>每个节点的特征 x<ol>
<li>形状是[num_nodes, num_node_features]。</li>
</ol>
</li>
<li>节点之间的边 edge_index<ol>
<li>形状是 [2, num_edges]</li>
</ol>
</li>
<li>节点的标签 y<ol>
<li>假如有。形状是[num_nodes, *]</li>
</ol>
</li>
<li>边的特征 edge_attr<ol>
<li>[num_edges, num_edge_features]</li>
</ol>
</li>
</ol>
<h3 id="数据支持自定义"><a href="#数据支持自定义" class="headerlink" title="数据支持自定义"></a>数据支持自定义</h3><p>通过data.face来扩展Data</p>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><p>在 PyG 中，我们使用的不是这种写法，而是在get()函数中根据 index 返回torch_geometric.data.Data类型的数据，在Data里包含了数据和 label。</p>
<h3 id="数据处理的例子"><a href="#数据处理的例子" class="headerlink" title="数据处理的例子"></a>数据处理的例子</h3><p><img src="https://pic.shaojiemike.top/img/20220413165624.png"><br>由于是无向图，因此有 4 条边：(0 -&gt; 1), (1 -&gt; 0), (1 -&gt; 2), (2 -&gt; 1)。每个节点都有自己的特征。上面这个图可以使用 <code>torch_geometric.data.Data</code>来表示如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch_geometric.data import Data</span><br><span class="line"># 由于是无向图，因此有 4 条边：(0 -&gt; 1), (1 -&gt; 0), (1 -&gt; 2), (2 -&gt; 1)</span><br><span class="line">edge_index = torch.tensor([[0, 1, 1, 2],</span><br><span class="line">                           [1, 0, 2, 1]], dtype=torch.long)</span><br><span class="line"># 节点的特征                         </span><br><span class="line">x = torch.tensor([[-1], [0], [1]], dtype=torch.float)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index)</span><br></pre></td></tr></table></figure>

<p>注意edge_index中边的存储方式，有两个list，第 1 个list是边的起始点，第 2 个list是边的目标节点。注意与下面的存储方式的区别。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch_geometric.data import Data</span><br><span class="line"></span><br><span class="line">edge_index = torch.tensor([[0, 1],</span><br><span class="line">                           [1, 0],</span><br><span class="line">                           [1, 2],</span><br><span class="line">                           [2, 1]], dtype=torch.long)</span><br><span class="line">x = torch.tensor([[-1], [0], [1]], dtype=torch.float)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index.t().contiguous())</span><br></pre></td></tr></table></figure>

<p>这种情况edge_index需要先转置然后使用contiguous()方法。关于contiguous()函数的作用，查看 PyTorch中的contiguous。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> InMemoryDataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyOwnDataset</span>(<span class="title class_ inherited__">InMemoryDataset</span>): <span class="comment"># or (Dataset)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, transform=<span class="literal">None</span>, pre_transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MyOwnDataset, self).__init__(root, transform, pre_transform)</span><br><span class="line">        self.data, self.slices = torch.load(self.processed_paths[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回一个包含没有处理的数据的名字的list。如果你只有一个文件，那么它返回的list将只包含一个元素。事实上，你可以返回一个空list，然后确定你的文件在后面的函数process()中。</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">raw_file_names</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;some_file_1&#x27;</span>, <span class="string">&#x27;some_file_2&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 很像上一个函数，它返回一个包含所有处理过的数据的list。在调用process()这个函数后，通常返回的list只有一个元素，它只保存已经处理过的数据的名字。</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">processed_file_names</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;data.pt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="comment"># Download to `self.raw_dir`. or just pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整合你的数据成一个包含data的list。然后调用 self.collate()去计算将用DataLodadr的片段。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># Read data into huge `Data` list.</span></span><br><span class="line">        data_list = [...]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_filter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list [data <span class="keyword">for</span> data <span class="keyword">in</span> data_list <span class="keyword">if</span> self.pre_filter(data)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list = [self.pre_transform(data) <span class="keyword">for</span> data <span class="keyword">in</span> data_list]</span><br><span class="line"></span><br><span class="line">        data, slices = self.collate(data_list)</span><br><span class="line">        torch.save((data, slices), self.processed_paths[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>DataLoader 这个类允许你通过batch的方式feed数据。创建一个DotaLoader实例，可以简单的指定数据集和你期望的batch size。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loader = DataLoader(dataset, batch_size=512, shuffle=True)</span><br></pre></td></tr></table></figure>

<p>DataLoader的每一次迭代都会产生一个Batch对象。它非常像Data对象。但是带有一个‘batch’属性。它指明了了对应图上的节点连接关系。因为DataLoader聚合来自不同图的的batch的x,y 和edge_index，所以GNN模型需要batch信息去知道那个节点属于哪一图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for batch in loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; Batch(x=[1024, 21], edge_index=[2, 1568], y=[512], batch=[1024])</span><br></pre></td></tr></table></figure>

<h2 id="MessagePassing-核心"><a href="#MessagePassing-核心" class="headerlink" title="MessagePassing(核心)"></a>MessagePassing(核心)</h2><p><img src="https://pic.shaojiemike.top/img/20220413214848.png"><br>其中，x 表示表格节点的 embedding，e 表示边的特征，ϕ 表示 message 函数，□ 表示聚合 aggregation 函数，γ 表示 update 函数。上标表示层的 index，比如说，当 k &#x3D; 1 时，x 则表示所有输入网络的图结构的数据。</p>
<p>为了实现这个，我们需要定义：</p>
<ol>
<li>message<ol>
<li>定义了对于每个节点对 (xi,xj)，怎样生成信息（message）。</li>
</ol>
</li>
<li>update</li>
<li>aggregation scheme</li>
<li>propagate(edge_index, size&#x3D;None, **kwargs)<ol>
<li>这个函数最终会按序调用 message、aggregate 和 update 函数。</li>
</ol>
</li>
<li>update(aggr_out, **kwargs)<ol>
<li>这个函数利用聚合好的信息（message）更新每个节点的 embedding。</li>
</ol>
</li>
</ol>
<h3 id="propagate-edge-index-Union-torch-Tensor-torch-sparse-tensor-SparseTensor-size-Optional-Tuple-int-int-None-kwargs"><a href="#propagate-edge-index-Union-torch-Tensor-torch-sparse-tensor-SparseTensor-size-Optional-Tuple-int-int-None-kwargs" class="headerlink" title="propagate(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Optional[Tuple[int, int]] &#x3D; None, **kwargs)"></a>propagate(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Optional[Tuple[int, int]] &#x3D; None, **kwargs)</h3><ol>
<li>edge_index (Tensor or SparseTensor)<ol>
<li>输入的边的信息，定义底层图形连接&#x2F;消息传递流。</li>
<li>torch.LongTensor类型<ol>
<li>its shape must be defined as <code>[2, num_messages]</code>, where messages from nodes in <code>edge_index[0]</code> are sent to nodes in <code>edge_index[1]</code></li>
</ol>
</li>
<li>torch_sparse.SparseTensor类型<ol>
<li>its sparse indices (row, col) should relate to row &#x3D; edge_index[1] and col &#x3D; edge_index[0].</li>
</ol>
</li>
</ol>
</li>
<li>也不一定是方形节点矩阵。x&#x3D;(x_N, x_M).</li>
</ol>
<h3 id="MessagePassing-message-…"><a href="#MessagePassing-message-…" class="headerlink" title="MessagePassing.message(…)"></a>MessagePassing.message(…)</h3><p>会根据 flow&#x3D;“source_to_target”和if flow&#x3D;“target_to_source”或者x_i,x_j,来区分处理的边。</p>
<p>x_j表示提升张量，它包含每个边的源节点特征，即每个节点的邻居。通过在变量名后添加_i或_j，可以自动提升节点特征。事实上，任何张量都可以通过这种方式转换，只要它们包含源节点或目标节点特征。</p>
<p>_j表示每条边的起点，_i表示每条边的终点。x_j表示的就是每条边起点的x值（也就是Feature）。如果你手动加了别的内容，那么它的_j, _i也会自动进行处理，这个自己稍微单步执行一下就知道了</p>
<p>在实现message的时候，节点特征会自动map到各自的source and target nodes。</p>
<h3 id="aggregate-inputs-torch-Tensor-index-torch-Tensor-ptr-Optional-torch-Tensor-None-dim-size-Optional-int-None-aggr-Optional-str-None-→-torch-Tensor"><a href="#aggregate-inputs-torch-Tensor-index-torch-Tensor-ptr-Optional-torch-Tensor-None-dim-size-Optional-int-None-aggr-Optional-str-None-→-torch-Tensor" class="headerlink" title="aggregate(inputs: torch.Tensor, index: torch.Tensor, ptr: Optional[torch.Tensor] &#x3D; None, dim_size: Optional[int] &#x3D; None, aggr: Optional[str] &#x3D; None) → torch.Tensor"></a>aggregate(inputs: torch.Tensor, index: torch.Tensor, ptr: Optional[torch.Tensor] &#x3D; None, dim_size: Optional[int] &#x3D; None, aggr: Optional[str] &#x3D; None) → torch.Tensor</h3><p>aggregation scheme 只需要设置参数就好，“add”, “mean”, “min”, “max” and “mul” operations</p>
<h3 id="MessagePassing-update-aggr-out-…"><a href="#MessagePassing-update-aggr-out-…" class="headerlink" title="MessagePassing.update(aggr_out, …)"></a>MessagePassing.update(aggr_out, …)</h3><p>aggregation 输出作为第一个参数，后面的参数是 propagate()的</p>
<h3 id="实现GCN-例子"><a href="#实现GCN-例子" class="headerlink" title="实现GCN 例子"></a>实现GCN 例子</h3><p>$$<br>\mathbf{x}<em>i^{(k)} &#x3D; \sum</em>{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot \left( \mathbf{\Theta}^{\top} \cdot \mathbf{x}_j^{(k-1)} \right)<br>$$</p>
<p>该式子先将周围的节点与权重矩阵\theta相乘, 然后通过节点的度degree正则化，最后相加</p>
<p>步骤可以拆分如下</p>
<ol>
<li>添加self-loop 到邻接矩阵（Adjacency Matrix）。</li>
<li>节点特征的线性变换。</li>
<li>计算归一化系数</li>
<li>Normalize 节点特征。</li>
<li>sum相邻节点的feature（“add”聚合）。</li>
</ol>
<p>步骤1 和 2 需要在message passing 前被计算好。 3 - 5 可以torch_geometric.nn.MessagePassing 类。</p>
<p>添加self-loop的目的是让featrue在聚合的过程中加入当前节点自己的feature，没有self-loop聚合的就只有邻居节点的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(aggr=<span class="string">&#x27;add&#x27;</span>)  <span class="comment"># &quot;Add&quot; aggregation (Step 5).</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.<span class="built_in">pow</span>(-<span class="number">0.5</span>)</span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] = <span class="number">0</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j, norm</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(-<span class="number">1</span>, <span class="number">1</span>) * x_j</span><br></pre></td></tr></table></figure>

<p>所有的逻辑代码都在forward()里面，当我们调用propagate()函数之后，它将会在内部调用message()和update()。</p>
<h3 id="使用-GCN-的例子"><a href="#使用-GCN-的例子" class="headerlink" title="使用 GCN 的例子"></a>使用 GCN 的例子</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv = GCNConv(16, 32)</span><br><span class="line">x = conv(x, edge_index)</span><br></pre></td></tr></table></figure>

<h3 id="SAGE的例子"><a href="#SAGE的例子" class="headerlink" title="SAGE的例子"></a>SAGE的例子</h3><p><img src="https://pic.shaojiemike.top/img/20220413232648.png"><br>聚合函数（aggregation）我们用最大池化（max pooling），这样上述公示中的 AGGREGATE 可以写为：<br><img src="https://pic.shaojiemike.top/img/20220413232702.png"><br>上述公式中，对于每个邻居节点，都和一个 weighted matrix 相乘，并且加上一个 bias，传给一个激活函数。相关代码如下(对应第二个图)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(SAGEConv, self).__init__(aggr=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, in_channels]</span></span><br><span class="line"> </span><br><span class="line">        x_j = self.lin(x_j)</span><br><span class="line">        x_j = self.act(x_j)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> x_j</span><br></pre></td></tr></table></figure>

<p>对于 update 方法，我们需要聚合更新每个节点的 embedding，然后加上权重矩阵和偏置(对应第一个图第二行)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">        self.update_act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out, x</span>):</span><br><span class="line">        <span class="comment"># aggr_out has shape [N, out_channels]</span></span><br><span class="line">      </span><br><span class="line">        new_embedding = torch.cat([aggr_out, x], dim=<span class="number">1</span>)</span><br><span class="line">        new_embedding = self.update_lin(new_embedding)</span><br><span class="line">        new_embedding = torch.update_act(new_embedding)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> new_embedding</span><br></pre></td></tr></table></figure>

<p>综上所述，SageConv 层的定于方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential <span class="keyword">as</span> Seq, Linear, ReLU</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> remove_self_loops, add_self_loops</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(SAGEConv, self).__init__(aggr=<span class="string">&#x27;max&#x27;</span>) <span class="comment">#  &quot;Max&quot; aggregation.</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.act = torch.nn.ReLU()</span><br><span class="line">        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">        self.update_act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line">      </span><br><span class="line">        <span class="comment"># Removes every self-loop in the graph given by edge_index, so that (i,i)∉E for every i ∈ V.</span></span><br><span class="line">        edge_index, _ = remove_self_loops(edge_index)</span><br><span class="line">        <span class="comment"># Adds a self-loop (i,i)∈ E to every node i ∈ V in the graph given by edge_index</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, size=(x.size(<span class="number">0</span>), x.size(<span class="number">0</span>)), x=x)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, in_channels]</span></span><br><span class="line"> </span><br><span class="line">        x_j = self.lin(x_j)</span><br><span class="line">        x_j = self.act(x_j)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> x_j</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out, x</span>):</span><br><span class="line">        <span class="comment"># aggr_out has shape [N, out_channels]</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">        new_embedding = torch.cat([aggr_out, x], dim=<span class="number">1</span>)</span><br><span class="line">      </span><br><span class="line">        new_embedding = self.update_lin(new_embedding)</span><br><span class="line">        new_embedding = self.update_act(new_embedding)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> new_embedding</span><br></pre></td></tr></table></figure>

<h2 id="batch的实现"><a href="#batch的实现" class="headerlink" title="batch的实现"></a>batch的实现</h2><p>GNN的batch实现和传统的有区别。</p>
<h3 id="zzq的观点"><a href="#zzq的观点" class="headerlink" title="zzq的观点"></a>zzq的观点</h3><p>将网络复制batch次，batchSize的数据产生batchSize个Loss。通过Sum或者Max处理Loss，整体同时更新所有的网络参数。至于网络中循环输入和输出的H^(t-1)和H^t。（感觉直接平均就行了。</p>
<p>有几个可能的问题</p>
<ol>
<li>网络中参数不是线性层，CNN这种的网络。pytorch会自动并行吗？还需要手动</li>
<li>还有个问题，如果你还想用PyG的X和edge。并不能额外拓展维度。</li>
</ol>
<h3 id="图像和语言处理领域的传统基本思路："><a href="#图像和语言处理领域的传统基本思路：" class="headerlink" title="图像和语言处理领域的传统基本思路："></a>图像和语言处理领域的传统基本思路：</h3><p>通过 rescaling or padding(填充) 将相同大小的网络复制，来实现新添加维度。而新添加维度的大小就是batch_size。</p>
<p>但是由于图神经网络的特殊性：边和节点的表示。传统的方法要么不可行，要么会有数据的重复表示产生的大量内存消耗。</p>
<h2 id="ADVANCED-MINI-BATCHING-in-PyG"><a href="#ADVANCED-MINI-BATCHING-in-PyG" class="headerlink" title="ADVANCED MINI-BATCHING in PyG"></a>ADVANCED MINI-BATCHING in PyG</h2><p>为此引入了ADVANCED MINI-BATCHING来实现对大量数据的并行。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html">https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html</a></p>
<h3 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h3><ol>
<li>邻接矩阵以对角线的方式堆叠(创建包含多个孤立子图的巨大图)</li>
<li>节点和目标特征只是在节点维度中串联???<br><img src="https://pic.shaojiemike.top/img/20220417155734.png"></li>
</ol>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol>
<li>依赖message passing 方案的GNN operators不需要修改，因为消息仍然不能在属于不同图的两个节点之间交换。</li>
<li>没有计算或内存开销。例如，此batching 过程完全可以在不填充节点或边特征的情况下工作。请注意，邻接矩阵没有额外的内存开销，因为它们以稀疏方式保存，只保存非零项，即边。</li>
</ol>
<h3 id="torch-geometric-loader-DataLoader"><a href="#torch-geometric-loader-DataLoader" class="headerlink" title="torch_geometric.loader.DataLoader"></a>torch_geometric.loader.DataLoader</h3><p>可以实现将多个图batch成一个大图。 通过重写collate()来实现，并继承了pytorch的所有参数，比如num_workers.</p>
<p>在合并的时候，除开edge_index [2, num_edges]通过增加第二维度。其余（节点）都是增加第一维度的个数。</p>
<h3 id="最重要的作用"><a href="#最重要的作用" class="headerlink" title="最重要的作用"></a>最重要的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 原本是[2*4]</span><br><span class="line"># 自己实现的话，是直接连接</span><br><span class="line"> &gt;&gt;&gt; tensor([[0, 0, 1, 1, 0, 0, 1, 1],</span><br><span class="line">             [0, 1, 1, 2, 0, 1, 1, 2]])</span><br><span class="line"># 会修改成新的边</span><br><span class="line"> print(batch.edge_index)</span><br><span class="line"> &gt;&gt;&gt; tensor([[0, 0, 1, 1, 2, 2, 3, 3],</span><br><span class="line">             [0, 1, 1, 2, 3, 4, 4, 5]])</span><br></pre></td></tr></table></figure>

<h3 id="torch-geometric-loader-DataLoader-例子1"><a href="#torch-geometric-loader-DataLoader-例子1" class="headerlink" title="torch_geometric.loader.DataLoader 例子1"></a>torch_geometric.loader.DataLoader 例子1</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from torch_geometric.data import Data</span><br><span class="line">from torch_geometric.loader import DataLoader</span><br><span class="line"></span><br><span class="line">data_list = [Data(...), ..., Data(...)]</span><br><span class="line">loader = DataLoader(data_list, batch_size=32)</span><br></pre></td></tr></table></figure>
<h3 id="torch-geometric-loader-DataLoader-例子2"><a href="#torch-geometric-loader-DataLoader-例子2" class="headerlink" title="torch_geometric.loader.DataLoader 例子2"></a>torch_geometric.loader.DataLoader 例子2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from torch_geometric.datasets import TUDataset</span><br><span class="line">from torch_geometric.loader import DataLoader</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;, use_node_attr=True)</span><br><span class="line">loader = DataLoader(dataset, batch_size=32, shuffle=True)</span><br><span class="line"></span><br><span class="line">for batch in loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])</span><br><span class="line"></span><br><span class="line">    batch.num_graphs</span><br><span class="line">    &gt;&gt;&gt; 32</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">351</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">29</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">473</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">49</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-27T07:44:46.000Z">2023-11-27</time></p><p class="title"><a href="/2023/11/27/OutOfWork/3-homepage/deployment/howSSGGetWork/">How SSG Get Work?</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-26T02:45:00.000Z">2023-11-26</time></p><p class="title"><a href="/2023/11/26/OutOfWork/1-lifeAndCareer/salaryTaxInsurance/">Salary &amp; Tax &amp; Insurance</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-24T10:33:09.000Z">2023-11-24</time></p><p class="title"><a href="/2023/11/24/OutOfWork/3-homepage/team/When4teampage/">When &amp; How 4 team presentation page &amp; knowledge database pool</a></p><p class="categories"><a href="/categories/thinking/">thinking</a> / <a href="/categories/thinking/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-22T08:12:35.000Z">2023-11-22</time></p><p class="title"><a href="/2023/11/22/Work/hardware/dataLink/">Data Link</a></p><p class="categories"><a href="/categories/hardware/">hardware</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-19T10:15:31.000Z">2023-11-19</time></p><p class="title"><a href="/2023/11/19/Work/network/example/wireguardServer2Server/">Wireguard Server 2 Server in OpenWRT</a></p><p class="categories"><a href="/categories/network/">network</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">212</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>