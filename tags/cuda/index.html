<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: cuda - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">cuda</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-11T16:00:00.000Z" title="5/11/2023, 4:00:00 PM">2023-05-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-15T16:59:48.469Z" title="11/15/2023, 4:59:48 PM">2023-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">14 minutes read (About 2170 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/11/Work/software/perf/nvidiaNsight/">Nvidia Nsight</a></p><div class="content"><h2 id="Nsight-system-compute-Graph-的关系"><a href="#Nsight-system-compute-Graph-的关系" class="headerlink" title="Nsight system compute &amp; Graph 的关系"></a>Nsight system compute &amp; Graph 的关系</h2><p><img src="https://pic.shaojiemike.top/img/20220513195618.png"></p>
<h3 id="Nsight-Systems"><a href="#Nsight-Systems" class="headerlink" title="Nsight Systems"></a>Nsight Systems</h3><p>All developers should start with Nsight Systems to identify the largest optimization opportunities. Nsight Systems provides developers a <strong>system-wide visualization</strong> of an applications performance. Developers can optimize <strong>bottlenecks</strong> to scale efficiently across any number or size of CPUs and GPUs; from large servers to our smallest SoC. For <strong>further optimizations to compute kernels developers should use Nsight Compute</strong> or to further optimize a graphics workloads, use Nsight Graphics.</p>
<h3 id="Nsight-Compute"><a href="#Nsight-Compute" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h3><p>Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool. Nsight Compute also provides customizable and data-driven user interface and metric collection that can be extended with analysis scripts for post-processing results.</p>
<h3 id="Nsight-Graphics"><a href="#Nsight-Graphics" class="headerlink" title="Nsight Graphics"></a>Nsight Graphics</h3><p>Nsight Graphics is a standalone application for the debugging, profiling, and analysis of <strong>graphics applications</strong> on Microsoft Windows and Linux. It allows you to optimize the performance of your Direct3D 11, Direct3D 12, DirectX Raytracing 1.1, <strong>OpenGL</strong>, Vulkan, and KHR Vulkan <strong>Ray Tracing</strong> Extension based applications.</p>
<h2 id="Install-Nsight-local"><a href="#Install-Nsight-local" class="headerlink" title="Install Nsight local"></a>Install Nsight local</h2><ol>
<li>check the perf config To collect thread scheduling data and IP (instruction pointer) samples<ol>
<li><code>cat /proc/sys/kernel/perf_event_paranoid</code></li>
<li>如果大于2，临时改变 <code>sudo sh -c &#39;echo 2 &gt;/proc/sys/kernel/perf_event_paranoid&#39;</code>重启会重置</li>
<li>永久修改 <code>sudo sh -c &#39;echo kernel.perf_event_paranoid=2 &gt; /etc/sysctl.d/local.conf&#39;</code></li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/gameworksdownload#?dn=nsight-systems-2022-2">下载Nsight</a><ol>
<li>但是单独下载要会员</li>
<li>下载cuda toolkit,有集成</li>
</ol>
</li>
</ol>
<h2 id="Nsight-System"><a href="#Nsight-System" class="headerlink" title="Nsight System"></a>Nsight System</h2><p>运行 <code>nsight-sys</code></p>
<h3 id="使用基本说明"><a href="#使用基本说明" class="headerlink" title="使用基本说明"></a>使用基本说明</h3><p>勾选了CUDA-trace等选项<br><img src="https://pic.shaojiemike.top/img/20220521143324.png"></p>
<p>可以从整体上看资源的使用情况，</p>
<p>将鼠标放在上面会有<strong>具体</strong>的数值或者名称的解释</p>
<p><img src="https://pic.shaojiemike.top/img/20220521143753.png"><br><img src="https://pic.shaojiemike.top/img/20220521144435.png"></p>
<p>比较有用的是能看出 PCIE, GPU DRAM Bandwidth, Warp的使用情况。</p>
<p>由于没有根据kernel function区分，很难读。为此提供了NVTX来给代码打标签</p>
<h3 id="The-NVIDIA-Tools-Extension-Library-NVTX-使用"><a href="#The-NVIDIA-Tools-Extension-Library-NVTX-使用" class="headerlink" title="The NVIDIA Tools Extension Library (NVTX)使用"></a>The NVIDIA Tools Extension Library (NVTX)使用</h3><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-visual-studio-edition/2020.1/nvtx/index.html">https://docs.nvidia.com/nsight-visual-studio-edition/2020.1/nvtx/index.html</a><br>头文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;nvToolsExt.h&gt;</span><br></pre></td></tr></table></figure>

<p>需要标记代码前后加入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvtxRangePush(&quot;checkResult&quot;); //nvtxRangePushA,nvtxRangePushW,nvtxRangePushEx 好像都差不多</span><br><span class="line">checkResult&lt;&lt;&lt;dim3(row_num / TPBX, col_num / TPBY, 1), dim3(TPBX, TPBY, 1)&gt;&gt;&gt;(row_num, col_num, result);</span><br><span class="line">cudaDeviceSynchronize(); </span><br><span class="line">nvtxRangePop();</span><br></pre></td></tr></table></figure>

<p>注意NVTX是作用在<strong>CPU线程</strong>上的，无法在GPU里用。</p>
<p>注意需要 <code>g++ -o testnv -I/usr/local/cuda/include -L/usr/local/cuda/lib64 -lnvToolsExt testnv.cpp</code>。或者修改cmake来实现同样的效果</p>
<h3 id="NVTX问题"><a href="#NVTX问题" class="headerlink" title="NVTX问题"></a>NVTX问题</h3><p><img src="https://pic.shaojiemike.top/img/20220521153540.png"></p>
<p>怎么不在同一竖直方向上？GPU还先跑是什么情况</p>
<h2 id="Nsight-Compute-1"><a href="#Nsight-Compute-1" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h2><p>Nsight Systems 就是nvprof的继任者，NVIDIA最新的用于监测 kernel timeline的工具。NVIDIA 计算能力7.5及以上的GPU设备不再支持nvprof工具进行性能剖析，提示使用Nsight Compute作为替代品.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ncu # 命令行</span><br><span class="line">ncu-ui</span><br></pre></td></tr></table></figure>

<h3 id="使用Nsight-Compute-CLI-nv-nsight-cu-cli-ncu-输出数据"><a href="#使用Nsight-Compute-CLI-nv-nsight-cu-cli-ncu-输出数据" class="headerlink" title="使用Nsight Compute CLI (nv-nsight-cu-cli &#x2F; ncu) 输出数据"></a>使用Nsight Compute CLI (nv-nsight-cu-cli &#x2F; ncu) 输出数据</h3><p><code>nv-nsight-cu-cli -&gt; ncu</code><br>下面是一个使用样例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/NVIDIA-Nsight-Compute/nv-nsight-cu-cli -o mnist -f --csv --profile-from-start off /usr/bin/python3 mnist.py</span><br></pre></td></tr></table></figure>

<p>其中-o是为了输出.nsight-cuprof-report文件用于后续的可视化查看，-f为强制覆盖原有文件，–csv可是在console输出除 timeline 以外数据的时候以逗号分隔数据，方便拷贝至csv文件， –profile-from-start的使用方法和Nsight System以及nvprof一样。其余flag信息可见<a target="_blank" rel="noopener" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html</a> 。</p>
<p>上面的例子会生成mnist.nsight-cuprof-report文件。</p>
<p>注意</p>
<p>最前面的可执行文件需要绝对路径，如上面的python3需要使用 &#x2F;usr&#x2F;bin&#x2F;python3。<br>生成过程中可能会产生很大的临时文件（几十G）。如果本次磁盘空间不够，可以设置如下环境变量来调整存储临时文件的地址。没有找到能直接使用 Nsight Compute 修改临时文件地址的方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export /TMPDIR=/path/for/tmp</span><br></pre></td></tr></table></figure>

<h3 id="ncu与nvprof命令行抓取参数的映射表"><a href="#ncu与nvprof命令行抓取参数的映射表" class="headerlink" title="ncu与nvprof命令行抓取参数的映射表"></a>ncu与nvprof命令行抓取参数的映射表</h3><p><a target="_blank" rel="noopener" href="https://www.freesion.com/article/34871449930/">https://www.freesion.com/article/34871449930/</a></p>
<h3 id="ncu-ui教程"><a href="#ncu-ui教程" class="headerlink" title="ncu-ui教程"></a>ncu-ui教程</h3><p>为了显示原代码makefile添加 <code>-g -G</code>选项<br>对应CmakeList.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">target_compile_options(better PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:--extended-lambda</span><br><span class="line">    -G -src-in-ptx</span><br><span class="line">    &gt;)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yan31415/article/details/109491749">https://blog.csdn.net/yan31415/article/details/109491749</a></p>
<h3 id="ncu-ui表格-图"><a href="#ncu-ui表格-图" class="headerlink" title="ncu-ui表格&amp;图"></a>ncu-ui表格&amp;图</h3><p><img src="https://pic.shaojiemike.top/img/20220521160243.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220521161200.png"><br>我不明白我的SMEM怎么不是从DRAM来的， 而且峰值怎么这么低？</p>
<p>这个错误也是令人迷惑<br>The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 3.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request.</p>
<p><img src="https://pic.shaojiemike.top/img/20220521163326.png"></p>
<p>不知道为什么有1%和2% 的bank conflict</p>
<p>可以看到 SMEM， Register，Block Size是怎么影响GPU Warp的分配调度的。<br><img src="https://pic.shaojiemike.top/img/20220521163505.png"><br>上图没有拖累，吃满了64个warp。</p>
<p>关于if语句<br><img src="https://pic.shaojiemike.top/img/20220521163918.png"><br>if语句只要warp里执行相同就行。</p>
<p>可以提示出不连续访问的地方。(这里是这样设计的，已经避免了绝大部分的不连续访问)<br><img src="https://pic.shaojiemike.top/img/20220521164456.png"></p>
<p>显示stall最多的指令是什么以及在等待什么。还有执行最多的指令<br><img src="https://pic.shaojiemike.top/img/20220521164627.png"></p>
<p>假如 file mismatched 手动选择文件就行<br><img src="https://pic.shaojiemike.top/img/20220521165836.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220521170004.png"></p>
<p>stall的信息，感觉就这些有点用。(其中sb是scoreboard的意思)</p>
<h2 id="ncu-ui-分析汇编"><a href="#ncu-ui-分析汇编" class="headerlink" title="ncu-ui 分析汇编"></a>ncu-ui 分析汇编</h2><h3 id="PTX-SASS汇编说明"><a href="#PTX-SASS汇编说明" class="headerlink" title="PTX&amp;SASS汇编说明"></a>PTX&amp;SASS汇编说明</h3><p>有两种汇编</p>
<p>请看PTX SASS一文</p>
<h3 id="基本说明"><a href="#基本说明" class="headerlink" title="基本说明"></a>基本说明</h3><p><img src="https://pic.shaojiemike.top/img/20220522095802.png"></p>
<p>可以通过指令执行数或者采样率来得知，执行最多的指令。</p>
<p>鼠标悬停可以知道具体命令的含义</p>
<h3 id="Ex1-for循环头"><a href="#Ex1-for循环头" class="headerlink" title="Ex1: for循环头"></a>Ex1: for循环头</h3><p><img src="https://pic.shaojiemike.top/img/20220522101042.png"></p>
<h3 id="Ex2-for-loop-kernel"><a href="#Ex2-for-loop-kernel" class="headerlink" title="Ex2: for-loop kernel"></a>Ex2: for-loop kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sdata[Regular_local_index]=arr_data[Regular_global_index];</span><br></pre></td></tr></table></figure>

<p>该从DRAM里读取到SMEM的指令对应的PTX和SASS代码<br><img src="https://pic.shaojiemike.top/img/20220522105005.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cvt.f32.u16 d, a;   // convert 16-bit unsigned to 32-bit float</span><br></pre></td></tr></table></figure>

<h3 id="问题：无效self-mov？"><a href="#问题：无效self-mov？" class="headerlink" title="问题：无效self-mov？"></a>问题：无效self-mov？</h3><p><img src="https://pic.shaojiemike.top/img/20220522101410.png"></p>
<p>为了隐藏延迟？</p>
<p>直接原因是PTX翻译成SASS。一条mov变多条了</p>
<p><img src="https://pic.shaojiemike.top/img/20220522103503.png"></p>
<h2 id="CUDA-Visual-Profiler"><a href="#CUDA-Visual-Profiler" class="headerlink" title="CUDA Visual Profiler"></a>CUDA Visual Profiler</h2><p>老一代debugger工具，逐渐被Nsight淘汰</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof # 命令行,nsys 之前的名称叫做 nvprof</span><br><span class="line">nvvp</span><br></pre></td></tr></table></figure>

<p>在more里有建议</p>
<h3 id="nvprof捕获信息存储"><a href="#nvprof捕获信息存储" class="headerlink" title="nvprof捕获信息存储"></a>nvprof捕获信息存储</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./nbody --benchmark -numdevices=2 -i=1</span><br><span class="line"># 下面输出 .qdrep 文件</span><br><span class="line">nsys profile --stats=true --force-overwrite=true  -o baseline-report ./single-thread-vector-add</span><br></pre></td></tr></table></figure>

<h2 id="CUDA-Visual-Profiler-问题"><a href="#CUDA-Visual-Profiler-问题" class="headerlink" title="CUDA Visual Profiler 问题"></a>CUDA Visual Profiler 问题</h2><p>&#x3D;&#x3D;7196&#x3D;&#x3D; Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.<br>解决方法在程序末尾加cudaDeviceReset()或者cudaProfilerStop()</p>
<h2 id="Nsight-Compute-问题"><a href="#Nsight-Compute-问题" class="headerlink" title="Nsight Compute 问题"></a>Nsight Compute 问题</h2><h3 id="OpenGL-没有安装"><a href="#OpenGL-没有安装" class="headerlink" title="OpenGL 没有安装"></a>OpenGL 没有安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Warning: Failed to get OpenGL version. OpenGL version 2.0 or higher is required.</span><br><span class="line">OpenGL version is too low (0). Falling back to Mesa software rendering.</span><br><span class="line">qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.</span><br><span class="line">This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.</span><br><span class="line"></span><br><span class="line">Available platform plugins are: offscreen, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, xcb.</span><br></pre></td></tr></table></figure>

<p>解决办法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libxcb-xinerama0</span><br><span class="line">sudo apt install libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0</span><br></pre></td></tr></table></figure>

<h3 id="Qt插件缺失"><a href="#Qt插件缺失" class="headerlink" title="Qt插件缺失"></a>Qt插件缺失</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.</span><br><span class="line">This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.</span><br><span class="line"></span><br><span class="line">Available platform plugins are: xcb.</span><br><span class="line"></span><br><span class="line">Application could not be initialized!</span><br><span class="line">    This is likely due to missing Qt platform dependencies.</span><br><span class="line">    For a list of dependencies, please refer to https://doc.qt.io/qt-5/linux-requirements.html</span><br><span class="line">    To view missing libraries, set QT_DEBUG_PLUGINS=1 and re-run the application.</span><br></pre></td></tr></table></figure>

<p>按照说明 <code>export QT_DEBUG_PLUGINS=1</code>再次运行, 显示具体问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot load library /staff/shaojiemike/Install/cuda_11.7.0_515.43.04_linux/nsight-compute-2022.2.0/host/linux-desktop-glibc_2_11_3-x64/Plugins/platforms/libqxcb.so: (libxcb-xinput.so.0: cannot open shared object file: No such file or directory)</span><br></pre></td></tr></table></figure>

<p>解决 <code>sudo apt-get install libxcb-xinput0</code></p>
<h3 id="kernel没权限profile"><a href="#kernel没权限profile" class="headerlink" title="kernel没权限profile"></a>kernel没权限profile</h3><p>mobaXterm打开，每个核函数都会出现ERR_NVGPUCTRPERM - The user does not have permission to profile on the target device这个错误</p>
<ol>
<li>说要用sudo，或者最新的NV</li>
</ol>
<h3 id="sudo-ncu-ui-不能远程打开"><a href="#sudo-ncu-ui-不能远程打开" class="headerlink" title="sudo ncu-ui 不能远程打开"></a>sudo ncu-ui 不能远程打开</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ncu-ui</span><br><span class="line">MobaXterm X11 proxy: Authorisation not recognised</span><br><span class="line">qt.qpa.xcb: could not connect to display localhost:10.0</span><br></pre></td></tr></table></figure>

<p>解决办法(原因是sudo相当于切换到root用户，丢失了xauth信息)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ xauth list</span><br><span class="line">snode0/unix:12  MIT-MAGIC-COOKIE-1  84941f1f8be97d19436356685f75b884</span><br><span class="line">snode0/unix:13  MIT-MAGIC-COOKIE-1  5172ee2c7364b055cd37538b460f7741</span><br><span class="line">snode0/unix:11  MIT-MAGIC-COOKIE-1  589f3b5ab852f24ca3710c53e6439260</span><br><span class="line">hades1/unix:10  MIT-MAGIC-COOKIE-1  9346adec202bd65250f3d21239025750</span><br><span class="line">snode0/unix:10  MIT-MAGIC-COOKIE-1  52285c563f1688741fa1b434ed2b7b2c</span><br><span class="line"></span><br><span class="line">sudo -s # 切换</span><br><span class="line">xauth add snode0/unix:10  MIT-MAGIC-COOKIE-1  52285c563f1688741fa1b434ed2b7b2c # 补全xauth</span><br><span class="line"># 正常执行 xauth有用的总是最后一个</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220606170556.png"></p>
<h3 id="Error-0-UnsupportedGpu"><a href="#Error-0-UnsupportedGpu" class="headerlink" title="Error 0: UnsupportedGpu"></a>Error 0: UnsupportedGpu</h3><p>原因是 <a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/nsight-unsupported-gpu/163617">软件对GPU的支持是逐步</a>的需要安装最新的。</p>
<p>不支持的Nsight的可以尝试老的debugger工具 CUDA Visual Profiler</p>
<h3 id="Error-Profiling-is-not-supported-on-this-device"><a href="#Error-Profiling-is-not-supported-on-this-device" class="headerlink" title="Error: Profiling is not supported on this device"></a>Error: Profiling is not supported on this device</h3><p>Pascal support was deprecated, then dropped from Nsight Compute after Nsight Compute 2019.5.1.</p>
<p>The profiling tools that support Pascal in the CUDA Toolkit 11.1 and later are <code>nvprof</code> and <code>visual profiler</code>.</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>NVTX问题</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/tools-overview">https://developer.nvidia.com/tools-overview</a></p>
<p><a target="_blank" rel="noopener" href="https://www.365seal.com/y/zyn1yxJQn3.html">https://www.365seal.com/y/zyn1yxJQn3.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-06T16:00:00.000Z" title="5/6/2023, 4:00:00 PM">2023-05-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-15T16:59:48.449Z" title="11/15/2023, 4:59:48 PM">2023-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">41 minutes read (About 6140 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/06/Work/HPC/cuda/cudaProgram/">Cuda Program</a></p><div class="content"><h2 id="Nvidia-经典优化"><a href="#Nvidia-经典优化" class="headerlink" title="Nvidia 经典优化"></a>Nvidia 经典优化</h2><p>Optimizing Parallel Reduction in CUDA - Mark Harris</p>
<p><img src="https://pic.shaojiemike.top/img/20220511211558.png"></p>
<p>详细见SC07 <a target="_blank" rel="noopener" href="https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf">PDF</a></p>
<h2 id="并行计算课程-CUDA"><a href="#并行计算课程-CUDA" class="headerlink" title="并行计算课程-CUDA"></a>并行计算课程-CUDA</h2><p><a target="_blank" rel="noopener" href="http://202.38.64.11/~xuyun/GPU_Computing.pdf">http://202.38.64.11/~xuyun/GPU_Computing.pdf</a> 密码pa22</p>
<ol>
<li>GPU线程的创建与调度使用硬件而不是操作系统，速度很快（PowerPC创建线程需要37万个周期）</li>
</ol>
<h3 id="常见的优化方法"><a href="#常见的优化方法" class="headerlink" title="常见的优化方法"></a>常见的优化方法</h3><h3 id="shared-memory-matrix-multiplication"><a href="#shared-memory-matrix-multiplication" class="headerlink" title="shared memory matrix multiplication"></a>shared memory matrix multiplication</h3><h3 id="Global-Memory：coalesced-access"><a href="#Global-Memory：coalesced-access" class="headerlink" title="Global Memory：coalesced access"></a>Global Memory：coalesced access</h3><p>利用好每个block里的thread，全部每个线程各自读取自己对齐(Starting address for a region must be a multiple of region size 不一定是自己用的)数据到shared memory开辟的总空间。由于需要的数据全部合力读取进来了，计算时正常使用需要的读入的数据。</p>
<p>特别是对于结构体</p>
<p>使用SoA(structure of arrays)而不是AoS（array of structures）<br>如果结构体实在不能对齐使用 <code>__align(X)</code>, where X &#x3D; 4, 8, or 16.强制对齐</p>
<p>有无采用对齐shared读取，有10倍的加速。</p>
<p><img src="https://pic.shaojiemike.top/img/20220505203920.png"></p>
<p>由于需要对齐读取，3float是12字节，所以只能拆成三份。</p>
<p><img src="https://pic.shaojiemike.top/img/20220519000548.png"></p>
<p>对于small Kernel和访存瓶颈的Kernel影响很大</p>
<h3 id="隐藏延迟的方法"><a href="#隐藏延迟的方法" class="headerlink" title="隐藏延迟的方法"></a>隐藏延迟的方法</h3><ol>
<li>增加SM上线程数量，</li>
<li>block数&gt; SM数，这样所有的multiprocessors至少有一个block执行</li>
<li>threads&#x2F;block&gt;128 。原因：机器上一般有最多4个Warp调度器&#x3D;4*32&#x3D;128</li>
<li>threadsInblock&#x3D;N*WarpSize&#x3D;N*32</li>
<li>在 SM 上的 TB 越多越好，让 Thread Block 不停的跑我们的利用率就会高。</li>
<li>但是如果 Thread Block 太多，我们每一个 SM 能分配的寄存器就会变少，所以就会发生 Register Spill, 使用更高级的 L1、L2 Cache 去代替 Registers。所以 TB 不能太多，需要减少 Register Spill 的次数。<ol>
<li>资源占用率不要太高（最多一半？</li>
</ol>
</li>
<li>多使用 <code>__syncthreads</code></li>
<li>最好的参数需要self-tuning出来</li>
</ol>
<h3 id="shared-memory-In-Stencil-Computing"><a href="#shared-memory-In-Stencil-Computing" class="headerlink" title="shared memory In Stencil Computing"></a>shared memory In Stencil Computing</h3><p><img src="https://pic.shaojiemike.top/img/20220519000613.png"></p>
<h3 id="shared-memory-bank-conflit"><a href="#shared-memory-bank-conflit" class="headerlink" title="shared memory bank conflit"></a>shared memory bank conflit</h3><p>如果没有bank冲突的话，共享内存的访存速度将会非常的快，大约比全局内存的访问延迟低100多倍，但是速度没有寄存器快。然而，如果在使用共享内存时发生了bank冲突的话，性能将会降低很多很多。</p>
<h3 id="shared-memory-原理"><a href="#shared-memory-原理" class="headerlink" title="shared memory 原理"></a>shared memory 原理</h3><p>GPU 的共享内存，实际上是 32 块内存条通过并联组成的，每个时钟周期都可以读取一个 int。第 i 块内存，负责 addr % 32 &#x3D;&#x3D; i 的数据。这样交错存储，可以保证随机访问时，访存能够尽量分摊到 32 个块。</p>
<p>如果在block内多个线程访问的地址落入到同一个bank内，那么就会访问同一个bank就会产生bank conflict，这些访问将是变成串行，在实际开发调式中非常主要bank conflict.</p>
<p>处理方法非常简单，我们不要把 shared memory 开辟的空间设置成 32 的倍数即可（线性同余方程，原理也很好理解）或者修改bank的size大小，默认是4字节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__host__ cudaError_t cudaDeviceSetSharedMemConfig ( cudaSharedMemConfig config )</span><br></pre></td></tr></table></figure>

<p>其中 cudaSharedMemConfi为一个枚举型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cudaSharedMemBankSizeDefault = 0</span><br><span class="line">cudaSharedMemBankSizeFourByte = 1</span><br><span class="line">cudaSharedMemBankSizeEightByte = 2</span><br></pre></td></tr></table></figure>

<p> 只支持在host端进行调用，不支持在device端调用。<br>CUDA API中还支持获取bank size大小：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__host__  __device__ cudaError_t cudaDeviceGetSharedMemConfig ( cudaSharedMemConfig ** pConfig )</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42730667/article/details/106171382">https://blog.csdn.net/weixin_42730667/article/details/106171382</a></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000007533157">https://segmentfault.com/a/1190000007533157</a></p>
<p>值得注意的是：</p>
<ol>
<li>多个线程同时访问同一个bank中<strong>相同</strong>的数组元素 <strong>不会</strong>产生bank conflict，将会出发广播</li>
<li>同一个 warp 的不同线程会访问到同一个 bank 的<strong>不同</strong>地址就会<strong>发生</strong> bank conflict</li>
</ol>
<h3 id="容易发生bank-conflit的情况"><a href="#容易发生bank-conflit的情况" class="headerlink" title="容易发生bank conflit的情况"></a>容易发生bank conflit的情况</h3><ol>
<li>数据类型是4字节，但是不是单位步长</li>
<li><img src="https://pic.shaojiemike.top/img/20220511235932.png"></li>
<li>数据类型是1字节，步长是1<img src="https://pic.shaojiemike.top/img/20220512000042.png"></li>
</ol>
<h3 id="zerocopy"><a href="#zerocopy" class="headerlink" title="zerocopy"></a>zerocopy</h3><p>如果我们数据只会在 GPU 产生和使用，我们不需要来回进行拷贝。</p>
<p><a target="_blank" rel="noopener" href="https://migocpp.wordpress.com/2018/06/08/cuda-memory-access-global-zero-copy-unified/">https://migocpp.wordpress.com/2018/06/08/cuda-memory-access-global-zero-copy-unified/</a></p>
<p>简而言之，在 host 使用命令：cudaHostRegisterMapped<br>之后用 cudaHostGetDevicePointer 进行映射<br>最后解除绑定 cudaHostUnregister</p>
<p>即，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// First, pin the memory (or cudaHostAlloc instead)</span><br><span class="line">cudaHostRegister(h_a, …, cudaHostRegisterMapped);</span><br><span class="line">cudaHostRegister(h_b, …, cudaHostRegisterMapped);</span><br><span class="line">cudaHostRegister(h_c, …, cudaHostRegisterMapped);</span><br><span class="line"></span><br><span class="line">cudaHostGetDevicePointer(&amp;a, h_a, 0);</span><br><span class="line">cudaHostGetDevicePointer(&amp;b, h_b, 0);</span><br><span class="line">cudaHostGetDevicePointer(&amp;c, h_c, 0);</span><br><span class="line"></span><br><span class="line">kernel&lt;&lt;&lt;...&gt;&gt;&gt;(a, b, c);</span><br><span class="line">cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line">// unpin/release host memory</span><br><span class="line">cudaHostUnregister(h_a);</span><br><span class="line">cudaHostUnregister(h_b);</span><br><span class="line">cudaHostUnregister(h_c);</span><br></pre></td></tr></table></figure>

<h3 id="cuda-warp-shuffle"><a href="#cuda-warp-shuffle" class="headerlink" title="cuda warp shuffle"></a>cuda warp shuffle</h3><p>只要两个thread在 同一个warp中，允许thread直接读其他thread的寄存器值，这种比通过shared Memory进行thread间的通讯效果更好，latency更低，同时也不消耗额外的内存资源来执行数据交换。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Bruce_0712/article/details/64926471">https://blog.csdn.net/Bruce_0712/article/details/64926471</a></p>
<h3 id="GPU-编译器相对于CPU编译器简单一些"><a href="#GPU-编译器相对于CPU编译器简单一些" class="headerlink" title="GPU 编译器相对于CPU编译器简单一些"></a>GPU 编译器相对于CPU编译器简单一些</h3><p>可能要手动循环展开, 消除分支，GPU分支预测几乎没有</p>
<p><code>#pragma unroll</code> 一句即可展开</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol start="2">
<li><p>thread 和硬件的关系？</p>
</li>
<li><p>shared memory位置和cache的关系（根据GA100，L1 data cache&#x3D;shared memory）</p>
<ol>
<li>联合访问搬数据，没有cache line的概念吗？</li>
</ol>
</li>
<li><p>shared memory VS streaming Multiprocessor</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41598072/article/details/82877655">https://blog.csdn.net/qq_41598072/article/details/82877655</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/junparadox/article/details/50540602">https://blog.csdn.net/junparadox/article/details/50540602</a></li>
</ol>
</li>
<li><p>一个SM有2048个线程？</p>
<ol>
<li><img src="https://pic.shaojiemike.top/img/20220409155719.png"></li>
</ol>
</li>
</ol>
<h2 id="设备参数"><a href="#设备参数" class="headerlink" title="设备参数"></a>设备参数</h2><h3 id="Cuda-Version-GPU-Version"><a href="#Cuda-Version-GPU-Version" class="headerlink" title="Cuda Version &amp; GPU Version"></a>Cuda Version &amp; GPU Version</h3><p>在 <code>CMakeLists.txt</code>里设置 <code>set (CMAKE_CUDA_ARCHITECTURES 61)</code>可用的最大版本号以获得最好的驱动支持。</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/CUDA">https://en.wikipedia.org/wiki/CUDA</a></p>
<h3 id="max-block-max-thread"><a href="#max-block-max-thread" class="headerlink" title="max block &amp; max thread"></a>max block &amp; max thread</h3><p>通过cuda-samples运行输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 下载对应nvcc对应的cuda version的版本</span><br><span class="line">git clone https://github.com/NVIDIA/cuda-samples.git</span><br><span class="line">cd</span><br><span class="line">make -j16</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [23:08:29]</span><br><span class="line">$ ./bin/x86_64/linux/release/deviceQuery</span><br><span class="line">./bin/x86_64/linux/release/deviceQuery Starting...</span><br><span class="line"></span><br><span class="line"> CUDA Device Query (Runtime API) version (CUDART static linking)</span><br><span class="line"></span><br><span class="line">Detected 7 CUDA Capable device(s)</span><br><span class="line"></span><br><span class="line">Device 0: &quot;Tesla P40&quot;</span><br><span class="line">  CUDA Driver Version / Runtime Version          11.4 / 11.0</span><br><span class="line">  CUDA Capability Major/Minor version number:    6.1</span><br><span class="line">  Total amount of global memory:                 22919 MBytes (24032378880 bytes)</span><br><span class="line">  (30) Multiprocessors, (128) CUDA Cores/MP:     3840 CUDA Cores</span><br><span class="line">  GPU Max Clock rate:                            1531 MHz (1.53 GHz)</span><br><span class="line">  Memory Clock rate:                             3615 Mhz</span><br><span class="line">  Memory Bus Width:                              384-bit</span><br><span class="line">  L2 Cache Size:                                 3145728 bytes (3 Gbytes)</span><br><span class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)</span><br><span class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers</span><br><span class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers</span><br><span class="line">  Total amount of constant memory:               65536 bytes (64 Kbytes)</span><br><span class="line">  Total amount of shared memory per block:       49152 bytes (48 Kbytes)</span><br><span class="line">  Total shared memory per multiprocessor(SM):    98304 bytes (96 Kbytes)</span><br><span class="line">  Total number of registers available per block: 65536</span><br><span class="line">  Warp size:                                     32</span><br><span class="line">  Maximum number of threads per multiprocessor:  2048</span><br><span class="line">  Maximum number of threads per block:           1024</span><br><span class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</span><br><span class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</span><br><span class="line">  Maximum memory pitch:                          2147483647 bytes (2 Gbytes)</span><br><span class="line">  Texture alignment:                             512 bytes</span><br><span class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</span><br><span class="line">  Run time limit on kernels:                     No</span><br><span class="line">  Integrated GPU sharing Host Memory:            No</span><br><span class="line">  Support host page-locked memory mapping:       Yes</span><br><span class="line">  Alignment requirement for Surfaces:            Yes</span><br><span class="line">  Device has ECC support:                        Enabled</span><br><span class="line">  Device supports Unified Addressing (UVA):      Yes</span><br><span class="line">  Device supports Managed Memory:                Yes</span><br><span class="line">  Device supports Compute Preemption:            Yes</span><br><span class="line">  Supports Cooperative Kernel Launch:            Yes</span><br><span class="line">  Supports MultiDevice Co-op Kernel Launch:      Yes</span><br><span class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0</span><br><span class="line">  Compute Mode:</span><br><span class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</span><br></pre></td></tr></table></figure>

<p>核心Pascal GP102</p>
<h3 id="各种参数什么意思？"><a href="#各种参数什么意思？" class="headerlink" title="各种参数什么意思？"></a>各种参数什么意思？</h3><ol>
<li>Texture和贴图有关？</li>
<li>global memory 显存</li>
<li>Constant memory: 为特殊的read-only不变量存储来加速，当所有线程同时访问相同的值时，固定内存也是最有效的。</li>
<li>Texture memory：同理为read-only贴图资源，最初是为OpenGL和DirectX渲染设计的</li>
</ol>
<h2 id="CUDA-程序执行的逻辑空间结构"><a href="#CUDA-程序执行的逻辑空间结构" class="headerlink" title="CUDA 程序执行的逻辑空间结构"></a>CUDA 程序执行的逻辑空间结构</h2><!-- <div align="center">
<img src="https://pic.shaojiemike.top/img/20220120182538.png" height="70%" width="70%" >
</div> -->

<p><img src="https://pic.shaojiemike.top/img/20220120182538.png?60"></p>
<p>Host 指“CPU和CPU直接调用的内存”两部分的集合</p>
<p>Device 指“GPU和GPU直接调用的内存”两部分的集合，感觉可以看作显存。<br><img src="https://pic.shaojiemike.top/img/20220120202703.png?60"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);</span><br></pre></td></tr></table></figure>

<h3 id="Block和Thread的理解"><a href="#Block和Thread的理解" class="headerlink" title="Block和Thread的理解"></a>Block和Thread的理解</h3><ol>
<li>cuda Block 级别相当于 C++ 线程，数目可以设置比较大，调度依靠 GPU ，方式类似于 CPU 调度 threads</li>
<li>cuda Thread 级别相当于 SIMD，有数目上限，受限于 cuda core 的数目和一些维度参数</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</span><br><span class="line">Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</span><br></pre></td></tr></table></figure>

<h3 id="使用grid来解决数据数比线程数多的问题"><a href="#使用grid来解决数据数比线程数多的问题" class="headerlink" title="使用grid来解决数据数比线程数多的问题"></a>使用grid来解决数据数比线程数多的问题</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int loopCount = .....;</span><br><span class="line"></span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">int block_dim = ...;</span><br><span class="line">int grid_dim = (loopCount - 1) / block_dim + 1;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">call_kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;();</span><br><span class="line"></span><br><span class="line">__global__ void saxpy(int n, float a, float *x, float *y) &#123;</span><br><span class="line">	for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">		y[i] = a * x[i] + y[i];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="WARP模型——资源调度模型"><a href="#WARP模型——资源调度模型" class="headerlink" title="WARP模型——资源调度模型"></a>WARP模型——资源调度模型</h2><ol>
<li>Nvidia把32个threads组成一个warp，warp是调度和运行的基本单元。warp中所有threads并行的执行相同的指令。一个warp需要占用一个SM运行，多个warps需要轮流进入SM。由SM的硬件warp scheduler负责调度。目前每个warp包含32个threads（Nvidia保留修改数量的权利）。所以，一个GPU上resident thread最多只有 SM*warp个。</li>
<li>大量的thread可能会被分配到不同的SM，<ol>
<li><strong>同一个block中的threads必然在同一个SM中并行（SIMT）执行</strong></li>
<li>每个thread拥有它自己的程序计数器和状态寄存器，并且用该线程自己的数据执行指令，这就是所谓的Single Instruction Multiple Thread。</li>
</ol>
</li>
<li>一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行</li>
<li>Warp内会自动同步？</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(30) Multiprocessors, (128) CUDA Cores/MP:     3840 CUDA Cores</span><br><span class="line">Warp size:                                     32</span><br><span class="line">Maximum number of threads per multiprocessor:  2048</span><br><span class="line">Maximum number of threads per block:           1024</span><br><span class="line">Max dimension size of a thread block (x,y,z): (1024, 1024, 64) # 是x,y,z 各自最大值</span><br><span class="line">Total amount of shared memory per block:       49152 bytes (48 Kbytes)</span><br><span class="line">Total shared memory per multiprocessor(SM):    98304 bytes (96 Kbytes)</span><br><span class="line">Total number of registers available per block: 65536</span><br></pre></td></tr></table></figure>

<h3 id="thread-block-和-Warp-和-core-SM的关系"><a href="#thread-block-和-Warp-和-core-SM的关系" class="headerlink" title="thread block 和 Warp 和 core SM的关系"></a>thread block 和 Warp 和 core SM的关系</h3><ol>
<li><p>为什么一个SM上只有128核但是能同时有1024个线程.</p>
</li>
<li><p>对于P40 一个SM有4个Warp调度器，这是不是意味着，一个SM同时只能有4个，也就是最多128个线程。然而一个SM不是最多2048个thread吗？那岂不是要串行。</p>
<ol>
<li>一个SM发射的32个线程能在小于32个core上运行吗？不能</li>
</ol>
</li>
<li><p>GPU core有多线程吗？ 应该是没有的</p>
<ol>
<li>首先GPU core其实只是CPU里的ALU</li>
<li>Warp调度器当只有4个cuda core需要<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/62147624/how-many-cuda-cores-is-used-to-process-a-cuda-warp">花费8个周期来运行一条指令</a>。<ol>
<li>这4个ALU的core其实实现了SIMD的效果</li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/how-do-cuda-cores-on-a-sm-execute-warps-concurrently/20803/6">Warp调度原理</a></li>
</ol>
</li>
<li><p>虽然我们遗憾的发现 GPU core没有多线程，但是对于Pascal架构的SM只有一种32位的core。我们很容易猜想到对于Int8和Int16是不是有SIMD</p>
<ol>
<li>NVIDIA Tesla P100 can perform FP16 arithmetic at <strong>twice</strong> the throughput of FP32.</li>
<li>Tesla P40 and NVIDIA Titan X, Tesla P4 all support instructions that can perform integer dot products on 2- and <strong>4-element 8-bit vectors</strong>, with accumulation into a 32-bit integer.</li>
<li>可以通过<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/mixed-precision-programming-cuda-8/">cuda8 DP2A and DP4A</a> 等函数编程</li>
<li><a target="_blank" rel="noopener" href="https://www.studocu.com/row/document/sichuan-university-of-science-engineering/computer-science/introduction-to-cuda-10-tensor-core-mixed-precision/6088325">https://www.studocu.com/row/document/sichuan-university-of-science-engineering/computer-science/introduction-to-cuda-10-tensor-core-mixed-precision/6088325</a></li>
</ol>
</li>
<li><p>一个core上能有几个thread并行，是32个吗？还是像CPU一样超线程是2个。还是没有</p>
<ol>
<li>后面这个回答要么是错误的，要么</li>
<li><a target="_blank" rel="noopener" href="https://streamhpc.com/blog/2017-01-24/many-threads-can-run-gpu/">在GPU core上有4到10个线程。</a></li>
<li>原因简单来说是GPU的行为没有CPU那么复杂，可以设计多一点</li>
<li>而且GPU core相当于没有调度器的CPU core是只能数据并行的(SIMD)</li>
<li>CPU 2个线程的设计，只是为了提高利用率</li>
<li>GPU 多线程的设计主要是为了隐藏访存延迟<ol>
<li>由于GPU核数多，导致每个核对应的cache小而且，由于没有复杂的核调度结构来预取</li>
<li>所以通过多线程来隐藏延迟</li>
</ol>
</li>
</ol>
</li>
<li><p>虽然可能一个SM最多有128*16以上线程的能力，但是考虑到寄存器，shared memory等的调度。</p>
<ol>
<li>Nvidia做出了如下<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/question-about-threads-per-block-and-warps-per-sm/77491">限制</a><ol>
<li><strong>Most recent GPUs (excepting Turing) allow a hardware limit of 64 warps per SM</strong></li>
</ol>
</li>
<li>假设1个block有992线程也就是 992&#x2F;32&#x3D;31个warp, 由于有64个的上限.所以一个SM只能有2个block，而不能有更多。</li>
</ol>
</li>
<li><p>我们只能指定block和thread。但是具体怎么划分和调度是由GPU决定的？(我不知道有没有选项)</p>
<ol>
<li><strong>同一个block中的threads必然在同一个SM中并行（SIMT）执行</strong>，来共享shared memory</li>
<li>当然也可以舍弃shared memory的快速访存，来使用更多的计算核(SM&amp;core)并行。这取决于具体问题。</li>
<li>根据前面的问题2，如果为了shared memory硬塞进一个SM会导致串行的问题。<ol>
<li>即便串行也会更快？</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="GP102"><a href="#GP102" class="headerlink" title="GP102"></a>GP102</h3><p><img src="https://pic.shaojiemike.top/img/20220512220943.png"><br>图中红框是一个SM, 绿点是core</p>
<ol>
<li>P40有30个SM，每个SM有4*32&#x3D;128个核。<br><img src="https://pic.shaojiemike.top/img/20220512220904.png"></li>
</ol>
<h3 id="限制的参数"><a href="#限制的参数" class="headerlink" title="限制的参数"></a>限制的参数</h3><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications__technical-specifications-per-compute-capability">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications__technical-specifications-per-compute-capability</a></p>
<table>
<thead>
<tr>
<th>限制</th>
<th>具体值</th>
</tr>
</thead>
<tbody><tr>
<td>Maximum number of threads per block</td>
<td>1024</td>
</tr>
<tr>
<td>Maximum number of resident blocks per SM</td>
<td>16&#x2F;32</td>
</tr>
<tr>
<td>Maximum number of resident warps per SM</td>
<td>64&#x2F;32</td>
</tr>
<tr>
<td>Maximum number of resident threads per SM</td>
<td>2048&#x2F;1024</td>
</tr>
<tr>
<td>Maximum number of 32-bit registers per thread</td>
<td>255</td>
</tr>
<tr>
<td>Maximum amount of shared memory per thread block</td>
<td>48KB&#x2F;96KB&#x2F;64KB</td>
</tr>
</tbody></table>
<h2 id="编程语法"><a href="#编程语法" class="headerlink" title="编程语法"></a>编程语法</h2><h3 id="函数前缀"><a href="#函数前缀" class="headerlink" title="函数前缀"></a>函数前缀</h3><p>与函数调用设备有关<br><img src="https://pic.shaojiemike.top/img/20220504203555.png"></p>
<table>
<thead>
<tr>
<th>函数前缀名称</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>__ global__</td>
<td>指定函数是CPU上调用，GPU上执行</td>
</tr>
<tr>
<td>__ device__</td>
<td>指定函数是GPU上调用，GPU上执行</td>
</tr>
<tr>
<td>__ host __</td>
<td>指定函数是CPU上调用，CPU上执行(最正常的函数，平常就省略不写)</td>
</tr>
</tbody></table>
<p>如果一个函数不加修饰，默认他是 <code>_device_</code> 函数，正如上面的 main 一样。</p>
<h3 id="变量修饰符"><a href="#变量修饰符" class="headerlink" title="变量修饰符"></a>变量修饰符</h3><table>
<thead>
<tr>
<th>变量修饰符</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>__ device__</td>
<td>数据存放在显存中，所有的线程都可以访问，而且CPU也可以通过运行时库访问</td>
</tr>
<tr>
<td>__ shared__</td>
<td>数据存放在共享存储器在，只有在所在的块内的线程可以访问，其它块内的线程不能访问</td>
</tr>
<tr>
<td>__ constant__</td>
<td>数据存放在常量存储器中，可以被所有的线程访问，也可以被CPU通过运行时库访问</td>
</tr>
<tr>
<td>Texture</td>
<td>纹理内存（Texture Memory）也是一种只读内存。</td>
</tr>
<tr>
<td>&#x2F;</td>
<td>没有限定符，那表示它存放在寄存器或者本地存储器中，在寄存器中的数据只归线程所有，其它线程不可见。</td>
</tr>
</tbody></table>
<h3 id="SMEM-静态与动态声明"><a href="#SMEM-静态与动态声明" class="headerlink" title="SMEM 静态与动态声明"></a>SMEM 静态与动态声明</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// array with a fixed size</span><br><span class="line">__shared__ float s_in[34];</span><br><span class="line">// allocate the array dynamically,</span><br><span class="line">extern __shared__ float s_in[];</span><br></pre></td></tr></table></figure>
<p>动态的<code>s_in</code>大小，在kernel的第三个参数指定<code>smemSize</code>字节数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int smemSize = (TPB + 2)*sizeof(float);</span><br><span class="line">ddKernel &lt;&lt;&lt; (n+TPB-1)/TPB, TPB, smemSize&gt;&gt;&gt; (args)</span><br></pre></td></tr></table></figure>
<h3 id="配置运算符"><a href="#配置运算符" class="headerlink" title="配置运算符"></a>配置运算符</h3><p><img src="https://pic.shaojiemike.top/img/20220120195454.png"><br><img src="https://pic.shaojiemike.top/img/20220120195629.png"></p>
<p> 执行配置运算符 <code>&lt;&lt;&lt; &gt;&gt;&gt;</code>，用来传递内核函数的执行参数。执行配置有四个参数，</p>
<p> 第一个参数声明<strong>网格</strong>的大小，</p>
<p> 第二个参数声明<strong>块</strong>的大小，</p>
<p> 第三个参数声明动态分配的<strong>共享存储器</strong>大小，默认为 0，</p>
<p> 最后一个参数声明<strong>执行的流</strong>，默认为 0.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;grid,block&gt;&gt;&gt;(a,b);</span><br></pre></td></tr></table></figure>

<h4 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h4><p><img src="https://pic.shaojiemike.top/img/20220120200109.png"></p>
<h3 id="CUDA内置变量"><a href="#CUDA内置变量" class="headerlink" title="CUDA内置变量"></a>CUDA内置变量</h3><table>
<thead>
<tr>
<th>变量</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>gridDim</td>
<td>gridDim 是一个包含三个元素 x,y,z 的结构体，分别表示网格在x,y,z 三个方向上的尺寸(一般只有2维度)</td>
</tr>
<tr>
<td>blockDim</td>
<td>blockDim 也是一个包含三个元素 x,y,z 的结构体，分别表示块在x,y,z 三个方向上的尺寸</td>
</tr>
<tr>
<td>blockIdx</td>
<td>blockIdx 也是一个包含三个元素 x,y,z 的结构体，分别表示当前线程块在网格中 x,y,z 三个方向上的索引</td>
</tr>
<tr>
<td>threadIdx</td>
<td>是一个包含三个元素 x,y,z 的结构体，分别表示当前线程在其所在块中 x,y,z 三个方向上的索引</td>
</tr>
<tr>
<td>warpSize</td>
<td>在计算能力为 1.0 的设备中，这个值是24，在 1.0 以上的设备中，这个值是 32</td>
</tr>
</tbody></table>
<p>三维的举例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kernel() &#123;  </span><br><span class="line">   printf(&quot;Block (%d,%d,%d) of (%d,%d,%d), Thread (%d,%d,%d) of (%d,%d,%d)\n&quot;,  </span><br><span class="line">          blockIdx.x, blockIdx.y, blockIdx.z,  </span><br><span class="line">          gridDim.x, gridDim.y, gridDim.z,  </span><br><span class="line">          threadIdx.x, threadIdx.y, threadIdx.z,  </span><br><span class="line">          blockDim.x, blockDim.y, blockDim.z);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">int main() &#123;  </span><br><span class="line">   kernel&lt;&lt;&lt;dim3(2, 1, 1), dim3(2, 2, 2)&gt;&gt;&gt;();  </span><br><span class="line">   cudaDeviceSynchronize();  </span><br><span class="line">   return 0;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (0,0,0) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (1,0,0) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (0,1,0) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (1,1,0) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (0,0,1) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (1,0,1) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (0,1,1) of (2,2,2)  </span><br><span class="line">Block (0,0,0) of (2,1,1), Thread (1,1,1) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (0,0,0) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (1,0,0) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (0,1,0) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (1,1,0) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (0,0,1) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (1,0,1) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (0,1,1) of (2,2,2)  </span><br><span class="line">Block (1,0,0) of (2,1,1), Thread (1,1,1) of (2,2,2)</span><br></pre></td></tr></table></figure>

<p>二维的例子,最后一个维度都是 0, 我们使用结果的时候不使用 z 维度即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kernel() &#123;  </span><br><span class="line">   printf(&quot;Block (%d,%d,%d) of (%d,%d,%d), Thread (%d,%d,%d) of (%d,%d,%d)\n&quot;,  </span><br><span class="line">          blockIdx.x, blockIdx.y, blockIdx.z,  </span><br><span class="line">          gridDim.x, gridDim.y, gridDim.z,  </span><br><span class="line">          threadIdx.x, threadIdx.y, threadIdx.z,  </span><br><span class="line">          blockDim.x, blockDim.y, blockDim.z);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">int main() &#123;  </span><br><span class="line">   kernel&lt;&lt;&lt;dim3(2, 3, 1), dim3(2, 1, 1)&gt;&gt;&gt;();  </span><br><span class="line">   cudaDeviceSynchronize();  </span><br><span class="line">   return 0;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Block (1,2,0) of (2,3,1), Thread (0,0,0) of (2,1,1)  </span><br><span class="line">Block (1,2,0) of (2,3,1), Thread (1,0,0) of (2,1,1)  </span><br><span class="line">Block (0,2,0) of (2,3,1), Thread (0,0,0) of (2,1,1)  </span><br><span class="line">Block (0,2,0) of (2,3,1), Thread (1,0,0) of (2,1,1)  </span><br><span class="line">Block (0,1,0) of (2,3,1), Thread (0,0,0) of (2,1,1)  </span><br><span class="line">Block (0,1,0) of (2,3,1), Thread (1,0,0) of (2,1,1)  </span><br><span class="line">Block (1,0,0) of (2,3,1), Thread (0,0,0) of (2,1,1)  </span><br><span class="line">Block (1,0,0) of (2,3,1), Thread (1,0,0) of (2,1,1)  </span><br><span class="line">Block (0,0,0) of (2,3,1), Thread (0,0,0) of (2,1,1)  </span><br><span class="line">Block (0,0,0) of (2,3,1), Thread (1,0,0) of (2,1,1)  </span><br><span class="line">Block (1,1,0) of (2,3,1), Thread (0,0,0) of (2,1,1)  </span><br><span class="line">Block (1,1,0) of (2,3,1), Thread (1,0,0) of (2,1,1)</span><br></pre></td></tr></table></figure>

<h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h2><p>调用 GPU 的函数声明和定义不要分离，写在同一个文件里。分开(如：CUDA_SEPARABLE_COMPILATION)可能影响内联导致性能损失。</p>
<h3 id="访存"><a href="#访存" class="headerlink" title="访存"></a>访存</h3><p><img src="https://pic.shaojiemike.top/img/20220504210154.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__host____device__cudaError_t 	cudaMalloc ( void** devPtr, size_t size )</span><br><span class="line">cudaMallocPitch() //分配二维数组空间并自动对齐</span><br><span class="line">//在显存中为待运算的数据以及需要存放结果的变量开辟显存空间。</span><br><span class="line">__host____device__cudaError_t cudaFree ( void* devPtr )</span><br><span class="line">__host__cudaError_t cudaMemcpy ( void* dst, const void* src, size_t count, cudaMemcpyKind kind )</span><br></pre></td></tr></table></figure>

<p> where <strong>kind</strong> specifies the direction of the copy, and must be one of <strong>cudaMemcpyHostToHost</strong>, <strong>cudaMemcpyHostToDevice</strong>, <strong>cudaMemcpyDeviceToHost</strong>, <strong>cudaMemcpyDeviceToDevice</strong>, or <strong>cudaMemcpyDefault</strong>. Passing <strong>cudaMemcpyDefault</strong> is recommended, in which case the type of transfer is inferred from the pointer values. However, cudaMemcpyDefault is only allowed on systems that support unified virtual addressing. Calling cudaMemcpy() with dst and src pointers that do not match the direction of the copy results in an undefined behavior.</p>
<p> cudaMemcpy可以自动实现同步工作，可以省去cudaDeviceSynchronize。</p>
<p>可以通过 <code>cudaMallocManaged(&amp;a, sizeof(int) * 12)</code>申请在 Host 和 Device 上都直接使用的<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/unified-memory-in-cuda-6/">Unified Memory</a>。性能多数情况会损失。</p>
<h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__host____device__cudaError_t 	cudaDeviceSynchronize ( void )</span><br><span class="line">//Wait for compute device to finish.</span><br><span class="line"></span><br><span class="line">__syncthreads() //block内线程快速同步</span><br></pre></td></tr></table></figure>

<h3 id="字符打印输出"><a href="#字符打印输出" class="headerlink" title="字符打印输出"></a>字符打印输出</h3><p>很明显CPU和GPU打印是异步的，需要同步。</p>
<p>而且cuda暂时不支持cout等流输出语句。</p>
<h3 id="Debug打印"><a href="#Debug打印" class="headerlink" title="Debug打印"></a>Debug打印</h3><p><code>cudaError_t</code>是不能理解的输出。 cuda samples 里面提供了 <code>helper_cuda.h</code> 头文件解决问题。 Debug 的时候也可以直接把 gridDim 改成 1, 更方便</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># CMakeLists.txt</span><br><span class="line">target_include_directories(hello PUBLIC /usr/local/cuda/samples/common/inc)</span><br><span class="line"></span><br><span class="line">checkCudaErrors(cudaDeviceSynchronize());</span><br></pre></td></tr></table></figure>

<h3 id="时间统计打印"><a href="#时间统计打印" class="headerlink" title="时间统计打印"></a>时间统计打印</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t begin, end;</span><br><span class="line">cudaEventCreate(&amp;begin);</span><br><span class="line">cudaEventCreate(&amp;end);</span><br><span class="line"></span><br><span class="line">cudaEventRecord(begin);</span><br><span class="line"></span><br><span class="line">// do sth</span><br><span class="line"></span><br><span class="line">cudaEventRecord(end);</span><br><span class="line">cudaEventSynchronize (end);</span><br><span class="line"></span><br><span class="line">float elapsedTime;</span><br><span class="line">cudaEventElapsedTime (&amp;elapsed, begin, end);</span><br><span class="line">elapsedTime /= 1000;</span><br><span class="line"></span><br><span class="line">cudaEventDestroy (end);</span><br><span class="line">cudaEventDestroy (begin);</span><br><span class="line"></span><br><span class="line">return elapsedTime;</span><br></pre></td></tr></table></figure>

<h3 id="函数指针和lambda算子"><a href="#函数指针和lambda算子" class="headerlink" title="函数指针和lambda算子"></a>函数指针和lambda算子</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;  </span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n, Func func)</span> </span>&#123;  </span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;  </span><br><span class="line">        i &lt; n; i += blockDim.x * gridDim.x) &#123;  </span><br><span class="line">       <span class="built_in">func</span>(arr, i);  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">funcop1</span> &#123;  </span><br><span class="line">   <span class="function">__device__ <span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> i)</span> </span>&#123;  </span><br><span class="line">       arr[i] = i;  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">funcop2</span> &#123;  </span><br><span class="line">   <span class="function">__device__ <span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> i)</span> </span>&#123;  </span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">&quot;%d %f\n&quot;</span>, arr[i], <span class="built_in">sinf</span>(arr[i]));  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用</span></span><br><span class="line">kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(arr, n, funcop1&#123;&#125;); </span><br><span class="line">kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(arr, n, funcop2&#123;&#125;);</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// lambda算子</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;  </span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;  </span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;  </span><br><span class="line">        i &lt; n; i += blockDim.x * gridDim.x) &#123;  </span><br><span class="line">       <span class="built_in">func</span>(i);  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (<span class="type">int</span> i) &#123;  </span><br><span class="line">       arr[i] = i;  </span><br><span class="line">   &#125;);</span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line">kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (<span class="type">int</span> i) &#123;  </span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">&quot;%d, %f\n&quot;</span>, i, <span class="built_in">sinf</span>(arr[i]));  </span><br><span class="line">   &#125;);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// lambda算子例子2</span><br><span class="line">template &lt;class Func&gt;  </span><br><span class="line">__global__ void kernel(int n, Func func) &#123;  </span><br><span class="line">   for (int i = blockDim.x * blockIdx.x + threadIdx.x;  </span><br><span class="line">        i &lt; n; i += blockDim.x * gridDim.x) &#123;  </span><br><span class="line">       func(i);  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [x = x_dev.data(), y = y_dev.data()] __device__ (int index)&#123;  </span><br><span class="line">       x[index] = x[index] + y[index];  </span><br><span class="line">   &#125;);</span><br></pre></td></tr></table></figure>

<h3 id="cuda-容器的实现——thrust"><a href="#cuda-容器的实现——thrust" class="headerlink" title="cuda 容器的实现——thrust"></a>cuda 容器的实现——thrust</h3><p>STL 容器 cuda 并没有很好的适配和实现，CUDA对应的叫做thrust 库被称为： Template library for CUDA</p>
<p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/thrust/index.html">https://docs.nvidia.com/cuda/thrust/index.html</a></p>
<p><a target="_blank" rel="noopener" href="https://thrust.github.io/doc/namespacethrust.html">https://thrust.github.io/doc/namespacethrust.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">thrust::host_vector&lt;float&gt; x_host(n);</span><br><span class="line">thrust::generate(x_host.begin(), x_host.end(), []&#123;return std::rand() / 3.0;&#125;);</span><br><span class="line"></span><br><span class="line">thrust::device_vector&lt;float&gt; x_dev(n); </span><br><span class="line">x_dev = x_host;</span><br></pre></td></tr></table></figure>

<h3 id="全局变量传递"><a href="#全局变量传递" class="headerlink" title="全局变量传递"></a>全局变量传递</h3><p>GPU计算的全局变量 <code>sum</code>最后传递到CPU的 <code>result</code>里</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__device__ float sum = 0;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    float result = 0;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">cudaMemcpyFromSymbol(&amp;result, sum, sizeof(float), 0, cudaMemcpyDeviceToHost);</span><br></pre></td></tr></table></figure>

<h3 id="常见原子操作"><a href="#常见原子操作" class="headerlink" title="常见原子操作"></a>常见原子操作</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">atomicAdd (dst, src)</span><br><span class="line">atomicSub(dst, src)</span><br><span class="line">atomicOr(dst, src)</span><br><span class="line">atomicAnd(dst, src)</span><br><span class="line">atomicXor(dst, src)</span><br><span class="line">atomicMax(dst, src)</span><br><span class="line">atomicMin(dst, src)</span><br></pre></td></tr></table></figure>

<p>他们都有返回值，返回违背更改前的数值。</p>
<p>也可以通过 <code>atomicCAS</code>自定义原子操作。但是前面的原子操作有特殊设计的，会基于blockDim和gridDim,并行各块串行执行然后规约。</p>
<h2 id="单卡多GPU的实现"><a href="#单卡多GPU的实现" class="headerlink" title="单卡多GPU的实现"></a>单卡多GPU的实现</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> gpu_numbers = <span class="built_in">cudaGetDeviceCount</span>();</span><br><span class="line"><span class="type">int</span> *pointers[gpu_numbers];</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> index = <span class="number">0</span>; index &lt; gpu_numbers; ++index) &#123;</span><br><span class="line">   <span class="built_in">cudaSetDevice</span>(index);</span><br><span class="line">   <span class="built_in">cudaMalloc</span>(&amp;pointers[index], size);</span><br><span class="line">&#125;<span class="comment">//在各自卡上声明空间</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> indexi = <span class="number">0</span>; indexi &lt; gpu_numbers; ++indexi) &#123;</span><br><span class="line">   <span class="built_in">cudaSetDevice</span>(indexi); <span class="comment">//设置当前卡</span></span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> indexj = <span class="number">0</span>; indexj &lt; gpu_numbers; ++indexj) &#123;</span><br><span class="line">      <span class="keyword">if</span> (indexi == indexj)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">      <span class="built_in">cudaDeviceEnablePeerAccess</span>(indexj, <span class="number">0</span>); <span class="comment">//打通indexj与当前卡的访问</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> index = <span class="number">1</span>; index &lt; gpu_numbers; ++index) &#123;</span><br><span class="line">   <span class="built_in">cudaMemcpyAsync</span>(pointers[<span class="number">0</span>], pointers[index], size, cudaMemcpyDeviceToDevice); <span class="comment">//非阻塞memoryCopy，在这里实现device0到其他的广播</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="指定某卡运行程序"><a href="#指定某卡运行程序" class="headerlink" title="指定某卡运行程序"></a>指定某卡运行程序</h2><p>通过环境变量实现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=1</span><br><span class="line">export CUDA_VISIBLE_DEVICES=0,1 # 多卡</span><br><span class="line">CUDA_VISIBLE_DEVICES=1 ./cuda_executable</span><br></pre></td></tr></table></figure>

<h2 id="测试运行"><a href="#测试运行" class="headerlink" title="测试运行"></a>测试运行</h2><p>现有cuda 是兼容 C++17 语法的，可以减少移植工作量<br><img src="https://pic.shaojiemike.top/img/20220504204514.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_ROOT=/usr/local/cuda/bin</span><br><span class="line">export PATH=$CUDA_ROOT:$PATH</span><br><span class="line">which nvcc</span><br><span class="line">nvcc -V</span><br><span class="line">nvcc src.cu -o a.out</span><br><span class="line">./a.out</span><br></pre></td></tr></table></figure>

<p>发现版本太老了不支持更新的gcc，自己安装最新cuda</p>
<h2 id="nvcc优化选项"><a href="#nvcc优化选项" class="headerlink" title="nvcc优化选项"></a>nvcc优化选项</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">target_compile_options($&#123;exe&#125;  PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:</span><br><span class="line">			-Xptxas </span><br><span class="line">			-O3 </span><br><span class="line">			-v </span><br><span class="line">			--use_fast_math</span><br><span class="line">	&gt;)</span><br></pre></td></tr></table></figure>
<h3 id="fast-math"><a href="#fast-math" class="headerlink" title="fast math"></a>fast math</h3><p><code>–-use_fast_math</code>对于频繁的数学函数：三角函数、快速傅立叶变换、幂次、根号有5~15%的效率提升。</p>
<h3 id="ECC"><a href="#ECC" class="headerlink" title="ECC"></a>ECC</h3><p>ECC(error correcting code,  错误检查和纠正)能够提高数据的正确性，随之而来的是可用内存的减少和性能上的损失。对于Tesla系列伺服器该功能默认开启。</p>
<p>通过命令 nvidia-smi -i n</p>
<p>可查看第n个个显卡的简要信息（详细信息可通过 nvidia-smi -q -i 0获取），其中有一项是volatile Uncorr. ECC, 可通过该选项查看当前配置。</p>
<p>通过 nvidia-smi -i n -e 0&#x2F;1 可关闭(0)&#x2F;开启(1)第n号GPU的ECC模式。</p>
<p>通过实践，关闭ECC程序的性能能得到13%~15%的提升。</p>
<h2 id="CUDA实例"><a href="#CUDA实例" class="headerlink" title="CUDA实例"></a>CUDA实例</h2><h3 id="CUDA项目"><a href="#CUDA项目" class="headerlink" title="CUDA项目"></a>CUDA项目</h3><p><a target="_blank" rel="noopener" href="https://github.com/Kirrito-k423/StencilAcc">https://github.com/Kirrito-k423/StencilAcc</a></p>
<h3 id="一维的例子"><a href="#一维的例子" class="headerlink" title="一维的例子"></a>一维的例子</h3><p>2^m次个数组的数，怎么求和。</p>
<p>先将数据分成多个block,每个block里面进行第一遍归约。</p>
<p>第二个for的作用</p>
<p> for 循环中的算法就是将数组的后一半加到前一半上去,然后再在前一半中的后一半加到前一半的前一半中…</p>
<p> 这中被称为“对数归约”,循环完成后一个block 中的和是sPartials[0]的值.</p>
<p> 接着，将这个值导出到out中.</p>
<p><img src="https://pic.shaojiemike.top/img/20220120210401.png"><br><img src="https://pic.shaojiemike.top/img/20220120210632.png"></p>
<h2 id="CUDA使用的常见问题"><a href="#CUDA使用的常见问题" class="headerlink" title="CUDA使用的常见问题"></a>CUDA使用的常见问题</h2><h3 id="Install-CUDA-Toolkit-without-sudo"><a href="#Install-CUDA-Toolkit-without-sudo" class="headerlink" title="Install CUDA Toolkit without sudo"></a>Install CUDA Toolkit without sudo</h3><ol>
<li>Download your runfile according to your OS（<br><code>lsb_release -a</code> <code>unname -a</code>） in here(<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=runfile_local">https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=20.04&amp;target_type=runfile_local</a>).</li>
<li>Run <code>md5sum</code> on your run file to make sure it is not corrupted. The correct checksum is on your CUDA download page. Note, somehow, this file is easily being corrupted. Make sure to check it.</li>
<li>Execute the <code>runfile</code> with the <code>--toolkitpath</code> option, <strong>where the path</strong> is where you would like the toolkit to sit on. Thus, there is no root requirement. –toolkit is to only install CUDA toolkit (no driver). The <code>--override</code> option might not be needed but if there is warning you might want to turn it on.<br><code>bash cuda_10.0.130_410.48_linux --silent --override --toolkit --toolkitpath=$HOME/Install/cuda10</code></li>
<li>In your <code>bashrc</code> or <code>zshrc</code> file, specify the three PATHs</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PATH=/usr/local/cuda/bin:$PATH</span><br><span class="line">CPATH=/usr/local/cuda/include:$CPATH </span><br><span class="line">LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>

<h3 id="Install-pre-CUDA-Toolkit"><a href="#Install-pre-CUDA-Toolkit" class="headerlink" title="Install pre CUDA Toolkit"></a>Install pre CUDA Toolkit</h3><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/95939378">https://zhuanlan.zhihu.com/p/95939378</a></p>
<h3 id="Failed-to-initialize-NVML-Driver-library-version-mismatch"><a href="#Failed-to-initialize-NVML-Driver-library-version-mismatch" class="headerlink" title="Failed to initialize NVML: Driver&#x2F;library version mismatch"></a>Failed to initialize NVML: Driver&#x2F;library version mismatch</h3><p><img src="https://pic.shaojiemike.top/img/20220127174948.png"></p>
<h3 id="driver-version-VS-runtime-version"><a href="#driver-version-VS-runtime-version" class="headerlink" title="driver version VS runtime version?"></a>driver version VS runtime version?</h3><p><img src="https://pic.shaojiemike.top/img/20220123210917.png"></p>
<p>cuda有两套主要的API，</p>
<p>一套是 the <strong>driver</strong> API (e.g. libcuda.so on linux and <strong>nvidia-smi</strong>) is installed by the <strong>GPU driver installer.</strong> 识别GPU硬件的驱动</p>
<p>另一套是 the <strong>runtime</strong> API (e.g. libcudart.so on linux, and also <strong>nvcc</strong>) is installed by the <strong>CUDA toolkit installer</strong> (which may also have a GPU driver installer bundled in it). 提供cuda编程的各种常用函数库和接口</p>
<p>关系：</p>
<ol>
<li>两者不是必须一致。</li>
<li>CUDA Driver Version应该是跟着GPU驱动走的，Runtime Version取决于当前设置。Driver Version一般 &gt;&#x3D; Runtime Version, 否则insufficient。</li>
<li>软件运行时调用的应该是Runtime Version。</li>
</ol>
<h3 id="check-driver-version-VS-runtime-version"><a href="#check-driver-version-VS-runtime-version" class="headerlink" title="check driver version VS runtime version"></a>check driver version VS runtime version</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># runtime version</span><br><span class="line">nvcc -V</span><br><span class="line">cat /usr/local/cuda/version.txt</span><br><span class="line"># driver version</span><br><span class="line">nvidia-smi</span><br><span class="line">cat /proc/driver/nvidia/version</span><br><span class="line">modinfo nvidia|grep version:</span><br></pre></td></tr></table></figure>

<h4 id="how-to-download-driver-version"><a href="#how-to-download-driver-version" class="headerlink" title="how to download driver version"></a>how to download driver version</h4><p>windows:<br><a target="_blank" rel="noopener" href="https://www.nvidia.com/Download/driverResults.aspx/185108/en-us">https://www.nvidia.com/Download/driverResults.aspx/185108/en-us</a></p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247507610&idx=1&sn=755193a7dcd1cad4a165e97e1732121b&chksm=c1946184f6e3e892ad65417c24ab329700e25e755e595a991984ecc3303a90c2dd946cba6001&mpshare=1&scene=24&srcid=05073XR8nAsQu7SWEpiog9Wa&sharer_sharetime=1683440747315&sharer_shareid=63ffea37fc31f685dff5e527826646aa#rd">实例：手写 CUDA 算子，让 Pytorch 提速 20 倍</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#function-parameters">https://docs.nvidia.com/cuda/cuda-c-programming-guide/#function-parameters</a></p>
<p>例子代码:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/chivier/cutests">https://github.com/chivier/cutests</a></p>
<p><a target="_blank" rel="noopener" href="https://chivier.github.io/2022/02/20/2022/2202-CudaProgramming/">https://chivier.github.io/2022/02/20/2022/2202-CudaProgramming/</a></p>
<p><a target="_blank" rel="noopener" href="https://chivier.github.io/2022/04/11/2022/2204-GPU%E7%A8%8B%E5%BA%8F%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/">https://chivier.github.io/2022/04/11/2022/2204-GPU%E7%A8%8B%E5%BA%8F%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</a></p>
<p><a target="_blank" rel="noopener" href="https://comzyh.com/blog/archives/967/">https://comzyh.com/blog/archives/967/</a></p>
<p><a target="_blank" rel="noopener" href="https://itlanyan.com/cuda-enable-disable-ecc/">https://itlanyan.com/cuda-enable-disable-ecc/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-22T16:00:00.000Z" title="5/22/2022, 4:00:00 PM">2022-05-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-15T16:59:48.449Z" title="11/15/2023, 4:59:48 PM">2023-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">5 minutes read (About 802 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/22/Work/HPC/cuda/cudaVectorizedMemoryAccess/">Cuda Vectorized Memory Access</a></p><div class="content"><h2 id="baseline"><a href="#baseline" class="headerlink" title="baseline"></a>baseline</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">device_copy_scalar_kernel</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> &#123; </span><br><span class="line">  <span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x; </span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = idx; i &lt; N; i += blockDim.x * gridDim.x) &#123; </span><br><span class="line">    d_out[i] = d_in[i]; </span><br><span class="line">  &#125; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">device_copy_scalar</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> </span><br><span class="line">&#123; </span><br><span class="line">  <span class="type">int</span> threads = <span class="number">128</span>; </span><br><span class="line">  <span class="type">int</span> blocks = min((N + threads<span class="number">-1</span>) / threads, MAX_BLOCKS);  </span><br><span class="line">  device_copy_scalar_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_in, d_out, N); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>简单的分块拷贝。</p>
<p>通过<code>cuobjdump -sass executable</code>.得到对应的标量copy对应的SASS代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/*0058*/ IMAD R6.CC, R0, R9, c[0x0][0x140]                </span><br><span class="line">/*0060*/ IMAD.HI.X R7, R0, R9, c[0x0][0x144]              </span><br><span class="line">/*0068*/ IMAD R4.CC, R0, R9, c[0x0][0x148]               </span><br><span class="line">/*0070*/ LD.E R2, [R6]                                   </span><br><span class="line">/*0078*/ IMAD.HI.X R5, R0, R9, c[0x0][0x14c]              </span><br><span class="line">/*0090*/ ST.E [R4], R2</span><br></pre></td></tr></table></figure>
<p>（SASS不熟悉，请看SASS一文）</p>
<p>其中4条IMAD指令计算出读取和存储的指令地址<code>R6:R7</code>和<code>R4:R5</code>。第4和6条指令执行32位的访存命令。</p>
<h2 id="Vector-way1-CUDA-C-C-standard-headers"><a href="#Vector-way1-CUDA-C-C-standard-headers" class="headerlink" title="Vector way1:  CUDA C&#x2F;C++ standard headers"></a>Vector way1:  CUDA C&#x2F;C++ standard headers</h2><p>通过使用<code>int2</code>, <code>int4</code>, or <code>float2</code></p>
<p>比如将<code>int</code>的指针<code>d_in</code>类型转换然后赋值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reinterpret_cast&lt;int2*&gt;(d_in)</span><br><span class="line">// simple in C99</span><br><span class="line">(int2*(d_in))</span><br></pre></td></tr></table></figure>

<p>但是需要注意对齐问题，比如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reinterpret_cast&lt;int2*&gt;(d_in+1)</span><br></pre></td></tr></table></figure>
<p>这样是非法的。</p>
<h2 id="Vector-way2-structures"><a href="#Vector-way2-structures" class="headerlink" title="Vector way2:  structures"></a>Vector way2:  structures</h2><p>通过使用对齐的结构体来实现同样的目的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct Foo &#123;int a, int b, double c&#125;; // 16 bytes in size</span><br><span class="line">Foo *x, *y;</span><br><span class="line">…</span><br><span class="line">x[i]=y[i];</span><br></pre></td></tr></table></figure>

<h2 id="实际修改LD-E-64"><a href="#实际修改LD-E-64" class="headerlink" title="实际修改LD.E.64"></a>实际修改LD.E.64</h2><p>执行for循环次数减半，注意边界处理。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void device_copy_vector2_kernel(int* d_in, int* d_out, int N) &#123;</span><br><span class="line">  int idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  for (int i = idx; i &lt; N/2; i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    reinterpret_cast&lt;int2*&gt;(d_out)[i] = reinterpret_cast&lt;int2*&gt;(d_in)[i];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // in only one thread, process final element (if there is one)</span><br><span class="line">  if (idx==N/2 &amp;&amp; N%2==1)</span><br><span class="line">    d_out[N-1] = d_in[N-1];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void device_copy_vector2(int* d_in, int* d_out, int n) &#123;</span><br><span class="line">  threads = 128; </span><br><span class="line">  blocks = min((N/2 + threads-1) / threads, MAX_BLOCKS); </span><br><span class="line"></span><br><span class="line">  device_copy_vector2_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_in, d_out, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对应汇编可以看出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/*0088*/                IMAD R10.CC, R3, R5, c[0x0][0x140]              </span><br><span class="line">/*0090*/                IMAD.HI.X R11, R3, R5, c[0x0][0x144]            </span><br><span class="line">/*0098*/                IMAD R8.CC, R3, R5, c[0x0][0x148]             </span><br><span class="line">/*00a0*/                LD.E.64 R6, [R10]                                      </span><br><span class="line">/*00a8*/                IMAD.HI.X R9, R3, R5, c[0x0][0x14c]           </span><br><span class="line">/*00c8*/                ST.E.64 [R8], R6</span><br></pre></td></tr></table></figure>
<p>变成了<code>LD.E.64</code></p>
<h2 id="实际修改LD-E-128"><a href="#实际修改LD-E-128" class="headerlink" title="实际修改LD.E.128"></a>实际修改LD.E.128</h2><p>执行for循环次数减半，注意边界处理。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">__global__ void device_copy_vector4_kernel(int* d_in, int* d_out, int N) &#123;</span><br><span class="line">  int idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  for(int i = idx; i &lt; N/4; i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    reinterpret_cast&lt;int4*&gt;(d_out)[i] = reinterpret_cast&lt;int4*&gt;(d_in)[i];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // in only one thread, process final elements (if there are any)</span><br><span class="line">  int remainder = N%4;</span><br><span class="line">  if (idx==N/4 &amp;&amp; remainder!=0) &#123;</span><br><span class="line">    while(remainder) &#123;</span><br><span class="line">      int idx = N - remainder--;</span><br><span class="line">      d_out[idx] = d_in[idx];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void device_copy_vector4(int* d_in, int* d_out, int N) &#123;</span><br><span class="line">  int threads = 128;</span><br><span class="line">  int blocks = min((N/4 + threads-1) / threads, MAX_BLOCKS);</span><br><span class="line"></span><br><span class="line">  device_copy_vector4_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_in, d_out, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对应汇编可以看出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/*0090*/                IMAD R10.CC, R3, R13, c[0x0][0x140]              </span><br><span class="line">/*0098*/                IMAD.HI.X R11, R3, R13, c[0x0][0x144]            </span><br><span class="line">/*00a0*/                IMAD R8.CC, R3, R13, c[0x0][0x148]               </span><br><span class="line">/*00a8*/                LD.E.128 R4, [R10]                               </span><br><span class="line">/*00b0*/                IMAD.HI.X R9, R3, R13, c[0x0][0x14c]             </span><br><span class="line">/*00d0*/                ST.E.128 [R8], R4</span><br></pre></td></tr></table></figure>
<p>变成了<code>LD.E.128</code></p>
<h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p><img src="https://pic.shaojiemike.top/img/20220523145942.png"></p>
<p>(个人感觉，提升也不大吗？也没有两倍和四倍的效果)</p>
<p>绝大部分情况，向量比标量好， increase bandwidth, reduce instruction count, and reduce latency. 。</p>
<p>但是会增加额外的寄存器(SASS里也没有看到？？)和降低并行性(什么意思？？？)</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/#entry-content-comments">https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/#entry-content-comments</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-21T16:00:00.000Z" title="5/21/2022, 4:00:00 PM">2022-05-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-15T16:59:48.449Z" title="11/15/2023, 4:59:48 PM">2023-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">4 minutes read (About 578 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/21/Work/HPC/cuda/StencilOptimize/">Stencil Cuda Optimize</a></p><div class="content"><h2 id="课程报告PPT"><a href="#课程报告PPT" class="headerlink" title="课程报告PPT"></a>课程报告PPT</h2><p>有对应的<a target="_blank" rel="noopener" href="https://github.com/Kirrito-k423/StencilAcc">PPT，代码。</a></p>
<p>最终将1000ms程序优化到1~2ms</p>
<p>乔良师兄有根据<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/435908830">知乎</a>介绍如何利用寄存器文件缓存</p>
<h2 id="SMEM难点-跨线程访存"><a href="#SMEM难点-跨线程访存" class="headerlink" title="SMEM难点: 跨线程访存"></a>SMEM难点: 跨线程访存</h2><ol>
<li>不仅每个线程需要访问自己划分对应区域之外的元素</li>
<li>而且访问的总个数也不是线程数对应的倍数<br><img src="https://pic.shaojiemike.top/img/20220518112312.png"></li>
</ol>
<p>导致Embarrassingly Parallel Problems</p>
<p><img src="https://pic.shaojiemike.top/img/20220518112443.png"></p>
<h2 id="1D-梯度计算-Stencil实例"><a href="#1D-梯度计算-Stencil实例" class="headerlink" title="1D 梯度计算 Stencil实例"></a>1D 梯度计算 Stencil实例</h2><p>计算某点的梯度，需要前后的function值。<br><img src="https://pic.shaojiemike.top/img/20220518113236.png"></p>
<h2 id="Halo-Ghost-Cells-光晕"><a href="#Halo-Ghost-Cells-光晕" class="headerlink" title="Halo&#x2F;Ghost Cells 光晕"></a>Halo&#x2F;Ghost Cells 光晕</h2><p>问题:<br>对于边界上的cells，需要访问相邻区域的元素。</p>
<p>解决办法:<br>将他们也加入进当前block的SMEM</p>
<p><img src="https://pic.shaojiemike.top/img/20220518114256.png"></p>
<h3 id="Indexing-with-Halo-Cells"><a href="#Indexing-with-Halo-Cells" class="headerlink" title="Indexing with Halo Cells"></a>Indexing with Halo Cells</h3><ol>
<li>Stencil问题的半径 radius (RAD) 是边缘元素需要的某方向的额外元素<ol>
<li>在梯度的例子里是1</li>
</ol>
</li>
<li>SMEM声明的大小，需要在每个维度上都增加 2*RAD的个数</li>
<li>这导致SMEM的index的每个维度需要增加RAD. <code>s_idx = threadIdx.x + RAD;</code></li>
</ol>
<h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">int main() &#123;</span><br><span class="line">    const float PI = 3.1415927;</span><br><span class="line">    const int N = 150;</span><br><span class="line">    const float h = 2 * PI / N;</span><br><span class="line">    float x[N] = &#123; 0.0 &#125;;</span><br><span class="line">    float u[N] = &#123; 0.0 &#125;;</span><br><span class="line">    float result_parallel[N] = &#123; 0.0 &#125;;</span><br><span class="line">    for (int i = 0; i &lt; N; ++i) &#123;</span><br><span class="line">        x[i] = 2 * PI*i / N;</span><br><span class="line">        u[i] = sinf(x[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    ddParallel(result_parallel, u, N, h);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Kernel Launching</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#define TPB 64</span><br><span class="line">#define RAD 1 // radius of the stencil</span><br><span class="line">…</span><br><span class="line">void ddParallel(float *out, const float *in, int n, float h) &#123;</span><br><span class="line">    float *d_in = 0, *d_out = 0;</span><br><span class="line">    cudaMalloc(&amp;d_in, n * sizeof(float));</span><br><span class="line">    cudaMalloc(&amp;d_out, n * sizeof(float));</span><br><span class="line">    cudaMemcpy(d_in, in, n * sizeof(float), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    // Set shared memory size in bytes</span><br><span class="line">    const size_t smemSize = (TPB + 2 * RAD) * sizeof(float);</span><br><span class="line">    ddKernel&lt;&lt;&lt;(n + TPB - 1)/TPB, TPB, smemSize&gt;&gt;&gt;(d_out, d_in, n, h);</span><br><span class="line">    cudaMemcpy(out, d_out, n * sizeof(float), cudaMemcpyDeviceToHost);</span><br><span class="line">    cudaFree(d_in);</span><br><span class="line">    cudaFree(d_out);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Kernel Definition</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void ddKernel(float *d_out, const float *d_in, int size, float h) &#123;</span><br><span class="line">    const int i = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    if (i &gt;= size) return;</span><br><span class="line">  </span><br><span class="line">    const int s_idx = threadIdx.x + RAD;</span><br><span class="line">    extern __shared__ float s_in[];</span><br><span class="line"></span><br><span class="line">    // Regular cells</span><br><span class="line">    s_in[s_idx] = d_in[i];</span><br><span class="line">    // Halo cells</span><br><span class="line">    if (threadIdx.x &lt; RAD) &#123;</span><br><span class="line">        s_in[s_idx - RAD] = d_in[i - RAD];</span><br><span class="line">        s_in[s_idx + blockDim.x] = d_in[i + blockDim.x];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    d_out[i] = (s_in[s_idx-1] - 2.f*s_in[s_idx] + s_in[s_idx+1])/(h*h);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>研一下USTC并行计算自己的选题</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://dumas.ccsd.cnrs.fr/dumas-00636254/document">https://dumas.ccsd.cnrs.fr/dumas-00636254/document</a></p>
<p><a target="_blank" rel="noopener" href="https://indico.fysik.su.se/event/6743/contributions/10338/attachments/4175/4801/4.CUDA-StencilsSharedMemory-Markidis.pdf">https://indico.fysik.su.se/event/6743/contributions/10338/attachments/4175/4801/4.CUDA-StencilsSharedMemory-Markidis.pdf</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-14T16:00:00.000Z" title="5/14/2022, 4:00:00 PM">2022-05-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-15T16:59:48.449Z" title="11/15/2023, 4:59:48 PM">2023-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">14 minutes read (About 2081 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/14/Work/HPC/cuda/nvidiaOptimize/">Nvidia Optimize</a></p><div class="content"><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ol>
<li>General optimization guidance<ol>
<li>Coalescing memory operations</li>
<li>Occupancy and latency hiding</li>
<li>Using shared memory</li>
</ol>
</li>
<li>Example 1: transpose<ol>
<li>Coalescing and bank conflict avoidance</li>
</ol>
</li>
<li>Example 2: efficient parallel reductions<ol>
<li>Using peak performance metrics to guide optimization</li>
<li>Avoiding SIMD divergence &amp; bank conflicts</li>
<li>Loop unrolling</li>
<li>Using template parameters to write general-yet-optimized code</li>
<li>Algorithmic strategy: Cost efficiency</li>
</ol>
</li>
</ol>
<h2 id="专业术语-terminology"><a href="#专业术语-terminology" class="headerlink" title="专业术语 terminology"></a>专业术语 terminology</h2><ol>
<li>Thread : 并行的基本单位<ol>
<li>但是创建和切换的成本比CPU小多了</li>
</ol>
</li>
<li>Warp: 一堆能硬件物理支持并行的线程(SIMD)</li>
<li>Thread Block: 在一个SM(multiprocessor) 里共享shared memory的一堆线程</li>
</ol>
<h2 id="CUDA-优化策略"><a href="#CUDA-优化策略" class="headerlink" title="CUDA 优化策略"></a>CUDA 优化策略</h2><h3 id="GPU的优化算法"><a href="#GPU的优化算法" class="headerlink" title="GPU的优化算法"></a>GPU的优化算法</h3><ol>
<li>最大化并行独立性</li>
<li>最大化计算密度</li>
<li>减少数据传输<ol>
<li>数据可以直接在GPU生成。</li>
<li>一次大传输也比分开的小批次快</li>
</ol>
</li>
</ol>
<h3 id="访存连续性"><a href="#访存连续性" class="headerlink" title="访存连续性"></a>访存连续性</h3><ol>
<li>对齐(Starting address for a region must be a multiple of region size)集体访问，有数量级的差异Coalesced</li>
<li><strong>Optimize for spatial locality in cached texture memory</strong> ???</li>
<li>避免bank conflict</li>
</ol>
<h3 id="利用好Shared-Memory"><a href="#利用好Shared-Memory" class="headerlink" title="利用好Shared Memory"></a>利用好Shared Memory</h3><ol>
<li>比globalMemory快百倍</li>
<li>可以来避免 non-Coalesced access</li>
<li>SM的线程可以共享</li>
<li><strong>Use one &#x2F; a few threads to load &#x2F; compute data shared by all threads</strong></li>
</ol>
<h3 id="占用率高不一定是好事"><a href="#占用率高不一定是好事" class="headerlink" title="占用率高不一定是好事"></a>占用率高不一定是好事</h3><p>占用率是指每个多处理器（Streaming Multiprocessor，SM）的实际的活动warps数量与最大理论的warps数量的比率。<br>高的占用率不一定能提升性能，因为这一般意味着每个线程分配的寄存器和shared memory变少。但低的占用率会导致内存延迟无法隐藏。</p>
<p>实际需要计算每个线程大概需要的shared memory和register数量</p>
<h4 id="实际例子测试-待研究"><a href="#实际例子测试-待研究" class="headerlink" title="实际例子测试-待研究"></a>实际例子测试-待研究</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4541313.html">https://www.cnblogs.com/1024incn/p/4541313.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4545265.html">https://www.cnblogs.com/1024incn/p/4545265.html</a></p>
<h2 id="优化实例1-矩阵转置"><a href="#优化实例1-矩阵转置" class="headerlink" title="优化实例1 - 矩阵转置"></a>优化实例1 - 矩阵转置</h2><p>通过SMEM实现coalescing access</p>
<p>原本代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">_global__ void transpose_naive(float *odata, float *idata, int width, int height)</span><br><span class="line">&#123;</span><br><span class="line">   unsigned int xIndex = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">   unsigned int yIndex = blockDim.y * blockIdx.y + threadIdx.y;</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      unsigned int index_in = xIndex + width * yIndex;</span><br><span class="line">      unsigned int index_out = yIndex + height * xIndex;</span><br><span class="line">      odata[index_out] = idata[index_in]; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思想：将大矩阵划分成方块，并且存储在SMEM里。不仅SMEM速度更快，而且每行元素个数变少，跨行访问的间距变小，局部性增强。而且对于大矩阵加速效果会更明显。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void transpose(float *odata, float *idata, int width, int height)</span><br><span class="line">&#123;</span><br><span class="line">   __shared__ float block[BLOCK_DIM*BLOCK_DIM];</span><br><span class="line">   unsigned int xBlock = blockDim.x * blockIdx.x;</span><br><span class="line">   unsigned int yBlock = blockDim.y * blockIdx.y;</span><br><span class="line">   unsigned int xIndex = xBlock + threadIdx.x;</span><br><span class="line">   unsigned int yIndex = yBlock + threadIdx.y;</span><br><span class="line">   unsigned int index_out, index_transpose;</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      unsigned int index_in = width * yIndex + xIndex;</span><br><span class="line">      unsigned int index_block = threadIdx.y * BLOCK_DIM + threadIdx.x;</span><br><span class="line">      block[index_block] = idata[index_in];</span><br><span class="line">      index_transpose = threadIdx.x * BLOCK_DIM + threadIdx.y;</span><br><span class="line">      index_out = height * (xBlock + threadIdx.y) + yBlock + threadIdx.x;</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">      odata[index_out] = block[index_transpose]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="coalescing-access"><a href="#coalescing-access" class="headerlink" title="coalescing access"></a>coalescing access</h3><p>when Block&#x2F;tile dimensions are multiples of 16 ???</p>
<h3 id="关于bank-conflict"><a href="#关于bank-conflict" class="headerlink" title="关于bank conflict"></a>关于bank conflict</h3><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/">https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/</a></p>
<p>对于一个32 × 32个元素的共享内存块，一列数据中的所有元素都映射到相同的SMEM bank ，导致bank conflict 的最坏情况:读取一列数据会导致32路的存储库冲突。</p>
<p>幸运的是，只需要将tile的元素宽度改为33，而不是32就行。</p>
<h2 id="优化实例2-数据归约"><a href="#优化实例2-数据归约" class="headerlink" title="优化实例2 - 数据归约"></a>优化实例2 - 数据归约</h2><p>具体问题：将长数组的所有元素，归约求和为一个结果</p>
<h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3><p>为了避免全局同步的巨大开销，采取分级归约<br><img src="https://pic.shaojiemike.top/img/20220515105630.png"></p>
<p>由于归约的计算密度低<br>1 flop per element loaded (bandwidth-optimal)</p>
<p>所以优化目标是将访存带宽用满。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">384-bit memory interface, 900 MHz DDR</span><br><span class="line">384 * 1800 / 8 = 86.4 GB/s</span><br></pre></td></tr></table></figure>

<h3 id="step0-baseline-Interleaved-Addressing-交错-间隔寻址"><a href="#step0-baseline-Interleaved-Addressing-交错-间隔寻址" class="headerlink" title="step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址"></a>step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce0(int *g_idata, int *g_odata) &#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   // each thread loads one element from global to shared mem</span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">   sdata[tid] = g_idata[i];</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   // do reduction in shared mem</span><br><span class="line">   for(unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">      if (tid % (s) == 0) &#123;</span><br><span class="line">         sdata[tid] += sdata[tid + s];</span><br><span class="line">      &#125;</span><br><span class="line">      __syncthreads();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   // write result for this block to global mem</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515150953.png"><br>工作的线程越来越少。一开始是全部，最后一次只有thread0.</p>
<h3 id="Step1-使用连续的index"><a href="#Step1-使用连续的index" class="headerlink" title="Step1 : 使用连续的index"></a>Step1 : 使用连续的index</h3><p>Just replace divergent branch With strided index and non-divergent branch，但是会带来bank conflict。</p>
<p>原理和Warp发射有关，假如在这里每个Warp并行的线程是2。一个Warp运行耗时为T.</p>
<p>Step0: 4+4+2+1&#x3D;11T</p>
<p>Step1: 4+2+1+1&#x3D;8T</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">   int index = 2 * s * tid;</span><br><span class="line">   if (index &lt; blockDim.x) &#123;</span><br><span class="line">      sdata[index] += sdata[index + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515144525.png"><br><img src="https://pic.shaojiemike.top/img/20220515151516.png"></p>
<h3 id="Step2-连续寻址"><a href="#Step2-连续寻址" class="headerlink" title="Step2: 连续寻址"></a>Step2: 连续寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=blockDim.x/2; s&gt;0; s&gt;&gt;=1) &#123;</span><br><span class="line">   if (tid &lt; s) &#123;</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原本寻址<img src="https://pic.shaojiemike.top/img/20220515151840.png"></p>
<p>现在寻址有一边连续了<br><img src="https://pic.shaojiemike.top/img/20220515151937.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220515152034.png"></p>
<h3 id="Step3-弥补浪费的线程"><a href="#Step3-弥补浪费的线程" class="headerlink" title="Step3 : 弥补浪费的线程"></a>Step3 : 弥补浪费的线程</h3><p>方法： 在load SMEM的时候提前做一次规约加法，通过减少一半的block数，将原本两个block里的值load+add存储在sum里。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// perform first level of reduction,</span><br><span class="line">// reading from global memory, writing to shared memory</span><br><span class="line">unsigned int tid = threadIdx.x;</span><br><span class="line">unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;</span><br><span class="line">sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515152704.png"></p>
<h3 id="step4-Unrolling-the-Last-Warp"><a href="#step4-Unrolling-the-Last-Warp" class="headerlink" title="step4 : Unrolling the Last Warp"></a>step4 : Unrolling the Last Warp</h3><p>当s&lt; 32的时候，就只有一个Warp工作了。</p>
<p>使用warp的SIMD还省去了<code>__syncthreads()</code>的麻烦</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=blockDim.x/2; s&gt;32; s&gt;&gt;=1) </span><br><span class="line">&#123;</span><br><span class="line">   if (tid &lt; s)</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line">if (tid &lt; 32)</span><br><span class="line">&#123;</span><br><span class="line">   sdata[tid] += sdata[tid + 32]; </span><br><span class="line">   sdata[tid] += sdata[tid + 16]; </span><br><span class="line">   sdata[tid] += sdata[tid + 8]; </span><br><span class="line">   sdata[tid] += sdata[tid + 4]; </span><br><span class="line">   sdata[tid] += sdata[tid + 2]; </span><br><span class="line">   sdata[tid] += sdata[tid + 1]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了保持整洁，最后一个if还做了无效的计算。eg, Warp里的最后一个线程只有第一句命令有用。<br><img src="https://pic.shaojiemike.top/img/20220515162352.png"></p>
<h3 id="Step5-根据blockSize完全展开for和去除代码"><a href="#Step5-根据blockSize完全展开for和去除代码" class="headerlink" title="Step5 : 根据blockSize完全展开for和去除代码"></a>Step5 : 根据blockSize完全展开for和去除代码</h3><p>由于for循环里是二分的，而且小于32的单独处理了，导致for循环里实际运行代码最多就3句。</p>
<p>利用代码模板和编译器的自动优化实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce5(int *g_idata, int *g_odata)</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515163110.png"></p>
<p>红色代码会在编译时自动优化。<br><img src="https://pic.shaojiemike.top/img/20220515163243.png"></p>
<h3 id="step6-：归并算法优化"><a href="#step6-：归并算法优化" class="headerlink" title="step6 ：归并算法优化"></a>step6 ：归并算法优化</h3><p>加速级联？？</p>
<p>Cost&#x3D; processors × time complexity</p>
<p>我们知道N个元素直接二叉树归约是O(log N)<br>时间 Cost&#x3D;N*O(log N).</p>
<p>但是假如只有P个线程先做N&#x2F;P的串行加法, 然后是log(P)的归约。<br>总cost&#x3D;P(N&#x2F;P+log(P))</p>
<p>当P&#x3D;N&#x2F;log(N), cost&#x3D;O(N)</p>
<p>each thread should sum O(log n) elements来设置</p>
<p>比如，1024 or 2048 elements per block vs. 256 线程。每个sum n&#x3D;4个元素。 具体参数要perf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">unsigned int tid = threadIdx.x;</span><br><span class="line">unsigned int i = blockIdx.x*(blockSize*2) + threadIdx.x;</span><br><span class="line">unsigned int gridSize = blockSize*2*gridDim.x;</span><br><span class="line">sdata[tid] = 0;</span><br><span class="line">while (i &lt; n) &#123;</span><br><span class="line">   sdata[tid] += g_idata[i] + g_idata[i+blockSize];</span><br><span class="line">   i += gridSize;</span><br><span class="line">&#125;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515171758.png"></p>
<h3 id="final-code"><a href="#final-code" class="headerlink" title="final code"></a>final code</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce6(int *g_idata, int *g_odata, unsigned int n)</span><br><span class="line">&#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*(blockSize*2) + tid;</span><br><span class="line">   unsigned int gridSize = blockSize*2*gridDim.x;</span><br><span class="line">   sdata[tid] = 0;</span><br><span class="line"></span><br><span class="line">   do &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; while (i &lt; n);</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   if (blockSize &gt;= 512) &#123; if (tid &lt; 256) &#123; sdata[tid] += sdata[tid + 256]; &#125; __syncthreads(); &#125;</span><br><span class="line">   if (blockSize &gt;= 256) &#123; if (tid &lt; 128) &#123; sdata[tid] += sdata[tid + 128]; &#125; __syncthreads(); &#125;</span><br><span class="line">   if (blockSize &gt;= 128) &#123; if (tid &lt; 64) &#123; sdata[tid] += sdata[tid + 64]; &#125; __syncthreads(); &#125;</span><br><span class="line"></span><br><span class="line">   if (tid &lt; 32) &#123;</span><br><span class="line">      if (blockSize &gt;= 64) sdata[tid] += sdata[tid + 32];</span><br><span class="line">      if (blockSize &gt;= 32) sdata[tid] += sdata[tid + 16];</span><br><span class="line">      if (blockSize &gt;= 16) sdata[tid] += sdata[tid + 8];</span><br><span class="line">      if (blockSize &gt;= 8) sdata[tid] += sdata[tid + 4];</span><br><span class="line">      if (blockSize &gt;= 4) sdata[tid] += sdata[tid + 2];</span><br><span class="line">      if (blockSize &gt;= 2) sdata[tid] += sdata[tid + 1];</span><br><span class="line">   &#125;</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="关于if语句的补充"><a href="#关于if语句的补充" class="headerlink" title="关于if语句的补充"></a>关于if语句的补充</h2><p>有if语句是没问题的，只要运行的时候全部执行if或者else就行。不要有些执行if，有些执行else，这才会等待。<img src="https://pic.shaojiemike.top/img/20220515153440.png"></p>
<p>说不定也不是全部执行if或者else就行，只需要连续32个Thread Index，是相同的执行就行。（猜想，需要测试。</p>
<h2 id="关于延迟隐藏"><a href="#关于延迟隐藏" class="headerlink" title="关于延迟隐藏"></a>关于延迟隐藏</h2><p>通过增加block里的线程数，并且同时读取来隐藏延迟。 不仅可以隐藏Global Memory的延迟，还可以隐藏写后读的延迟</p>
<p><img src="https://pic.shaojiemike.top/img/20220515181043.png"></p>
<h3 id="线程资源查看"><a href="#线程资源查看" class="headerlink" title="线程资源查看"></a>线程资源查看</h3><p>线程太多会导致分配到每一个的寄存器和SMEM变少</p>
<p>通过编译时加<code>-cubin</code>选项，<code>.cubin</code>文件前几行会显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">architecture &#123;sm_10&#125;</span><br><span class="line">abiversion &#123;0&#125;</span><br><span class="line">modname &#123;cubin&#125;</span><br><span class="line">code &#123;</span><br><span class="line">   name = BlackScholesGPU</span><br><span class="line">   lmem = 0    # per thread local memory</span><br><span class="line">   smem = 68   # per thread block shared memory</span><br><span class="line">   reg = 20    # per thread registers</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf">https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf</a></p>
<p>类似的cuda优化资料有09年的， 清华 邓仰东 cuda lecture pdf <a target="_blank" rel="noopener" href="https://download.csdn.net/download/yujia269/4203734%E3%80%82">https://download.csdn.net/download/yujia269/4203734。</a> 注意也是参考的上面Nvidia的这个。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-12T01:18:42.000Z" title="5/12/2022, 1:18:42 AM">2022-05-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-15T16:59:48.469Z" title="11/15/2023, 4:59:48 PM">2023-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">3 minutes read (About 424 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/12/Work/software/perf/nvprof/">Nvprof</a></p><div class="content"><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ which nvprof </span><br><span class="line">/usr/local/cuda/bin/nvprof</span><br></pre></td></tr></table></figure>

<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="摘要模式"><a href="#摘要模式" class="headerlink" title="摘要模式"></a>摘要模式</h3><p>命令行直接运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="跟踪API"><a href="#跟踪API" class="headerlink" title="跟踪API"></a>跟踪API</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --print-gpu-trace ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="保存在log里"><a href="#保存在log里" class="headerlink" title="保存在log里"></a>保存在log里</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/nvprof --log-file a.log --metrics achieved_occupancy /staff/shaojiemike/github/cutests/22-commonstencil/common</span><br></pre></td></tr></table></figure>

<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ol>
<li>nsight可以直接在远程机器上运行<ol>
<li>ssh -X host</li>
<li>.ssh&#x2F;config<ol>
<li>add</li>
<li>XAuthLocation &#x2F;opt&#x2F;X11&#x2F;bin&#x2F;xauth #for macbookAir</li>
<li>ForwardX11Trusted yes</li>
<li>ForwardX11 yes</li>
</ol>
</li>
</ol>
</li>
<li>Visual Profiler也可以ssh直接连接远程机器</li>
<li>或者导出分析结果以便可视化, 在Visual Profiler使用</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof --export-profile timeline.prof &lt;app&gt; &lt;app args&gt;</span><br><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="profile-kernel"><a href="#profile-kernel" class="headerlink" title="profile kernel"></a>profile kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/ncu -k stencil_kernel -s 0 -c 1 /staff/shaojiemike/github/cutests/22-commonstencil/best</span><br></pre></td></tr></table></figure>

<p>ncu-ui是可视化界面，但是没弄懂</p>
<h2 id="带宽profile"><a href="#带宽profile" class="headerlink" title="带宽profile"></a>带宽profile</h2><h3 id="上限测量"><a href="#上限测量" class="headerlink" title="上限测量"></a>上限测量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:02:08]                                                                                                                                                                      $ ./bin/x86_64/linux/release/bandwidthTest                                                                                                                                                                                           [CUDA Bandwidth Test] - Starting...                                                                                                                                                                                                  Running on...                                                                                                                                                                                                                                                                                                                                                                                                                                                              Device 0: Tesla P40                                                                                                                                                                                                                  Quick Mode                                                                                                                                                                                                                                                                                                                                                                                                                                                                Host to Device Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     11.8                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Host Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     13.0                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Device Bandwidth, 1 Device(s)                                                                                                                                                                                              PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     244.3                                                                                                                                                                                                                                                                                                                                                                                                                                     Result = PASS                                                                                                                                                                                                                                                                                                                                                                                                                                                             NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.                                                                                                                                                                                       # shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:03:24]                                                                                                                                                                      $ ./bin/x86_64/linux/release/p2pBandwidthLatencyTest        </span><br></pre></td></tr></table></figure>

<h3 id="实际值"><a href="#实际值" class="headerlink" title="实际值"></a>实际值</h3><p>nvprof通过指定与dram，L1或者L2 的metrics来实现。具体解释可以参考<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">官网</a></p>
<p>在 Maxwell 和之后的架构中 L1 和 SMEM 合并</p>
<table>
<thead>
<tr>
<th>Metric Name</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>achieved_occupancy</td>
<td>活跃cycle是 Warps 活跃的比例</td>
</tr>
<tr>
<td>dram_read_throughput</td>
<td></td>
</tr>
<tr>
<td>dram_utilization</td>
<td>在0到10的范围内，相对于峰值利用率，设备内存的利用率水平</td>
</tr>
<tr>
<td>shared_load_throughput</td>
<td></td>
</tr>
<tr>
<td>shared_utilization</td>
<td></td>
</tr>
<tr>
<td>l2_utilization</td>
<td></td>
</tr>
</tbody></table>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">342</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">470</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">49</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-15T01:11:04.000Z">2023-11-15</time></p><p class="title"><a href="/2023/11/15/Work/Algorithms/datastructure/dataStructureSummary/">Data Structure Summary</a></p><p class="categories"><a href="/categories/Algorithms/">Algorithms</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-14T07:38:50.000Z">2023-11-14</time></p><p class="title"><a href="/2023/11/14/Work/Architecture/PIM/HostCoreWithPIMCoreIn3DMem/">Host-Core With PIM-Core In 3D-stacked Mem</a></p><p class="categories"><a href="/categories/Architecture/">Architecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-14T03:24:26.000Z">2023-11-14</time></p><p class="title"><a href="/2023/11/14/Work/Architecture/PIM/AddressTranslationForPIM/">AddressTranslationForPIM</a></p><p class="categories"><a href="/categories/toLearn/">toLearn</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-14T03:23:38.000Z">2023-11-14</time></p><p class="title"><a href="/2023/11/14/Work/Architecture/PIM/experimentsForPIMMotivation/">Experiments For PIM Motivation</a></p><p class="categories"><a href="/categories/toLearn/">toLearn</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-13T01:42:31.000Z">2023-11-13</time></p><p class="title"><a href="/2023/11/13/Work/Architecture/microHardware/Predictor/">Predictor</a></p><p class="categories"><a href="/categories/toLearn/">toLearn</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">203</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>