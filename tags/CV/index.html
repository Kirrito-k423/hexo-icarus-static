<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: CV - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">CV</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-09-26T16:00:00.000Z" title="9/26/2023, 4:00:00 PM">2023-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-08T13:39:55.834Z" title="12/8/2023, 1:39:55 PM">2023-12-08</time></span><span class="level-item"><a class="link-muted" href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></span><span class="level-item">2 hours read (About 17650 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/09/26/Work/Artificial%20Intelligence/MachineLearning/">Machine Learning</a></p><div class="content"><h2 id="AI-Artificial-Intelligence-vs-Machine-Learning-vs-Deep-Learning"><a href="#AI-Artificial-Intelligence-vs-Machine-Learning-vs-Deep-Learning" class="headerlink" title="AI(Artificial Intelligence) vs. Machine Learning vs. Deep Learning"></a>AI(Artificial Intelligence) vs. Machine Learning vs. Deep Learning</h2><p>AI是人工智能（Artificial Intelligence）的缩写，是指通过计算机系统和算法模拟、模仿和扩展人类智能的科学和技术领域。</p>
<p>人工智能的目标是使计算机具备像人类一样的智能和学习能力，能够理解、推理、学习、决策和解决问题。</p>
<p><img src="https://pic.shaojiemike.top/img/20211121155911.png"></p>
<p>这张图很好的说明了发展的历程。很早人们就注意到了人工智能的概念，但是直到GPU的出现，极大的提高了并行运行的效率，这个深度学习才高速发展起来。</p>
<h3 id="强人工智能（General-AI）vs-弱人工智能（Narrow-AI）"><a href="#强人工智能（General-AI）vs-弱人工智能（Narrow-AI）" class="headerlink" title="强人工智能（General AI）vs. 弱人工智能（Narrow AI）"></a>强人工智能（General AI）vs. 弱人工智能（Narrow AI）</h3><p>AI先驱的梦想就是构建具有与人类智慧相同特征的由当时新兴计算机构成的复杂机器。这个概念就是我们所说的“强人工智能（General AI）”，这是一个神话般的机器，具有我们所有的感觉（甚至更多），我们所有的理智，像我们一样想。</p>
<p>“弱人工智能（Narrow AI）”的概念,是一种能够执行特定任务的技术，或者比我们人类能做的更好的技术。例如，Pinterest利用AI进行图片分类，Facebook使用AI对脸部识别。</p>
<h2 id="常见的任务"><a href="#常见的任务" class="headerlink" title="常见的任务"></a>常见的任务</h2><p>数据来自文本和图像两类, 很自然有下面几大类。</p>
<ul>
<li>自然语言处理（Natural Language Processing，NLP）：NLP任务涉及处理和理解人类语言文本。<ul>
<li>包括文本分类、命名实体识别、情感分析、机器翻译等。</li>
<li>大型语言模型Large Language Model 核心原理是根据前文推算出下一个可能发生的字的模型，能够理解和生成语言，具备对话、问答、翻译、摘要等能力。</li>
</ul>
</li>
<li>计算机视觉（Computer Vision）：计算机视觉任务涉及处理和分析图像和视频数据。<ul>
<li>包括目标检测、图像分割、人脸识别、图像生成，医学影像标注,自动驾驶等。</li>
</ul>
</li>
<li>AIGC（AI generated content）是指由人工智能生成的内容，<ul>
<li>包括文本续写、文字转图像视频、AI主持人、音乐生成、游戏场景生成、代码补全与生成<a target="_blank" rel="noopener" href="https://hub.baai.ac.cn/view/23295">等应用</a>。</li>
<li>生成模型（Generative Models）：生成模型是指能够生成新的数据样本的模型。<ul>
<li>包括生成对抗网络（GANs）、变分自编码器（Variational Autoencoder，VAE）等。</li>
</ul>
</li>
</ul>
</li>
<li>AGI 通用人工智能<ul>
<li>普遍认为AGI将在2030年左右到来</li>
<li>LeCun 世界模型？！</li>
</ul>
</li>
</ul>
<p>细分的领域包括：</p>
<ul>
<li>HPC&#x2F;科学计算 + AI </li>
<li>异常检测（Anomaly Detection）：异常检测任务涉及识别与正常行为模式不符的异常样本或事件。<ul>
<li>包括检测欺诈行为、网络入侵、设备故障等。</li>
</ul>
</li>
<li>分类问题（如图像分类、垃圾邮件检测等）和回归问题（如房价预测、股票价格预测等）<ul>
<li>监督学习（Supervised Learning）：在监督学习中，模型通过使用标记好的训练数据来学习输入与输出之间的映射关系。</li>
</ul>
</li>
<li>聚类（将相似的数据点分组）和降维（减少数据维度）<ul>
<li>无监督学习（Unsupervised Learning）：在无监督学习中，模型从未标记的数据中发现数据之间的结构、模式或关系，而无需预先提供标签信息。</li>
</ul>
</li>
<li>机器人控制、AI与人的游戏对抗、游戏玩法优化<ul>
<li>强化学习（Reinforcement Learning）：在强化学习中，模型通过与环境进行交互来学习最佳行为策略。模型根据环境的反馈（奖励或惩罚）来调整自己的行为，以最大化累积奖励。</li>
</ul>
</li>
<li>大模型在具体任务上的加速学习<ul>
<li>迁移学习（Transfer Learning）：迁移学习是指将在一个任务上学到的知识应用到另一个相关任务上。通过在一个大规模任务上训练模型，然后将其用于相关任务，可以加快学习速度并提高性能。</li>
</ul>
</li>
</ul>
<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>机器学习是一种人工智能（Artificial Intelligence，AI）的分支，旨在让计算机通过数据和经验自动学习和改进算法(修改参数权重, <del>不是</del>)，而无需明确编程。</p>
<p>机器学习<strong>最基本的方法</strong>是使用**算法(统计学算法)**来解析处理数据，从中学习，然后对世界中的某些事物, 进行识别，做出决定或预测。</p>
<p>出发点: 与其用特定的指令集编写软件程序来完成特定的任务，还不如使用<strong>大量的数据和算法</strong>“训练”机器，让它能够学习如何执行任务。</p>
<p>事实证明，多年来机器学习的最佳应用领域之一是<strong>计算机视觉领域</strong>。要实现计算机视觉，它仍然需要大量的手工编码来完成工作。研究人员会去写<strong>手动编写分类器</strong>，比如边缘检测过滤器，这样程序就能识别出物体的起点和停止位置；形状检测确定是否有八面；识别字母“S-T-O-P”的分类器。从所有这些手工编写的分类器中，他们将<strong>开发算法</strong>来理解图像和学习识别图像，确定它是否是一个停止符号。</p>
<h2 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h2><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0</a></p>
<p>在接下来的讨论前，你需要知道<strong>概率论</strong>的相关知识，本人有稍微介绍。</p>
<p>包括：</p>
<ol>
<li>常用离散分布<ol>
<li>二项分布</li>
</ol>
</li>
<li>常用连续分布<ol>
<li>正态分布（高斯分布）</li>
<li>指数分布</li>
<li>伽马分布</li>
<li>贝塔分布</li>
</ol>
</li>
<li>三大抽样分布</li>
<li>随机过程<ol>
<li>泊松过程与泊松分布</li>
<li>马尔科夫链</li>
<li>平稳过程</li>
<li>布朗运动</li>
<li>鞅过程</li>
</ol>
</li>
<li>大数定理，中心极限定理</li>
<li>参数估计<ol>
<li>先验分布 后验概率分布 </li>
<li>点估计</li>
<li>矩估计</li>
<li>最大似然估计与EM算法</li>
<li>最小方差无偏估计</li>
<li>贝叶斯估计</li>
<li>区间估计</li>
</ol>
</li>
<li>方差回归与回归分析</li>
</ol>
<h3 id="参数学习-监督学习"><a href="#参数学习-监督学习" class="headerlink" title="参数学习(监督学习)"></a>参数学习(监督学习)</h3><p>在机器学习领域，参数学习（Parameter Learning）是指通过观测数据来估计模型中的参数，从而使得模型能够适应数据并具有预测能力的过程。参数学习是机器学习中的一种重要任务，它通常涉及以下步骤：</p>
<ul>
<li>定义模型：首先，需要选择或定义适当的模型来描述数据的生成过程或模式。<ul>
<li>模型可以是线性模型、非线性模型、神经网络、决策树等各种形式。</li>
</ul>
</li>
<li>确定损失函数：为了估计模型的参数，需要定义一个损失函数，用于衡量模型预测结果与实际观测值之间的差异。<ul>
<li>常见的损失函数包括均方误差、交叉熵等，具体选择取决于任务的特点和模型的性质。</li>
</ul>
</li>
<li>构建目标函数：目标函数是将损失函数与参数联系起来的函数。通过最小化目标函数，可以找到使模型在训练数据上表现最好的参数值。</li>
<li>优化算法：为了找到目标函数的最小值，需要使用优化算法进行参数的更新和调整。<ul>
<li>常见的优化算法包括梯度下降、牛顿法、共轭梯度等，它们通过迭代地调整参数来最小化目标函数。</li>
<li>反向传播算法（Backpropagation）主要用于计算神经网络模型中的参数梯度，以便通过网络的反向路径使用梯度下降等优化方法更新参数。</li>
</ul>
</li>
<li>训练模型：使用训练数据进行模型的训练。训练过程中，优化算法根据当前参数值和损失函数的梯度信息，更新参数，并不断迭代，直到达到停止条件（如达到最大迭代次数或损失函数收敛）。</li>
<li>参数估计：一旦训练完成，模型的参数就得到了估计。这些参数可以用于对新的未见过的数据进行预测或分类。</li>
</ul>
<p>需要注意的是，参数学习是监督学习的一部分，它要求训练数据中包含标签或目标值，以便通过比较模型的预测结果和实际标签来计算损失并进行参数更新。无监督学习和强化学习等其他类型的学习方法可能采用不同的学习方式和算法。</p>
<h3 id="参数学习-无监督学习和强化学习"><a href="#参数学习-无监督学习和强化学习" class="headerlink" title="参数学习(无监督学习和强化学习)"></a>参数学习(无监督学习和强化学习)</h3><p>在无监督学习和强化学习中，参数的训练过程有所不同。</p>
<ul>
<li>在无监督学习中，参数的训练是通过对数据的内在结构和模式进行建模来实现的，而不需要事先标记的目标值。<ul>
<li>常见的无监督学习算法包括聚类、降维和生成模型等。</li>
<li>训练参数的方法可以使用最大似然估计、最小化损失函数或其他自定义的优化目标。<ul>
<li>例如，在聚类算法中，我们可以使用期望最大化算法（EM算法）来估计潜在的类别分布和数据点的类别归属。</li>
</ul>
</li>
</ul>
</li>
<li>在强化学习中，参数的训练是通过智能体与环境的交互来实现的。强化学习是一种通过试错的方式来学习最优策略的方法。智能体通过观察环境状态，采取行动并接收奖励信号，然后根据奖励信号调整参数。<ul>
<li>常用的强化学习算法包括Q-learning、策略梯度方法和深度强化学习等。</li>
<li>参数的训练通常使用值函数估计、策略梯度优化或深度神经网络等技术。</li>
</ul>
</li>
</ul>
<p>在无监督学习和强化学习中，参数的训练过程都是通过优化方法来最大化某种指标或最小化某种损失函数。无监督学习更侧重于发现数据中的结构和模式，而强化学习更关注于学习与环境交互的最优策略。具体的训练方法和算法选择取决于具体的问题和应用领域。</p>
<h3 id="最大似然估计与损失函数的关系"><a href="#最大似然估计与损失函数的关系" class="headerlink" title="最大似然估计与损失函数的关系"></a>最大似然估计与损失函数的关系</h3><p>可以理解成现有的监督学习的参数，都是在知道标签后的最大似然估计。由于模型不同，最大似然估计的公式就具体<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33828141">变成了各种损失函数与优化算法</a>。</p>
<ul>
<li>回归问题：特化成最小二乘估计(最小二乘法)，对应的损失函数： 均方误差</li>
<li>分类问题：特化 损失函数：交叉熵</li>
</ul>
<h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><ul>
<li>监督学习通过训练数据集中的输入和对应的标签进行学习，从而能够预测或分类新的未标记数据</li>
<li>训练集是有标注的。</li>
</ul>
<p>常见的监督学习算法包括</p>
<ol>
<li>回归分析(自变量与因变量的关系，多在一二维的数据分析上)<ol>
<li>线性回归（Linear Regression）：线性回归是回归分析中最简单和最常见的方法之一。它假设自变量和因变量之间存在线性关系，并试图拟合出最优的线性模型来预测因变量。</li>
<li>多项式回归（Polynomial Regression）：多项式回归是在线性回归的基础上，通过引入高阶多项式项来拟合非线性关系。它可以处理自变量和因变量之间的非线性关系，并更灵活地拟合曲线。</li>
<li>岭回归（Ridge Regression）和Lasso回归（Lasso Regression）：这是在线性回归中使用的正则化方法，用于处理自变量之间存在共线性（多重共线性）的情况。它们通过添加正则化项来控制模型的复杂度，防止过拟合。</li>
<li>Logistic回归（Logistic Regression）：尽管名为回归，但实际上是一种分类算法。它用于处理因变量是二分类或多分类问题的情况，通过拟合逻辑函数来预测样本属于不同类别的概率。</li>
<li>非线性回归（Nonlinear Regression）：非线性回归适用于自变量和因变量之间存在复杂的非线性关系的情况。它使用非线性函数拟合数据，并尝试找到最优的非线性模型。</li>
<li></li>
</ol>
</li>
<li>统计分类(分类器)<ol>
<li>决策树学习和随机森林<ol>
<li>隨機森林是一個包含多個決策樹的分類器</li>
<li>过拟合剪枝</li>
</ol>
</li>
<li>支持向量机(SVM,support vector machine)</li>
<li>最近邻居法（KNN算法，又译K-近邻算法）</li>
<li>朴素贝叶斯(贝叶斯网络)</li>
</ol>
</li>
</ol>
<p>当然人工神经网络也能分类，但是有种杀鸡用牛刀的感觉，费力结果不一定更好。</p>
<p>决定适合某一问题的分类器仍旧是一项艺术，而非科学。</p>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><ul>
<li>无监督学习则从未标记的数据中学习数据的结构和模式，用于聚类、降维和异常检测等任务。</li>
<li>与监督学习相比，训练集没有人为标注的结果。</li>
</ul>
<p>常见的无监督学习算法有</p>
<ol>
<li>聚类<ol>
<li>（模糊）K-均值聚类（动态聚类法）</li>
</ol>
</li>
<li>人工神经网络(无监督我也来了)<ol>
<li>自编码器</li>
<li>生成对抗网络（GAN，Generative Adversarial Network）<ol>
<li>通过让两个神经网络相互博弈的方式进行学习。生成对抗网络由一个<strong>生成网络</strong>与一个<strong>判别网络</strong>组成。生成网络从潜在空间（latent space）中随机取样作为输入，其输出结果需要尽量<strong>模仿</strong>训练集中的真实样本。判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能<strong>分辨</strong>出来。而生成网络则要尽可能地<strong>欺骗</strong>判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。(常用于生成以假乱真的图片)</li>
</ol>
</li>
<li>自组织映射（SOM）</li>
<li>适应性共振理论（ART）</li>
</ol>
</li>
</ol>
<h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>半监督学习是介于监督学习和无监督学习之间的一种学习方式，利用带有标签的部分数据和未标记的数据进行学习。</p>
<h3 id="强化学习-增强学习"><a href="#强化学习-增强学习" class="headerlink" title="强化学习(增强学习)"></a>强化学习(增强学习)</h3><ul>
<li>强化学习(Reinforcement learning，简称RL)是通过智能体与环境进行交互学习最佳行动策略，通过奖励信号来指导学习过程。通过正确就正向激励，错误就反向评价来修正模型。(多出现在游戏AI上，比如AlphaGo)</li>
<li>强化学习不需要带标签的输入输出对，同时也无需对非最优解的精确地纠正。其关注点在于寻找探索（对未知领域的）和利用（对已有知识的）的平衡。</li>
</ul>
<h2 id="深度学习-人工神经网络-！"><a href="#深度学习-人工神经网络-！" class="headerlink" title="深度学习 ?&#x3D; 人工神经网络 &#x3D;！"></a>深度学习 ?&#x3D; 人工神经网络 &#x3D;！</h2><h3 id="基本概念与关系"><a href="#基本概念与关系" class="headerlink" title="基本概念与关系"></a>基本概念与关系</h3><p>人工神经网络（Artificial Neural Network，ANN）是深度学习的<strong>基础和核心组成</strong>部分之一。</p>
<p><strong>人工神经网络</strong>是一种受到生物神经系统启发的数学模型，用于模拟和处理信息。它由多个人工神经元（或称为节点）组成，这些神经元通过连接权重相互连接，并通过激活函数对输入信号进行处理。人工神经网络可以通过学习调整连接权重，以适应输入和输出之间的关系，并进行任务如分类、回归等。</p>
<p><strong>深度学习</strong>是机器学习的一个分支，专注于使用深层次的神经网络（即具有多个隐藏层的神经网络）进行学习和表示学习。深度学习的关键创新是引入了深层次的非线性模型，这些模型能够通过多个层次的转换逐渐提取和组合输入数据中的高级特征。</p>
<p>深度学习通过使用深层神经网络来自动学习数据表示，并在大规模数据集上进行训练。深度学习的强大之处在于，通过增加网络的深度，它能够学习到更抽象、更高级别的特征表示，从而提高模型的表达能力和性能。</p>
<p>因此，深度学习利用了人工神经网络的结构和算法，通过增加网络的深度来提高模型的学习能力和表达能力。人工神经网络是深度学习中最基础、最重要的组成部分之一，为深度学习的发展提供了坚实的理论基础和工具。</p>
<h3 id="人工神经网络的历史"><a href="#人工神经网络的历史" class="headerlink" title="人工神经网络的历史"></a>人工神经网络的历史</h3><ul>
<li>概念的出现：“人工神经网络（Artificial Neural Networks）”也是早期机器学习专家提出的，存在已经几十年了。<ul>
<li>每个神经元都将一个<strong>权重</strong>分配给它的输入，确定它与所执行任务的关系，对应正确与不正确的程度。最后的输出结果由这些权重的总和决定。</li>
</ul>
</li>
<li>关键进展：保罗·韦伯斯发明的<strong>反向传播算法</strong>（Werbos 1975）。这个算法有效地解决了异或的问题，还有更普遍的训练多层神经网络的问题。</li>
<li>初期不够流行：支持向量机和其他更简单的方法（例如线性分类器）在机器学习领域的流行度逐渐超过了神经网络，但是在2000年代后期出现的深度学习重新激发了人们对神经网络的兴趣。<ul>
<li>现在有<strong>循环神经网络</strong>和<strong>前馈神经网络</strong>两种，CNN就是一种前馈神经网络。</li>
</ul>
</li>
<li>大幅度发展：2014年出现了残差神经网络，该网络极大解放了神经网络的深度限制，出现了深度学习的概念。</li>
</ul>
<h3 id="人工神经网络-与-深度学习的历史关系"><a href="#人工神经网络-与-深度学习的历史关系" class="headerlink" title="人工神经网络 与 深度学习的历史关系"></a>人工神经网络 与 深度学习的历史关系</h3><p>2014年出现了残差神经网络，该网络极大解放了神经网络的深度限制，出现了深度学习的概念。</p>
<p>利用这些神经网络，增加了层和神经元，然后通过系统运行大量的数据来训练它。真正实现深度学习的“深度”，使得其能够描述神经网络中的所有的层次信息。</p>
<p>神经网络现在一般用于深度学习，所以将<strong>两者等价</strong>也不是不可以。</p>
<h3 id="人工神经网络特点"><a href="#人工神经网络特点" class="headerlink" title="人工神经网络特点"></a>人工神经网络特点</h3><p>人工神经网络（Artificial Neural Networks，ANN）具有以下特点：</p>
<ul>
<li><strong>自适应学习</strong>：人工神经网络可以通过学习算法自适应地调整神经元之间的连接权重，从而改变网络的行为和性能。通过与训练数据的反馈，神经网络可以逐步优化自己的权重参数，提高对输入模式的识别和预测能力。</li>
<li>非线性映射能力：人工神经网络可以通过非线性函数来建模复杂的输入与输出之间的关系。它能够学习和表示非线性模式和特征，从而更好地适应现实世界中的复杂问题。<ul>
<li>广义的通用函数逼近器：根据万能逼近定理（Universal Approximation Theorem），具有足够多神经元和适当的激活函数的人工神经网络可以逼近任意复杂的函数。这使得神经网络在各种问题和任务中具备较强的建模能力。</li>
</ul>
</li>
<li>分布式表示：人工神经网络采用分布式表示的方式来存储和处理信息。即信息被分散在网络中的多个神经元之间，每个神经元负责处理一部分信息。这种分布式表示的特点使得神经网络能够<strong>同时</strong>处理多个输入特征，并具有一定的<strong>容错性</strong>。<ul>
<li>并行处理能力：人工神经网络的计算是并行进行的，多个神经元同时对输入进行处理。这种并行性能够加速计算过程，使得神经网络具有高效的计算能力。</li>
<li>容错性：人工神经网络具有一定的容错性，即在部分神经元或连接失效的情况下，仍然能够保持良好的性能。这种容错性使得神经网络在面对噪声和部分信息缺失的情况下仍然能够有效地处理数据。</li>
</ul>
</li>
<li><strong>可解释性</strong>挑战：随着神经网络的深度和复杂性增加，解释网络内部运行机制和权重的含义变得困难。这使得人工神经网络的解释性成为一个挑战，特别是在需要透明性和可解释性的应用场景中。</li>
</ul>
<p>总的来说，人工神经网络是一种强大的模型，具有非线性映射能力、分布式表示、并行处理能力、自适应学习、容错性和广义的函数逼近能力。它在解决复杂问题和处理大规模数据时具有广泛的应用潜力。</p>
<h3 id="与传统的机器学习不同的特点"><a href="#与传统的机器学习不同的特点" class="headerlink" title="与传统的机器学习不同的特点"></a>与传统的机器学习不同的特点</h3><p>人工神经网络与传统的机器学习算法相比具有以下不同的特点：</p>
<ul>
<li><p>特征学习与表示学习：传统机器学习算法通常需要手动选择和提取适合任务的特征。而人工神经网络可以通过训练自动学习特征表示，从原始数据中学习到更高级别、更抽象的特征表示，减少了对特征工程的依赖。</p>
</li>
<li><p>非线性模型能力：人工神经网络可以建模和学习非线性关系，而传统机器学习算法通常是基于线性模型。这使得神经网络在处理复杂的、非线性的数据模式时具有更好的表达能力。</p>
</li>
<li><p>大规模数据处理：人工神经网络在大规模数据集上具有较好的处理能力。通过深层网络结构和并行计算，可以处理大量的数据并从中学习到更准确的模式和规律。</p>
</li>
<li><p>端到端学习：人工神经网络可以实现端到端的学习，从原始输入直接学习到输出，无需手动设计多个阶段的处理和特征。这简化了机器学习系统的设计和开发流程。</p>
</li>
<li><p>非凸优化问题：人工神经网络的训练通常涉及非凸优化问题，即寻找全局最优解的问题。相比之下，传统机器学习算法通常涉及凸优化问题，有较好的全局最优解保证。</p>
</li>
<li><p>模型的复杂性与解释性：人工神经网络通常具有复杂的网络结构和大量的参数，使得模型更加复杂。这导致了神经网络的解释性相对较低，难以理解模型内部的运行机制和权重的含义。</p>
</li>
<li><p>训练复杂性和计算资源需求：相对于传统机器学习算法，训练神经网络通常需要更多的计算资源和时间。深层网络的训练可能需要大量的训练数据和更复杂的优化算法，同时也需要更多的计算资源来进行模型的训练和推理。</p>
</li>
</ul>
<p>综上所述，人工神经网络相对于传统机器学习算法具有<strong>更强的</strong>特征学习能力、非线性模型能力、大规模数据处理能力和端到端学习能力。但<strong>同时也存在</strong>模型复杂性、解释性挑战、训练复杂性和计算资源需求等方面的特点。选择使用哪种方法取决于具体的任务、数据和资源要求。</p>
<h2 id="人工神經网络分类"><a href="#人工神經网络分类" class="headerlink" title="人工神經网络分类"></a>人工神經网络分类</h2><ul>
<li>依学习策略（Algorithm）分类主要有：<ul>
<li>监督式学习网络（Supervised Learning Network）为主</li>
<li>无监督式学习网络（Unsupervised Learning Network）</li>
<li>强化学习（Reinforcement Learning）：基于奖励机制，在与环境交互中学习最优策略。</li>
</ul>
</li>
<li>依网络架构（Connectionism）分类主要有：<ul>
<li>前馈神经网络（Feed Forward Network）信息在网络中单向传播，没有循环连接。<ul>
<li>包括MLP、CNN、Transformer、GPT-3(基于Transformer)</li>
</ul>
</li>
<li>循环神经网络（Recurrent Network）网络中存在循环连接，可以处理具有时间依赖性的序列数据。<ul>
<li>包括RNN，LSTM</li>
<li>循环神经网络具有循环连接，可以处理具有时间依赖性的序列数据。RNN 在处理序列数据时能够保留先前状态的信息，并具有记忆能力。</li>
</ul>
</li>
<li>卷积神经网络（Convolutional Neural Networks）：主要用于图像和视觉任务，通过卷积层和池化层来提取图像特征。<ul>
<li>CNN 属于前馈神经网络（Feedforward Neural Networks）的一种，但它在结构上具有一些特殊的设计。CNN 主要用于图像和视觉任务，通过卷积层和池化层来提取图像特征，从而捕捉图像中的局部关系和空间结构。</li>
</ul>
</li>
<li>自编码器（Autoencoders）：用于无监督学习和特征提取，由编码器和解码器组成。</li>
</ul>
</li>
<li>基于层级结构：<ul>
<li>单层神经网络：仅包含一个神经元层。</li>
<li>浅层神经网络：包含一到多个隐藏层（通常少于3层）。常用于处理较简单的任务，例如基本的模式识别和分类问题。</li>
<li>深度神经网络：包含多个隐藏层（例如5层或更多），通常用于处理更复杂的任务，如图像识别、自然语言处理等。</li>
</ul>
</li>
<li>基于应用领域：<ul>
<li>图像识别神经网络：用于图像分类、目标检测等计算机视觉任务。</li>
<li>语音识别神经网络：用于语音识别和语音合成任务。</li>
<li>自然语言处理神经网络：用于文本分类、机器翻译、情感分析等自然语言处理任务。</li>
</ul>
</li>
</ul>
<h3 id="特殊的神经网络"><a href="#特殊的神经网络" class="headerlink" title="特殊的神经网络"></a>特殊的神经网络</h3><p>表示网络节点关系的<strong>图神经网络</strong>属于一类特殊的神经网络模型，专门用于处理图结构数据的任务。它们利用图的节点和边表示数据之间的关系和连接。</p>
<p>图神经网络在处理图结构数据时具有独特的优势，可以考虑节点之间的邻近关系和全局拓扑结构，从而更好地捕捉图中的信息和模式。与传统的神经网络模型相比，图神经网络能够处理非欧几里德空间中的数据，如社交网络、蛋白质相互作用网络、推荐系统中的用户-物品关系等。</p>
<p>图神经网络的具体设计可以包括以下组件和操作：</p>
<ul>
<li>图卷积层（Graph Convolutional Layer）：通过将节点的特征与其邻居节点的特征进行聚合，更新节点的表示。</li>
<li>图池化层（Graph Pooling Layer）：通过对图的节点进行聚合和降维，减少图的规模和复杂性。</li>
<li>图注意力机制（Graph Attention Mechanism）：通过学习权重，动态地聚焦于图中重要的节点和边。</li>
<li>图生成模型（Graph Generation Models）：用于生成新的图样本，如图生成对抗网络（GANs）。</li>
<li>图自编码器（Graph Autoencoders）：用于无监督学习和图的特征提取。</li>
</ul>
<p>图神经网络的发展和研究是为了解决图数据分析和图结构任务，如图分类、节点分类、链接预测、图生成、图聚类等。这些任务通常需要考虑节点之间的关系和全局拓扑结构，并且图神经网络提供了一种有效的方式来处理和分析这种复杂的数据结构。</p>
<h2 id="多层神经网络常见组成结构"><a href="#多层神经网络常见组成结构" class="headerlink" title="多层神经网络常见组成结构"></a>多层神经网络常见组成结构</h2><p>现在的多层神经网络结构一般包含以下几种常见的层：</p>
<ul>
<li>输入层（Input Layer）：接收原始数据作为模型的输入，每个输入特征对应网络中的一个节点。</li>
<li>隐藏层（Hidden Layer）：位于输入层和输出层之间的一层或多层。每个隐藏层都包含多个节点（神经元），并使用激活函数对输入进行非线性变换。</li>
<li>输出层（Output Layer）：位于网络的最后一层，输出模型的预测结果或表示。输出层的节点数通常取决于具体的任务，例如分类任务可能有多个类别的节点，回归任务可能只有一个节点。</li>
</ul>
<p>除了这些基本层之外，还有一些特殊的层和技术，常见的包括：</p>
<ul>
<li>卷积层（Convolutional Layer）：主要用于处理图像和计算机视觉任务。卷积层通过应用一系列卷积核（过滤器）来提取输入数据中的局部特征，并共享权重以减少参数量。</li>
<li>池化层（Pooling Layer）：常与卷积层结合使用，用于减少特征图的尺寸和参数数量，同时保留主要特征。常见的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。</li>
<li>循环层（Recurrent Layer）：用于处理序列数据，如自然语言处理和时间序列分析。循环层中的神经元具有循环连接，可以在每个时间步骤上保留先前的状态信息。</li>
<li>规范化层（Normalization Layer）：如批归一化（Batch Normalization）和层归一化（Layer Normalization），用于提高网络的稳定性和收敛速度。</li>
<li>注意力层（Attention Layer）：通过学习注意力权重来对输入的不同部分进行加权处理，用于处理序列和集合数据中的相关性和重要性。</li>
</ul>
<p>需要注意的是，具体的网络结构和层数可能因任务和研究领域而异。不同的问题和应用可能会使用不同的层和技术来构建适合的神经网络结构。</p>
<h3 id="CNN神经网络的各种常见的网络层"><a href="#CNN神经网络的各种常见的网络层" class="headerlink" title="CNN神经网络的各种常见的网络层"></a>CNN神经网络的各种常见的网络层</h3><ol>
<li>卷积层、</li>
<li>激励层：由于卷积也是一种线性运算，因此需要对卷积层的输出进行一个非线性映射，一般为ReLu函数。</li>
<li>池化层：进行降维操作，一般有两种方式：进行下采样，对特征图稀疏处理，减少数据运算量<ol>
<li>max pooling：取池化视野中的最大值</li>
<li>Average pooling：取池化视野中的平均值</li>
</ol>
</li>
<li>归一化层：<ol>
<li>在Batch Normalization（简称BN）出现之前，我们的归一化操作一般都在数据输入层，对输入的数据进行求均值以及求方差做归一化，但是BN的出现打破了这一个规定，我们可以在网络中任意一层进行归一化处理。</li>
<li>不仅可以加快了模型的收敛速度，而且更重要的是在一定程度缓解了深层网络中“梯度弥散”的问题，从而使得训练深层网络模型更加容易和稳定。</li>
<li>也有更先进的，比如layernorm</li>
</ol>
</li>
<li>切分层：对某些（图片）数据的进行分区域的单独学习</li>
<li>融合层：对某些（图片）数据的进行分区域的单独学习</li>
<li>dropout层：为了防止过拟合（模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。）<ol>
<li>在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征</li>
</ol>
</li>
<li>全连接层：通常在CNN的尾部进行重新拟合，减少特征信息的损失。</li>
<li>输出层</li>
</ol>
<h2 id="经典深度学习方法模型"><a href="#经典深度学习方法模型" class="headerlink" title="经典深度学习方法模型"></a>经典深度学习方法模型</h2><h3 id="感知器"><a href="#感知器" class="headerlink" title="感知器"></a>感知器</h3><p>最简单的结构，能二分类。</p>
<h3 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><p>是一种最简单的神经网络，各神经元分层排列，每个神经元只与前一层的神经元相连。 接收前一层的输出，并输出给下一层，各层间<strong>没有</strong>反馈。</p>
<h3 id="残差神经网络"><a href="#残差神经网络" class="headerlink" title="残差神经网络"></a>残差神经网络</h3><p>残差神经网络（Residual Neural Network，ResNet）是指一种特殊的深度神经网络结构，于2014年由Kaiming He等人提出。它属于前馈神经网络（Feedforward Neural Networks）的一种，具有深层的网络结构。</p>
<p>残差网络是为了解决深度神经网络（DNN）隐藏层过多时的网络退化问题而提出。</p>
<p>退化（degradation）问题是指：当网络隐藏层变多时，网络的准确度达到饱和然后急剧下降，而且这个退化不是由于过拟合引起的。而是由于网络的深度增加导致的优化问题。</p>
<p>退化问题的出现是由于网络深度增加后，梯度在反向传播过程中逐渐消失（梯度消失）或者变得非常大（梯度爆炸），导致网络的参数无法有效地更新，从而影响了网络的性能。这使得更深层的网络反而比较浅层的网络性能更差。</p>
<p>残差神经网络的主要特点是引入了跳跃连接（Skip Connection）或残差连接（Residual Connection）。跳跃连接通过将输入数据与输出数据直接相加，使得网络可以学习残差函数，即输入与期望输出之间的差异。这种结构可以解决深层神经网络训练中的梯度消失和梯度爆炸问题，有助于有效地训练更深的网络。</p>
<p>残差神经网络的核心思想是通过残差块（Residual Block）来构建网络层。每个残差块包含了多个卷积层和批归一化层，通过跳跃连接将输入和输出相加，并通过激活函数进行非线性变换。这样的结构可以让网络更容易地学习残差部分，从而提高网络的性能和训练效率。</p>
<h3 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h3><p>多层感知器（Multilayer Perceptron,缩写MLP）是一种<strong>前向</strong>结构的<strong>人工神经网络</strong></p>
<p>MLP可以被看作是一个有向图，由多个的节点层所组成，<strong>每一层都全连接到下一层</strong>。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。一种被称为<strong>反向传播算法BP</strong>的监督学习方法常被用来训练MLP。（该BP算法会先按前向传播方式计算（并缓存）每个节点的输出值，然后再按反向传播遍历图的方式计算损失函数值相对于每个参数的偏导数。）</p>
<p>术语“多层感知器”不是指具有多层的单感知器，每一层由多个感知器组成。</p>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><p>卷积神经网络（Convolutional Neural Network, CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。</p>
<p>卷积神经网络由一个或多个<strong>卷积层</strong>和顶端的<strong>全连通层</strong>（对应经典的神经网络）组成，同时也包括关联权重和<strong>池化层</strong>（pooling layer）。这一结构使得卷积神经网络能够利用输入数据的二维结构。</p>
<p>与其他深度学习结构相比，卷积神经网络在<strong>图像CV</strong>方面能够给出更好的结果。</p>
<p>这一模型也可以使用反向传播算法进行训练。相比较其他深度、前馈神经网络，卷积神经网络需要考量的参数更少，使之成为一种颇具吸引力的深度学习结构</p>
<p>经典网络：ResNet，LeNet，AlexNet</p>
<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>CNN是对<strong>空间</strong>上特征的提取， RNN则是对<strong>时序</strong>上特征的提取。</p>
<p>循环神经网络（Recurrent neural network：RNN）是神经网络的一种。单纯的RNN因为无法处理随着递归，权重<strong>指数级爆炸或梯度消失</strong>问题，难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。</p>
<p>时间循环神经网络可以描述动态时间行为，因为和前馈神经网络（feedforward neural network）接受较特定结构的输入不同，RNN将状态在自身网络中循环传递，因此可以接受更广泛的<strong>时间序列结构输入</strong>。手写识别，语音识别和视频这些与时间有关的是最早成功利用RNN的研究结果。</p>
<p>一般必须有<strong>编码器</strong>(将输入序列编码为一个固定长度的隐藏状态)与<strong>解码器</strong>（将编码后（Encoded）的信息解码为人类可识别的信息）<img src="https://pic.shaojiemike.top/img/20220125205323.png"></p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>RNN 的问题是非线性操作 σ 的存在且每一步间通过连乘操作传递，会导致长序列历史信息不能很好的传递到最后，而有了 LSTM 网络。</p>
<p>长短期记忆（英语：Long Short-Term Memory，LSTM）是一种时间循环神经网络（RNN），论文首次发表于1997年。由于独特的设计结构，LSTM适合于处理和预测时间序列中间隔和延迟非常长的重要事件。</p>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>为了解决RNN处理长句子(长时间)时，在机器翻译中，当前时间片的输出可能仅更注重原句子的某几个单词而不是整个句子。</p>
<ol>
<li>时间片 t 的计算依赖 t-1 时刻的计算结果，这样限制了模型的并行能力；</li>
<li>顺序计算的过程中信息会丢失，尽管LSTM等门机制的结构一定程度上缓解了长期依赖的问题，但是对于特别长期的依赖现象,LSTM依旧无能为力。</li>
</ol>
<p>通过Attention机制，模型可以同时学习原句子和目标句子的对齐关系和翻译关系。在编码过程中，将原句子编码成一组特征向量的一个集合，在翻译时，每个时间片会在该集合自行选择特征向量的一个子集用于产生输出结果。</p>
<h4 id="Attention注意力机制的历史"><a href="#Attention注意力机制的历史" class="headerlink" title="Attention注意力机制的历史"></a>Attention注意力机制的历史</h4><p>Attention 机制最早是在视觉图像领域提出来的（通过遮掩信息），应该是在九几年思想就提出来了，但是真正火起来应该算是 2014 年 Google Mind 团队的这篇论文 Recurrent Models of Visual Attention，他们在 RNN 模型上使用了 Attention机制来进行图像分类。</p>
<p>接着 Attention 机制被广泛应用在基于 RNN&#x2F;CNN 等神经网络模型的各种 NLP 任务中。2017 年，Google 机器翻译团队发表的 <strong>Attention is All You Need</strong> 中大量使用了自注意力（self-attention）机制来学习文本表示。自注意力机制也成为了大家近期的研究热点，并在各种 NLP 任务上进行探索。</p>
<h3 id="transformer（抛弃RNN的并行Attention）"><a href="#transformer（抛弃RNN的并行Attention）" class="headerlink" title="transformer（抛弃RNN的并行Attention）"></a>transformer（抛弃RNN的并行Attention）</h3><p>mask &amp; self-attention</p>
<p>Transformer中抛弃了传统的CNN和RNN，整个网络结构完全是由<strong>Attention机制</strong>组成。更准确地讲，Transformer由且仅由self-Attenion和Feed Forward Neural Network组成。一个基于Transformer的可训练的神经网络可以通过堆叠Transformer的形式进行搭建，作者的实验是通过搭建编码器和解码器各6层，总共12层的Encoder-Decoder。</p>
<p>首先它使用了Attention机制，将序列中的任意两个位置之间的<strong>距离</strong>是缩小为一个常量；</p>
<p>其次它不是类似RNN的顺序结构，因此具有更好的<strong>并行性</strong>，符合现有的GPU框架。颠覆了RNN在NLP领域的主流地位，为之后大厂暴力堆GPU训练大模型和ChatGPT的出现埋下了种子。</p>
<p>缺点：</p>
<p>（1）粗暴的抛弃RNN和CNN虽然非常炫技，但是它也使模型丧失了捕捉局部特征的能力，RNN + CNN + Transformer的结合可能会带来更好的效果。</p>
<p>（2）Transformer失去的位置信息其实在NLP中非常重要，而论文中在特征向量中加入Position Embedding也只是一个权宜之计，并没有改变Transformer结构上的固有缺陷。</p>
<h3 id="Bert（自编码模型）"><a href="#Bert（自编码模型）" class="headerlink" title="Bert（自编码模型）"></a>Bert（自编码模型）</h3><p>谷歌团队提出的用于生成词向量的BERT算法的最重要的部分便是本文中提出的Transformer的概念。</p>
<p>BERT的全称是Bidirectional Encoder Representation from Transformers，就是双向Transformer的Encoder。</p>
<p>BERT还有一点很重要，它将CV里的预训练引入了NLP问题中，使得其余的NLP任务可以在其预训练集上进一步训练，或者拿来直接用。</p>
<h3 id="ELMO"><a href="#ELMO" class="headerlink" title="ELMO"></a>ELMO</h3><p>ELMO的全称是Embedding from Language Models。就ELMO模型本身的训练过程来说，它通过一个<strong>两层的双向LSTM，使用语言模型训练</strong>，也就是说利用一句话的上文Context-Before和下文Context-After来预测当前词。</p>
<h3 id="GPT-3（自回归模型）"><a href="#GPT-3（自回归模型）" class="headerlink" title="GPT-3（自回归模型）"></a>GPT-3（自回归模型）</h3><p><img src="https://pic.shaojiemike.top/img/20230803082015.png" alt="gpt iterative evolution"></p>
<ul>
<li>GPT的全称是Generative Pre-Trained Transformer。<ul>
<li>2017年，OpenAI(2015年成立)提出GPT论文<ul>
<li>2018.6 推出GPT1 1.2亿</li>
<li>2019.11 推出GPT2 15亿 。这时OpenAI没钱了，非盈利组织变收益封顶的盈利组织，微软注资10亿美元</li>
<li>2020.6 推出GPT3 1750亿，这时没有人工反馈，导致参数量再增大，效果也无法提升了。</li>
<li>2022.3 推出GPT3.5</li>
<li>2022.11 推出ChatGPT</li>
<li>2023.4 推出GPT-4, 虽然诞生于22年8月，OpenAI经过8个月的时间来确保对齐后才发布。</li>
</ul>
</li>
<li>GPT核心原理：根据前面输入的语句，推测下一个字是什么<ul>
<li>GPT 拥有一张包含了五万个单词的词汇表，它会基于互联网上的海量文本，大致了解每个单词后面可能会跟着哪些单词，并给出相应的出现概率。</li>
</ul>
</li>
<li>GPT模型的生成过程核心是<ul>
<li>先通过无标签的文本去训练（<strong>无监督学习</strong>）生成语言模型，</li>
<li>再根据具体的NLP任务（如文本蕴涵、QA、文本分类等），来通过有标签的数据对模型进行fine-tuning微调（<strong>有监督学习、人工反馈的强化学习</strong>）。</li>
</ul>
</li>
<li>它与ELMO一样，仍然是用语言模型进行无监督训练的，但是它用了特征提取能力更强的Transformer，并且是单向的Transformer。</li>
</ul>
</li>
</ul>
<p>GPT-3 模型的参数量达到 1750 亿，即便拥有 1024 张 80GB A100， 那么完整训练 GPT-3 的时长都需要 1 个月。</p>
<p>2021年1月，OpenAI官宣了120亿参数的GPT-3变体DALL-E。<br>多模态可以实现语言到图像的转化。</p>
<h3 id="ChatGPT"><a href="#ChatGPT" class="headerlink" title="ChatGPT"></a>ChatGPT</h3><ul>
<li><p>使用了GPT-3.5大规模语言模型（LLM，Large Language Model），</p>
</li>
<li><p>并在该模型的基础上引入强化学习来Fine-turn预训练的语言模型。这里的强化学习采用的是RLHF（Reinforcement Learning from Human Feedback），</p>
<ul>
<li>即采用人工标注的方式。目的是通过其奖励惩罚机制（reward）让LLM模型学会理解各种NLP任务并学会判断什么样的答案是优质的（helpfulness、honest、harmless三个维度）。</li>
</ul>
</li>
<li><p>部分有趣的原理：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/R3S7qeif4Vkr5K2fx2NSiw">关于token和无法反转字符</a></p>
</li>
<li><p>意义</p>
<ul>
<li>chatGPT貌似打通了机器理解人类自然语言的屏障，表面上能理解人们的意思。</li>
<li>如果机器能直接理解人类的目的，就不需要编程人员来实现我们的想法，可以让chatGPT理解并自主实现，AutoGPT的出现就是如此，去掉了对目的实现方式的深究，直接获得AI结果的方式。就是AIGC的核心。</li>
<li>这也激发了人们对AGI的畅想，期待着会自主思考(思维链与常识)并学习进化的AI。</li>
</ul>
</li>
<li><p>带来的思考</p>
<ul>
<li>记忆力特别好，会找规律，但是不明白自己在说什么的小孩。(数学逻辑欠缺，如何修正？)<ul>
<li>不理解真实世界，没有真正在“回答”问题，只是在模仿人类的语言行为</li>
</ul>
</li>
<li>大力出奇迹，以及NLP+强化学习的方式能够取得很好的表现。</li>
<li>当无监督学习的数据量增大到一定到程度，有监督学习就算变少也不会影响模型效果。<ul>
<li>到了GPT-3，当参数到达了1750亿以后，更是突然出现了诸如<strong>思维链</strong>等特性。</li>
</ul>
</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>准确度(胡说 （人工标注强化学习过。过于专业或者网上缺少的知识，chatgpt难以回答</li>
<li>据对齐和伦理性</li>
<li>AI 生成的东西会污染网络</li>
<li>transform 绝对不是AGI的基础模型，不是未来。</li>
</ul>
</li>
<li><p>关于最佳模型的讨论 - 2023北京智源AI大会</p>
<ul>
<li>Transformer不会是超强AI的模型架构，大语言模型（LLM）不理解世界运转逻辑，更强的AI模型应具备对现实世界的无监督学习能力</li>
<li>自回归模型”(Auto-regressive model)没有关于基础现实的知识，既缺乏常识也没法规划答案</li>
</ul>
</li>
</ul>
<p>如何使用LLM：</p>
<ol>
<li>(L)借助庞大的数据库： 头脑风暴</li>
<li>(LM)语言模型<ol>
<li>办公辅助，生成书信论文格式，谦卑语气的检讨书</li>
</ol>
</li>
<li>整合版本的搜索引擎<ol>
<li>快速入门概念：不熟悉的领域的基本操作( 如何写简单前端，关于这一点的准确性，由于是入门的问题，也能精确解决</li>
</ol>
</li>
<li>模板或者格式化的工作 ，不再只限于重复工作<ol>
<li>如何使用新编程语言，如何爬虫。</li>
</ol>
</li>
</ol>
<h3 id="LLM-Research-path"><a href="#LLM-Research-path" class="headerlink" title="LLM Research path"></a>LLM Research path</h3><p><img src="https://pic.shaojiemike.top/shaojiemike/2023/11/4af172ccdaa6e74c9fd11c7eb20bcc95.png">[^1]</p>
<h3 id="GPT-5-6"><a href="#GPT-5-6" class="headerlink" title="GPT-5 &#x2F; 6"></a>GPT-5 &#x2F; 6</h3><p>OpenAI 已经在尝试用AI训练(面临<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/cLgL0zNB3dsbMBfxAGyCpQ">崩溃问题</a>)和解释AI，并且直接从世界中学习</p>
<h3 id="世界模型？"><a href="#世界模型？" class="headerlink" title="世界模型？"></a>世界模型？</h3><p>论文： A Path Towards Autonomous Machine Intelligence</p>
<p>通过世界模型，AI可以真正理解这个世界、能预测和规划未来。通过成本核算模块，结合一个简单的需求（按照最节约行动成本的逻辑去规划未来），它就可以杜绝一切潜在的毒害和不可靠性</p>
<p>这个未来如何实现？世界模型如何学习？杨立昆只给了一些规划性的想法，比如还是采用自监督模型去训练，比如一定要建立多层级的思维模式。他介绍了联合嵌入预测架构（JEPA），系统性地介绍了这一实现推理和规划的关键</p>
<p><img src="https://pic.shaojiemike.top/img/20230616182806.png"></p>
<h3 id="Stable-Diffusion"><a href="#Stable-Diffusion" class="headerlink" title="Stable Diffusion"></a>Stable Diffusion</h3><p>Stable diffusion是一个基于Latent Diffusion Models（潜在扩散模型，LDMs）的文图生成（text-to-image）模型。</p>
<p>扩散模型（Diffusion Models, DM）是基于Transformer的生成模型，它采样一段数据（例如图像）并随着时间的推移逐渐增加噪声，直到数据无法被识别。该模型尝试将图像回退到原始形式，在此过程中学习如何生成图片或其他数据。<br>DM存在的问题是强大的DM往往要消耗大量GPU资源，而且由于序列化评估(Sequential Evaluations)，推理的成本相当高。</p>
<p>为了使DM在有限的计算资源上进行训练而不影响其质量以及灵活性，Stable Diffusion将DM应用于强大的预训练自动编码器（Pre-trained Autoencoders）。<br>在这样的前提下训练扩散模型，使其有可能在降低复杂性和保留数据细节之间达到一个最佳平衡点，显著提高视觉真实程度。</p>
<p>在模型结构中引入<strong>交叉注意力层</strong>（cross attention layer），使扩散模型成为一个强大而灵活的生成器，实现基于卷积的高分辨率图像生成。</p>
<h3 id="Midjourney"><a href="#Midjourney" class="headerlink" title="Midjourney"></a>Midjourney</h3><p>也是基于Diffusion？</p>
<h3 id="DALL-E-2"><a href="#DALL-E-2" class="headerlink" title="DALL*E -2"></a>DALL*E -2</h3><p>DALL-E 2由OpenAI开发，它通过一段文本描述生成图像。其使用超过100亿个参数训练的GPT-3转化器模型，能够解释自然语言输入并生成相应的图像。</p>
<h3 id="Firefly-Photoshop"><a href="#Firefly-Photoshop" class="headerlink" title="Firefly - Photoshop"></a>Firefly - Photoshop</h3><h3 id="ViT"><a href="#ViT" class="headerlink" title="ViT"></a>ViT</h3><p>ViT（vision transformer）是Google在2020年提出的直接将transformer应用在图像分类的模型，后面很多的工作都是基于ViT进行改进的。</p>
<p>ViT的思路很简单：</p>
<ol>
<li>直接把图像分成固定大小的patchs，然后通过线性变换得到patch embedding，这就类比NLP的words和word embedding，</li>
<li>由于transformer的输入就是a sequence of token embeddings，所以将图像的patch embeddings送入transformer后就能够进行特征提取从而分类了。</li>
</ol>
<p>ViT模型原理如下图所示，其实ViT模型只是用了transformer的Encoder来提取特征（原始的transformer还有decoder部分，用于实现sequence to sequence，比如机器翻译）。<br><img src="https://pic.shaojiemike.top/img/20211121204428.png"></p>
<h3 id="自回归语言模型-VS-自编码语言模型"><a href="#自回归语言模型-VS-自编码语言模型" class="headerlink" title="自回归语言模型 VS 自编码语言模型"></a>自回归语言模型 VS 自编码语言模型</h3><p><strong>自回归语言模型</strong>是根据上文或者下文来预测后一个单词。那不妨换个思路，我把句子中随机一个单词用[mask]替换掉，是不是就能同时根据该单词的上下文来预测该单词。我们都知道Bert在预训练阶段使用[mask]标记对句子中15%的单词进行随机屏蔽，然后根据被mask单词的上下文来预测该单词，这就是<strong>自编码语言模型</strong>的典型应用。</p>
<p>自回归语言模型没能自然的同时获取单词的上下文信息（ELMo把两个方向的LSTM做concat是一个很好的尝试，但是效果并不是太好），而自编码语言模型能很自然的把上下文信息融合到模型中（Bert中的每个Transformer都能看到整句话的所有单词，等价于双向语言模型），但自编码语言模型也有其缺点，就是在Fine-tune阶段，模型是看不到[mask]标记的，所以这就会带来一定的误差。</p>
<h3 id="自监督任务"><a href="#自监督任务" class="headerlink" title="自监督任务"></a>自监督任务</h3><p>自监督学习实际上与监督学习、非监督学习、半监督学习并没有本质上的鸿沟。</p>
<p>自我监督方法可以看作是一种具有监督形式的特殊形式的非监督学习方法，这里的监督是由自我监督任务而不是预设先验知识诱发的。与完全不受监督的设置相比，自监督学习使用数据集本身的信息来构造伪标签。在表示学习方面，自我监督学习具有取代完全监督学习的巨大潜力。人类学习的本质告诉我们，大型注释数据集可能不是必需的，我们可以自发地从未标记的数据集中学习。更为现实的设置是使用少量带注释的数据进行自学习。</p>
<h2 id="AI-挑战-与-展望"><a href="#AI-挑战-与-展望" class="headerlink" title="AI 挑战 与 展望"></a>AI 挑战 与 展望</h2><h3 id="人工智能三定律"><a href="#人工智能三定律" class="headerlink" title="人工智能三定律"></a>人工智能三定律</h3><p>（引用《AI的25种可能》）</p>
<ul>
<li>第一定律：任何有效的控制系统都必须与它所控制的系统一样复杂（阿什比定律（Ashby’s law)）</li>
<li>第二定律：生物体最简单的完整模型就是生物体本身。试图将系统的行为简化为任何形式的描述都会使事情变得更复杂，而不是更简单（冯·诺依曼提出）</li>
<li>第三定律：任何简单到可以理解的系统都不会复杂到可以智能地运行，而任何复杂到可以智能运行的系统都会复杂到无法理解（第三定律存在一个漏洞—完全有可能在不理解智能的情况下将它构建出来）</li>
</ul>
<h3 id="抛弃硬件与软件结合的可朽计算、凡人计算"><a href="#抛弃硬件与软件结合的可朽计算、凡人计算" class="headerlink" title="抛弃硬件与软件结合的可朽计算、凡人计算"></a>抛弃硬件与软件结合的可朽计算、凡人计算</h3><p>来自： AI教父Hinton智源大会闭幕主题演讲</p>
<p>在传统计算中，计算机被设计为精确地遵循指令。我们可以在不同的物理硬件上运行完全相同的程序和神经网络，这意味着程序或神经网络的权重中的知识是永生的（immortal），不依赖于任何特定的硬件</p>
<p>但要实现这种永生，需要付出高昂的代价—需要高功率运行晶体管，以便它们以数字方式运行，我们无法利用硬件的所有丰富的模拟和高度可变的特性</p>
<p>现在我们可以让计算机从例子中学习，因此可以考虑放弃计算机科学最基本的原则—软硬件可以分离，从而得到凡人计算（Mortal Computation)</p>
<p>凡人计算的巨大优点：以更少的能量运行大语言模型之类的AI，特别是使用更少的能量来训练AI大模型。通过放弃硬件（身体）和软件（灵魂）的分离，我们可以节省大量能源，可以使用非常低功耗的模拟计算—这正是大脑正在做的事情</p>
<p>我们还可以获得更便宜的硬件，硬件可以在3-D中便宜地生长，而不用在2-D中非常精确地制造。这需要大量的新的纳米技术，或可能需要对生物神经元进行基因改造</p>
<p>目前凡人计算还面临两大问题：1）学习过程必须利用它所运行的硬件的特定模拟属性，而无需确切知道这些属性是什么，这意味着无法使用反向传播算法（backpropagation)来获得梯度，因为反向传播算法需是前向传播的精确模型；2）凡人计算的生命是有限的，当特定的硬件死掉时，它学习的知识会随之消亡，因为知识和硬件错综复杂地绑定在一起；解决方案是在硬件失效前，将知识蒸馏出来给学生</p>
<h2 id="任务基本流程（图像处理）"><a href="#任务基本流程（图像处理）" class="headerlink" title="任务基本流程（图像处理）"></a>任务基本流程（图像处理）</h2><ol>
<li>数据预处理<ol>
<li>中值滤波（去噪）</li>
<li>(图像)数据标准化<ol>
<li>边缘检测</li>
<li>轮廓提取</li>
<li>图像裁剪</li>
</ol>
</li>
<li>去重&#x2F;训练数据平权<ol>
<li>定义相似关系（偏序）：满足自反，传递和对称性</li>
<li>并查集聚类（大于一定阈值）</li>
<li>原因:（假如原本只有pic1&#x2F;2,两个图片，如果第一个图片重复了一万次，训练出来的网络，只要无脑选1就可以正确度很高）</li>
</ol>
</li>
<li>数据特征提取</li>
</ol>
</li>
<li>数据增强<ol>
<li>通过等价性质，拓展训练数据集<ol>
<li>伽马变换（颜色变换漂白、变暗），高斯模糊（像素平滑化），颜色抖动</li>
<li>仿射变换</li>
<li>随机旋转，水平垂直翻转，尺寸缩放</li>
<li>随机擦除</li>
</ol>
</li>
</ol>
</li>
<li>选择网络模型<ol>
<li>eg 预训练的EfficientNet-b5</li>
<li>魔改网络<ol>
<li>采用多分支：不同分支使用不同大小的卷积核</li>
<li>卷积核大小（扩大感受野）、通道数调整</li>
<li>并行的多层空洞卷积提取多尺度特征</li>
</ol>
</li>
<li>调整参数<img src="https://pic.shaojiemike.top/img/20220125073434.png"></li>
<li>注意是否过拟合或者欠拟合</li>
</ol>
</li>
<li>对数据多折迭代训练<ol>
<li><p>伪标签 + 多折融合 + 测试时增强（TTA）</p>
</li>
<li><p>K折交叉检验法<br>在机器学习的建模工作中，首先会将数据集分为训练集和测试集，在训练集上对模型进行训练以及参数的调优，在测试集上对模型进行评估，但是测试集的选择会对模型的效果产生影响，在随机切分训练集&#x2F;测试集的情况下，可能刚好选择了比较容易预测的数据点作为测试集，所以采用交叉验证（cross validation）的方式，通过获取模型在多个测试集上的平均效果来总体评估模型的效果。</p>
<p>而交叉验证中常用的方法K折交叉检验法（k-fold cross validation）用于模型调优，可以缓解过拟合现象的产生，具体实现方法：</p>
<p>将样本数据集分为k组大小相似的互斥子集，每次抽取出k份中的一份作为测试集，剩下来的k-1份作为训练集，尽量保证每个子集数据分布的一致性。依次得到测试结果S1,S2,…,Sk,然后求其平均值得到模型在多个测试集上的平均效果，用求得的平均值评估模型的总体效果。</p>
<p><a target="_blank" rel="noopener" href="https://developer.huaweicloud.com/hero/thread-74349-1-1.html">https://developer.huaweicloud.com/hero/thread-74349-1-1.html</a></p>
</li>
</ol>
</li>
<li>通过分析结果相似性等，修正结果</li>
</ol>
<h2 id="任务优化常见方法"><a href="#任务优化常见方法" class="headerlink" title="任务优化常见方法"></a>任务优化常见方法</h2><h3 id="样本不均衡的解决方法"><a href="#样本不均衡的解决方法" class="headerlink" title="样本不均衡的解决方法"></a>样本不均衡的解决方法</h3><ol>
<li>数据处理<ol>
<li>数据扩增- 通过变换或者转换产生一堆相同的正例子数据</li>
<li>只用一部分negative的样本</li>
</ol>
</li>
<li>loss计算改变权重<ol>
<li><ol>
<li><strong>加权交叉熵</strong></li>
</ol>
</li>
<li><strong>focal Loss</strong></li>
</ol>
</li>
</ol>
<h2 id="任务优化-提高精度（最后成绩"><a href="#任务优化-提高精度（最后成绩" class="headerlink" title="任务优化 - 提高精度（最后成绩"></a>任务优化 - 提高精度（最后成绩</h2><ol>
<li>知识蒸馏</li>
<li>迁移学习</li>
<li>伪标签 + 多折融合 + 测试时增强（TTA）</li>
<li>针对具体问题的特殊设计<ol>
<li>函数的连续平滑化处理<img src="https://pic.shaojiemike.top/img/20220125071255.png"></li>
<li>为保证结果的特殊性质而特别设计的网络（平移旋转不变性，拓展不变性<img src="https://pic.shaojiemike.top/img/20220125071228.png"></li>
<li>已知结果分布的情况下修正</li>
</ol>
</li>
</ol>
<h2 id="任务优化-提升速度"><a href="#任务优化-提升速度" class="headerlink" title="任务优化 - 提升速度"></a>任务优化 - 提升速度</h2><ol>
<li>kernel fusion<ol>
<li>所谓内核融合，就是将一个计算图中的节点所对应的内核函数融合成一个函数，使得整个数据流图只需要通过一次函数调用即可完成，从而减小平台调度和内核启动带来的开销。并且，通过合理地设计不同内核函数的输入输出数据的放置（例如使用GPU上的共享内存或寄存器），可以极大地提高数据传输效率，从而提升整体计算性能。</li>
</ol>
</li>
<li>预训练模型？</li>
<li>使用Batch Normalization折叠来加速模型推理<ol>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1749026">https://cloud.tencent.com/developer/article/1749026</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24810318">https://zhuanlan.zhihu.com/p/24810318</a></li>
<li>也有更先进的，比如layernorm</li>
</ol>
</li>
<li>模型量化(混合精度)（向低精度走更快，但是会更容易炸，数据存储不下）</li>
<li>训练的时候不同阶段冻结不同的层也可能可以加速。 <a target="_blank" rel="noopener" href="https://blog.csdn.net/ningyanggege/article/details/80596858">https://blog.csdn.net/ningyanggege/article/details/80596858</a></li>
<li>扩大batch size，像并行训练，deepspeed都是为了扩大batch size的。batch size扩大需要调整学习率，warmingup这些参数来提高精度 <a target="_blank" rel="noopener" href="https://blog.csdn.net/zr459927180/article/details/50527529">https://blog.csdn.net/zr459927180/article/details/50527529</a></li>
<li>算子融合</li>
<li>cudnn</li>
</ol>
<h3 id="模型量化"><a href="#模型量化" class="headerlink" title="模型量化"></a>模型量化</h3><p>模型量化旨在将深度学习模型中的参数和激活值从高精度表示（如32位浮点数）转换为低精度表示（如8位整数或更低精度），以降低计算和存储开销，提高推理速度。常见的模型量化技术包括：</p>
<ul>
<li>权重量化（Weight Quantization）：将模型的权重参数从高精度浮点数转换为低位整数或定点数表示。这样可以减小权重的存储空间，降低内存带宽需求，提高计算效率。</li>
<li>激活量化（Activation Quantization）：将模型中的激活值从高精度浮点数转换为低位整数或定点数表示。这样可以减小激活值的表示大小，降低内存带宽需求，并加快推理速度。</li>
<li>量化感知训练（Quantization-Aware Training）：在训练过程中，通过模拟低精度推理的效果，将模型参数训练为适应量化的形式。这样可以减小量化对模型性能的影响，并提高量化后模型的准确性。</li>
</ul>
<h2 id="任务优化-节约空间，扩大参数规模"><a href="#任务优化-节约空间，扩大参数规模" class="headerlink" title="任务优化 - 节约空间，扩大参数规模"></a>任务优化 - 节约空间，扩大参数规模</h2><p>模型压缩旨在减小深度学习模型的存储空间，以便更好地适应资源受限的环境。常见的模型压缩技术包括：</p>
<ul>
<li>权重剪枝（Weight Pruning）：通过将模型中接近于零的权重置为零，从而减少模型中的参数数量。这样可以减小模型的存储需求，并降低计算开销。</li>
<li>稀疏矩阵技术（Sparse Matrix Techniques）：利用稀疏矩阵的特性，只存储非零元素和其对应的索引，从而减少模型存储所需的内存空间。</li>
<li>低秩分解（Low-Rank Decomposition）：将模型参数矩阵分解为多个低秩矩阵的乘积形式，从而减少参数的数量，并提高计算效率。</li>
<li>网络量化（Network Quantization）：将模型的参数从浮点数转换为低精度的定点数或整数，从而减小参数的表示大小，降低存储和计算开销。</li>
</ul>
<h2 id="HPC-AI-科学计算-的新发展方向"><a href="#HPC-AI-科学计算-的新发展方向" class="headerlink" title="HPC + AI + 科学计算 的新发展方向"></a>HPC + AI + 科学计算 的新发展方向</h2><h3 id="静态代码分析器的机器学习实现"><a href="#静态代码分析器的机器学习实现" class="headerlink" title="静态代码分析器的机器学习实现"></a>静态代码分析器的机器学习实现</h3><p>LSTM（确实是和时间有关的问题，毕竟是指令按序指令）</p>
<h3 id="DeepMD实现分子动力学模拟"><a href="#DeepMD实现分子动力学模拟" class="headerlink" title="DeepMD实现分子动力学模拟"></a>DeepMD实现分子动力学模拟</h3><p>网络其实设计的很简单，除开为了满足物理性质的特殊设计，其实就是一个全联接的前馈神经网络（MLP），计算出loss反向传播修改每个全连接层的权值。</p>
<p>原因很简单，输出和输出很简单，只需要寻找各个原子初始坐标和基态能量和结果总能量的关系。即没有CV图像庞大的数据需要通过CNN特征提取，也没有语音和文字这种按时间大量输入的问题需要引入时间，用RNN或者注意力机制解决。</p>
<h2 id="一些基本概念"><a href="#一些基本概念" class="headerlink" title="一些基本概念"></a>一些基本概念</h2><h3 id="梯度累加"><a href="#梯度累加" class="headerlink" title="梯度累加"></a>梯度累加</h3><p>为了应对batchsize(训练cover的数据量)不够大的问题，将多次迭代的梯度累加后再统一一次反向传播更新。</p>
<h3 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h3><p>模型参数的初始化一直是一个重要的研究问题，一个合适的初始化能够提升模型性能，加速收敛找到最优解。</p>
<p>由于不需要训练数据，所以无监督或自监督训练后的模型，能够很自然地作为下游任务（如图像分类、目标检测）模型微调前的初始化参数。</p>
<p>无监督算法的性能由微调后模型在下游任务的性能，如准确率、收敛速度等等相比基线模型是否有提高来进行判断。</p>
<p>在计算机视觉领域，由于CNN在过去的统治力，所以无监督深度学习通常都是基于标准卷积网络模型。例如将ResNet预训练后的模型迁移到其他基于CNN模型也是相当容易且直接的。</p>
<p>但现在时代变了，Vision Transformer（ViT）成为了新的主流模型。</p>
<h3 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h3><p>知识蒸馏指的是模型压缩的思想，通过一步一步地使用一个较大的已经训练好的网络去教导一个较小的网络确切地去做什么。</p>
<h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>迁移学习(transfer learning)通俗来讲，就是运用已有的知识来学习新的知识，核心是找到已有知识和新知识之间的相似性，用成语来说就是举一反三。由于直接对目标域从头开始学习成本太高，我们故而转向运用已有的相关知识来辅助尽快地学习新知识。比如，已经会下中国象棋，就可以类比着来学习国际象棋；已经会编写Java程序，就可以类比着来学习C#；已经学会英语，就可以类比着来学习法语；等等。世间万事万物皆有共性，如何合理地找寻它们之间的相似性，进而利用这个桥梁来帮助学习新知识，是迁移学习的核心问题。</p>
<h3 id="skip-connect"><a href="#skip-connect" class="headerlink" title="skip connect"></a>skip connect</h3><p>也就是残差连接。skip connect的思想，将输出表述为输入和输入的一个非线性变换的线性叠加，没用新的公式，没有新的理论，只是换了一种新的表达。<br><img src="https://pic.shaojiemike.top/img/20220128214428.png"></p>
<h3 id="SOTA"><a href="#SOTA" class="headerlink" title="SOTA"></a>SOTA</h3><p>SOTA也就是state-of-the-art，若某篇论文能够称为SOTA，就表明其提出的算法（模型）的性能在当前是最优的。</p>
<p>网址：<a target="_blank" rel="noopener" href="https://www.stateoftheart.ai/models">https://www.stateoftheart.ai/models</a></p>
<p><a target="_blank" rel="noopener" href="https://sota.jiqizhixin.com/">https://sota.jiqizhixin.com/</a></p>
<h3 id="CVPR"><a href="#CVPR" class="headerlink" title="CVPR"></a>CVPR</h3><p>Conference on Computer Vision and Pattern Recognition</p>
<h3 id="下采样"><a href="#下采样" class="headerlink" title="下采样"></a>下采样</h3><p>对于一个样值序列间隔几个样值取样一次，这样得到新序列就是原序列的下采样。</p>
<p>在图像上， 缩小图像就是下采样。</p>
<h3 id="卷积可视化"><a href="#卷积可视化" class="headerlink" title="卷积可视化"></a>卷积可视化</h3><p><a target="_blank" rel="noopener" href="https://setosa.io/ev/image-kernels/">https://setosa.io/ev/image-kernels/</a></p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>各种优化技巧 <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/bs-E6lVkc9U_5a6ej5Y9EQ">https://mp.weixin.qq.com/s/bs-E6lVkc9U_5a6ej5Y9EQ</a></p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/">https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/98f138c5ac11">https://www.jianshu.com/p/98f138c5ac11</a></p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/">https://zh.wikipedia.org/wiki/</a></p>
<p>[^1]: Harnessing the Power of LLMs in Practice A Survey on ChatGPT and Beyond</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">361</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">29</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">481</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">51</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-08T13:13:26.000Z">2023-12-08</time></p><p class="title"><a href="/2023/12/08/OutOfWork/5-VideoEntertainment/CalibreAndItsPuginsForEhentaiBooks/">Calibre and its Pugins for e-hentai Books</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-07T12:34:56.000Z">2023-12-07</time></p><p class="title"><a href="/2023/12/07/OutOfWork/3-homepage/blogWebsiteBuilderOrSSG/dokuwiki/">Dokuwiki: </a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-06T08:10:02.000Z">2023-12-06</time></p><p class="title"><a href="/2023/12/06/OutOfWork/4-devices/nas/UgreenNas/">Ugreen Nas</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-03T09:31:21.000Z">2023-12-03</time></p><p class="title"><a href="/2023/12/03/OutOfWork/3-homepage/deployment/webDesign4customizeMarkdownGrammarInSSG/">Web Design 4 : Customize Markdown Grammar In SSG</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-30T21:48:21.000Z">2023-11-30</time></p><p class="title"><a href="/2023/11/30/OutOfWork/3-homepage/deployment/webDesign3FutureFeatures/">Web Design 3 : Future Features</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">222</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>