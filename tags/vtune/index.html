<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: vtune - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">vtune</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-14T16:00:00.000Z" title="7/14/2023, 4:00:00 PM">2023-07-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-16T10:11:57.867Z" title="12/16/2023, 10:11:57 AM">2023-12-16</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">20 minutes read (About 3059 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/07/14/Work/software/perf/vtuneOptimize/">VtuneOptimize</a></p><div class="content"><h2 id="vtune的安装和profile"><a href="#vtune的安装和profile" class="headerlink" title="vtune的安装和profile"></a>vtune的安装和profile</h2><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>由于snode0有sudo</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /opt/intel/oneapi/setvars.sh</span><br><span class="line">sudo vtune-gui</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="http://home.ustc.edu.cn/~shaojiemike/posts/nvidiansight/#sudo-ncu-ui-%E4%B8%8D%E8%83%BD%E8%BF%9C%E7%A8%8B%E6%89%93%E5%BC%80">sudo后图形化界面 MobaXterm打不开的原因参考这个</a></p>
<h2 id="Step1-Performance-Snapshot-参数说明"><a href="#Step1-Performance-Snapshot-参数说明" class="headerlink" title="Step1 : Performance Snapshot 参数说明"></a>Step1 : Performance Snapshot 参数说明</h2><p>以IPCC2022 初赛 支撑点计算的baseline为例</p>
<h2 id="Logical-Core-Utilization"><a href="#Logical-Core-Utilization" class="headerlink" title="Logical Core Utilization"></a>Logical Core Utilization</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Effective Logical Core Utilization: 3.8% (2.436 out of 64)</span><br><span class="line">    Effective Physical Core Utilization: 6.4% (2.053 out of 32)</span><br></pre></td></tr></table></figure>

<p>CPU利用率主要是指计算有效占比。为100%意味着所有逻辑CPU都是由应用程序的计算占用。</p>
<h2 id="Microarchitecture-Usage"><a href="#Microarchitecture-Usage" class="headerlink" title="Microarchitecture Usage"></a>Microarchitecture Usage</h2><p>微架构使用指标是一个关键指标，可以帮助评估(以%为单位)你的代码在当前微架构上运行的效率。</p>
<p>微架构的使用可能会受到</p>
<ol>
<li>long-latency memory长延迟访存、</li>
<li>floating-point, or SIMD operations浮点或SIMD操作的影响;</li>
<li>non-retired instructions due to branch mispredictions;由于分支错误预测导致的未退役指令;</li>
<li>instruction starvation in the front-end.前端指令不足。</li>
</ol>
<h3 id="vtune的建议"><a href="#vtune的建议" class="headerlink" title="vtune的建议"></a>vtune的建议</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Microarchitecture Usage: 37.7% of Pipeline Slots</span><br><span class="line">    Retiring: 37.7%</span><br><span class="line">    Front-End Bound: 16.9%</span><br><span class="line">    Back-End Bound: 23.8%</span><br><span class="line">    Memory Bound: 11.9%</span><br><span class="line">    Core Bound: 11.9%</span><br><span class="line">    Bad Speculation: 21.5%</span><br></pre></td></tr></table></figure>

<p>针对<code>Back-End Bound: 23.8%</code>的建议如下：</p>
<p>A significant portion of pipeline slots are remaining empty.<br>(??? 他是指有23.8% empty还是被使用了呢)</p>
<p>When operations take <strong>too long</strong> in the back-end, they introduce <strong>bubbles</strong> in the pipeline that ultimately cause fewer pipeline slots containing useful work to be retired per cycle than the machine is capable to support.</p>
<p>This opportunity cost results in slower execution.</p>
<ol>
<li><strong>Long-latency operation</strong>s like <strong>divides</strong> and <strong>memory operations</strong> can cause this,</li>
<li>as can <strong>too many operations</strong> being directed to a single execution port (for example, more <strong>multiply</strong> operations arriving in the back-end per cycle than the execution unit can support).</li>
</ol>
<p>针对<code>Bad Speculation: 21.5%</code>的建议如下：</p>
<p>A significant proportion of pipeline slots containing <strong>21.5% useful work are being cancelled</strong>.</p>
<p>This can be caused by <strong>mispredicting branches</strong> or by <strong>machine clears</strong>. Note that this metric value may be highlighted due to Branch Resteers issue.</p>
<h3 id="Retiring-metric"><a href="#Retiring-metric" class="headerlink" title="Retiring metric"></a>Retiring metric</h3><p>Retiring metric represents a Pipeline Slots fraction utilized by useful work, meaning the issued uOps that eventually get retired.<br>Retiring metric 表示<strong>有用工作</strong>所使用的Pipeline slot流水线管道的比例，所有发射的uOps最终都会retired。</p>
<p>Ideally, all Pipeline Slots would be attributed to the Retiring category.<br>理想情况下，所有的管道槽都应该归于退休类别。</p>
<p>Retiring of 100% would indicate the maximum possible number of uOps retired per cycle has been achieved. 100%的退役表明每个周期内退役的uop数量达到了可能的最大值。</p>
<p>Maximizing Retiring typically increases the Instruction-Per-Cycle metric.<br>最大化Retiring通常会增加IPC。</p>
<p>Note that a high Retiring value <strong>does not necessary mean no more room</strong> for performance improvement.<br>For example, <strong>Microcode assists</strong> are categorized under Retiring. They hurt performance and can often be avoided.</p>
<p>Microcode assists根据Intel的解释是</p>
<p>当遇到特殊的计算(比如处理非常小的浮点值(所谓的逆法线)时），浮点单元并没有被设置为本机执行这些操作。为此需要在指令流中插入可能有数百个指令长的小程序，对性能会造成很大的影响。</p>
<h3 id="Front-End-Bound"><a href="#Front-End-Bound" class="headerlink" title="Front-End Bound"></a>Front-End Bound</h3><p>Front-End Bound metric represents a slots fraction where the processor’s Front-End undersupplies its Back-End. 该指标表示前端产生的指令是否足以支持后端处理。</p>
<p>Front-End denotes the first part of the processor core responsible for fetching operations that are executed later on by the Back-End part. 前端将指令分解成uops供后端处理。</p>
<p>Within the Front-End, a branch predictor predicts the next address to fetch, cache-lines are fetched from the memory subsystem, parsed into instructions, and lastly decoded into micro-ops (uOps). 在前端中，分支预测器预测下一个要获取的地址，缓存行从内存子系统中获取，解析为指令，最后解码为微操作(uOps)。</p>
<p>Front-End Bound metric denotes unutilized <strong>issue-slots</strong> when there is <strong>no Back-End stall</strong> (bubbles where Front-End delivered no uOps while Back-End could have accepted them). For example, stalls due to <strong>instruction-cache misses</strong> would be categorized as Front-End Bound</p>
<p>Front-End Bound指标表示当后端没有停顿时未使用的<strong>发射槽</strong>(bubbles: 前端没有交付uOps，而发射给后端的)。例如，由于指令缓存未命中而导致的暂停将被归类为Front-End Bound</p>
<h3 id="Back-End-Bound"><a href="#Back-End-Bound" class="headerlink" title="Back-End Bound"></a>Back-End Bound</h3><p>metric represents a Pipeline Slots fraction where no uOps are being delivered due to a lack of required resources for accepting new uOps in the Back-End. 该指标表示后端uops是否出现了因为硬件资源紧张而无法处理的问题。</p>
<p>Back-End is the portion of the processor core where an out-of-order scheduler dispatches ready uOps into their respective execution units, and, once completed, these uOps get retired according to the program order. 后端的乱序执行，顺序Reire模型。</p>
<p>For example, stalls due to <strong>data-cache misses</strong> or stalls due to the <strong>divider unit(除法器？) being overloaded</strong> are both categorized as Back-End Bound. Back-End Bound is further divided into two main categories: Memory Bound and Core Bound.</p>
<h3 id="Memory-Bound"><a href="#Memory-Bound" class="headerlink" title="Memory Bound"></a>Memory Bound</h3><p>This metric shows how memory subsystem issues affect the performance. Memory Bound measures a fraction of slots where pipeline could be stalled due to demand load or store instructions. This accounts mainly for incomplete in-flight memory demand loads that coincide with execution starvation in addition to less common cases where stores could imply back-pressure on the pipeline.</p>
<h3 id="Core-Bound"><a href="#Core-Bound" class="headerlink" title="Core Bound"></a>Core Bound</h3><p>This metric represents how much Core non-memory issues were of a bottleneck. 表明核心的非内存原因成为了瓶颈</p>
<ol>
<li>Shortage in hardware compute resources, 硬件资源的短缺</li>
<li>or dependencies software’s instructions are both categorized under Core Bound. 指令间的依赖</li>
</ol>
<p>Hence it may indicate</p>
<ol>
<li>the machine ran out of an OOO resources,</li>
<li>certain execution units are overloaded</li>
<li>or dependencies in program’s data- or instruction- flow are limiting the performance (e.g. <strong>FP-chained long-latency arithmetic operations</strong>).</li>
</ol>
<h3 id="Bad-Speculation-分支预测错误"><a href="#Bad-Speculation-分支预测错误" class="headerlink" title="Bad Speculation(分支预测错误)"></a>Bad Speculation(分支预测错误)</h3><p>represents a Pipeline Slots fraction wasted due to incorrect speculations.</p>
<p>This includes slots used to issue uOps that do not eventually get retired and slots for which the issue-pipeline was blocked due to <strong>recovery</strong> from an earlier incorrect speculation.</p>
<p>For example, wasted work due to <strong>mispredicted branches</strong> is categorized as a Bad Speculation category. Incorrect data speculation followed by Memory Ordering Nukes is another example.</p>
<p>这里的Nukes, 猜测是数据预取预测错误，带来的访存影响像核爆一样大吧.</p>
<h2 id="Memory-Bound-1"><a href="#Memory-Bound-1" class="headerlink" title="Memory Bound"></a>Memory Bound</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Memory Bound: 11.9% of Pipeline Slots</span><br><span class="line">    L1 Bound: 7.9%</span><br><span class="line">    L2 Bound: 0.2%</span><br><span class="line">    L3 Bound: 2.5%</span><br><span class="line">    DRAM Bound: 2.0%</span><br><span class="line">    Store Bound: 0.3%</span><br><span class="line">    NUMA: % of Remote Accesses: 13.2%</span><br></pre></td></tr></table></figure>

<p>This metric shows how memory subsystem issues affect the performance. Memory Bound measures a fraction of slots where pipeline could be stalled due to demand load or store instructions. 该项表明了有多少流水线的slots因为load或者store指令的需求而被迫等待</p>
<p>This accounts mainly for <strong>incomplete in-flight memory demand loads</strong> that coincide with execution starvation<br>这是指不连续访存吗？</p>
<p>in addition to less common cases where stores could imply back-pressure on the pipeline.</p>
<h3 id="L1-Bound"><a href="#L1-Bound" class="headerlink" title="L1 Bound"></a>L1 Bound</h3><p>This metric shows how often machine was stalled without missing the L1 data cache.<br>在不发生L1 miss的情况下，指令stall的频率。(因为其他原因导致stall？)</p>
<p>The L1 cache typically has the shortest latency. However, in certain cases like loads blocked on older stores, a load might suffer a high latency even though it is being satisfied by the L1. 假设load了一个刚store的值，load指令也会遇到很大的延迟。</p>
<h3 id="L2-Bound"><a href="#L2-Bound" class="headerlink" title="L2 Bound"></a>L2 Bound</h3><p>This metric shows how often machine was stalled on L2 cache. Avoiding cache misses (L1 misses&#x2F;L2 hits) will improve the latency and increase performance.</p>
<h3 id="L3-Bound"><a href="#L3-Bound" class="headerlink" title="L3 Bound"></a>L3 Bound</h3><p>This metric shows how often CPU was stalled on L3 cache, or contended with a sibling Core(与兄弟姐妹核竞争). Avoiding cache misses (L2 misses&#x2F;L3 hits) improves the latency and increases performance.</p>
<h3 id="DRAM-Bound"><a href="#DRAM-Bound" class="headerlink" title="DRAM Bound"></a>DRAM Bound</h3><p>This metric shows how often CPU was stalled on the main memory (DRAM). Caching typically improves the latency and increases performance.</p>
<h3 id="DRAM-Bandwidth-Bound"><a href="#DRAM-Bandwidth-Bound" class="headerlink" title="DRAM Bandwidth Bound"></a>DRAM Bandwidth Bound</h3><p>This metric represents percentage of elapsed time the system spent with high DRAM bandwidth utilization. Since this metric relies on the accurate peak system DRAM bandwidth measurement, explore the Bandwidth Utilization Histogram and make sure the Low&#x2F;Medium&#x2F;High utilization thresholds are correct for your system. You can manually adjust them, if required.</p>
<h3 id="Store-Bound"><a href="#Store-Bound" class="headerlink" title="Store Bound"></a>Store Bound</h3><p>This metric shows how often CPU was stalled on store operations. Even though memory store accesses do not typically stall out-of-order CPUs; there are few cases where stores can lead to actual stalls.</p>
<h3 id="NUMA-of-Remote-Accesses"><a href="#NUMA-of-Remote-Accesses" class="headerlink" title="NUMA: % of Remote Accesses"></a>NUMA: % of Remote Accesses</h3><p>In NUMA (non-uniform memory architecture) machines, memory requests missing LLC may be serviced either by local or remote DRAM. Memory requests to remote DRAM incur much greater latencies than those to local DRAM. It is recommended to keep as much frequently accessed data local as possible. This metric shows <strong>percent of remote accesses, the lower the better.</strong></p>
<p>可以用之前的<br><img src="https://pic.shaojiemike.top/img/20220724194827.png"></p>
<h2 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h2><p>This metric represents the percentage of <strong>packed (vectorized) floating point operations</strong>. 0% means that the code is fully scalar. The metric does not take into account the actual vector length that was used by the code for vector instructions. So if the code is fully vectorized and uses a legacy instruction set that loaded only half a vector length, the Vectorization metric shows 100%.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Vectorization: 23.7% of Packed FP Operations</span><br><span class="line">    Instruction Mix: </span><br><span class="line">    SP FLOPs: 0.9%</span><br><span class="line">    Packed: 99.9%</span><br><span class="line">    128-bit: 0.1%</span><br><span class="line">    256-bit: 99.8%</span><br><span class="line">    512-bit: 0.0%</span><br><span class="line">    Scalar: 0.1%</span><br><span class="line">    DP FLOPs: 2.9%</span><br><span class="line">    Packed: 0.0%</span><br><span class="line">    Scalar: 100.0%</span><br><span class="line">    x87 FLOPs: 0.0%</span><br><span class="line">    Non-FP: 96.2%</span><br><span class="line">    FP Arith/Mem Rd Instr. Ratio: 0.091</span><br><span class="line">    FP Arith/Mem Wr Instr. Ratio: 0.308</span><br></pre></td></tr></table></figure>

<p>针对<code>Vectorization: 23.7%</code>的建议</p>
<p>A significant fraction of floating point arithmetic instructions are scalar. Use <strong>Intel Advisor</strong> to see possible reasons why the code was not vectorized.</p>
<h3 id="SP-FLOPs"><a href="#SP-FLOPs" class="headerlink" title="SP FLOPs"></a>SP FLOPs</h3><p>The metric represents the percentage of single precision floating point operations from all operations executed by the applications. Use the metric for rough estimation of a SP FLOP fraction. If <strong>FMA vector instructions</strong> are used the metric may overcount.</p>
<h3 id="X87-FLOPs"><a href="#X87-FLOPs" class="headerlink" title="X87 FLOPs"></a>X87 FLOPs</h3><p>The metric represents the percentage of x87 floating point operations from all operations executed by the applications. Use the metric for rough estimation of an x87 fraction. If FMA vector instructions are used the metric may overcount.</p>
<p>X87是X86体系结构指令集的<strong>浮点相关子集</strong>。 它起源于8086指令的扩展，以可选的浮点协处理器的形式与相应的x86 cpus配合使用。 这些微芯片的名称在“ 87”中结尾。</p>
<h3 id="FP-Arith-Mem-Rd-Instr-Ratio"><a href="#FP-Arith-Mem-Rd-Instr-Ratio" class="headerlink" title="FP Arith&#x2F;Mem Rd Instr. Ratio"></a>FP Arith&#x2F;Mem Rd Instr. Ratio</h3><p>This metric represents the ratio between arithmetic floating point instructions and memory write instructions. A value less than 0.5 indicates unaligned data access for vector operations, which can negatively impact the performance of vector instruction execution.</p>
<p>小于0.5的值表示向量操作的未对齐数据访问，这可能会对矢量指令执行的性能产生负面影响。</p>
<h2 id="Step2-Hotspots"><a href="#Step2-Hotspots" class="headerlink" title="Step2 : Hotspots"></a>Step2 : Hotspots</h2><p>User-Mode Sampling只能采集单核的数据，来分析算法的优化。</p>
<p>Hardware Event-Based Sampling硬件时间采集能采集全部核心，但是要少于几秒钟？</p>
<p>这个硬件采集慢，而且到一半报错了，发生什么事了？<img src="https://pic.shaojiemike.top/img/20220724201411.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220726222036.png"></p>
<p>网上说是root权限的原因,但是我是用root运行的</p>
<p>反而用普通用户能正常跑Hardware Event-Based Sampling和微架构分析<br><img src="https://pic.shaojiemike.top/img/20220728204538.png"></p>
<h2 id="example"><a href="#example" class="headerlink" title="example"></a>example</h2><p><img src="https://pic.shaojiemike.top/img/20220724202614.png"><br><img src="https://pic.shaojiemike.top/img/20220724204414.png"></p>
<p>手动向量化该区域。</p>
<p>核心时间是 $k*n^2$ 次绝对值和，取最大值</p>
<p>优化思路：</p>
<ol>
<li><p>手动向量化（假设一次处理p个）</p>
<p> 第一个n层取出 k个 <code>rebuilt[i*k+ki]</code> 重复读取到向量寄存器里，</p>
<p> 第二个n层取出k 个 连续的p个，到向量寄存器里。最后不足补0特殊处理，但是一般n都是4的倍数，可能可以不处理。8就要处理了。</p>
<p> 做向量fabs的结果缓存在k个向量寄存器里。</p>
<p> 再对这个k个向量寄存器做横向的向量最大值操作到一个向量寄存器。不足的补0(取最大值不影响)</p>
<p> 最后这一个向量寄存器做寄存器内求和，再加到 <code>chebyshevSum</code> 里.</p>
<p> 这样就实现了p个元素的向量操作。这样一趟共需要3*k个向量寄存器。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/dongzhiquan/p/3694858.html">手动数据预取</a></p>
<ol>
<li><code>__builtin_prefetch()</code></li>
</ol>
</li>
<li><p>手动循环展开形成计算访存流水</p>
<ol>
<li>怎么根据输入来规模来展开？</li>
</ol>
</li>
<li><p>分块</p>
</li>
</ol>
<h3 id="访存分析"><a href="#访存分析" class="headerlink" title="访存分析"></a>访存分析</h3><h2 id="github对应项目与赛题"><a href="#github对应项目与赛题" class="headerlink" title="github对应项目与赛题"></a>github对应项目与赛题</h2><h2 id="HPL-PL"><a href="#HPL-PL" class="headerlink" title="HPL-PL"></a>HPL-PL</h2><h3 id="复现机器"><a href="#复现机器" class="headerlink" title="复现机器"></a>复现机器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ lscpu</span><br><span class="line">Architecture:                    x86_64</span><br><span class="line">CPU op-mode(s):                  32-bit, 64-bit</span><br><span class="line">Byte Order:                      Little Endian</span><br><span class="line">Address sizes:                   46 bits physical, 48 bits virtual</span><br><span class="line">CPU(s):                          36</span><br><span class="line">On-line CPU(s) list:             0-35</span><br><span class="line">Thread(s) per core:              1</span><br><span class="line">Core(s) per socket:              18</span><br><span class="line">Socket(s):                       2</span><br><span class="line">NUMA node(s):                    2</span><br><span class="line">Vendor ID:                       GenuineIntel</span><br><span class="line">CPU family:                      6</span><br><span class="line">Model:                           79</span><br><span class="line">Model name:                      Intel(R) Xeon(R) CPU E5-2695 v4 @ 2.10GHz</span><br><span class="line">Stepping:                        1</span><br><span class="line">CPU MHz:                         1296.157</span><br><span class="line">CPU max MHz:                     3300.0000</span><br><span class="line">CPU min MHz:                     1200.0000</span><br><span class="line">BogoMIPS:                        4199.98</span><br><span class="line">Virtualization:                  VT-x</span><br><span class="line">L1d cache:                       1.1 MiB</span><br><span class="line">L1i cache:                       1.1 MiB</span><br><span class="line">L2 cache:                        9 MiB</span><br><span class="line">L3 cache:                        90 MiB</span><br></pre></td></tr></table></figure>

<h3 id="baseline"><a href="#baseline" class="headerlink" title="baseline"></a>baseline</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ gcc --version</span><br><span class="line">gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0</span><br><span class="line">$ gcc -std=c11 conway.c -o Conway</span><br><span class="line">$ ./Conway</span><br><span class="line">……</span><br><span class="line">Iter 997...</span><br><span class="line">Iter 998...</span><br><span class="line">Iter 999...</span><br><span class="line">136527.433000 ms</span><br></pre></td></tr></table></figure>

<h3 id="优化步骤"><a href="#优化步骤" class="headerlink" title="优化步骤"></a>优化步骤</h3><p>由于O3和并行会导致热点代码不可读</p>
<p>在可迭代优化的例子下，根据vtune最大化单核性能。</p>
<p>很明显不是计算密集的应用，怎么形成流水最大化带宽利用，划分<strong>重复利用元素</strong>提高Cache命中率是重点(向量化对计算加速明显)</p>
<p><img src="https://pic.shaojiemike.top/img/20221202184317.png"><br><img src="https://pic.shaojiemike.top/img/20221202184438.png"></p>
<ol>
<li>替换if <code>tmp[i][j] = (!(cnt^3))||((a[i][j]&amp;1)&amp;&amp;(!(cnt^4)));</code></li>
<li>去除中间不必要的拷贝</li>
<li>int 变 char</li>
<li><strong>OMP_PROC_BIND&#x3D;true</strong> 绑定线程到对应local处理器和对应local内存</li>
</ol>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><ol>
<li>实验室同学黄业琦参加了HPC-PL全明星。想复现一下效果</li>
<li>之前Nvidia Nsight用得很爽， 想到vtune的访存优化部分和汇编对应的分析，使用的很少。想从提高计算流水和访存连续流水的角度结合vtune优化。</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-08-13T16:00:00.000Z" title="8/13/2022, 4:00:00 PM">2022-08-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-16T10:11:57.867Z" title="12/16/2023, 10:11:57 AM">2023-12-16</time></span><span class="level-item"><a class="link-muted" href="/categories/Architecture/">Architecture</a></span><span class="level-item">15 minutes read (About 2203 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/08/13/Work/software/perf/vtuneAssembly/">Vtune Assembly Analysis</a></p><div class="content"><h2 id="超算机器用vtune的命令行文件分析"><a href="#超算机器用vtune的命令行文件分析" class="headerlink" title="超算机器用vtune的命令行文件分析"></a>超算机器用vtune的命令行文件分析</h2><ol>
<li><p>首先找到vtune程序</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; module load intel/2022.1                                    </span><br><span class="line">&gt; <span class="built_in">which</span> icc                                                        </span><br><span class="line">/public1/soft/oneAPI/2022.1/compiler/latest/linux/bin/intel64/icc                          </span><br><span class="line">&gt; <span class="built_in">cd</span> /public1/soft/oneAPI/2022.1  </span><br><span class="line">&gt; find . -executable -<span class="built_in">type</span> f -name <span class="string">&quot;*vtune*&quot;</span></span><br><span class="line">./vtune/2022.0.0/bin64/vtune-worker-crash-reporter</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-gui.desktop</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-gui</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-agent</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-self-checker.sh</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-backend</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-worker</span><br><span class="line">./vtune/2022.0.0/bin64/vtune</span><br><span class="line">./vtune/2022.0.0/bin64/vtune-set-perf-caps.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>vtune-gui</code>获取可执行命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/intel/oneapi/vtune/2021.1.1/bin64/vtune -collect hotspots -knob enable-stack-collection=<span class="literal">true</span> -knob stack-size=4096 -data-limit=1024000 -app-working-dir /home/shaojiemike/github/IPCC2022first/build/bin -- /home/shaojiemike/github/IPCC2022first/build/bin/pivot /home/shaojiemike/github/IPCC2022first/src/uniformvector-2dim-5h.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>编写<code>sbatch_vtune.sh</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#SBATCH -o ./slurmlog/job_%j_rank%t_%N_%n.out</span></span><br><span class="line"><span class="comment">#SBATCH -p IPCC</span></span><br><span class="line"><span class="comment">#SBATCH -t 15:00</span></span><br><span class="line"><span class="comment">#SBATCH --nodes=1</span></span><br><span class="line"><span class="comment">#SBATCH --exclude=</span></span><br><span class="line"><span class="comment">#SBATCH --cpus-per-task=64</span></span><br><span class="line"><span class="comment">#SBATCH --mail-type=FAIL</span></span><br><span class="line"><span class="comment">#SBATCH --mail-user=ta1ly@mail.ustc.edu.cn</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /public1/soft/modules/module.sh</span><br><span class="line">module purge</span><br><span class="line"></span><br><span class="line">module load intel/2022.1</span><br><span class="line"></span><br><span class="line"><span class="built_in">logname</span>=vtune</span><br><span class="line"><span class="built_in">export</span> OMP_PROC_BIND=close; <span class="built_in">export</span> OMP_PLACES=cores</span><br><span class="line"><span class="comment"># ./pivot |tee ./log/$logname</span></span><br><span class="line">/public1/soft/oneAPI/2022.1/vtune/2022.0.0/bin64/vtune -collect hotspots -knob enable-stack-collection=<span class="literal">true</span> -knob stack-size=4096 -data-limit=1024000 -app-working-dir /public1/home/ipcc22_0029/shaojiemike/slurm -- /public1/home/ipcc22_0029/shaojiemike/slurm/pivot /public1/home/ipcc22_0029/shaojiemike/slurm/uniformvector-2dim-5h.txt |<span class="built_in">tee</span> ./log/<span class="variable">$logname</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>log文件如下，但是将生成的trace文件<code>r000hs</code>导入识别不了AMD</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="built_in">cat</span> <span class="built_in">log</span>/vtune</span><br><span class="line">dim = 2, n = 500, k = 2</span><br><span class="line">Using time : 452.232000 ms</span><br><span class="line">max : 143 351 58880.823709</span><br><span class="line">min : 83 226 21884.924801</span><br><span class="line">Elapsed Time: 0.486s</span><br><span class="line">   CPU Time: 3.540s</span><br><span class="line">      Effective Time: 3.540s</span><br><span class="line">      Spin Time: 0s</span><br><span class="line">      Overhead Time: 0s</span><br><span class="line">   Total Thread Count: 8</span><br><span class="line">   Paused Time: 0s</span><br><span class="line"></span><br><span class="line">Top Hotspots</span><br><span class="line">Function         Module  CPU Time  % of CPU Time(%)</span><br><span class="line">---------------  ------  --------  ----------------</span><br><span class="line">SumDistance      pivot     0.940s             26.6%</span><br><span class="line">_mm256_add_pd    pivot     0.540s             15.3%</span><br><span class="line">_mm256_and_pd    pivot     0.320s              9.0%</span><br><span class="line">_mm256_loadu_pd  pivot     0.300s              8.5%</span><br><span class="line">Combination      pivot     0.250s              7.1%</span><br><span class="line">[Others]         N/A       1.190s             33.6%</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220731223945.png"></p>
</li>
</ol>
<h3 id="汇编"><a href="#汇编" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objdump -Sd ../build/bin/pivot &gt; pivot1.s</span><br><span class="line">gcc -S -O3 -fverbose-asm ../src/pivot.c -o pivot_O1.s</span><br></pre></td></tr></table></figure>

<h2 id="汇编分析技巧"><a href="#汇编分析技巧" class="headerlink" title="汇编分析技巧"></a>汇编分析技巧</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/thisinnocence/article/details/80767776">https://blog.csdn.net/thisinnocence/article/details/80767776</a></p>
<h2 id="如何设置GNU和Intel汇编语法"><a href="#如何设置GNU和Intel汇编语法" class="headerlink" title="如何设置GNU和Intel汇编语法"></a>如何设置GNU和Intel汇编语法</h2><p><img src="https://pic.shaojiemike.top/img/20220725221103.png"><br><img src="https://pic.shaojiemike.top/img/20220725221213.png"></p>
<h2 id="vtune汇编实例"><a href="#vtune汇编实例" class="headerlink" title="vtune汇编实例"></a>vtune汇编实例</h2><p>(没有开O3，默认值)</p>
<p><img src="https://pic.shaojiemike.top/img/20220725220142.png"><br>偏移 -64 是k</p>
<p>-50 是ki</p>
<p><img src="https://pic.shaojiemike.top/img/20220725220301.png"><br>CDQE复制EAX寄存器双字的符号位(bit 31)到RAX的高32位。</p>
<p><img src="https://pic.shaojiemike.top/img/20220725220351.png"></p>
<p>这里的movsdq的q在intel里的64位，相当于使用了128位的寄存器，做了64位的事情，并没有自动向量化。</p>
<p><img src="https://pic.shaojiemike.top/img/20220725215938.png"></p>
<h2 id="生成带代码注释的O3汇编代码"><a href="#生成带代码注释的O3汇编代码" class="headerlink" title="生成带代码注释的O3汇编代码"></a>生成带代码注释的O3汇编代码</h2><p>如果想把 C 语言变量的名称作为汇编语言语句中的注释，可以加上 <code>-fverbose-asm</code> 选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -S -O3 -fverbose-asm ../src/pivot.c -o pivot_O1.s</span><br></pre></td></tr></table></figure>

<figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">.L15:</span></span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">38</span>:                 double dis = <span class="keyword">fabs</span>(rebuiltCoordFirst - rebuiltCoordSecond)<span class="comment">;</span></span><br><span class="line">   <span class="keyword">movsd</span> (%rax), %xmm0 # MEM[base: _15, offset: <span class="number">0B</span>], MEM[base: _15, offset: <span class="number">0B</span>]</span><br><span class="line">   <span class="keyword">subsd</span> (%rax,%rdx,<span class="number">8</span>), %xmm0 # MEM[base: _15, index: _21, step: <span class="number">8</span>, offset: <span class="number">0B</span>], tmp226</span><br><span class="line">   addq <span class="number">$8</span>, %rax #, ivtmp<span class="number">.66</span></span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">38</span>:                 double dis = <span class="keyword">fabs</span>(rebuiltCoordFirst - rebuiltCoordSecond)<span class="comment">;</span></span><br><span class="line">   <span class="keyword">andpd</span> %xmm2, %xmm0 # tmp235, dis</span><br><span class="line">   <span class="keyword">maxsd</span> %xmm1, %xmm0 # chebyshev, dis</span><br><span class="line">   <span class="keyword">movapd</span> %xmm0, %xmm1 # dis, chebyshev</span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">35</span>:             for(ki=<span class="number">0</span><span class="comment">; ki&lt;k; ki++)&#123;</span></span><br><span class="line">   cmpq %rax, %rcx # ivtmp<span class="number">.66</span>, _115</span><br><span class="line">   <span class="keyword">jne</span> .L15 #,</span><br><span class="line"><span class="symbol">.L19:</span></span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">32</span>:         for(j=i+<span class="number">1</span><span class="comment">; j&lt;n; j++)&#123;</span></span><br><span class="line">   addl <span class="number">$1</span>, %esi #, j</span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">41</span>:             chebyshevSum += chebyshev<span class="comment">;</span></span><br><span class="line">   <span class="keyword">addsd</span> %xmm1, %xmm4 # chebyshev, &lt;retval&gt;</span><br><span class="line">   addl %r14d, %edi # k, ivtmp<span class="number">.75</span></span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">32</span>:         for(j=i+<span class="number">1</span><span class="comment">; j&lt;n; j++)&#123;</span></span><br><span class="line">   cmpl %esi, %r15d # j, n</span><br><span class="line">   <span class="keyword">jg</span> .L13 #,</span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">32</span>:         for(j=i+<span class="number">1</span><span class="comment">; j&lt;n; j++)&#123;</span></span><br><span class="line">   addl <span class="number">$1</span>, %r10d #, j</span><br><span class="line"># ../src/pivot<span class="number">.</span>c:<span class="number">32</span>:         for(j=i+<span class="number">1</span><span class="comment">; j&lt;n; j++)&#123;</span></span><br><span class="line">   cmpl %r10d, %r15d # j, n</span><br><span class="line">   <span class="keyword">jne</span> .L16 #,</span><br></pre></td></tr></table></figure>

<h2 id="vtune-O3汇编分析"><a href="#vtune-O3汇编分析" class="headerlink" title="vtune O3汇编分析"></a>vtune O3汇编分析</h2><p>原本以为O3是看不了原代码与汇编的对应关系的，但实际可以<code>-g -O3</code> 是不冲突的。</p>
<h3 id="指令的精简合并"><a href="#指令的精简合并" class="headerlink" title="指令的精简合并"></a>指令的精简合并</h3><ol>
<li>访存指令的合并</li>
<li><img src="https://pic.shaojiemike.top/img/20220726131315.png"><ol>
<li>将<code>r9</code> mov到 <code>rax</code>里，<ol>
<li>又<code>leaq (%r12,%r8,8), %r9</code>。其中<code>r12</code>是<code>rebuiltCoord</code>,所以<code>r8</code>原本存储的是<code>[i*k]</code>的值</li>
<li><code>rax</code>是<code>rebuiltCoord+[i*k]</code>的地址，由于和i有关，index的计算在外层就计算好了。</li>
</ol>
</li>
<li><code>rdx</code>的值减去<code>r8</code>存储在<code>rdx</code>里<ol>
<li><code>rdx</code>原本存储的是<code>[j*k]</code>的地址</li>
<li><code>r8</code>原本存储的是<code>[i*k]</code>的值</li>
<li><code>rdx</code>之后存储的是<code>[(j-i)*k]</code>的地址</li>
</ol>
</li>
<li><code>data16 nop</code>是为了对齐插入的nop</li>
</ol>
</li>
<li><img src="https://pic.shaojiemike.top/img/20220726135136.png"><ol>
<li>值得注意的是取最大值操作，这里变成了<code>maxsd</code></li>
<li><code>xmm0</code>是<code>缓存值</code></li>
<li><code>xmm1</code>是<code>chebyshev</code></li>
<li><code>xmm2</code>是<code>fabs的掩码</code></li>
<li><code>xmm4</code>是<code>chebyshevSum</code></li>
</ol>
</li>
</ol>
<h3 id="自动循环展开形成流水"><a href="#自动循环展开形成流水" class="headerlink" title="自动循环展开形成流水"></a>自动循环展开形成流水</h3><ol>
<li><img src="https://pic.shaojiemike.top/img/20220726140445.png"><ol>
<li><code>r14d</code>存储<code>k</code>的值，所以<code>edi</code>存储<code>j*k</code>值</li>
<li>Block22后的指令验证了<code>rdx</code>原本存储的是<code>[j*k]</code>的地址</li>
</ol>
</li>
<li><img src="https://pic.shaojiemike.top/img/20220726141434.png"><ol>
<li>最外层循环</li>
<li>因为<code>r14d</code>存储<code>k</code>的值，<code>r8</code>和<code>r11d</code>存储了<code>i*k</code>的值</li>
</ol>
</li>
</ol>
<p>从汇编看不出有该操作，需要开启编译选项</p>
<h3 id="自动向量化"><a href="#自动向量化" class="headerlink" title="自动向量化"></a>自动向量化</h3><p>从汇编看不出有该操作，需要开启编译选项</p>
<h3 id="自动数据预取"><a href="#自动数据预取" class="headerlink" title="自动数据预取"></a>自动数据预取</h3><p>从汇编看不出有该操作，需要开启编译选项</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>为什么求和耗时这么多<br><img src="https://pic.shaojiemike.top/img/20220726142524.png"></p>
<h2 id="添加向量化选项"><a href="#添加向量化选项" class="headerlink" title="添加向量化选项"></a>添加向量化选项</h2><p>gcc</p>
<h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><p><img src="https://pic.shaojiemike.top/img/20220726190206.png"></p>
<h3 id="mavx2-march-core-avx2"><a href="#mavx2-march-core-avx2" class="headerlink" title="-mavx2 -march&#x3D;core-avx2"></a>-mavx2 -march&#x3D;core-avx2</h3><p><img src="https://pic.shaojiemike.top/img/20220726190342.png"></p>
<ol>
<li>阅读文档, 虽然全部变成了<code>vmov，vadd</code>的操作，但是实际还是64位的工作。<ol>
<li>这点<code>add rax, 0x8</code>没有变成<code>add rax, 0x16</code>可以体现</li>
<li>但是avx2不是256位的向量化吗？用的还是xmm0这类的寄存器。</li>
</ol>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">VADDSD (VEX.128 encoded version)</span><br><span class="line">DEST[63:0] := SRC1[63:0] + SRC2[63:0]</span><br><span class="line">DEST[127:64] := SRC1[127:64]</span><br><span class="line">DEST[MAXVL-1:128] := 0</span><br><span class="line"></span><br><span class="line">ADDSD (128-bit Legacy SSE version)</span><br><span class="line">DEST[63:0] := DEST[63:0] + SRC[63:0]</span><br><span class="line">DEST[MAXVL-1:64] (Unmodified)</span><br></pre></td></tr></table></figure>

<h3 id="march-skylake-avx512"><a href="#march-skylake-avx512" class="headerlink" title="-march&#x3D;skylake-avx512"></a>-march&#x3D;skylake-avx512</h3><p>汇编代码表面没变，但是快了10s(49s - 39s)</p>
<p>下图是avx2的<br><img src="https://pic.shaojiemike.top/img/20220726194928.png"><br>下图是avx512的<br><img src="https://pic.shaojiemike.top/img/20220726193836.png"></p>
<p>猜测注意原因是</p>
<ol>
<li>nop指令导致代码没对齐</li>
<li>不太可能和红框里的代码顺序有关</li>
</ol>
<h2 id="添加数据预取选项"><a href="#添加数据预取选项" class="headerlink" title="添加数据预取选项"></a>添加数据预取选项</h2><h3 id="判断机器是否支持"><a href="#判断机器是否支持" class="headerlink" title="判断机器是否支持"></a>判断机器是否支持</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lscpu|grep pref</span><br><span class="line">3dnowprefetch //3DNow prefetch instructions</span><br></pre></td></tr></table></figure>

<p>应该是支持的</p>
<h3 id="汇编分析"><a href="#汇编分析" class="headerlink" title="汇编分析"></a>汇编分析</h3><p>虽然时间基本没变，主要是对主体循环没有进行预取操作，对其余循环(热点占比少的)有重新调整。如下图增加了预取指令<br><img src="https://pic.shaojiemike.top/img/20220726201240.png"></p>
<h2 id="添加循环展开选项"><a href="#添加循环展开选项" class="headerlink" title="添加循环展开选项"></a>添加循环展开选项</h2><p>变慢很多(39s -&gt; 55s)</p>
<h3 id="funroll-loops"><a href="#funroll-loops" class="headerlink" title="-funroll-loops"></a>-funroll-loops</h3><p>汇编实现，在最内层循环根据k的值直接跳转到对应的展开块，这里k是2。<br><img src="https://pic.shaojiemike.top/img/20220726214111.png"><br>默认是展开了8层，这应该和xmm寄存器总数有关<br><img src="https://pic.shaojiemike.top/img/20220726214335.png"></p>
<h3 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h3><ol>
<li>循环展开的核心是形成计算和访存的流水<ol>
<li>不是简单的少几个跳转指令</li>
<li>这种简单堆叠循环核心的循环展开，并不能形成流水。所以时间不会减少</li>
</ol>
</li>
<li>但是完全无法解释循环控制的时间增加<ol>
<li><img src="https://pic.shaojiemike.top/img/20220726221451.png"></li>
<li>比如图中cmp的次数应该减半了，时间反而翻倍了</li>
</ol>
</li>
</ol>
<h2 id="手动分块"><a href="#手动分块" class="headerlink" title="手动分块"></a>手动分块</h2><p>由于数据L1能全部存储下，没有提升</p>
<h2 id="手动数据预取"><a href="#手动数据预取" class="headerlink" title="手动数据预取"></a>手动数据预取</h2><p>并没有形成想象中预取的流水。每512位取，还有重复。</p>
<p><img src="https://pic.shaojiemike.top/img/20220727162255.png"><br>每次预取一个Cache Line，后面两条指令预取的数据还有重复部分(导致时间增加 39s-&gt;61s)</p>
<p><img src="https://pic.shaojiemike.top/img/20220727163228.png"><br>想预取全部，循环每次预取了512位&#x3D;64字节</p>
<h2 id="手动向量化"><a href="#手动向量化" class="headerlink" title="手动向量化"></a>手动向量化</h2><h3 id="avx2"><a href="#avx2" class="headerlink" title="avx2"></a>avx2</h3><p>（能便于编译器自动展开来使用所有的向量寄存器,avx2</p>
<p>39s -&gt; 10s -&gt; 8.4s 编译器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">for(i=0; i&lt;n-blockSize; i+=blockSize)&#123;</span><br><span class="line">   for(j=i+blockSize; j&lt;n-blockSize; j+=blockSize)&#123;</span><br><span class="line">      for(ii=i; ii&lt;i+blockSize; ii++)&#123;</span><br><span class="line">            __m256d vi1 = _mm256_broadcast_sd(&amp;rebuiltCoord[0*n+ii]);</span><br><span class="line">            __m256d vi2 = _mm256_broadcast_sd(&amp;rebuiltCoord[1*n+ii]);</span><br><span class="line">               </span><br><span class="line">            __m256d vj11 = _mm256_loadu_pd(&amp;rebuiltCoord[0*n+j]); //读取4个点</span><br><span class="line">            __m256d vj12 = _mm256_loadu_pd(&amp;rebuiltCoord[1*n+j]);</span><br><span class="line"></span><br><span class="line">            __m256d vj21 = _mm256_loadu_pd(&amp;rebuiltCoord[0*n+j+4]); //读取4个点</span><br><span class="line">            __m256d vj22 = _mm256_loadu_pd(&amp;rebuiltCoord[1*n+j+4]);</span><br><span class="line"></span><br><span class="line">            vj11 = _mm256_and_pd(_mm256_sub_pd(vi1,vj11), vDP_SIGN_Mask);</span><br><span class="line">            vj12 = _mm256_and_pd(_mm256_sub_pd(vi2,vj12), vDP_SIGN_Mask);</span><br><span class="line"></span><br><span class="line">            vj21 = _mm256_and_pd(_mm256_sub_pd(vi1,vj21), vDP_SIGN_Mask);</span><br><span class="line">            vj22 = _mm256_and_pd(_mm256_sub_pd(vi2,vj22), vDP_SIGN_Mask);</span><br><span class="line"></span><br><span class="line">            __m256d tmp = _mm256_add_pd(_mm256_max_pd(vj11,vj12), _mm256_max_pd(vj21,vj22));</span><br><span class="line">            _mm256_storeu_pd(vchebyshev1, tmp);</span><br><span class="line"></span><br><span class="line">            chebyshevSum += vchebyshev1[0] + vchebyshev1[1] + vchebyshev1[2] + vchebyshev1[3];</span><br><span class="line"></span><br><span class="line">            // for(jj=j; jj&lt;j+blockSize; jj++)&#123;</span><br><span class="line">            //     double chebyshev = 0;</span><br><span class="line">            //     int ki;</span><br><span class="line">            //     for(ki=0; ki&lt;k; ki++)&#123;</span><br><span class="line">            //         double dis = fabs(rebuiltCoord[ki*n + ii] - rebuiltCoord[ki*n + jj]);</span><br><span class="line">            //         chebyshev = dis&gt;chebyshev ? dis : chebyshev;</span><br><span class="line">            //     &#125;</span><br><span class="line">            //     chebyshevSum += chebyshev;</span><br><span class="line">            // &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>明明展开了一次，但是编译器继续展开了，总共8次。用满了YMM 16个向量寄存器。</p>
<p>下图是avx512，都出现寄存器<code>ymm26</code>了。<br><img src="https://pic.shaojiemike.top/img/20220728204812.png"></p>
<p><code>vhaddpd</code>是水平的向量内加法指令</p>
<h3 id="avx512"><a href="#avx512" class="headerlink" title="avx512"></a>avx512</h3><p>当在avx512的情况下展开4次，形成了相当工整的代码。</p>
<ol>
<li>向量用到了寄存器<code>ymm18</code>，估计只能展开到6次了。<ol>
<li>avx2 应该寄存器不够<br><img src="https://pic.shaojiemike.top/img/20220729102432.png"></li>
</ol>
</li>
</ol>
<p>最后求和的处理，编译器首先识别出了，不需要实际store。还是在寄存器层面完成了计算。并且通过三次add和两次数据 移动指令自动实现了二叉树型求和。<br><img src="https://pic.shaojiemike.top/img/490591d3247248b05ab6a4c9ac79929.jpg"></p>
<p>avx2 寄存器不够会出现下面的情况。</p>
<h2 id="avx求和的更快速归约"><a href="#avx求和的更快速归约" class="headerlink" title="avx求和的更快速归约"></a>avx求和的更快速归约</h2><p>假如硬件存在四个一起归约的就好了，但是对于底层元件可能过于复杂了。</p>
<p><img src="https://pic.shaojiemike.top/img/20220729132206.png"><br><img src="https://pic.shaojiemike.top/img/20220729133155.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">__m256d _mm256_hadd_pd (__m256d a, __m256d b);</span><br><span class="line">VEXTRACTF128 __m128d _mm256_extractf128_pd (__m256d a, int offset);</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/c4bbaddb021d23d7be7b92dfa448bc7.jpg"><br>如果可以实现会节约一次数据移动和一次数据add。没有分析两种情况的寄存器依赖。可能依赖长度是一样的，导致优化后时间反而增加一点。</p>
<p><img src="https://pic.shaojiemike.top/img/20220729144311.png"></p>
<p>对于int还有这种实现<br><img src="https://pic.shaojiemike.top/img/20220729132834.png"><br><img src="https://pic.shaojiemike.top/img/20220729133019.png"></p>
<h3 id="将横向归约全部提取到外面"><a href="#将横向归约全部提取到外面" class="headerlink" title="将横向归约全部提取到外面"></a>将横向归约全部提取到外面</h3><p>并且将j的循环展开变成i的循环展开</p>
<p><img src="https://pic.shaojiemike.top/img/20220729190050.png"></p>
<h2 id="手动向量化-手动循环展开？"><a href="#手动向量化-手动循环展开？" class="headerlink" title="手动向量化+手动循环展开？"></a>手动向量化+手动循环展开？</h2><p>支持的理由：打破了循环间的壁垒，编译器会识别出无效中间变量，在for的jump指令划出的基本块内指令会乱序执行，并通过寄存器重命名来形成最密集的计算访存流水。</p>
<p>不支持的理由：如果编译器为了形成某一指令的流水，占用了太多资源。导致需要缓存其他结果（比如，向量寄存器不够，反而需要额外的指令来写回，和产生延迟。</p>
<p>理想的平衡: 在不会达到资源瓶颈的情况下展开。</p>
<h3 id="支持的分析例子"><a href="#支持的分析例子" class="headerlink" title="支持的分析例子"></a>支持的分析例子</h3><p>手动展开后，识别出来了连续的访存应该在一起进行，并自动调度。将+1的偏移编译器提前计算了。<br><img src="https://pic.shaojiemike.top/img/20220806153455.png"></p>
<p>如果写成macro define,可以发现编译器自动重排了汇编。<br><img src="https://pic.shaojiemike.top/img/20220808183850.png"></p>
<h3 id="不支持的分析例子"><a href="#不支持的分析例子" class="headerlink" title="不支持的分析例子"></a>不支持的分析例子</h3><p>avx2可以看出有写回的操作，把值从内存读出来压入栈中。<br><img src="https://pic.shaojiemike.top/img/20220806155318.png"></p>
<p>寄存器足够时没有这种问题<br><img src="https://pic.shaojiemike.top/img/20220806155437.png"></p>
<h3 id="寻找理想的展开次数"><a href="#寻找理想的展开次数" class="headerlink" title="寻找理想的展开次数"></a>寻找理想的展开次数</h3><p>由于不同代码对向量寄存器的使用次数不同，不同机器的向量寄存器个数和其他资源数不同。汇编也难以分析。在写好单次循环之后，最佳的展开次数需要手动测量。如下图，6次应该是在不会达到资源瓶颈的情况下展开来获得最大流水。<br><img src="https://pic.shaojiemike.top/img/20220806190954.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for(j=beginJ; j&lt;n-jBlockSize; j+=jBlockSize)&#123;  /</span><br><span class="line">//展开jBlockSize次</span><br><span class="line">&#125;</span><br><span class="line">for(jj=j; jj&lt;n; jj++)&#123;  //j初始值继承自上面的循环</span><br><span class="line">//正常单次</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于基本块内乱序执行，代码的顺序也不重要。<br>加上寄存器重命名来形成流水的存在，寄存器名也不重要。当然数据依赖还是要正确。</p>
<h3 id="对于两层循环的双层手动展开"><a href="#对于两层循环的双层手动展开" class="headerlink" title="对于两层循环的双层手动展开"></a>对于两层循环的双层手动展开</h3><p>思路： 外层多load数据到寄存器，但是运行的任何时候也不要超过寄存器数量的上限（特别注意在内层循环运行一遍到末尾时）。<br><img src="https://pic.shaojiemike.top/img/20220806204942.png"><br>左图外层load了8个寄存器，但是右边只有2个。</p>
<p>特别注意在内层循环运行一遍到末尾时：<br><img src="https://pic.shaojiemike.top/img/20220806210453.png"><br>如图，黄框就有16个了。</p>
<h3 id="注意load的速度也有区别"><a href="#注意load的速度也有区别" class="headerlink" title="注意load的速度也有区别"></a>注意load的速度也有区别</h3><p>所以内层调用次数多，尽量用快的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">_mm256_loadu_ps &gt;&gt; _mm256_broadcast_ss &gt; _mm256_set_epi16</span><br><span class="line">0.04 &gt;&gt; 0.5</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vsub  vmax    ps 0.02      Latency 4</span><br><span class="line">vand                       Latency 1</span><br><span class="line"></span><br><span class="line">vadd              ps 0.80              Throughput 0.5</span><br><span class="line">vhadd                      Latency 7</span><br><span class="line">vcvtps2pd            2.00  Latency 7</span><br><span class="line">vextractf128         0.50  Latency 3</span><br></pre></td></tr></table></figure>

<p>|指令|精度|时间(吞吐延迟和实际依赖导致)|Latency|Throughput<br>|-|-|-|-|-|-|<br>|_mm256_loadu_ps &#x2F;_mm256_broadcast_ss|||7|0.5<br>|vsub vmax |     ps| 0.02   |   4|0.5<br>vand      ||0.02|                1|0.33<br>vadd              |ps |0.80   |4| 0.5<br>vhadd              ||0.8| 7|2<br>vcvtps2pd         ||   2.00  | 7|1<br>vextractf128        || 0.50  | 3|1</p>
<h3 id="向量化double变单精度没有提升"><a href="#向量化double变单精度没有提升" class="headerlink" title="向量化double变单精度没有提升"></a>向量化double变单精度没有提升</h3><p><img src="https://pic.shaojiemike.top/img/20220811011442.png"></p>
<p>17条avx计算 5load 2cvt 2extract</p>
<p><img src="https://pic.shaojiemike.top/img/20220811012833.png"></p>
<table>
<thead>
<tr>
<th>单位时间</th>
<th>avx计算</th>
<th>load</th>
<th>cvt</th>
<th>extract</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>2.33</td>
<td>3.68</td>
<td>12.875</td>
<td>4.1</td>
</tr>
</tbody></table>
<p>可见类型转换相当耗费时间，最好在循环外，精度不够，每几次循环做一次转换。</p>
<h2 id="GCC编译器优化"><a href="#GCC编译器优化" class="headerlink" title="GCC编译器优化"></a>GCC编译器优化</h2><p>-march&#x3D;skylake-avx512是一条指令<br><img src="https://pic.shaojiemike.top/img/20220806154101.png"></p>
<p>-mavx2 是两条指令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vmovupd xmm7, xmmword ptr [rdx+rsi*8]</span><br><span class="line">vinsertf128 ymm1, ymm7, xmmword ptr [rdx+rsi*8+0x10], 0x1</span><br></pre></td></tr></table></figure>

<p>原因是<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/52626726/why-doesnt-gcc-resolve-mm256-loadu-pd-as-single-vmovupd">不对齐的访存在老架构上可能更快</a></p>
<h2 id="O3对于核心已经向量化的代码还有加速吗？"><a href="#O3对于核心已经向量化的代码还有加速吗？" class="headerlink" title="O3对于核心已经向量化的代码还有加速吗？"></a>O3对于核心已经向量化的代码还有加速吗？</h2><p>将IPCC初赛的代码去掉O3发现还是慢了10倍。</p>
<p><img src="https://pic.shaojiemike.top/img/20220814195555.png"></p>
<p>为什么连汇编函数调用也慢这么多呢？</p>
<p>这个不开O3的编译器所属有点弱智了，一条指令的两个操作数竟然在<code>rbp</code>的栈里存来存去的。<br><img src="https://pic.shaojiemike.top/img/20220814200435.png"></p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-14T04:16:32.000Z" title="7/14/2021, 4:16:32 AM">2021-07-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-16T10:11:57.843Z" title="12/16/2023, 10:11:57 AM">2023-12-16</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">6 minutes read (About 911 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/14/Work/HPC/IPCC/ipcc5/">IPCC Preliminary SLIC Analysis part3 : Hot spot analysis</a></p><div class="content"><h2 id="vtune-hotspots"><a href="#vtune-hotspots" class="headerlink" title="vtune hotspots"></a>vtune hotspots</h2><p><img src="https://pic.shaojiemike.top/PicGo20210714124245.png"><br><img src="https://pic.shaojiemike.top/PicGo20210714124503.png"><br><img src="https://pic.shaojiemike.top/PicGo20210714124939.png"><br><img src="https://pic.shaojiemike.top/PicGo20210714125041.png"></p>
<h3 id="vtune-threading"><a href="#vtune-threading" class="headerlink" title="vtune threading"></a>vtune threading</h3><p><img src="https://pic.shaojiemike.top/img/20210723205435.png"><br><img src="https://pic.shaojiemike.top/img/20210723202925.png"></p>
<!-- ![](https://pic.shaojiemike.top/img/20210723203113.png) -->
<p><img src="https://pic.shaojiemike.top/img/20210723205608.png"><br><img src="https://pic.shaojiemike.top/img/20210723205525.png"></p>
<h2 id="GUN-profile-gprof-gprof2dot-graphviz"><a href="#GUN-profile-gprof-gprof2dot-graphviz" class="headerlink" title="GUN profile gprof + gprof2dot graphviz"></a>GUN profile gprof + gprof2dot graphviz</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">g++ -pg -g -std=c++11 SLIC.cpp -o SLIC</span><br><span class="line">./SLIC # generate gmon.out</span><br><span class="line">less gmon.out</span><br><span class="line">    &quot;gmon.out&quot; may be a binary file.  See it anyway?</span><br><span class="line">gprof ./SLIC</span><br><span class="line">gprof ./SLIC|  /home/shaojiemike/github/isc21-gpaw/LogOrResult/profile/gprof2dot.py -n0 -e0 | dot -Tpng -o output.png</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/PicGo20210714153808.png"><br><img src="https://pic.shaojiemike.top/PicGooutput.png"><br>没什么用</p>
<h2 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h2><ol>
<li>向量化</li>
<li>并行化</li>
</ol>
<h2 id="什么时候OpenMP并行-什么时候MPI并行"><a href="#什么时候OpenMP并行-什么时候MPI并行" class="headerlink" title="什么时候OpenMP并行,什么时候MPI并行"></a>什么时候OpenMP并行,什么时候MPI并行</h2><p>根据具体资源情况来，貌似是一个节点，那可以从OpenMP入手</p>
<h2 id="自动并行化"><a href="#自动并行化" class="headerlink" title="自动并行化"></a>自动并行化</h2><p>Intel编译器的自动并行化功能可以<strong>自动</strong>的将串行程序的一部分转换为线程化代码。进行自动向量化主要包括的步骤有，找到有良好的工作共享(worksharing)的候选循环；对循环进行<strong>数据流(dataflow)分析</strong>，确认并行执行可以得到正确结果；<strong>使用OpenMP指令</strong>生成线程化代码。</p>
<p>&#x2F;Qparallel：允许编译器进行自动并行化</p>
<p>&#x2F;Qpar-reportn：n为0、1、2、3，输出自动并行化的报告</p>
<p>说明：&#x2F;Qparallel必须在使用<strong>O2&#x2F;3</strong>选项下有效</p>
<h2 id="c-向量化怎么实现"><a href="#c-向量化怎么实现" class="headerlink" title="c++向量化怎么实现"></a>c++向量化怎么实现</h2><h3 id="什么是向量化"><a href="#什么是向量化" class="headerlink" title="什么是向量化"></a>什么是向量化</h3><p>所谓的向量化，简单理解，就是使用高级的向量化SIMD指令（如SSE、SSE2等）优化程序，属于数据并行的范畴。</p>
<h3 id="如何对代码向量化"><a href="#如何对代码向量化" class="headerlink" title="如何对代码向量化"></a>如何对代码向量化</h3><p>向量化的目标是生成SIMD指令，那么很显然，要对代码进行向量化，</p>
<p>第一是依靠编译器来生成这些指令；</p>
<p>第二是使用汇编或Intrinsics函数。</p>
<h4 id="自动向量分析器"><a href="#自动向量分析器" class="headerlink" title="自动向量分析器"></a>自动向量分析器</h4><p>Intel编译器中，利用其自动向量分析器（auto-vectorizer）对代码进行分析并生成SIMD指令。另外，也会提供一些pragmas等方式使得用户能更好的处理代码来帮助编译器进行向量化。</p>
<ol>
<li><p>基本向量化<br>&#x2F;Qvec：开启自动向量化功能，<strong>需要在O2以上使用</strong>。在O2以上，这是默认的向量化选项，默认开启的。此选项生成的代码能用于Intel处理器和非Intel处理器。向量化还可能受其他选项影响。由于此选项是默认开启的，所以不需要在命令行增加此选项。</p>
</li>
<li><p>针对指令集（处理器）的向量化<br>&#x2F;QxHost：针对当前使用的主机处理器选择最优的指令集优化。</p>
</li>
</ol>
<p>对于双重循环，外层循环被自动并行化了，而内层循环并没有被自动并行化，内层循环被会自动向量化。</p>
<h4 id="影响向量化的因素"><a href="#影响向量化的因素" class="headerlink" title="影响向量化的因素"></a>影响向量化的因素</h4><ol>
<li>首先当然是指令集是否支持</li>
<li>内存对齐相关的问题，也是影响向量化的，很多的SSE指令都要求内存是16字节对齐，如果不对齐，向量化会得到错误结果。</li>
</ol>
<h3 id="如何判断向量化成功"><a href="#如何判断向量化成功" class="headerlink" title="如何判断向量化成功"></a>如何判断向量化成功</h3><p>看汇编代码<br>没成功需要手动内联向量化汇编代码???</p>
<h3 id="Intel-编译器的向量化实现"><a href="#Intel-编译器的向量化实现" class="headerlink" title="Intel 编译器的向量化实现"></a>Intel 编译器的向量化实现</h3><h3 id="AMD-编译器向量化实现"><a href="#AMD-编译器向量化实现" class="headerlink" title="AMD 编译器向量化实现"></a>AMD 编译器向量化实现</h3><h4 id="AMD-与-Intel-编译器的区别"><a href="#AMD-与-Intel-编译器的区别" class="headerlink" title="AMD 与 Intel 编译器的区别"></a>AMD 与 Intel 编译器的区别</h4><h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/gengshenghong/article/details/7027186">https://blog.csdn.net/gengshenghong/article/details/7027186</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/gengshenghong/article/details/7034748">https://blog.csdn.net/gengshenghong/article/details/7034748</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/gengshenghong/article/details/7022459">https://blog.csdn.net/gengshenghong/article/details/7022459</a></p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">361</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">29</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">482</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">50</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-08T13:13:26.000Z">2023-12-08</time></p><p class="title"><a href="/2023/12/08/OutOfWork/5-VideoEntertainment/CalibreAndItsPuginsForEhentaiBooks/">Calibre and its Pugins for e-hentai Books</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-07T12:34:56.000Z">2023-12-07</time></p><p class="title"><a href="/2023/12/07/OutOfWork/3-homepage/blogWebsiteBuilderOrSSG/dokuwiki/">Dokuwiki</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-06T08:10:02.000Z">2023-12-06</time></p><p class="title"><a href="/2023/12/06/OutOfWork/4-devices/nas/UgreenNas/">Ugreen Nas</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-03T09:31:21.000Z">2023-12-03</time></p><p class="title"><a href="/2023/12/03/OutOfWork/3-homepage/deployment/webDesign4customizeMarkdownGrammarInSSG/">Web Design 4 : Customize Markdown Grammar In SSG</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-30T21:48:21.000Z">2023-11-30</time></p><p class="title"><a href="/2023/11/30/OutOfWork/3-homepage/deployment/webDesign3FutureFeatures/">Web Design 3 : Future Features</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">222</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>