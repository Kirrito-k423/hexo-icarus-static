<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Programming - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Programming</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-22T16:00:00.000Z" title="5/22/2022, 4:00:00 PM">2022-05-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-26T12:13:47.662Z" title="5/26/2024, 12:13:47 PM">2024-05-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">5 minutes read (About 761 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/22/Work/HPC/cuda/CudaOptimizeVectorizedMemoryAccess/">Cuda Optimize : Vectorized Memory Access</a></p><div class="content"><h2 id="baseline"><a href="#baseline" class="headerlink" title="baseline"></a>baseline</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">device_copy_scalar_kernel</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> &#123; </span><br><span class="line">  <span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x; </span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = idx; i &lt; N; i += blockDim.x * gridDim.x) &#123; </span><br><span class="line">    d_out[i] = d_in[i]; </span><br><span class="line">  &#125; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">device_copy_scalar</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> </span><br><span class="line">&#123; </span><br><span class="line">  <span class="type">int</span> threads = <span class="number">128</span>; </span><br><span class="line">  <span class="type">int</span> blocks = min((N + threads<span class="number">-1</span>) / threads, MAX_BLOCKS);  </span><br><span class="line">  device_copy_scalar_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_in, d_out, N); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>简单的分块拷贝。</p>
<p>通过<code>cuobjdump -sass executable</code>.得到对应的标量copy对应的SASS代码</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*0058*/</span> IMAD R6.CC, R0, R9, c[<span class="number">0x0</span>][<span class="number">0x140</span>]                </span><br><span class="line"><span class="comment">/*0060*/</span> IMAD.HI.X R7, R0, R9, c[<span class="number">0x0</span>][<span class="number">0x144</span>]              </span><br><span class="line"><span class="comment">/*0068*/</span> IMAD R4.CC, R0, R9, c[<span class="number">0x0</span>][<span class="number">0x148</span>]               </span><br><span class="line"><span class="comment">/*0070*/</span> LD.E R2, [R6]                                   </span><br><span class="line"><span class="comment">/*0078*/</span> IMAD.HI.X R5, R0, R9, c[<span class="number">0x0</span>][<span class="number">0x14c</span>]              </span><br><span class="line"><span class="comment">/*0090*/</span> ST.E [R4], R2</span><br></pre></td></tr></table></figure>

<p>（SASS不熟悉，请看SASS一文）</p>
<p>其中4条IMAD指令计算出读取和存储的指令地址<code>R6:R7</code>和<code>R4:R5</code>。第4和6条指令执行32位的访存命令。</p>
<h2 id="Vector-way1-CUDA-C-C-standard-headers"><a href="#Vector-way1-CUDA-C-C-standard-headers" class="headerlink" title="Vector way1:  CUDA C&#x2F;C++ standard headers"></a>Vector way1:  CUDA C&#x2F;C++ standard headers</h2><p>通过使用<code>int2</code>, <code>int4</code>, or <code>float2</code></p>
<p>比如将<code>int</code>的指针<code>d_in</code>类型转换然后赋值。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reinterpret_cast&lt;int2*&gt;(d_in)</span><br><span class="line"><span class="comment">// simple in C99</span></span><br><span class="line">(int2*(d_in))</span><br></pre></td></tr></table></figure>

<p>但是需要注意对齐问题，比如</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reinterpret_cast&lt;int2*&gt;(d_in+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>这样是非法的。</p>
<h2 id="Vector-way2-structures"><a href="#Vector-way2-structures" class="headerlink" title="Vector way2:  structures"></a>Vector way2:  structures</h2><p>通过使用对齐的结构体来实现同样的目的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Foo</span> &#123;</span><span class="type">int</span> a, <span class="type">int</span> b, <span class="type">double</span> c&#125;; <span class="comment">// 16 bytes in size</span></span><br><span class="line">Foo *x, *y;</span><br><span class="line">…</span><br><span class="line">x[i]=y[i];</span><br></pre></td></tr></table></figure>

<h2 id="实际修改LD-E-64"><a href="#实际修改LD-E-64" class="headerlink" title="实际修改LD.E.64"></a>实际修改LD.E.64</h2><p>执行for循环次数减半，注意边界处理。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">device_copy_vector2_kernel</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">  <span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = idx; i &lt; N/<span class="number">2</span>; i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    reinterpret_cast&lt;int2*&gt;(d_out)[i] = reinterpret_cast&lt;int2*&gt;(d_in)[i];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// in only one thread, process final element (if there is one)</span></span><br><span class="line">  <span class="keyword">if</span> (idx==N/<span class="number">2</span> &amp;&amp; N%<span class="number">2</span>==<span class="number">1</span>)</span><br><span class="line">    d_out[N<span class="number">-1</span>] = d_in[N<span class="number">-1</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">device_copy_vector2</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">  threads = <span class="number">128</span>; </span><br><span class="line">  blocks = min((N/<span class="number">2</span> + threads<span class="number">-1</span>) / threads, MAX_BLOCKS); </span><br><span class="line"></span><br><span class="line">  device_copy_vector2_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_in, d_out, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应汇编可以看出</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*0088*/</span>                IMAD R10.CC, R3, R5, c[<span class="number">0x0</span>][<span class="number">0x140</span>]              </span><br><span class="line"><span class="comment">/*0090*/</span>                IMAD.HI.X R11, R3, R5, c[<span class="number">0x0</span>][<span class="number">0x144</span>]            </span><br><span class="line"><span class="comment">/*0098*/</span>                IMAD R8.CC, R3, R5, c[<span class="number">0x0</span>][<span class="number">0x148</span>]             </span><br><span class="line"><span class="comment">/*00a0*/</span>                LD.E<span class="number">.64</span> R6, [R10]                                      </span><br><span class="line"><span class="comment">/*00a8*/</span>                IMAD.HI.X R9, R3, R5, c[<span class="number">0x0</span>][<span class="number">0x14c</span>]           </span><br><span class="line"><span class="comment">/*00c8*/</span>                ST.E<span class="number">.64</span> [R8], R6</span><br></pre></td></tr></table></figure>

<p>变成了<code>LD.E.64</code></p>
<h2 id="实际修改LD-E-128"><a href="#实际修改LD-E-128" class="headerlink" title="实际修改LD.E.128"></a>实际修改LD.E.128</h2><p>执行for循环次数减半，注意边界处理。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">device_copy_vector4_kernel</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">  <span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = idx; i &lt; N/<span class="number">4</span>; i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    reinterpret_cast&lt;int4*&gt;(d_out)[i] = reinterpret_cast&lt;int4*&gt;(d_in)[i];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// in only one thread, process final elements (if there are any)</span></span><br><span class="line">  <span class="type">int</span> remainder = N%<span class="number">4</span>;</span><br><span class="line">  <span class="keyword">if</span> (idx==N/<span class="number">4</span> &amp;&amp; remainder!=<span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span>(remainder) &#123;</span><br><span class="line">      <span class="type">int</span> idx = N - remainder--;</span><br><span class="line">      d_out[idx] = d_in[idx];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">device_copy_vector4</span><span class="params">(<span class="type">int</span>* d_in, <span class="type">int</span>* d_out, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">  <span class="type">int</span> threads = <span class="number">128</span>;</span><br><span class="line">  <span class="type">int</span> blocks = min((N/<span class="number">4</span> + threads<span class="number">-1</span>) / threads, MAX_BLOCKS);</span><br><span class="line"></span><br><span class="line">  device_copy_vector4_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_in, d_out, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应汇编可以看出</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*0090*/</span>                IMAD R10.CC, R3, R13, c[<span class="number">0x0</span>][<span class="number">0x140</span>]              </span><br><span class="line"><span class="comment">/*0098*/</span>                IMAD.HI.X R11, R3, R13, c[<span class="number">0x0</span>][<span class="number">0x144</span>]            </span><br><span class="line"><span class="comment">/*00a0*/</span>                IMAD R8.CC, R3, R13, c[<span class="number">0x0</span>][<span class="number">0x148</span>]               </span><br><span class="line"><span class="comment">/*00a8*/</span>                LD.E<span class="number">.128</span> R4, [R10]                               </span><br><span class="line"><span class="comment">/*00b0*/</span>                IMAD.HI.X R9, R3, R13, c[<span class="number">0x0</span>][<span class="number">0x14c</span>]             </span><br><span class="line"><span class="comment">/*00d0*/</span>                ST.E<span class="number">.128</span> [R8], R4</span><br></pre></td></tr></table></figure>

<p>变成了<code>LD.E.128</code></p>
<h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p><img src="https://pic.shaojiemike.top/img/20220523145942.png"></p>
<p>(个人感觉，提升也不大吗？也没有两倍和四倍的效果)</p>
<p>绝大部分情况，向量比标量好， increase bandwidth, reduce instruction count, and reduce latency. 。</p>
<p>但是会增加额外的寄存器(SASS里也没有看到？？)和降低并行性(什么意思？？？)</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/#entry-content-comments">https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/#entry-content-comments</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-13T13:39:29.000Z" title="4/13/2022, 1:39:29 PM">2022-04-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-26T12:13:47.662Z" title="5/26/2024, 12:13:47 PM">2024-05-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">22 minutes read (About 3279 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/13/Work/Artificial%20Intelligence/framework/PyTorchGeometric/">PyTorchGeometric</a></p><div class="content"><h2 id="PyTorch-Geometric-Liberty"><a href="#PyTorch-Geometric-Liberty" class="headerlink" title="PyTorch Geometric Liberty"></a>PyTorch Geometric Liberty</h2><p>PyG是一个基于PyTorch的用于处理不规则数据（比如图）的库，或者说是一个用于在图等数据上快速实现表征学习的框架。它的运行速度很快，训练模型速度可以达到DGL（Deep Graph Library ）v0.2 的40倍（数据来自论文）。除了出色的运行速度外，PyG中也集成了很多论文中提出的方法（GCN,SGC,GAT,SAGE等等）和常用数据集。因此对于复现论文来说也是相当方便。</p>
<p>经典的库才有函数可以支持，自己的模型，自己根据自动微分实现。还要自己写GPU并行。</p>
<p>MessagePassing 是网络交互的核心</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="数据怎么存储"><a href="#数据怎么存储" class="headerlink" title="数据怎么存储"></a>数据怎么存储</h3><p>torch_geometric.data.Data (下面简称Data) 用于构建图</p>
<ol>
<li>每个节点的特征 x<ol>
<li>形状是[num_nodes, num_node_features]。</li>
</ol>
</li>
<li>节点之间的边 edge_index<ol>
<li>形状是 [2, num_edges]</li>
</ol>
</li>
<li>节点的标签 y<ol>
<li>假如有。形状是[num_nodes, *]</li>
</ol>
</li>
<li>边的特征 edge_attr<ol>
<li>[num_edges, num_edge_features]</li>
</ol>
</li>
</ol>
<h3 id="数据支持自定义"><a href="#数据支持自定义" class="headerlink" title="数据支持自定义"></a>数据支持自定义</h3><p>通过data.face来扩展Data</p>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><p>在 PyG 中，我们使用的不是这种写法，而是在get()函数中根据 index 返回torch_geometric.data.Data类型的数据，在Data里包含了数据和 label。</p>
<h3 id="数据处理的例子"><a href="#数据处理的例子" class="headerlink" title="数据处理的例子"></a>数据处理的例子</h3><p><img src="https://pic.shaojiemike.top/img/20220413165624.png"><br>由于是无向图，因此有 4 条边：(0 -&gt; 1), (1 -&gt; 0), (1 -&gt; 2), (2 -&gt; 1)。每个节点都有自己的特征。上面这个图可以使用 <code>torch_geometric.data.Data</code>来表示如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch_geometric.data import Data</span><br><span class="line"># 由于是无向图，因此有 4 条边：(0 -&gt; 1), (1 -&gt; 0), (1 -&gt; 2), (2 -&gt; 1)</span><br><span class="line">edge_index = torch.tensor([[0, 1, 1, 2],</span><br><span class="line">                           [1, 0, 2, 1]], dtype=torch.long)</span><br><span class="line"># 节点的特征                         </span><br><span class="line">x = torch.tensor([[-1], [0], [1]], dtype=torch.float)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index)</span><br></pre></td></tr></table></figure>

<p>注意edge_index中边的存储方式，有两个list，第 1 个list是边的起始点，第 2 个list是边的目标节点。注意与下面的存储方式的区别。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch_geometric.data import Data</span><br><span class="line"></span><br><span class="line">edge_index = torch.tensor([[0, 1],</span><br><span class="line">                           [1, 0],</span><br><span class="line">                           [1, 2],</span><br><span class="line">                           [2, 1]], dtype=torch.long)</span><br><span class="line">x = torch.tensor([[-1], [0], [1]], dtype=torch.float)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index.t().contiguous())</span><br></pre></td></tr></table></figure>

<p>这种情况edge_index需要先转置然后使用contiguous()方法。关于contiguous()函数的作用，查看 PyTorch中的contiguous。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> InMemoryDataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyOwnDataset</span>(<span class="title class_ inherited__">InMemoryDataset</span>): <span class="comment"># or (Dataset)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, transform=<span class="literal">None</span>, pre_transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MyOwnDataset, self).__init__(root, transform, pre_transform)</span><br><span class="line">        self.data, self.slices = torch.load(self.processed_paths[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回一个包含没有处理的数据的名字的list。如果你只有一个文件，那么它返回的list将只包含一个元素。事实上，你可以返回一个空list，然后确定你的文件在后面的函数process()中。</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">raw_file_names</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;some_file_1&#x27;</span>, <span class="string">&#x27;some_file_2&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 很像上一个函数，它返回一个包含所有处理过的数据的list。在调用process()这个函数后，通常返回的list只有一个元素，它只保存已经处理过的数据的名字。</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">processed_file_names</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;data.pt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="comment"># Download to `self.raw_dir`. or just pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整合你的数据成一个包含data的list。然后调用 self.collate()去计算将用DataLodadr的片段。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># Read data into huge `Data` list.</span></span><br><span class="line">        data_list = [...]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_filter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list [data <span class="keyword">for</span> data <span class="keyword">in</span> data_list <span class="keyword">if</span> self.pre_filter(data)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list = [self.pre_transform(data) <span class="keyword">for</span> data <span class="keyword">in</span> data_list]</span><br><span class="line"></span><br><span class="line">        data, slices = self.collate(data_list)</span><br><span class="line">        torch.save((data, slices), self.processed_paths[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>DataLoader 这个类允许你通过batch的方式feed数据。创建一个DotaLoader实例，可以简单的指定数据集和你期望的batch size。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loader = DataLoader(dataset, batch_size=512, shuffle=True)</span><br></pre></td></tr></table></figure>

<p>DataLoader的每一次迭代都会产生一个Batch对象。它非常像Data对象。但是带有一个‘batch’属性。它指明了了对应图上的节点连接关系。因为DataLoader聚合来自不同图的的batch的x,y 和edge_index，所以GNN模型需要batch信息去知道那个节点属于哪一图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for batch in loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; Batch(x=[1024, 21], edge_index=[2, 1568], y=[512], batch=[1024])</span><br></pre></td></tr></table></figure>

<h2 id="MessagePassing-核心"><a href="#MessagePassing-核心" class="headerlink" title="MessagePassing(核心)"></a>MessagePassing(核心)</h2><p><img src="https://pic.shaojiemike.top/img/20220413214848.png"><br>其中，x 表示表格节点的 embedding，e 表示边的特征，ϕ 表示 message 函数，□ 表示聚合 aggregation 函数，γ 表示 update 函数。上标表示层的 index，比如说，当 k &#x3D; 1 时，x 则表示所有输入网络的图结构的数据。</p>
<p>为了实现这个，我们需要定义：</p>
<ol>
<li>message<ol>
<li>定义了对于每个节点对 (xi,xj)，怎样生成信息（message）。</li>
</ol>
</li>
<li>update</li>
<li>aggregation scheme</li>
<li>propagate(edge_index, size&#x3D;None, **kwargs)<ol>
<li>这个函数最终会按序调用 message、aggregate 和 update 函数。</li>
</ol>
</li>
<li>update(aggr_out, **kwargs)<ol>
<li>这个函数利用聚合好的信息（message）更新每个节点的 embedding。</li>
</ol>
</li>
</ol>
<h3 id="propagate-edge-index-Union-torch-Tensor-torch-sparse-tensor-SparseTensor-size-Optional-Tuple-int-int-None-kwargs"><a href="#propagate-edge-index-Union-torch-Tensor-torch-sparse-tensor-SparseTensor-size-Optional-Tuple-int-int-None-kwargs" class="headerlink" title="propagate(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Optional[Tuple[int, int]] &#x3D; None, **kwargs)"></a>propagate(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Optional[Tuple[int, int]] &#x3D; None, **kwargs)</h3><ol>
<li>edge_index (Tensor or SparseTensor)<ol>
<li>输入的边的信息，定义底层图形连接&#x2F;消息传递流。</li>
<li>torch.LongTensor类型<ol>
<li>its shape must be defined as <code>[2, num_messages]</code>, where messages from nodes in <code>edge_index[0]</code> are sent to nodes in <code>edge_index[1]</code></li>
</ol>
</li>
<li>torch_sparse.SparseTensor类型<ol>
<li>its sparse indices (row, col) should relate to row &#x3D; edge_index[1] and col &#x3D; edge_index[0].</li>
</ol>
</li>
</ol>
</li>
<li>也不一定是方形节点矩阵。x&#x3D;(x_N, x_M).</li>
</ol>
<h3 id="MessagePassing-message-…"><a href="#MessagePassing-message-…" class="headerlink" title="MessagePassing.message(…)"></a>MessagePassing.message(…)</h3><p>会根据 flow&#x3D;“source_to_target”和if flow&#x3D;“target_to_source”或者x_i,x_j,来区分处理的边。</p>
<p>x_j表示提升张量，它包含每个边的源节点特征，即每个节点的邻居。通过在变量名后添加_i或_j，可以自动提升节点特征。事实上，任何张量都可以通过这种方式转换，只要它们包含源节点或目标节点特征。</p>
<p>_j表示每条边的起点，_i表示每条边的终点。x_j表示的就是每条边起点的x值（也就是Feature）。如果你手动加了别的内容，那么它的_j, _i也会自动进行处理，这个自己稍微单步执行一下就知道了</p>
<p>在实现message的时候，节点特征会自动map到各自的source and target nodes。</p>
<h3 id="aggregate-inputs-torch-Tensor-index-torch-Tensor-ptr-Optional-torch-Tensor-None-dim-size-Optional-int-None-aggr-Optional-str-None-→-torch-Tensor"><a href="#aggregate-inputs-torch-Tensor-index-torch-Tensor-ptr-Optional-torch-Tensor-None-dim-size-Optional-int-None-aggr-Optional-str-None-→-torch-Tensor" class="headerlink" title="aggregate(inputs: torch.Tensor, index: torch.Tensor, ptr: Optional[torch.Tensor] &#x3D; None, dim_size: Optional[int] &#x3D; None, aggr: Optional[str] &#x3D; None) → torch.Tensor"></a>aggregate(inputs: torch.Tensor, index: torch.Tensor, ptr: Optional[torch.Tensor] &#x3D; None, dim_size: Optional[int] &#x3D; None, aggr: Optional[str] &#x3D; None) → torch.Tensor</h3><p>aggregation scheme 只需要设置参数就好，“add”, “mean”, “min”, “max” and “mul” operations</p>
<h3 id="MessagePassing-update-aggr-out-…"><a href="#MessagePassing-update-aggr-out-…" class="headerlink" title="MessagePassing.update(aggr_out, …)"></a>MessagePassing.update(aggr_out, …)</h3><p>aggregation 输出作为第一个参数，后面的参数是 propagate()的</p>
<h3 id="实现GCN-例子"><a href="#实现GCN-例子" class="headerlink" title="实现GCN 例子"></a>实现GCN 例子</h3><p>$$<br>\mathbf{x}<em>i^{(k)} &#x3D; \sum</em>{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot \left( \mathbf{\Theta}^{\top} \cdot \mathbf{x}_j^{(k-1)} \right)<br>$$</p>
<p>该式子先将周围的节点与权重矩阵\theta相乘, 然后通过节点的度degree正则化，最后相加</p>
<p>步骤可以拆分如下</p>
<ol>
<li>添加self-loop 到邻接矩阵（Adjacency Matrix）。</li>
<li>节点特征的线性变换。</li>
<li>计算归一化系数</li>
<li>Normalize 节点特征。</li>
<li>sum相邻节点的feature（“add”聚合）。</li>
</ol>
<p>步骤1 和 2 需要在message passing 前被计算好。 3 - 5 可以torch_geometric.nn.MessagePassing 类。</p>
<p>添加self-loop的目的是让featrue在聚合的过程中加入当前节点自己的feature，没有self-loop聚合的就只有邻居节点的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(aggr=<span class="string">&#x27;add&#x27;</span>)  <span class="comment"># &quot;Add&quot; aggregation (Step 5).</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.<span class="built_in">pow</span>(-<span class="number">0.5</span>)</span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] = <span class="number">0</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j, norm</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(-<span class="number">1</span>, <span class="number">1</span>) * x_j</span><br></pre></td></tr></table></figure>

<p>所有的逻辑代码都在forward()里面，当我们调用propagate()函数之后，它将会在内部调用message()和update()。</p>
<h3 id="使用-GCN-的例子"><a href="#使用-GCN-的例子" class="headerlink" title="使用 GCN 的例子"></a>使用 GCN 的例子</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv = GCNConv(16, 32)</span><br><span class="line">x = conv(x, edge_index)</span><br></pre></td></tr></table></figure>

<h3 id="SAGE的例子"><a href="#SAGE的例子" class="headerlink" title="SAGE的例子"></a>SAGE的例子</h3><p><img src="https://pic.shaojiemike.top/img/20220413232648.png"><br>聚合函数（aggregation）我们用最大池化（max pooling），这样上述公示中的 AGGREGATE 可以写为：<br><img src="https://pic.shaojiemike.top/img/20220413232702.png"><br>上述公式中，对于每个邻居节点，都和一个 weighted matrix 相乘，并且加上一个 bias，传给一个激活函数。相关代码如下(对应第二个图)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(SAGEConv, self).__init__(aggr=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, in_channels]</span></span><br><span class="line"> </span><br><span class="line">        x_j = self.lin(x_j)</span><br><span class="line">        x_j = self.act(x_j)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> x_j</span><br></pre></td></tr></table></figure>

<p>对于 update 方法，我们需要聚合更新每个节点的 embedding，然后加上权重矩阵和偏置(对应第一个图第二行)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">        self.update_act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out, x</span>):</span><br><span class="line">        <span class="comment"># aggr_out has shape [N, out_channels]</span></span><br><span class="line">      </span><br><span class="line">        new_embedding = torch.cat([aggr_out, x], dim=<span class="number">1</span>)</span><br><span class="line">        new_embedding = self.update_lin(new_embedding)</span><br><span class="line">        new_embedding = torch.update_act(new_embedding)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> new_embedding</span><br></pre></td></tr></table></figure>

<p>综上所述，SageConv 层的定于方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential <span class="keyword">as</span> Seq, Linear, ReLU</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> remove_self_loops, add_self_loops</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(SAGEConv, self).__init__(aggr=<span class="string">&#x27;max&#x27;</span>) <span class="comment">#  &quot;Max&quot; aggregation.</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.act = torch.nn.ReLU()</span><br><span class="line">        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">        self.update_act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line">      </span><br><span class="line">        <span class="comment"># Removes every self-loop in the graph given by edge_index, so that (i,i)∉E for every i ∈ V.</span></span><br><span class="line">        edge_index, _ = remove_self_loops(edge_index)</span><br><span class="line">        <span class="comment"># Adds a self-loop (i,i)∈ E to every node i ∈ V in the graph given by edge_index</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, size=(x.size(<span class="number">0</span>), x.size(<span class="number">0</span>)), x=x)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, in_channels]</span></span><br><span class="line"> </span><br><span class="line">        x_j = self.lin(x_j)</span><br><span class="line">        x_j = self.act(x_j)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> x_j</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out, x</span>):</span><br><span class="line">        <span class="comment"># aggr_out has shape [N, out_channels]</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">        new_embedding = torch.cat([aggr_out, x], dim=<span class="number">1</span>)</span><br><span class="line">      </span><br><span class="line">        new_embedding = self.update_lin(new_embedding)</span><br><span class="line">        new_embedding = self.update_act(new_embedding)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> new_embedding</span><br></pre></td></tr></table></figure>

<h2 id="batch的实现"><a href="#batch的实现" class="headerlink" title="batch的实现"></a>batch的实现</h2><p>GNN的batch实现和传统的有区别。</p>
<h3 id="zzq的观点"><a href="#zzq的观点" class="headerlink" title="zzq的观点"></a>zzq的观点</h3><p>将网络复制batch次，batchSize的数据产生batchSize个Loss。通过Sum或者Max处理Loss，整体同时更新所有的网络参数。至于网络中循环输入和输出的H^(t-1)和H^t。（感觉直接平均就行了。</p>
<p>有几个可能的问题</p>
<ol>
<li>网络中参数不是线性层，CNN这种的网络。pytorch会自动并行吗？还需要手动</li>
<li>还有个问题，如果你还想用PyG的X和edge。并不能额外拓展维度。</li>
</ol>
<h3 id="图像和语言处理领域的传统基本思路："><a href="#图像和语言处理领域的传统基本思路：" class="headerlink" title="图像和语言处理领域的传统基本思路："></a>图像和语言处理领域的传统基本思路：</h3><p>通过 rescaling or padding(填充) 将相同大小的网络复制，来实现新添加维度。而新添加维度的大小就是batch_size。</p>
<p>但是由于图神经网络的特殊性：边和节点的表示。传统的方法要么不可行，要么会有数据的重复表示产生的大量内存消耗。</p>
<h2 id="ADVANCED-MINI-BATCHING-in-PyG"><a href="#ADVANCED-MINI-BATCHING-in-PyG" class="headerlink" title="ADVANCED MINI-BATCHING in PyG"></a>ADVANCED MINI-BATCHING in PyG</h2><p>为此引入了ADVANCED MINI-BATCHING来实现对大量数据的并行。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html">https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html</a></p>
<h3 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h3><ol>
<li>邻接矩阵以对角线的方式堆叠(创建包含多个孤立子图的巨大图)</li>
<li>节点和目标特征只是在节点维度中串联???<br><img src="https://pic.shaojiemike.top/img/20220417155734.png"></li>
</ol>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol>
<li>依赖message passing 方案的GNN operators不需要修改，因为消息仍然不能在属于不同图的两个节点之间交换。</li>
<li>没有计算或内存开销。例如，此batching 过程完全可以在不填充节点或边特征的情况下工作。请注意，邻接矩阵没有额外的内存开销，因为它们以稀疏方式保存，只保存非零项，即边。</li>
</ol>
<h3 id="torch-geometric-loader-DataLoader"><a href="#torch-geometric-loader-DataLoader" class="headerlink" title="torch_geometric.loader.DataLoader"></a>torch_geometric.loader.DataLoader</h3><p>可以实现将多个图batch成一个大图。 通过重写collate()来实现，并继承了pytorch的所有参数，比如num_workers.</p>
<p>在合并的时候，除开edge_index [2, num_edges]通过增加第二维度。其余（节点）都是增加第一维度的个数。</p>
<h3 id="最重要的作用"><a href="#最重要的作用" class="headerlink" title="最重要的作用"></a>最重要的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 原本是[2*4]</span><br><span class="line"># 自己实现的话，是直接连接</span><br><span class="line"> &gt;&gt;&gt; tensor([[0, 0, 1, 1, 0, 0, 1, 1],</span><br><span class="line">             [0, 1, 1, 2, 0, 1, 1, 2]])</span><br><span class="line"># 会修改成新的边</span><br><span class="line"> print(batch.edge_index)</span><br><span class="line"> &gt;&gt;&gt; tensor([[0, 0, 1, 1, 2, 2, 3, 3],</span><br><span class="line">             [0, 1, 1, 2, 3, 4, 4, 5]])</span><br></pre></td></tr></table></figure>

<h3 id="torch-geometric-loader-DataLoader-例子1"><a href="#torch-geometric-loader-DataLoader-例子1" class="headerlink" title="torch_geometric.loader.DataLoader 例子1"></a>torch_geometric.loader.DataLoader 例子1</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from torch_geometric.data import Data</span><br><span class="line">from torch_geometric.loader import DataLoader</span><br><span class="line"></span><br><span class="line">data_list = [Data(...), ..., Data(...)]</span><br><span class="line">loader = DataLoader(data_list, batch_size=32)</span><br></pre></td></tr></table></figure>
<h3 id="torch-geometric-loader-DataLoader-例子2"><a href="#torch-geometric-loader-DataLoader-例子2" class="headerlink" title="torch_geometric.loader.DataLoader 例子2"></a>torch_geometric.loader.DataLoader 例子2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from torch_geometric.datasets import TUDataset</span><br><span class="line">from torch_geometric.loader import DataLoader</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;, use_node_attr=True)</span><br><span class="line">loader = DataLoader(dataset, batch_size=32, shuffle=True)</span><br><span class="line"></span><br><span class="line">for batch in loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])</span><br><span class="line"></span><br><span class="line">    batch.num_graphs</span><br><span class="line">    &gt;&gt;&gt; 32</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-02-05T16:00:00.000Z" title="2/5/2022, 4:00:00 PM">2022-02-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-26T12:13:47.666Z" title="5/26/2024, 12:13:47 PM">2024-05-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">7 minutes read (About 1046 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/02/05/Work/Programming/2-languageGrammar/Rust/">Rust</a></p><div class="content"><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Rust 速度惊人且内存利用率极高。由于没有运行时和垃圾回收，它能够胜任对性能要求特别高的服务，可以在嵌入式设备上运行，还能轻松和其他语言集成。</p>
<p>Rust 丰富的类型系统和所有权模型保证了内存安全和线程安全，让您在编译期就能够消除各种各样的错误。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>异常简单,默认安装在自己<code>.local/bin</code>下，会自动修改<code>bashrc/zshrc</code><br>On Linux and macOS systems, this is done as follows:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://sh.rustup.rs -sSf | sh</span><br></pre></td></tr></table></figure>


<h2 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h2><h3 id="printf"><a href="#printf" class="headerlink" title="printf"></a>printf</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">impl ClassName &#123;</span><br><span class="line">	pub fn printFunc() &#123;</span><br><span class="line">		let a = 12;</span><br><span class="line">		println!(&quot;a is &#123;0&#125;, a again is &#123;0&#125;&quot;, a); </span><br><span class="line">		//println 不是一个函数，而是一个宏规则。所以有感叹号</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>Rust 是强类型语言，但具有自动判断变量类型的能力。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//可以指定类型</span><br><span class="line">let a: u64 = 123;</span><br><span class="line">//不可变变量</span><br><span class="line">let a = 123;</span><br><span class="line">let a = 456; //不是复制是，重新绑定</span><br><span class="line">let s2 = s1.clone(); //这才是真复制</span><br><span class="line">//变量</span><br><span class="line">let mut a = 123;</span><br><span class="line">a = 456;</span><br><span class="line">//常量</span><br><span class="line">const a: i32 = 123;</span><br></pre></td></tr></table></figure>

<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><h4 id="函数返回值"><a href="#函数返回值" class="headerlink" title="函数返回值"></a>函数返回值</h4><p>Rust 函数声明返回值类型的方式：在参数声明之后用 <code>-&gt;</code> 来声明函数返回值的类型（不是 <code>:</code> ）。</p>
<p>不写return是将最后一个当作返回值？（貌似是</p>
<h2 id="Rust是如何实现内存安全的呢？"><a href="#Rust是如何实现内存安全的呢？" class="headerlink" title="Rust是如何实现内存安全的呢？"></a>Rust是如何实现内存安全的呢？</h2><h3 id="内存安全"><a href="#内存安全" class="headerlink" title="内存安全"></a>内存安全</h3><ol>
<li>buffer overflow</li>
<li>null pointer dereference</li>
<li>use after free</li>
<li>use of uninitialized memory</li>
<li>illegal free (of an already-freed pointer, or a non-malloced pointer)</li>
</ol>
<h3 id="所有权"><a href="#所有权" class="headerlink" title="所有权"></a>所有权</h3><p>所有权对大多数开发者而言是一个新颖的概念，它是 Rust 语言为高效使用内存而设计的语法机制。所有权概念是为了让 Rust 在<strong>编译</strong>阶段更有效地分析内存资源的有用性以实现内存管理而诞生的概念。</p>
<h4 id="所有权三规则"><a href="#所有权三规则" class="headerlink" title="所有权三规则"></a>所有权三规则</h4><ol>
<li>Rust 中的每个值都有一个变量，称为其所有者。</li>
<li>一次只能有一个所有者。</li>
<li>当所有者不在程序运行范围时，该值将被删除。</li>
</ol>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>如果我们定义了一个变量并给它赋予一个值，这个变量的值存在于内存中。这种情况很普遍。但如果我们需要<strong>储存的数据长度不确定</strong>（比如用户输入的一串字符串），我们就无法在定义时明确数据长度，也就<strong>无法在编译阶段令程序分配固定长度的内存空间供数据储存使用</strong>。（有人说分配尽可能大的空间可以解决问题，但这个方法很不文明）。这就需要提供一种在<strong>程序运行时程序自己申请使用内存的机制——堆</strong>。本章所讲的所有”内存资源”都指的是堆所占用的内存空间。</p>
<p>有分配就有释放，程序不能一直占用某个内存资源。因此决定资源是否浪费的关键因素就是资源有没有及时的释放。</p>
<p>我们把字符串样例程序用 C 语言等价编写：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    char *s = (char *)malloc(sizeof(char)*10);</span><br><span class="line">	s = &quot;nhooo&quot;; //伪代码了</span><br><span class="line">    free(s); // 释放 s 资源</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>很显然，Rust 中没有调用 free 函数来释放字符串 s 的资源（假设 “nhooo” 在堆中，这里）。Rust 之所以没有明示释放的步骤是因为在变量范围结束的时候，Rust 编译器<strong>自动添加了调用释放资源函数的步骤</strong>。</p>
<p>这种机制看似很简单了：它不过是帮助程序员在适当的地方添加了一个释放资源的函数调用而已。但这种简单的机制可以有效地解决一个史上最令程序员头疼的编程问题。</p>
<p><a target="_blank" rel="noopener" href="https://hashrust.com/blog/memory-safey-in-rust-part-1/">https://hashrust.com/blog/memory-safey-in-rust-part-1/</a></p>
<p><a target="_blank" rel="noopener" href="https://deathking.github.io/2020/08/03/blue-team-rust-what-is-memory-safety-really/">https://deathking.github.io/2020/08/03/blue-team-rust-what-is-memory-safety-really/</a></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000041151698">https://segmentfault.com/a/1190000041151698</a></p>
<p><a target="_blank" rel="noopener" href="https://bbs.huaweicloud.com/blogs/193974">https://bbs.huaweicloud.com/blogs/193974</a></p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-10-13T06:42:57.000Z" title="10/13/2021, 6:42:57 AM">2021-10-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-26T12:13:47.662Z" title="5/26/2024, 12:13:47 PM">2024-05-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">a few seconds read (About 65 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/13/Work/Artificial%20Intelligence/framework/PyTorch_VS_TensorFlow/">PyTorch_VS_TensorFlow</a></p><div class="content"><h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p>容易转换成TensorRT</p>
<h2 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h2><p>好像是属于NLP问题</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.163.com/dy/article/GAPBDHKG0511AQHO.html">https://www.163.com/dy/article/GAPBDHKG0511AQHO.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/452749603">https://www.zhihu.com/question/452749603</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-11T07:07:59.000Z" title="8/11/2021, 7:07:59 AM">2021-08-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-26T12:13:47.670Z" title="5/26/2024, 12:13:47 PM">2024-05-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">2 minutes read (About 364 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/11/Work/Programming/2-languageGrammar/c/datastructurequeue/">Data structure : queue</a></p><div class="content"><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ol>
<li>队列中的数据元素遵循“先进先出”（First In First Out）的原则，简称FIFO结构；</li>
<li>在队尾添加元素，在队头删除元素。</li>
</ol>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>c++ #include&lt; queue&gt; 。定义：queue&lt; int &gt; q;</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">q.empty()               如果队列为空返回true，否则返回false</span><br><span class="line">q.size()                返回队列中元素的个数</span><br><span class="line">q.pop()                 删除队列首元素但不返回其值</span><br><span class="line">q.front()               返回队首元素的值，但不删除该元素</span><br><span class="line">q.push()                在队尾压入新元素</span><br><span class="line">q.back()                返回队列尾元素的值，但不删除该元素</span><br></pre></td></tr></table></figure>
<h3 id="C-清空队列-queue-的几种方法"><a href="#C-清空队列-queue-的几种方法" class="headerlink" title="C++ 清空队列(queue)的几种方法"></a>C++ 清空队列(queue)的几种方法</h3><p>直接用空的队列对象赋值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">queue&lt;int&gt; q1;</span><br><span class="line">// process</span><br><span class="line">// ...</span><br><span class="line">q1 = queue&lt;int&gt;();</span><br></pre></td></tr></table></figure>
<p>使用swap，这种是最高效的，定义clear，保持STL容器的标准。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void clear(queue&lt;int&gt;&amp; q) &#123;</span><br><span class="line">	queue&lt;int&gt; empty;</span><br><span class="line">	swap(empty, q);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="队列保存一对数"><a href="#队列保存一对数" class="headerlink" title="队列保存一对数"></a>队列保存一对数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">queue&lt;pair&lt;int, int&gt; &gt; gq;</span><br><span class="line">gq.push(&#123; 10, 20 &#125;);</span><br><span class="line"></span><br><span class="line">pair&lt;int, int&gt; p;</span><br><span class="line">int x,y;</span><br><span class="line">p = gq.front();</span><br><span class="line">x = p.first;</span><br><span class="line">y = p.second;</span><br></pre></td></tr></table></figure>
<h3 id="队列保存结构体"><a href="#队列保存结构体" class="headerlink" title="队列保存结构体"></a>队列保存结构体</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">    int y;</span><br><span class="line">    int xbegin;</span><br><span class="line">    int xend;</span><br><span class="line">&#125;triple;</span><br><span class="line">queue&lt;triple&gt; threadq[64];</span><br><span class="line">delaytask.push(&#123;x1+delay,y-1&#125;);</span><br><span class="line">p = threadq[c].front();	</span><br><span class="line">p.xbegin;</span><br><span class="line">p.xend;</span><br></pre></td></tr></table></figure>
<h2 id="基于数组的循环队列（循环队列）"><a href="#基于数组的循环队列（循环队列）" class="headerlink" title="基于数组的循环队列（循环队列）"></a>基于数组的循环队列（循环队列）</h2><h2 id="基于链表的队列（链队列）"><a href="#基于链表的队列（链队列）" class="headerlink" title="基于链表的队列（链队列）"></a>基于链表的队列（链队列）</h2><h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>容器类型是可选的，默认为deque 类型</p>
<p>模板队列没大小的吗？</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zichen_ziqi/article/details/80819939">https://blog.csdn.net/zichen_ziqi/article/details/80819939</a></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/Programming/page/2/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/Programming/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/Programming/">1</a></li><li><a class="pagination-link" href="/categories/Programming/page/2/">2</a></li><li><a class="pagination-link is-current" href="/categories/Programming/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">402</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">500</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">41</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Camp/"><span class="level-start"><span class="level-item">Camp</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">25</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">25</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Thinking/"><span class="level-start"><span class="level-item">Thinking</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">117</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/love/"><span class="level-start"><span class="level-item">love</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">52</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-22T11:18:58.000Z">2024-04-22</time></p><p class="title"><a href="/2024/04/22/Work/Architecture/microHardware/cacheCoherence/">Memory Consistency and Cache Coherence </a></p><p class="categories"><a href="/categories/Architecture/">Architecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-20T06:54:32.000Z">2024-04-20</time></p><p class="title"><a href="/2024/04/20/Work/software/windows/WinUsefulTools/">Windows Useful Tools</a></p><p class="categories"><a href="/categories/software/">software</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-19T07:40:25.000Z">2024-04-19</time></p><p class="title"><a href="/2024/04/19/Work/Programming/2-languageGrammar/c/CplusDebugPrint/">C &amp; C++: Debug Print like icecream in Python</a></p><p class="categories"><a href="/categories/Programming/">Programming</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-18T01:54:32.000Z">2024-04-18</time></p><p class="title"><a href="/2024/04/18/Work/software/manager/podman/">Podman</a></p><p class="categories"><a href="/categories/software/">software</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-17T11:44:58.000Z">2024-04-17</time></p><p class="title"><a href="/2024/04/17/Work/software/simulator/Victima/">Victima: feature extension</a></p><p class="categories"><a href="/categories/software/">software</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">56</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2024 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>