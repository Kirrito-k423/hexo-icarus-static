<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Machine Learning - SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="AI(Artificial Intelligence) vs. Machine Learning vs. Deep LearningAI是人工智能（Artificial Intelligence）的缩写，是指通过计算机系统和算法模拟、模仿和扩展人类智能的科学和技术领域。 人工智能的目标是使计算机具备像人类一样的智能和学习能力，能够理解、推理、学习、决策和解决问题。 ^1 这张图很好的说明了发展的历"><meta property="og:type" content="blog"><meta property="og:title" content="Machine Learning"><meta property="og:url" content="http://icarus.shaojiemike.top/2023/09/26/Work/Artificial%20Intelligence/Basic/MachineLearning/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:description" content="AI(Artificial Intelligence) vs. Machine Learning vs. Deep LearningAI是人工智能（Artificial Intelligence）的缩写，是指通过计算机系统和算法模拟、模仿和扩展人类智能的科学和技术领域。 人工智能的目标是使计算机具备像人类一样的智能和学习能力，能够理解、推理、学习、决策和解决问题。 ^1 这张图很好的说明了发展的历"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://pic.shaojiemike.top/img/20211121155911.png"><meta property="og:image" content="https://pic.shaojiemike.top/shaojiemike/2024/01/97eacee62d986bec92e89288bedbb259.png"><meta property="og:image" content="https://pic.shaojiemike.top/shaojiemike/2023/12/9e6391bc3099176bcd72cfcc7dfeb1f6.png"><meta property="og:image" content="https://pic.shaojiemike.top/shaojiemike/2024/01/6cb4cd486cd753b6772c6e0b71c83aa4.png"><meta property="og:image" content="https://pic.shaojiemike.top/img/20220128214428.png"><meta property="article:published_time" content="2023-09-26T16:00:00.000Z"><meta property="article:modified_time" content="2024-04-18T08:04:59.105Z"><meta property="article:author" content="Shaojie Tan"><meta property="article:tag" content="AI"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="NLP"><meta property="article:tag" content="CV"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://pic.shaojiemike.top/img/20211121155911.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top/2023/09/26/Work/Artificial%20Intelligence/Basic/MachineLearning/"},"headline":"Machine Learning","image":["https://pic.shaojiemike.top/img/20211121155911.png","https://pic.shaojiemike.top/shaojiemike/2024/01/97eacee62d986bec92e89288bedbb259.png","https://pic.shaojiemike.top/shaojiemike/2023/12/9e6391bc3099176bcd72cfcc7dfeb1f6.png","https://pic.shaojiemike.top/shaojiemike/2024/01/6cb4cd486cd753b6772c6e0b71c83aa4.png","https://pic.shaojiemike.top/img/20220128214428.png"],"datePublished":"2023-09-26T16:00:00.000Z","dateModified":"2024-04-18T08:04:59.105Z","author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":"AI(Artificial Intelligence) vs. Machine Learning vs. Deep LearningAI是人工智能（Artificial Intelligence）的缩写，是指通过计算机系统和算法模拟、模仿和扩展人类智能的科学和技术领域。 人工智能的目标是使计算机具备像人类一样的智能和学习能力，能够理解、推理、学习、决策和解决问题。 ^1 这张图很好的说明了发展的历"}</script><link rel="canonical" href="http://icarus.shaojiemike.top/2023/09/26/Work/Artificial%20Intelligence/Basic/MachineLearning/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-09-26T16:00:00.000Z" title="9/26/2023, 4:00:00 PM">2023-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-04-18T08:04:59.105Z" title="4/18/2024, 8:04:59 AM">2024-04-18</time></span><span class="level-item"><a class="link-muted" href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></span><span class="level-item">an hour read (About 13475 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Machine Learning</h1><div class="content"><h2 id="AI-Artificial-Intelligence-vs-Machine-Learning-vs-Deep-Learning"><a href="#AI-Artificial-Intelligence-vs-Machine-Learning-vs-Deep-Learning" class="headerlink" title="AI(Artificial Intelligence) vs. Machine Learning vs. Deep Learning"></a>AI(Artificial Intelligence) vs. Machine Learning vs. Deep Learning</h2><p>AI是人工智能（Artificial Intelligence）的缩写，是指通过计算机系统和算法模拟、模仿和扩展人类智能的科学和技术领域。</p>
<p>人工智能的目标是使计算机具备像人类一样的智能和学习能力，能够理解、推理、学习、决策和解决问题。</p>
<p><img src="https://pic.shaojiemike.top/img/20211121155911.png"><a target="_blank" rel="noopener" href="https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/">^1</a></p>
<p>这张图很好的说明了发展的历程。很早人们就注意到了人工智能的概念，但是直到GPU的出现，极大的提高了并行运行的效率，这个深度学习才高速发展起来。</p>
<span id="more"></span>


<h3 id="强人工智能（General-AI）vs-弱人工智能（Narrow-AI）"><a href="#强人工智能（General-AI）vs-弱人工智能（Narrow-AI）" class="headerlink" title="强人工智能（General AI）vs. 弱人工智能（Narrow AI）"></a>强人工智能（General AI）vs. 弱人工智能（Narrow AI）</h3><p>AI先驱的梦想就是构建具有与人类智慧相同特征的由当时新兴计算机构成的复杂机器。这个概念就是我们所说的“强人工智能（General AI）”，这是一个神话般的机器，具有我们所有的感觉（甚至更多），我们所有的理智，像我们一样想。</p>
<p>“弱人工智能（Narrow AI）”的概念,是一种能够执行特定任务的技术，或者比我们人类能做的更好的技术。例如，Pinterest利用AI进行图片分类，Facebook使用AI对脸部识别。</p>
<h3 id="AI-Up-and-Down"><a href="#AI-Up-and-Down" class="headerlink" title="AI Up and Down"></a>AI Up and Down</h3><p><img src="https://pic.shaojiemike.top/shaojiemike/2024/01/97eacee62d986bec92e89288bedbb259.png"></p>
<p>??? tip “两次 AI 寒冬”</p>
<pre><code>第一次和第二次AI寒冬分别发生在20世纪中叶和末叶，这两个时期都伴随着对人工智能的热情减退和资金投入的减少。以下是两次AI寒冬的原因和后来的复苏：

 第一次AI寒冬（约1974年 - 1980年代中期）：

原因：

1. **不切实际的期望：** 早期对人工智能的期望过高，人们对AI系统的性能和能力寄予了过高的期望，但技术水平尚未达到这些期望。
2. **技术限制：** 计算机硬件和算法的限制使得早期的AI系统无法胜任更为复杂的任务，导致实际应用受限。
3. **资金压力：** 由于早期的研究成果与商业应用之间存在较大差距，资金投入减少，导致了一些研究项目的停滞。

走出方式：

1. **专注于实际问题：** AI研究者逐渐转向解决实际问题，例如专注于专家系统和应用程序的开发，而不是过于抽象的问题。
2. **技术进步：** 随着计算能力的提升和新的算法的发展，AI技术逐渐变得更加实用和可行。

 第二次AI寒冬（1987年 - 2000年代初）：

原因：

1. **专家系统破产：** 专家系统在商业应用上的表现未能达到预期，一些项目被认为是失败的，导致对AI的信心下降。
2. **资金问题：** 随着专家系统破产，投资者和企业减少对AI的投资，导致了一段时间的资金匮乏。
3. **技术局限：** 一些重要的技术问题，如处理不确定性和处理大规模数据的能力，限制了AI的进展。

走出方式：

1. **机器学习的崛起：** 随着机器学习算法的发展，尤其是深度学习的崛起，AI能力得到了显著提升。
2. **大数据的作用：** 数据的可用性和处理能力的提升，使得机器学习能够更好地处理复杂任务。
3. **商业应用的成功：** 成功的商业应用案例，如互联网搜索、语音助手和推荐系统，提高了对AI的信心，吸引了更多的投资和关注。

总体而言，每一次AI寒冬后的复苏都是通过技术创新、实际应用的成功以及对AI潜力的重新认知来实现的。
</code></pre>
<h2 id="常见的任务"><a href="#常见的任务" class="headerlink" title="常见的任务"></a>常见的任务</h2><p>数据来自文本和图像两类, 很自然有下面几大类。</p>
<ul>
<li>自然语言处理（Natural Language Processing，NLP）：NLP任务涉及处理和理解人类语言文本。<ul>
<li>包括文本分类、命名实体识别、情感分析、机器翻译等。</li>
<li>大型语言模型Large Language Model 核心原理是根据前文推算出下一个可能发生的字的模型，能够理解和生成语言，具备对话、问答、翻译、摘要等能力。</li>
</ul>
</li>
<li>计算机视觉（Computer Vision）：计算机视觉任务涉及处理和分析图像和视频数据。<ul>
<li>包括目标检测、图像分割、人脸识别、图像生成，医学影像标注,自动驾驶等。</li>
</ul>
</li>
<li>AIGC（AI generated content）是指由人工智能生成的内容，<ul>
<li>包括文本续写、文字转图像视频、AI主持人、音乐生成、游戏场景生成、代码补全与生成<a target="_blank" rel="noopener" href="https://hub.baai.ac.cn/view/23295">等应用</a>。</li>
<li>生成模型（Generative Models）：生成模型是指能够生成新的数据样本的模型。<ul>
<li>包括生成对抗网络（GANs）、变分自编码器（Variational Autoencoder，VAE）等。</li>
</ul>
</li>
</ul>
</li>
<li>AGI 通用人工智能<ul>
<li>普遍认为AGI将在2030年左右到来 —— 2022年 AIGC元年的观点。</li>
<li>LeCun 世界模型？！</li>
</ul>
</li>
</ul>
<h3 id="细分的领域"><a href="#细分的领域" class="headerlink" title="细分的领域"></a>细分的领域</h3><p>包括：</p>
<ul>
<li>HPC&#x2F;科学计算 + AI </li>
<li>异常检测（Anomaly Detection）：异常检测任务涉及识别与正常行为模式不符的异常样本或事件。<ul>
<li>包括检测欺诈行为、网络入侵、设备故障等。</li>
</ul>
</li>
<li>分类问题（如图像分类、垃圾邮件检测等）和回归问题（如房价预测、股票价格预测等）<ul>
<li>监督学习（Supervised Learning）：在监督学习中，模型通过使用标记好的训练数据来学习输入与输出之间的映射关系。</li>
</ul>
</li>
<li>聚类（将相似的数据点分组）和降维（减少数据维度）<ul>
<li>无监督学习（Unsupervised Learning）：在无监督学习中，模型从未标记的数据中发现数据之间的结构、模式或关系，而无需预先提供标签信息。</li>
</ul>
</li>
<li>机器人控制、AI与人的游戏对抗、游戏玩法优化<ul>
<li>强化学习（Reinforcement Learning）：在强化学习中，模型通过与环境进行交互来学习最佳行为策略。模型根据环境的反馈（奖励或惩罚）来调整自己的行为，以最大化累积奖励。</li>
</ul>
</li>
<li>大模型在具体任务上的加速学习<ul>
<li>迁移学习（Transfer Learning）：迁移学习是指将在一个任务上学到的知识应用到另一个相关任务上。通过在一个大规模任务上训练模型，然后将其用于相关任务，可以加快学习速度并提高性能。</li>
</ul>
</li>
</ul>
<h2 id="AI-挑战-与-展望"><a href="#AI-挑战-与-展望" class="headerlink" title="AI 挑战 与 展望"></a>AI 挑战 与 展望</h2><h3 id="人工智能三定律"><a href="#人工智能三定律" class="headerlink" title="人工智能三定律"></a>人工智能三定律</h3><ul>
<li>第一定律：任何有效的控制系统都必须与它所控制的系统一样复杂（阿什比定律（Ashby’s law)）[^3]</li>
<li>第二定律：生物体最简单的完整模型就是生物体本身。试图将系统的行为简化为任何形式的描述都会使事情变得更复杂，而不是更简单（冯·诺依曼提出）</li>
<li>第三定律：任何简单到可以理解的系统都不会复杂到可以智能地运行，而任何复杂到可以智能运行的系统都会复杂到无法理解（第三定律存在一个漏洞—完全有可能在不理解智能的情况下将它构建出来）</li>
</ul>
<h3 id="AI的软硬协同形态？可朽计算-凡人计算"><a href="#AI的软硬协同形态？可朽计算-凡人计算" class="headerlink" title="AI的软硬协同形态？可朽计算&#x2F;凡人计算"></a>AI的软硬协同形态？可朽计算&#x2F;凡人计算</h3><ul>
<li><p>在传统计算中，计算机被设计为精确地遵循指令。我们可以在不同的物理硬件上运行完全相同的程序和神经网络，这意味着程序或神经网络的权重中的知识是<strong>永生</strong>的（immortal），不依赖于任何特定的硬件。但要实现这种永生，需要付出高昂的代价—需要高功率运行晶体管，以便它们以数字方式运行。</p>
</li>
<li><p>放弃计算机科学最基本的原则—软硬件可以分离，从而得到凡人计算（Mortal Computation)。[^4]</p>
</li>
<li><p>凡人计算的巨大<strong>优点</strong>：</p>
<ul>
<li>以更少的<strong>能量</strong>运行大语言模型之类的AI，特别是使用更少的能量来训练AI大模型。通过放弃硬件（身体）和软件（灵魂）的分离，我们可以节省大量能源，可以使用非常低功耗的模拟计（这正是大脑正在做的事情）</li>
<li>获得更<strong>便宜</strong>的硬件，硬件可以在3-D中便宜地生长，而不用在2-D中非常精确地制造。这需要大量的新的纳米技术，或可能需要对生物神经元进行基因改造。</li>
</ul>
</li>
<li><p>凡人计算面临两大<strong>问题</strong>：</p>
<ul>
<li>1）学习过程必须利用它所运行的硬件的特定模拟属性，而无需确切知道这些属性是什么，这意味着无法使用反向传播算法（backpropagation)来获得梯度，因为反向传播算法需是前向传播的精确模型；</li>
<li>2）凡人计算的生命是有限的，当特定的硬件死掉时，它学习的知识会随之消亡，因为知识和硬件错综复杂地绑定在一起；解决方案是在硬件失效前，将知识蒸馏出来给学生。</li>
</ul>
</li>
</ul>
<p>类似的观点<a target="_blank" rel="noopener" href="https://www.numenta.com/blog/2022/01/25/the-path-to-machine-intelligence/">Biological Neural Network</a> </p>
<h2 id="AI-系统方法论"><a href="#AI-系统方法论" class="headerlink" title="AI 系统方法论"></a>AI 系统方法论</h2><p>方法论在许多学科中都扮演着核心角色，为研究和实践提供了系统化的框架。在人工智能（AI）领域，特别是近年来随着深度学习的迅速发展，一些关键的方法论思想对于理解和推进这一领域的发展至关重要。这里，我们将探讨三个具有代表性的概念：Rich Sutton 的 “The Bitter Lesson”、Scaling Law、以及 Emerging Properties。</p>
<h3 id="1-The-Bitter-Lesson-苦涩的教训"><a href="#1-The-Bitter-Lesson-苦涩的教训" class="headerlink" title="1. The Bitter Lesson (苦涩的教训)"></a>1. The Bitter Lesson (苦涩的教训)</h3><p>“The Bitter Lesson” 是由 Rich Sutton，在 2019 年发表的一篇经典文章中提出的观点。文章的核心观点是，人工智能的长期进步主要依赖于不断增长的计算能力，而不是更加精妙的算法设计或人类的先验知识。Sutton 通过回顾 AI 历史上的一系列突破，指出那些依赖通用方法和计算能力的进展往往比那些依赖特定领域知识或人工设计的技术更为持久和影响深远。这个教训强调了在设计 AI 系统时优先考虑可扩展性和计算效率的重要性。</p>
<h3 id="2-Scaling-Law"><a href="#2-Scaling-Law" class="headerlink" title="2. Scaling Law"></a>2. Scaling Law</h3><p>Scaling Laws 在深度学习和人工智能领域中描述了一个重要的现象：随着模型大小、数据集大小或计算预算的增加，模型的性能会按照某种可预测的方式提高。这种规律在各种类型的 AI 模型中都有观察到，特别是在大型语言模型（如 GPT 系列）的开发中尤为明显。Scaling Laws 不仅帮助研究者预测模型扩展的效果，而且还指导着资源的分配，比如如何平衡模型大小、训练时间和数据集大小以获得最佳性能。</p>
<h3 id="3-Emerging-Properties-涌现属性"><a href="#3-Emerging-Properties-涌现属性" class="headerlink" title="3. Emerging Properties (涌现属性)"></a>3. Emerging Properties (涌现属性)</h3><p>Emerging Properties 指的是当系统达到一定的复杂度时，会自然出现一些新的特性或行为，这些特性在系统的更简单或更小的版本中并不明显。在 AI 领域，尤其是在大型模型中，经常可以观察到这种现象。例如，一些大型语言模型能够展示出令人惊讶的创造力、推理能力或对复杂概念的理解，这些能力在小型模型中很难实现。这些涌现属性的出现通常与模型的规模和复杂度密切相关，强调了扩展模型可能带来意想不到的新能力和应用。</p>
<p>总的来说，这些方法论思想在人工智能的研究和应用中起着指导作用，强调了规模、计算能力和系统复杂度在实现 AI 长期进步中的重要性。通过理解和应用这些原则，研究人员和开发者可以更有效地设计和优化 AI 系统，以实现更高的性能和更广泛的应用。</p>
<h2 id="AI-各领域的近未来发展"><a href="#AI-各领域的近未来发展" class="headerlink" title="AI 各领域的近未来发展"></a>AI 各领域的近未来发展</h2><h3 id="绘画领域（数据驱动）"><a href="#绘画领域（数据驱动）" class="headerlink" title="绘画领域（数据驱动）"></a>绘画领域（数据驱动）</h3><p>数据飞轮（<strong>数据驱动</strong>模型的训练，数据资产化），和数据工厂越来越重要：</p>
<ol>
<li>数据的处理和标注占了SDXL开发的60-70%甚至更多的时间。[^6]</li>
<li>目前仍有 68% 的企业数据没有被用来分析、使用；高达 82% 的企业仍处于数据孤岛之中。[^5]</li>
</ol>
<h3 id="商业化思考"><a href="#商业化思考" class="headerlink" title="商业化思考"></a>商业化思考</h3><ol>
<li>移动互联网： ToC</li>
<li>深度学习时代, 人脸识别，目标检测, 赋能了互联网行业，安防行业，智慧城市行业以及智慧工业等强B端行业。</li>
<li>大模型时代： [^6]<ol>
<li>ToC&#x2F;ToB： 大模型+辅助工具 来形成的<strong>融入现有工作流</strong>的产品。</li>
<li>类似GPTs的生态</li>
<li>AGI的雏形：多模态的未来。</li>
</ol>
</li>
</ol>
<p><img src="https://pic.shaojiemike.top/shaojiemike/2023/12/9e6391bc3099176bcd72cfcc7dfeb1f6.png">[^7]</p>
<h3 id="数字孪生"><a href="#数字孪生" class="headerlink" title="数字孪生"></a>数字孪生</h3><p>Digital Twin(数字孪生)是对真实的世界进行建模和预测。一般我们将数字孪生的发展分为四个阶段：</p>
<ol>
<li>真实世界 </li>
<li>构建真实世界的数字镜像（分为实时镜像和延迟镜像两种）</li>
<li>真实世界和数字镜像的交互这导致了数字线程的扩展，数字世界具有影响物理实体操作的能力（可能以自主方式）</li>
<li>数字物理孪生对具有一定程度的自主性。</li>
<li>进入第五阶段，自治水平不断提高，数字物理孪生对可以作为自主代理在网络空间中进行交互，将本地数据分析扩展到全球数据分析。</li>
</ol>
<p>举一个简单的例子：</p>
<ol>
<li>在没有互联网出现的时候，我们生活在物理世界，没有虚拟世界，每天在真实的道路上走，这是第一阶段。</li>
<li>然后有了最早的地图软件，他们对真实的道路进行建模，我们可以在数字世界里看到真实的道路情况和交通情况，道路模型不是实时更新的，交通情况是实时更新的。这就是上面提到的延迟镜像和实时镜像，这是第二阶段。</li>
<li>后面地图软件通过各种数据分析，它知道哪条路上经常发生车祸，会提醒我们要注意，这个时候数字世界模型开始影响我们真实生活中的操作，这是第三阶段。</li>
<li>到了现在我们正在逐步进入第四阶段，地图软件上实时显示道路的交通情况，根据数据模拟告诉你要走哪条路，我们会实时受到他们的影响，而这种实时的预测就是自主性的。同时现实生活中的决策也会影响物理世界模型，比如某人热爱探险从庄稼地里走过，地图软件就认为这里有一条路，标记成道路，后面推荐给其他人（是谁家的智障在这里就不点名批评了）。</li>
</ol>
<h3 id="HPC-AI-科学计算-的新发展方向"><a href="#HPC-AI-科学计算-的新发展方向" class="headerlink" title="HPC + AI + 科学计算 的新发展方向"></a>HPC + AI + 科学计算 的新发展方向</h3><ol>
<li>静态代码分析器的机器学习实现：LSTM（确实是和时间有关的问题，毕竟是指令按序指令）</li>
<li>DeepMD实现分子动力学模拟<ol>
<li>网络其实设计的很简单，除开为了满足物理性质的特殊设计，其实就是一个全联接的前馈神经网络（MLP），计算出loss反向传播修改每个全连接层的权值。</li>
<li>原因很简单，输出和输出很简单，只需要寻找各个原子初始坐标和基态能量和结果总能量的关系。即没有CV图像庞大的数据需要通过CNN特征提取，也没有语音和文字这种按时间大量输入的问题需要引入时间，用RNN或者注意力机制解决。</li>
</ol>
</li>
</ol>
<h3 id="粗浅的观点"><a href="#粗浅的观点" class="headerlink" title="粗浅的观点"></a>粗浅的观点</h3><p>由于我不是学AI的，可以说是完全不懂。</p>
<ol>
<li>但是从抽象的层次来说，比如熵和信息量的角度说，信息量文本 &lt; 图片 &lt; 视频。 所以领域发展的成熟度的结果是，大语言模型先商业化(chatgpt),然后是图像（stable diffusion），最后才会是视频（AIGC电影片段）。当然这可能是对应训练的数据更不好整理的原因。</li>
<li>AIGC&#x2F;AGI产品产生商业化价值，其实分成两步：<ol>
<li>Step1: 使用者提出需求(文本为主)，模型接受后从无序的训练数据中尝试提取出相关的信息。</li>
<li>Step2: 使用者人工修正、过滤结果(反驳gpt的幻觉，丢弃SD生成的多指图)</li>
<li>Future: 如果第一步更成熟, 第二步人为的努力就更少，更容易商业化。</li>
</ol>
</li>
<li>AI模型设计的有效复杂性的探讨</li>
</ol>
<h2 id="End-to-end-lifecycle-of-AI-projects"><a href="#End-to-end-lifecycle-of-AI-projects" class="headerlink" title="End-to-end lifecycle of AI projects"></a>End-to-end lifecycle of AI projects</h2><p><img src="https://pic.shaojiemike.top/shaojiemike/2024/01/6cb4cd486cd753b6772c6e0b71c83aa4.png"></p>
<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>机器学习是一种人工智能（Artificial Intelligence，AI）的分支，旨在让计算机通过数据和经验自动学习和改进算法(修改参数权重, <del>不是</del>)，而无需明确编程。</p>
<p>机器学习<strong>最基本的方法</strong>是使用**算法(统计学算法)**来解析处理数据，从中学习，然后对世界中的某些事物, 进行识别，做出决定或预测。</p>
<p>出发点: 与其用特定的指令集编写软件程序来完成特定的任务，还不如使用<strong>大量的数据和算法</strong>“训练”机器，让它能够学习如何执行任务。</p>
<p>事实证明，多年来机器学习的最佳应用领域之一是<strong>计算机视觉领域</strong>。要实现计算机视觉，它仍然需要大量的手工编码来完成工作。研究人员会去写<strong>手动编写分类器</strong>，比如边缘检测过滤器，这样程序就能识别出物体的起点和停止位置；形状检测确定是否有八面；识别字母“S-T-O-P”的分类器。从所有这些手工编写的分类器中，他们将<strong>开发算法</strong>来理解图像和学习识别图像，确定它是否是一个停止符号。</p>
<h2 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h2><p>在接下来的讨论前，你需要知道<strong>概率论</strong>的相关知识，本人有稍微介绍。</p>
<p>包括：[^2]</p>
<ol>
<li>常用离散分布<ol>
<li>二项分布</li>
</ol>
</li>
<li>常用连续分布<ol>
<li>正态分布（高斯分布）</li>
<li>指数分布</li>
<li>伽马分布</li>
<li>贝塔分布</li>
</ol>
</li>
<li>三大抽样分布</li>
<li>随机过程<ol>
<li>泊松过程与泊松分布</li>
<li>马尔科夫链</li>
<li>平稳过程</li>
<li>布朗运动</li>
<li>鞅过程</li>
</ol>
</li>
<li>大数定理，中心极限定理</li>
<li>参数估计<ol>
<li>先验分布 后验概率分布 </li>
<li>点估计</li>
<li>矩估计</li>
<li>最大似然估计与EM算法</li>
<li>最小方差无偏估计</li>
<li>贝叶斯估计</li>
<li>区间估计</li>
</ol>
</li>
<li>方差回归与回归分析</li>
</ol>
<h3 id="参数学习-监督学习"><a href="#参数学习-监督学习" class="headerlink" title="参数学习(监督学习)"></a>参数学习(监督学习)</h3><p>在机器学习领域，参数学习（Parameter Learning）是指通过观测数据来估计模型中的参数，从而使得模型能够适应数据并具有预测能力的过程。参数学习是机器学习中的一种重要任务，它通常涉及以下步骤：</p>
<ul>
<li>定义模型：首先，需要选择或定义适当的模型来描述数据的生成过程或模式。<ul>
<li>模型可以是线性模型、非线性模型、神经网络、决策树等各种形式。</li>
</ul>
</li>
<li>确定损失函数：为了估计模型的参数，需要定义一个损失函数，用于衡量模型预测结果与实际观测值之间的差异。<ul>
<li>常见的损失函数包括均方误差、交叉熵等，具体选择取决于任务的特点和模型的性质。</li>
</ul>
</li>
<li>构建目标函数：目标函数是将损失函数与参数联系起来的函数。通过最小化目标函数，可以找到使模型在训练数据上表现最好的参数值。</li>
<li>优化算法：为了找到目标函数的最小值，需要使用优化算法进行参数的更新和调整。<ul>
<li>常见的优化算法包括梯度下降、牛顿法、共轭梯度等，它们通过迭代地调整参数来最小化目标函数。</li>
<li>反向传播算法（Backpropagation）主要用于计算神经网络模型中的参数梯度，以便通过网络的反向路径使用梯度下降等优化方法更新参数。</li>
</ul>
</li>
<li>训练模型：使用训练数据进行模型的训练。训练过程中，优化算法根据当前参数值和损失函数的梯度信息，更新参数，并不断迭代，直到达到停止条件（如达到最大迭代次数或损失函数收敛）。</li>
<li>参数估计：一旦训练完成，模型的参数就得到了估计。这些参数可以用于对新的未见过的数据进行预测或分类。</li>
</ul>
<p>需要注意的是，参数学习是监督学习的一部分，它要求训练数据中包含标签或目标值，以便通过比较模型的预测结果和实际标签来计算损失并进行参数更新。无监督学习和强化学习等其他类型的学习方法可能采用不同的学习方式和算法。</p>
<h3 id="参数学习-无监督学习和强化学习"><a href="#参数学习-无监督学习和强化学习" class="headerlink" title="参数学习(无监督学习和强化学习)"></a>参数学习(无监督学习和强化学习)</h3><p>在无监督学习和强化学习中，参数的训练过程有所不同。</p>
<ul>
<li>在无监督学习中，参数的训练是通过对数据的内在结构和模式进行建模来实现的，而不需要事先标记的目标值。<ul>
<li>常见的无监督学习算法包括聚类、降维和生成模型等。</li>
<li>训练参数的方法可以使用最大似然估计、最小化损失函数或其他自定义的优化目标。<ul>
<li>例如，在聚类算法中，我们可以使用期望最大化算法（EM算法）来估计潜在的类别分布和数据点的类别归属。</li>
</ul>
</li>
</ul>
</li>
<li>在强化学习中，参数的训练是通过智能体与环境的交互来实现的。强化学习是一种通过试错的方式来学习最优策略的方法。智能体通过观察环境状态，采取行动并接收奖励信号，然后根据奖励信号调整参数。<ul>
<li>常用的强化学习算法包括Q-learning、策略梯度方法和深度强化学习等。</li>
<li>参数的训练通常使用值函数估计、策略梯度优化或深度神经网络等技术。</li>
</ul>
</li>
</ul>
<p>在无监督学习和强化学习中，参数的训练过程都是通过优化方法来最大化某种指标或最小化某种损失函数。无监督学习更侧重于发现数据中的结构和模式，而强化学习更关注于学习与环境交互的最优策略。具体的训练方法和算法选择取决于具体的问题和应用领域。</p>
<h3 id="最大似然估计与损失函数的关系"><a href="#最大似然估计与损失函数的关系" class="headerlink" title="最大似然估计与损失函数的关系"></a>最大似然估计与损失函数的关系</h3><p>可以理解成现有的监督学习的参数，都是在知道标签后的最大似然估计。由于模型不同，最大似然估计的公式就具体<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33828141">变成了各种损失函数与优化算法</a>。</p>
<ul>
<li>回归问题：特化成最小二乘估计(最小二乘法)，对应的损失函数： 均方误差</li>
<li>分类问题：特化 损失函数：交叉熵</li>
</ul>
<h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><ul>
<li>监督学习通过训练数据集中的输入和对应的标签进行学习，从而能够预测或分类新的未标记数据</li>
<li>训练集是有标注的。</li>
</ul>
<p>常见的监督学习算法包括</p>
<ol>
<li>回归分析(自变量与因变量的关系，多在一二维的数据分析上)<ol>
<li>线性回归（Linear Regression）：线性回归是回归分析中最简单和最常见的方法之一。它假设自变量和因变量之间存在线性关系，并试图拟合出最优的线性模型来预测因变量。</li>
<li>多项式回归（Polynomial Regression）：多项式回归是在线性回归的基础上，通过引入高阶多项式项来拟合非线性关系。它可以处理自变量和因变量之间的非线性关系，并更灵活地拟合曲线。</li>
<li>岭回归（Ridge Regression）和Lasso回归（Lasso Regression）：这是在线性回归中使用的正则化方法，用于处理自变量之间存在共线性（多重共线性）的情况。它们通过添加正则化项来控制模型的复杂度，防止过拟合。</li>
<li>Logistic回归（Logistic Regression）：尽管名为回归，但实际上是一种分类算法。它用于处理因变量是二分类或多分类问题的情况，通过拟合逻辑函数来预测样本属于不同类别的概率。</li>
<li>非线性回归（Nonlinear Regression）：非线性回归适用于自变量和因变量之间存在复杂的非线性关系的情况。它使用非线性函数拟合数据，并尝试找到最优的非线性模型。</li>
</ol>
</li>
<li>统计分类(分类器)<ol>
<li>决策树学习和随机森林<ol>
<li>隨機森林是一個包含多個決策樹的分類器</li>
<li>过拟合剪枝</li>
</ol>
</li>
<li>支持向量机(SVM,support vector machine)</li>
<li>最近邻居法（KNN算法，又译K-近邻算法）</li>
<li>朴素贝叶斯(贝叶斯网络)</li>
</ol>
</li>
</ol>
<p>当然人工神经网络也能分类，但是有种杀鸡用牛刀的感觉，费力结果不一定更好。</p>
<p>决定适合某一问题的分类器仍旧是一项艺术，而非科学。</p>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><ul>
<li>无监督学习则从未标记的数据中学习数据的结构和模式，用于聚类、降维和异常检测等任务。</li>
<li>与监督学习相比，训练集没有人为标注的结果。</li>
</ul>
<p>常见的无监督学习算法有</p>
<ol>
<li>聚类<ol>
<li>（模糊）K-均值聚类（动态聚类法）</li>
</ol>
</li>
<li>人工神经网络(无监督我也来了)<ol>
<li>自编码器</li>
<li>生成对抗网络（GAN，Generative Adversarial Network）<ol>
<li>通过让两个神经网络相互博弈的方式进行学习。生成对抗网络由一个<strong>生成网络</strong>与一个<strong>判别网络</strong>组成。生成网络从潜在空间（latent space）中随机取样作为输入，其输出结果需要尽量<strong>模仿</strong>训练集中的真实样本。判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能<strong>分辨</strong>出来。而生成网络则要尽可能地<strong>欺骗</strong>判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。(常用于生成以假乱真的图片)</li>
</ol>
</li>
<li>自组织映射（SOM）</li>
<li>适应性共振理论（ART）</li>
</ol>
</li>
</ol>
<h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>半监督学习是介于监督学习和无监督学习之间的一种学习方式，利用带有标签的部分数据和未标记的数据进行学习。</p>
<h3 id="强化学习-增强学习"><a href="#强化学习-增强学习" class="headerlink" title="强化学习(增强学习)"></a>强化学习(增强学习)</h3><ul>
<li>强化学习(Reinforcement learning，简称RL)是通过智能体与环境进行交互学习最佳行动策略，通过奖励信号来指导学习过程。通过正确就正向激励，错误就反向评价来修正模型。(多出现在游戏AI上，比如AlphaGo)</li>
<li>强化学习不需要带标签的输入输出对，同时也无需对非最优解的精确地纠正。其关注点在于寻找探索（对未知领域的）和利用（对已有知识的）的平衡。</li>
</ul>
<h2 id="深度学习-人工神经网络-！"><a href="#深度学习-人工神经网络-！" class="headerlink" title="深度学习 ?&#x3D; 人工神经网络 &#x3D;！"></a>深度学习 ?&#x3D; 人工神经网络 &#x3D;！</h2><h3 id="基本概念与关系"><a href="#基本概念与关系" class="headerlink" title="基本概念与关系"></a>基本概念与关系</h3><p>人工神经网络（Artificial Neural Network，ANN）是深度学习的<strong>基础和核心组成</strong>部分之一。</p>
<p><strong>人工神经网络</strong>是一种受到生物神经系统启发的数学模型，用于模拟和处理信息。它由多个人工神经元（或称为节点）组成，这些神经元通过连接权重相互连接，并通过激活函数对输入信号进行处理。人工神经网络可以通过学习调整连接权重，以适应输入和输出之间的关系，并进行任务如分类、回归等。</p>
<p><strong>深度学习</strong>是机器学习的一个分支，专注于使用深层次的神经网络（即具有多个隐藏层的神经网络）进行学习和表示学习。深度学习的关键创新是引入了深层次的非线性模型，这些模型能够通过多个层次的转换逐渐提取和组合输入数据中的高级特征。</p>
<p>深度学习通过使用深层神经网络来自动学习数据表示，并在大规模数据集上进行训练。深度学习的强大之处在于，通过增加网络的深度，它能够学习到更抽象、更高级别的特征表示，从而提高模型的表达能力和性能。</p>
<p>因此，深度学习利用了人工神经网络的结构和算法，通过增加网络的深度来提高模型的学习能力和表达能力。人工神经网络是深度学习中最基础、最重要的组成部分之一，为深度学习的发展提供了坚实的理论基础和工具。</p>
<h3 id="人工神经网络的历史"><a href="#人工神经网络的历史" class="headerlink" title="人工神经网络的历史"></a>人工神经网络的历史</h3><ul>
<li>概念的出现：“人工神经网络（Artificial Neural Networks）”也是早期机器学习专家提出的，存在已经几十年了。<ul>
<li>每个神经元都将一个<strong>权重</strong>分配给它的输入，确定它与所执行任务的关系，对应正确与不正确的程度。最后的输出结果由这些权重的总和决定。</li>
</ul>
</li>
<li>关键进展：保罗·韦伯斯发明的<strong>反向传播算法</strong>（Werbos 1975）。这个算法有效地解决了异或的问题，还有更普遍的训练多层神经网络的问题。</li>
<li>初期不够流行：支持向量机和其他更简单的方法（例如线性分类器）在机器学习领域的流行度逐渐超过了神经网络，但是在2000年代后期出现的深度学习重新激发了人们对神经网络的兴趣。<ul>
<li>现在有<strong>循环神经网络</strong>和<strong>前馈神经网络</strong>两种，CNN就是一种前馈神经网络。</li>
</ul>
</li>
<li>大幅度发展：2014年出现了残差神经网络，该网络极大解放了神经网络的深度限制，出现了深度学习的概念。</li>
</ul>
<h3 id="人工神经网络-与-深度学习的历史关系"><a href="#人工神经网络-与-深度学习的历史关系" class="headerlink" title="人工神经网络 与 深度学习的历史关系"></a>人工神经网络 与 深度学习的历史关系</h3><p>2014年出现了残差神经网络，该网络极大解放了神经网络的深度限制，出现了深度学习的概念。</p>
<p>利用这些神经网络，增加了层和神经元，然后通过系统运行大量的数据来训练它。真正实现深度学习的“深度”，使得其能够描述神经网络中的所有的层次信息。</p>
<p>神经网络现在一般用于深度学习，所以将<strong>两者等价</strong>也不是不可以。</p>
<h3 id="人工神经网络特点"><a href="#人工神经网络特点" class="headerlink" title="人工神经网络特点"></a>人工神经网络特点</h3><p>人工神经网络（Artificial Neural Networks，ANN）具有以下特点：</p>
<ul>
<li><strong>自适应学习</strong>：人工神经网络可以通过学习算法自适应地调整神经元之间的连接权重，从而改变网络的行为和性能。通过与训练数据的反馈，神经网络可以逐步优化自己的权重参数，提高对输入模式的识别和预测能力。</li>
<li>非线性映射能力：人工神经网络可以通过非线性函数来建模复杂的输入与输出之间的关系。它能够学习和表示非线性模式和特征，从而更好地适应现实世界中的复杂问题。<ul>
<li>广义的通用函数逼近器：根据万能逼近定理（Universal Approximation Theorem），具有足够多神经元和适当的激活函数的人工神经网络可以逼近任意复杂的函数。这使得神经网络在各种问题和任务中具备较强的建模能力。</li>
</ul>
</li>
<li>分布式表示：人工神经网络采用分布式表示的方式来存储和处理信息。即信息被分散在网络中的多个神经元之间，每个神经元负责处理一部分信息。这种分布式表示的特点使得神经网络能够<strong>同时</strong>处理多个输入特征，并具有一定的<strong>容错性</strong>。<ul>
<li>并行处理能力：人工神经网络的计算是并行进行的，多个神经元同时对输入进行处理。这种并行性能够加速计算过程，使得神经网络具有高效的计算能力。</li>
<li>容错性：人工神经网络具有一定的容错性，即在部分神经元或连接失效的情况下，仍然能够保持良好的性能。这种容错性使得神经网络在面对噪声和部分信息缺失的情况下仍然能够有效地处理数据。</li>
</ul>
</li>
<li><strong>可解释性</strong>挑战：随着神经网络的深度和复杂性增加，解释网络内部运行机制和权重的含义变得困难。这使得人工神经网络的解释性成为一个挑战，特别是在需要透明性和可解释性的应用场景中。</li>
</ul>
<p>总的来说，人工神经网络是一种强大的模型，具有非线性映射能力、分布式表示、并行处理能力、自适应学习、容错性和广义的函数逼近能力。它在解决复杂问题和处理大规模数据时具有广泛的应用潜力。</p>
<h3 id="与传统的机器学习不同的特点"><a href="#与传统的机器学习不同的特点" class="headerlink" title="与传统的机器学习不同的特点"></a>与传统的机器学习不同的特点</h3><p>人工神经网络与传统的机器学习算法相比具有以下不同的特点：</p>
<ul>
<li><p>特征学习与表示学习：传统机器学习算法通常需要手动选择和提取适合任务的特征。而人工神经网络可以通过训练自动学习特征表示，从原始数据中学习到更高级别、更抽象的特征表示，减少了对特征工程的依赖。</p>
</li>
<li><p>非线性模型能力：人工神经网络可以建模和学习非线性关系，而传统机器学习算法通常是基于线性模型。这使得神经网络在处理复杂的、非线性的数据模式时具有更好的表达能力。</p>
</li>
<li><p>大规模数据处理：人工神经网络在大规模数据集上具有较好的处理能力。通过深层网络结构和并行计算，可以处理大量的数据并从中学习到更准确的模式和规律。</p>
</li>
<li><p>端到端学习：人工神经网络可以实现端到端的学习，从原始输入直接学习到输出，无需手动设计多个阶段的处理和特征。这简化了机器学习系统的设计和开发流程。</p>
</li>
<li><p>非凸优化问题：人工神经网络的训练通常涉及非凸优化问题，即寻找全局最优解的问题。相比之下，传统机器学习算法通常涉及凸优化问题，有较好的全局最优解保证。</p>
</li>
<li><p>模型的复杂性与解释性：人工神经网络通常具有复杂的网络结构和大量的参数，使得模型更加复杂。这导致了神经网络的解释性相对较低，难以理解模型内部的运行机制和权重的含义。</p>
</li>
<li><p>训练复杂性和计算资源需求：相对于传统机器学习算法，训练神经网络通常需要更多的计算资源和时间。深层网络的训练可能需要大量的训练数据和更复杂的优化算法，同时也需要更多的计算资源来进行模型的训练和推理。</p>
</li>
</ul>
<p>综上所述，人工神经网络相对于传统机器学习算法具有<strong>更强的</strong>特征学习能力、非线性模型能力、大规模数据处理能力和端到端学习能力。但<strong>同时也存在</strong>模型复杂性、解释性挑战、训练复杂性和计算资源需求等方面的特点。选择使用哪种方法取决于具体的任务、数据和资源要求。</p>
<h2 id="人工神經网络分类"><a href="#人工神經网络分类" class="headerlink" title="人工神經网络分类"></a>人工神經网络分类</h2><ul>
<li>依学习策略（Algorithm）分类主要有：<ul>
<li>监督式学习网络（Supervised Learning Network）为主</li>
<li>无监督式学习网络（Unsupervised Learning Network）</li>
<li>强化学习（Reinforcement Learning）：基于奖励机制，在与环境交互中学习最优策略。</li>
</ul>
</li>
<li>依网络架构（Connectionism）分类主要有：<ul>
<li>前馈神经网络（Feed Forward Network）信息在网络中单向传播，没有循环连接。<ul>
<li>包括MLP、CNN、Transformer、GPT-3(基于Transformer)</li>
</ul>
</li>
<li>循环神经网络（Recurrent Network）网络中存在循环连接，可以处理具有时间依赖性的序列数据。<ul>
<li>包括RNN，LSTM</li>
<li>循环神经网络具有循环连接，可以处理具有时间依赖性的序列数据。RNN 在处理序列数据时能够保留先前状态的信息，并具有记忆能力。</li>
</ul>
</li>
<li>卷积神经网络（Convolutional Neural Networks）：主要用于图像和视觉任务，通过卷积层和池化层来提取图像特征。<ul>
<li>CNN 属于前馈神经网络（Feedforward Neural Networks）的一种，但它在结构上具有一些特殊的设计。CNN 主要用于图像和视觉任务，通过卷积层和池化层来提取图像特征，从而捕捉图像中的局部关系和空间结构。</li>
</ul>
</li>
<li>自编码器（Autoencoders）：用于无监督学习和特征提取，由编码器和解码器组成。</li>
</ul>
</li>
<li>基于层级结构：<ul>
<li>单层神经网络：仅包含一个神经元层。</li>
<li>浅层神经网络：包含一到多个隐藏层（通常少于3层）。常用于处理较简单的任务，例如基本的模式识别和分类问题。</li>
<li>深度神经网络：包含多个隐藏层（例如5层或更多），通常用于处理更复杂的任务，如图像识别、自然语言处理等。</li>
</ul>
</li>
<li>基于应用领域：<ul>
<li>图像识别神经网络：用于图像分类、目标检测等计算机视觉任务。</li>
<li>语音识别神经网络：用于语音识别和语音合成任务。</li>
<li>自然语言处理神经网络：用于文本分类、机器翻译、情感分析等自然语言处理任务。</li>
</ul>
</li>
</ul>
<h3 id="特殊的神经网络"><a href="#特殊的神经网络" class="headerlink" title="特殊的神经网络"></a>特殊的神经网络</h3><p>表示网络节点关系的<strong>图神经网络</strong>属于一类特殊的神经网络模型，专门用于处理图结构数据的任务。它们利用图的节点和边表示数据之间的关系和连接。</p>
<p>图神经网络在处理图结构数据时具有独特的优势，可以考虑节点之间的邻近关系和全局拓扑结构，从而更好地捕捉图中的信息和模式。与传统的神经网络模型相比，图神经网络能够处理非欧几里德空间中的数据，如社交网络、蛋白质相互作用网络、推荐系统中的用户-物品关系等。</p>
<p>图神经网络的具体设计可以包括以下组件和操作：</p>
<ul>
<li>图卷积层（Graph Convolutional Layer）：通过将节点的特征与其邻居节点的特征进行聚合，更新节点的表示。</li>
<li>图池化层（Graph Pooling Layer）：通过对图的节点进行聚合和降维，减少图的规模和复杂性。</li>
<li>图注意力机制（Graph Attention Mechanism）：通过学习权重，动态地聚焦于图中重要的节点和边。</li>
<li>图生成模型（Graph Generation Models）：用于生成新的图样本，如图生成对抗网络（GANs）。</li>
<li>图自编码器（Graph Autoencoders）：用于无监督学习和图的特征提取。</li>
</ul>
<p>图神经网络的发展和研究是为了解决图数据分析和图结构任务，如图分类、节点分类、链接预测、图生成、图聚类等。这些任务通常需要考虑节点之间的关系和全局拓扑结构，并且图神经网络提供了一种有效的方式来处理和分析这种复杂的数据结构。</p>
<h2 id="多层神经网络常见组成结构"><a href="#多层神经网络常见组成结构" class="headerlink" title="多层神经网络常见组成结构"></a>多层神经网络常见组成结构</h2><p>现在的多层神经网络结构一般包含以下几种常见的层：</p>
<ul>
<li>输入层（Input Layer）：接收原始数据作为模型的输入，每个输入特征对应网络中的一个节点。</li>
<li>隐藏层（Hidden Layer）：位于输入层和输出层之间的一层或多层。每个隐藏层都包含多个节点（神经元），并使用激活函数对输入进行非线性变换。</li>
<li>输出层（Output Layer）：位于网络的最后一层，输出模型的预测结果或表示。输出层的节点数通常取决于具体的任务，例如分类任务可能有多个类别的节点，回归任务可能只有一个节点。</li>
</ul>
<p>除了这些基本层之外，还有一些特殊的层和技术，常见的包括：</p>
<ul>
<li>卷积层（Convolutional Layer）：主要用于处理图像和计算机视觉任务。卷积层通过应用一系列卷积核（过滤器）来提取输入数据中的局部特征，并共享权重以减少参数量。</li>
<li>池化层（Pooling Layer）：常与卷积层结合使用，用于减少特征图的尺寸和参数数量，同时保留主要特征。常见的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。</li>
<li>循环层（Recurrent Layer）：用于处理序列数据，如自然语言处理和时间序列分析。循环层中的神经元具有循环连接，可以在每个时间步骤上保留先前的状态信息。</li>
<li>规范化层（Normalization Layer）：如批归一化（Batch Normalization）和层归一化（Layer Normalization），用于提高网络的稳定性和收敛速度。</li>
<li>注意力层（Attention Layer）：通过学习注意力权重来对输入的不同部分进行加权处理，用于处理序列和集合数据中的相关性和重要性。</li>
</ul>
<p>需要注意的是，具体的网络结构和层数可能因任务和研究领域而异。不同的问题和应用可能会使用不同的层和技术来构建适合的神经网络结构。</p>
<h3 id="CNN神经网络的各种常见的网络层"><a href="#CNN神经网络的各种常见的网络层" class="headerlink" title="CNN神经网络的各种常见的网络层"></a>CNN神经网络的各种常见的网络层</h3><ol>
<li>卷积层、</li>
<li>激励层：由于卷积也是一种线性运算，因此需要对卷积层的输出进行一个非线性映射，一般为ReLu函数。</li>
<li>池化层：进行降维操作，一般有两种方式：进行下采样，对特征图稀疏处理，减少数据运算量<ol>
<li>max pooling：取池化视野中的最大值</li>
<li>Average pooling：取池化视野中的平均值</li>
</ol>
</li>
<li>归一化层：<ol>
<li>在Batch Normalization（简称BN）出现之前，我们的归一化操作一般都在数据输入层，对输入的数据进行求均值以及求方差做归一化，但是BN的出现打破了这一个规定，我们可以在网络中任意一层进行归一化处理。</li>
<li>不仅可以加快了模型的收敛速度，而且更重要的是在一定程度缓解了深层网络中“梯度弥散”的问题，从而使得训练深层网络模型更加容易和稳定。</li>
<li>也有更先进的，比如layernorm</li>
</ol>
</li>
<li>切分层：对某些（图片）数据的进行分区域的单独学习</li>
<li>融合层：对某些（图片）数据的进行分区域的单独学习</li>
<li>dropout层：为了防止过拟合（模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。）<ol>
<li>在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征</li>
</ol>
</li>
<li>全连接层：通常在CNN的尾部进行重新拟合，减少特征信息的损失。</li>
<li>输出层</li>
</ol>
<h2 id="经典深度学习方法模型"><a href="#经典深度学习方法模型" class="headerlink" title="经典深度学习方法模型"></a>经典深度学习方法模型</h2><h3 id="自回归语言模型-VS-自编码语言模型"><a href="#自回归语言模型-VS-自编码语言模型" class="headerlink" title="自回归语言模型 VS 自编码语言模型"></a>自回归语言模型 VS 自编码语言模型</h3><p><strong>自回归语言模型</strong>是根据上文或者下文来预测后一个单词。那不妨换个思路，我把句子中随机一个单词用[mask]替换掉，是不是就能同时根据该单词的上下文来预测该单词。我们都知道Bert在预训练阶段使用[mask]标记对句子中15%的单词进行随机屏蔽，然后根据被mask单词的上下文来预测该单词，这就是<strong>自编码语言模型</strong>的典型应用。</p>
<p>自回归语言模型没能自然的同时获取单词的上下文信息（ELMo把两个方向的LSTM做concat是一个很好的尝试，但是效果并不是太好），而自编码语言模型能很自然的把上下文信息融合到模型中（Bert中的每个Transformer都能看到整句话的所有单词，等价于双向语言模型），但自编码语言模型也有其缺点，就是在Fine-tune阶段，模型是看不到[mask]标记的，所以这就会带来一定的误差。</p>
<h3 id="自监督任务"><a href="#自监督任务" class="headerlink" title="自监督任务"></a>自监督任务</h3><p>自监督学习实际上与监督学习、非监督学习、半监督学习并没有本质上的鸿沟。</p>
<p>自我监督方法可以看作是一种具有监督形式的特殊形式的非监督学习方法，这里的监督是由自我监督任务而不是预设先验知识诱发的。与完全不受监督的设置相比，自监督学习使用数据集本身的信息来构造伪标签。在表示学习方面，自我监督学习具有取代完全监督学习的巨大潜力。人类学习的本质告诉我们，大型注释数据集可能不是必需的，我们可以自发地从未标记的数据集中学习。更为现实的设置是使用少量带注释的数据进行自学习。</p>
<h2 id="一些基本概念"><a href="#一些基本概念" class="headerlink" title="一些基本概念"></a>一些基本概念</h2><h3 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h3><p>模型参数的初始化一直是一个重要的研究问题，一个合适的初始化能够提升模型性能，加速收敛找到最优解。</p>
<p>由于不需要训练数据，所以无监督或自监督训练后的模型，能够很自然地作为下游任务（如图像分类、目标检测）模型微调前的初始化参数。</p>
<p>无监督算法的性能由微调后模型在下游任务的性能，如准确率、收敛速度等等相比基线模型是否有提高来进行判断。</p>
<p>在计算机视觉领域，由于CNN在过去的统治力，所以无监督深度学习通常都是基于标准卷积网络模型。例如将ResNet预训练后的模型迁移到其他基于CNN模型也是相当容易且直接的。</p>
<p>但现在时代变了，Vision Transformer（ViT）成为了新的主流模型。</p>
<h3 id="skip-connect"><a href="#skip-connect" class="headerlink" title="skip connect"></a>skip connect</h3><p>也就是残差连接。skip connect的思想，将输出表述为输入和输入的一个非线性变换的线性叠加，没用新的公式，没有新的理论，只是换了一种新的表达。<br><img src="https://pic.shaojiemike.top/img/20220128214428.png"></p>
<h3 id="SOTA"><a href="#SOTA" class="headerlink" title="SOTA"></a>SOTA</h3><p>SOTA也就是state-of-the-art，若某篇论文能够称为SOTA，就表明其提出的算法（模型）的性能在当前是最优的。</p>
<p>网址：<a target="_blank" rel="noopener" href="https://www.stateoftheart.ai/models">https://www.stateoftheart.ai/models</a></p>
<p><a target="_blank" rel="noopener" href="https://sota.jiqizhixin.com/">https://sota.jiqizhixin.com/</a></p>
<h3 id="CVPR"><a href="#CVPR" class="headerlink" title="CVPR"></a>CVPR</h3><p>Conference on Computer Vision and Pattern Recognition</p>
<h3 id="卷积可视化"><a href="#卷积可视化" class="headerlink" title="卷积可视化"></a>卷积可视化</h3><p><a target="_blank" rel="noopener" href="https://setosa.io/ev/image-kernels/">https://setosa.io/ev/image-kernels/</a></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/98f138c5ac11">https://www.jianshu.com/p/98f138c5ac11</a></p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/">https://zh.wikipedia.org/wiki/</a></p>
<p>[^2]: <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">ML wiki</a><br>[^3]: 《AI的25种可能》<br>[^4]: AI教父Hinton智源大会闭幕主题演讲<br>[^5]: <a target="_blank" rel="noopener" href="https://www.geekpark.net/news/317888">AI新浪潮观察, 畅想大模型之前，数据飞轮才是企业的「基本功」</a><br>[^6]: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/643420260">深入浅出完整解析Stable Diffusion XL（SDXL）核心基础知识</a><br>[^7]: <a target="_blank" rel="noopener" href="https://www.agilitypr.com/pr-news/public-relations/the-2023-path-to-ai-maturity-many-companies-have-reached-the-mature-level-but-at-what-cost/">The 2023 path to AI maturity: Many companies have reached the mature level—but at what cost?</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Machine Learning</p><p><a href="http://icarus.shaojiemike.top/2023/09/26/Work/Artificial Intelligence/Basic/MachineLearning/">http://icarus.shaojiemike.top/2023/09/26/Work/Artificial Intelligence/Basic/MachineLearning/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Shaojie Tan</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-09-26</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-04-18</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a><a class="link-muted mr-2" rel="tag" href="/tags/Machine-Learning/">Machine Learning</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a><a class="link-muted mr-2" rel="tag" href="/tags/CV/">CV</a><a class="link-muted mr-2" rel="tag" href="/tags/Deep-Learning/">Deep Learning</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>Afdian.net</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/09/27/Thinking/weekly/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Weekly</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/09/24/Work/Algorithms/leetcode/"><span class="level-item">Leetcode</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">397</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">497</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">39</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Camp/"><span class="level-start"><span class="level-item">Camp</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">25</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Thinking/"><span class="level-start"><span class="level-item">Thinking</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/love/"><span class="level-start"><span class="level-item">love</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">52</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-18T01:54:32.000Z">2024-04-18</time></p><p class="title"><a href="/2024/04/18/Work/software/manager/podman/">Podman</a></p><p class="categories"><a href="/categories/software/">software</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-17T11:44:58.000Z">2024-04-17</time></p><p class="title"><a href="/2024/04/17/Work/software/simulator/Victima/">Victima: feature extension</a></p><p class="categories"><a href="/categories/software/">software</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-15T02:55:06.000Z">2024-04-15</time></p><p class="title"><a href="/2024/04/15/OutOfWork/5-VideoEntertainment/Waifu2x8KUpscalingBug/">Waifu2x 8K Upscaling Bug</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-14T03:33:25.000Z">2024-04-14</time></p><p class="title"><a href="/2024/04/14/Work/Training/HuaweiTrainingCamp/">Huawei Training Camp</a></p><p class="categories"><a href="/categories/Camp/">Camp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-14T03:32:51.000Z">2024-04-14</time></p><p class="title"><a href="/2024/04/14/OutOfWork/0-love/wonyoung/">Jang Wonyoung</a></p><p class="categories"><a href="/categories/love/">love</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">56</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2024 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>