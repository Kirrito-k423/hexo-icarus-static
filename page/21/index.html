<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.1.1"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-03T16:00:00.000Z" title="7/3/2023, 4:00:00 PM">2023-07-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.248Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Network/">Network</a></span><span class="level-item">9 minutes read (About 1365 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/07/03/OutOfWork/4-devices/nas/SynologyNAS/">NAS configuration</a></p><div class="content"><h2 id="购买的考虑点"><a href="#购买的考虑点" class="headerlink" title="购买的考虑点"></a>购买的考虑点</h2><p><a target="_blank" rel="noopener" href="https://post.smzdm.com/p/a5d23w98/">https://post.smzdm.com/p/a5d23w98/</a></p>
<h3 id="处理器"><a href="#处理器" class="headerlink" title="处理器"></a>处理器</h3><p>建议至少是Intel的双核，ARM的还是不好使。单核性能太弱了。虚拟机，docker什么的就别想了。</p>
<h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>尽量8GB组双通道</p>
<h3 id="网口"><a href="#网口" class="headerlink" title="网口"></a>网口</h3><p>群晖的都是1Gb的老千兆(虽然我电脑，路由器网口也是)，但是威联通是2.5Gb的。</p>
<h3 id="M2-SSD加速"><a href="#M2-SSD加速" class="headerlink" title="M2.SSD加速"></a>M2.SSD加速</h3><p>是否支持SSD加速</p>
<h3 id="USB口是不是3-2Gen2"><a href="#USB口是不是3-2Gen2" class="headerlink" title="USB口是不是3.2Gen2"></a>USB口是不是3.2Gen2</h3><h2 id="群晖-DS220J-本体1200"><a href="#群晖-DS220J-本体1200" class="headerlink" title="群晖 DS220J (本体1200)"></a>群晖 DS220J (本体1200)</h2><p><img src="https://pic.shaojiemike.top/img/20220620103011.png"></p>
<p>PC公用路由器控制</p>
<p><a target="_blank" rel="noopener" href="http://find.synology.com/">http://find.synology.com</a></p>
<p>或者</p>
<p><a target="_blank" rel="noopener" href="http://synologynas:5000/">http://synologynas:5000</a></p>
<h3 id="QuickConnect"><a href="#QuickConnect" class="headerlink" title="QuickConnect"></a>QuickConnect</h3><p><a target="_blank" rel="noopener" href="https://quickconnect.to/shaojiemike">https://QuickConnect.to/shaojiemike</a></p>
<p><a target="_blank" rel="noopener" href="http://222.195.90.2/">http://222.195.90.2/</a> (能ping通，就能访问)</p>
<h3 id="电脑SMB直接访问"><a href="#电脑SMB直接访问" class="headerlink" title="电脑SMB直接访问"></a>电脑SMB直接访问</h3><p>\\192.168.31.247 (双斜杠，右键home有选项：映射网络驱动器)</p>
<p>\\tsjNas (需要在局域网下)</p>
<p>\\222.195.90.2&#x2F; (需要开启路由器的SMB（137-139，445）端口转发，否则能ping通，但是不能访问)</p>
<h2 id="网络配置脚本"><a href="#网络配置脚本" class="headerlink" title="网络配置脚本"></a>网络配置脚本</h2><p>使用开机wireguard脚本连接上网</p>
<ul>
<li>任意盘位置<code>/volume1/xxx</code>编辑脚本，赋予权限</li>
<li>群晖添加计划：点击任务计划。点击新增 -&gt; 触发的任务 -&gt; 用户定义的脚本(<strong>注意选择root用户权限</strong>)<ul>
<li>也可以选择写入启动文件中<code>vi /etc/rc</code></li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置本地ssh eth0的222.195.90.2的高优先级，不至于开启wg断开ssh</span></span><br><span class="line">ip ro add default via 222.195.90.254 dev eth0 table eth0-table</span><br><span class="line"><span class="comment"># 为了使得除开本地ssh网络走wg，需要删除屏蔽default的wg的DHCP</span></span><br><span class="line">ip ro d default via 222.195.90.254 dev eth0  src 222.195.90.2 table main</span><br><span class="line"><span class="comment"># 防止服务端重启，Nas的wg客户端失联</span></span><br><span class="line">ip ro a 114.214.233.0/24 via 222.195.90.254 dev eth0  src 222.195.90.2 table main </span><br><span class="line"><span class="comment"># 启动wg</span></span><br><span class="line">wg-quick up wg1</span><br></pre></td></tr></table></figure>

<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p><a target="_blank" rel="noopener" href="https://kb.synology.cn/zh-cn/DSM/help/DSM/StorageManager/disk?version=7#Drive">群晖文档</a></p>
<h3 id="删除失效网络硬盘"><a href="#删除失效网络硬盘" class="headerlink" title="删除失效网络硬盘"></a>删除失效网络硬盘</h3><p>无法直接取消，会报错”此连接不存在”，<a target="_blank" rel="noopener" href="https://pureinfotech.com/remove-network-drive-windows-10/">参考文章</a></p>
<p>需要删除两项<code>regedit</code>注册表<code>计算机\HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\MountPoints2\##10.0.0.12#homes</code> 和 <code>计算机\HKEY_CURRENT_USER\Network</code> 下对应的盘符即可。</p>
<h3 id="如果要利用空间"><a href="#如果要利用空间" class="headerlink" title="如果要利用空间"></a>如果要利用空间</h3><p>不要组RAID，通过添加<strong>存储池</strong>来使用每个盘。</p>
<p>RAID0也不要组，文件是打散的，虽然读和写块，但是是一个整体。坏一个就全坏了。</p>
<p>先配置存储池和存储空间</p>
<p><img src="https://pic.shaojiemike.top/img/20220714104716.png"></p>
<p>然后设置文件夹</p>
<p><img src="https://pic.shaojiemike.top/img/20220714104603.png"></p>
<p>再重新映射盘符即可</p>
<p><img src="https://pic.shaojiemike.top/img/20220714104912.png"></p>
<h3 id="停用与启用"><a href="#停用与启用" class="headerlink" title="停用与启用"></a>停用与启用</h3><p>若要激活硬盘：<br>已停用硬盘的分配状态会更改为未初始化，这表示此硬盘未安装 DSM，可以分配给存储池。请执行以下任何操作以激活硬盘：</p>
<ol>
<li>从硬盘插槽中移除硬盘，然后将其重新插入硬盘插槽。</li>
<li>重启系统。</li>
</ol>
<h3 id="图形化界面控制台很卡顿"><a href="#图形化界面控制台很卡顿" class="headerlink" title="图形化界面控制台很卡顿"></a>图形化界面控制台很卡顿</h3><p>原因内存和性能不行，建议升级DS220j+ 额外拓展内存</p>
<h3 id="电脑直接传输特别慢平均10M"><a href="#电脑直接传输特别慢平均10M" class="headerlink" title="电脑直接传输特别慢平均10M"></a>电脑直接传输特别慢平均10M</h3><p>群晖DS220j文件传输速度、外网访问速度、moment套件使用情况以及耗电情况。 最高写入速度为105MB&#x2F;S，最高读取速度为110MB&#x2F;S。</p>
<p>西数红盘 2T。 145MB&#x2F;s。</p>
<p>知乎评测: 局域网实际拷贝速度还不错，基本能达到千兆水平。下图是拷贝GB级文件（如电影）的截图，拷贝照片和音乐之类的小文件会慢不少，10MB大小的文件写入速度有60MB&#x2F;s左右，更小的文件就只有30MB&#x2F;s了。</p>
<p><img src="https://pic.shaojiemike.top/img/20220619223930.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220619221900.png"></p>
<h2 id="排查配置"><a href="#排查配置" class="headerlink" title="排查配置"></a>排查配置</h2><h3 id="网口-1"><a href="#网口-1" class="headerlink" title="网口"></a>网口</h3><p>路由器是Redmi AX3000wifi6 WAN口和LAN口都是千兆口 2000Mbit 3000Mbit</p>
<p>电脑的网口是B450 迫击炮的主板 千兆口</p>
<h3 id="网线"><a href="#网线" class="headerlink" title="网线"></a>网线</h3><p>电脑连路由器的的网线是cat.6A的</p>
<p>电脑连墙壁接口的是cat.5e的</p>
<p>网线，DS220J 送的是cat.5e</p>
<p><img src="https://pic.shaojiemike.top/img/20220619220956.png"></p>
<p>只要网线够短，cat.5e至少有5Gb&#x2F;s，一般都不是瓶颈。<a href="%5BCat5e%EF%BC%8C%E8%B6%85%E4%BA%94%E7%B1%BB%E7%BA%BF%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E6%94%AF%E6%8C%81%E5%8D%83%E5%85%86%EF%BC%9F%5D(https://zhuanlan.zhihu.com/p/136479005)">^1</a></p>
<h3 id="额外测试"><a href="#额外测试" class="headerlink" title="额外测试"></a>额外测试</h3><p>网线直连电脑和群晖的机器，用这根CAT.6A，速度也很慢。</p>
<p><img src="https://pic.shaojiemike.top/img/20220619232515.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220619232939.png"></p>
<p>(结果第二天就好多了，路由器平均50M，直连能跑满，感觉原因在于路由器缓存转发的问题，端口都是千兆的)<br><img src="https://pic.shaojiemike.top/img/20220620104536.png"><br><img src="https://pic.shaojiemike.top/img/20220620104452.png"></p>
<h2 id="其余测试"><a href="#其余测试" class="headerlink" title="其余测试"></a>其余测试</h2><h3 id="检测硬盘"><a href="#检测硬盘" class="headerlink" title="检测硬盘"></a>检测硬盘</h3><p>diskgenius</p>
<h3 id="命令行硬盘测速"><a href="#命令行硬盘测速" class="headerlink" title="命令行硬盘测速"></a>命令行硬盘测速</h3><p>控制面板 开启ssh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 2333 shaojiemike@192.168.233.242</span><br><span class="line">sudo -s</span><br><span class="line"></span><br><span class="line">sh-4.4<span class="comment"># df -h</span></span><br><span class="line">Filesystem         Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/md0           2.3G  1.1G  1.2G  50% /</span><br><span class="line">devtmpfs           225M     0  225M   0% /dev</span><br><span class="line">tmpfs              243M   24K  243M   1% /dev/shm</span><br><span class="line">tmpfs              243M   15M  228M   7% /run</span><br><span class="line">tmpfs              243M     0  243M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs              243M  1.5M  241M   1% /tmp</span><br><span class="line">/dev/vg1/volume_1  1.8T  1.5T  289G  85% /volume1</span><br><span class="line">/dev/vg3/volume_3  4.0T  2.0G  4.0T   1% /volume3</span><br><span class="line">/dev/vg3/volume_4  4.0T   89M  4.0T   1% /volume4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 磁盘读性能</span></span><br><span class="line">sh-4.4<span class="comment"># hdparm -Tt /dev/vg1/volume_1</span></span><br><span class="line"></span><br><span class="line">/dev/vg1/volume_1:</span><br><span class="line"> Timing cached reads:   1092 MB <span class="keyword">in</span>  2.00 seconds = 545.67 MB/sec</span><br><span class="line"> Timing buffered disk reads: 456 MB <span class="keyword">in</span>  3.03 seconds = 150.28 MB/sec</span><br><span class="line">sh-4.4<span class="comment"># hdparm -Tt /dev/md4</span></span><br><span class="line"></span><br><span class="line">/dev/md4:</span><br><span class="line"> Timing cached reads:   1086 MB <span class="keyword">in</span>  2.00 seconds = 542.89 MB/sec</span><br><span class="line"> Timing buffered disk reads: 838 MB <span class="keyword">in</span>  3.00 seconds = 279.23 MB/sec</span><br><span class="line">sh-4.4<span class="comment"># hdparm -Tt /dev/mapper/vg3-volume_4</span></span><br><span class="line"></span><br><span class="line">/dev/mapper/vg3-volume_4:</span><br><span class="line"> Timing cached reads:   1076 MB <span class="keyword">in</span>  2.00 seconds = 537.13 MB/sec</span><br><span class="line"> Timing buffered disk reads: 592 MB <span class="keyword">in</span>  3.01 seconds = 196.89 MB/sec</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 磁盘写性能</span></span><br><span class="line">sh-4.4<span class="comment"># dd if=/dev/vg3/volume_3 bs=1024 count=1000000 of=/1Gb.file</span></span><br><span class="line">1000000+0 records <span class="keyword">in</span></span><br><span class="line">1000000+0 records out</span><br><span class="line">1024000000 bytes (1.0 GB, 977 MiB) copied, 13.0458 s, 78.5 MB/s</span><br><span class="line">sh-4.4<span class="comment"># dd if=/dev/vg1/volume_1 bs=1024 count=1000000 of=/1Gb.file</span></span><br><span class="line">1000000+0 records <span class="keyword">in</span></span><br><span class="line">1000000+0 records out</span><br><span class="line">1024000000 bytes (1.0 GB, 977 MiB) copied, 18.837 s, 54.4 MB/s</span><br></pre></td></tr></table></figure>

<h3 id="群晖测网速"><a href="#群晖测网速" class="headerlink" title="群晖测网速"></a>群晖测网速</h3><p>群晖的docker里也有speedtest</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-03T16:00:00.000Z" title="7/3/2023, 4:00:00 PM">2023-07-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.272Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/network/">network</a></span><span class="level-item">19 minutes read (About 2782 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/07/03/Work/network/vpn/wireguard/">Wireguard</a></p><div class="content"><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>WireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec&#x2F;IKEv2、OpenVPN 或 L2TP 等其他 VPN 协议的问题。它与 Tinc 和 MeshBird 等现代 VPN 产品有一些相似之处，即加密技术先进、配置简单。</li>
<li>从 2020 年 1 月开始，它已经并入了 Linux 内核的 5.6 版本，这意味着大多数 Linux 发行版的用户将拥有一个开箱即用的 WireGuard。</li>
<li>WireGuard 作为一个更先进、更现代的 VPN 协议，比起传统的 IPSec、OpenVPN 等实现，效率更高，配置更简单，并且已经合并入 Linux 内核，使用起来更加方便。</li>
</ul>
<h3 id="常见VPN方法比较"><a href="#常见VPN方法比较" class="headerlink" title="常见VPN方法比较"></a>常见VPN方法比较</h3><p><img src="https://pic.shaojiemike.top/img/20230411194711.png"></p>
<ul>
<li>wireguard 精簡、速度極快：<ul>
<li>只有 4000 行程式碼，是最精簡的 VPN 協議。对比下 OpenVPN，大约有 10 万行代码。</li>
</ul>
</li>
<li>WireGuard 利用内核空间处理来提升性能（更高吞吐和更低延迟），同时避免了不必要的内核和用户空间频繁上下文切换开销。</li>
</ul>
<h2 id="Wireguard客户端连接Debug"><a href="#Wireguard客户端连接Debug" class="headerlink" title="Wireguard客户端连接Debug"></a>Wireguard客户端连接Debug</h2><ul>
<li>首先，服务端的ip或者域名能ping通</li>
<li>其次端口确定开放<code>&gt; nc -z -v -u 4.shaojiemike.top 51822</code>,wg是udp</li>
<li>修改wg客户端配置文件，限制ip为wg设置的内网段，<code>AllowedIPs = 192.168.31.0/24，10.0.233.1/24</code>.然后<code>ping 192.168.31.1</code>测试</li>
<li>如果还不行，判断为wg的VPN包被中间网关识别并丢弃</li>
</ul>
<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>配置详解<a target="_blank" rel="noopener" href="https://icloudnative.io/posts/wireguard-docs-practice/#2-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3">参考中文文档</a></p>
<h3 id="PersistentKeepalive"><a href="#PersistentKeepalive" class="headerlink" title="PersistentKeepalive"></a>PersistentKeepalive</h3><ul>
<li>一端位于 NAT 后面，另一端直接通过公网暴露</li>
<li>这种情况下，最简单的方案是：通过公网暴露的一端作为服务端，另一端指定服务端的公网地址和端口，然后通过 persistent-keepalive 选项维持长连接，让 NAT 记得对应的映射关系。<ul>
<li><code>[peer]</code>里设定字段 <code>PersistentKeepalive = 25</code>，表示每隔 25 秒发送一次 ping 来检查连接。</li>
</ul>
</li>
</ul>
<h3 id="AllowedIPs"><a href="#AllowedIPs" class="headerlink" title="AllowedIPs"></a>AllowedIPs</h3><p>虽然<code>AllowedIPs = 0.0.0.0/0</code>与<code>AllowedIPs = 0.0.0.0/1, 128.0.0.0/1</code>包含的都是全部的ip。</p>
<p>但是前者在iptable里为<code>default dev wg1</code>,后者为两条<code>0.0.0.0/1 dev wg1</code>和<code>128.0.0.0/1 dev wg1</code>。</p>
<p>由于路由的ip匹配遵循最长前缀匹配规则，如果路由表里原本有一条<code>efault dev eth0</code>。使用前者会导致混乱。但是使用后者，由于两条的优先级会更高，会屏蔽掉原本的default规则。</p>
<p>前者的iptable修改如下：（macbook上）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; ip route</span><br><span class="line">default via link#18 dev utun3</span><br><span class="line">default via 192.168.233.1 dev en0</span><br><span class="line">10.0.233.5/32 via 10.0.233.5 dev utun3</span><br><span class="line">224.0.0.0/4 dev utun3  scope link</span><br><span class="line">224.0.0.0/4 dev en0  scope link</span><br><span class="line">255.255.255.255/32 dev utun3  scope link</span><br><span class="line">255.255.255.255/32 dev en0  scope link</span><br></pre></td></tr></table></figure>

<p>后者的iptable修改如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; ip route</span><br><span class="line">0.0.0.0/1 dev utun3  scope link</span><br><span class="line">default via 192.168.233.1 dev en0</span><br><span class="line">default via link#18 dev utun3</span><br><span class="line">10.0.233.5/32 via 10.0.233.5 dev utun3</span><br><span class="line">128.0.0.0/1 dev utun3  scope link</span><br><span class="line">224.0.0.0/4 dev en0  scope link</span><br><span class="line">224.0.0.0/4 dev utun3  scope link</span><br><span class="line">255.255.255.255/32 dev en0  scope link</span><br><span class="line">255.255.255.255/32 dev utun3  scope link</span><br></pre></td></tr></table></figure>

<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>建议看<a target="_blank" rel="noopener" href="https://icloudnative.io/posts/wireguard-docs-theory/#1-wireguard-%E6%9C%AF%E8%AF%AD">WireGuard 教程：WireGuard 的工作原理</a> 和<a target="_blank" rel="noopener" href="https://icloudnative.io/posts/linux-routing-of-wireguard/">WireGuard 基础教程：wg-quick 路由策略解读</a>，详细解释了wg是如何修改路由表规则的。</p>
<h3 id="wireguard-运行原理以及配置文件"><a href="#wireguard-运行原理以及配置文件" class="headerlink" title="wireguard 运行原理以及配置文件"></a>wireguard 运行原理以及配置文件</h3><p>默认会产生51840的路由table，<code>ip rule</code>优先级较高。可以通过配置文件中添加<code>PostUp</code>来修改最后一个default的路由规则。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@snode6:/etc/wireguard<span class="comment"># cat wg0.conf</span></span><br><span class="line">[Interface]</span><br><span class="line">Address = 192.168.253.5/32,fd00::aaaa:5/128</span><br><span class="line">PrivateKey = eGj5skRAGJu8d………………1PVfu0lY=</span><br><span class="line"><span class="comment"># PublicKey = VWe0wBVztgX………………xd7/kZ2CVJlEvS51c=</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Table必须有，不然默认的还是会修改ip rule</span></span><br><span class="line">Table = 51820</span><br><span class="line"><span class="comment">#DNS = 1.1.1.1 #指定DNS服务器</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#启动时运行： %i 是指wg的路由， 默认修改default， metric 一般不用指定</span></span><br><span class="line">PostUp   = /sbin/ip -4 route replace default dev %i table default metric 1</span><br><span class="line">PostUp   = /sbin/ip -6 route replace default dev %i table default metric 1</span><br><span class="line"><span class="comment">#down后运行</span></span><br><span class="line">PostDown = /sbin/ip -4 route delete  default dev %i table default metric 1</span><br><span class="line">PostDown = /sbin/ip -6 route delete  default dev %i table default metric 1</span><br></pre></td></tr></table></figure>

<p><code>PostUp</code>会产生下面的规则</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@snode6:/staff/shaojiemike<span class="comment"># ip ro show table default</span></span><br><span class="line">default dev wg0 scope <span class="built_in">link</span> metric 1</span><br></pre></td></tr></table></figure>

<h3 id="OpenVPN原理"><a href="#OpenVPN原理" class="headerlink" title="OpenVPN原理"></a>OpenVPN原理</h3><p>OpenVPN原理通过在main添加all规则来实现</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaojiemike @ node5 in ~ [22:29:05]</span></span><br><span class="line">$ ip route show table main</span><br><span class="line">0.0.0.0/1 via 192.168.255.5 dev tun1</span><br></pre></td></tr></table></figure>

<h3 id="clash-TUN模式"><a href="#clash-TUN模式" class="headerlink" title="clash TUN模式"></a>clash TUN模式</h3><p>Macbook上的应用上的ClashX Pro的增强模式类似, 会添加如下配置，将基本所有流量代理（除开<code>0.0.0.0/8</code>）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; ip route</span><br><span class="line">1.0.0.0/8 via 198.18.0.1 dev utun3</span><br><span class="line">2.0.0.0/7 via 198.18.0.1 dev utun3</span><br><span class="line">4.0.0.0/6 via 198.18.0.1 dev utun3</span><br><span class="line">8.0.0.0/5 via 198.18.0.1 dev utun3</span><br><span class="line">16.0.0.0/4 via 198.18.0.1 dev utun3</span><br><span class="line">32.0.0.0/3 via 198.18.0.1 dev utun3</span><br><span class="line">64.0.0.0/2 via 198.18.0.1 dev utun3</span><br><span class="line">128.0.0.0/1 via 198.18.0.1 dev utun3 <span class="comment">#前面接受所有的ip，然后转换成198.18.0.1</span></span><br><span class="line">198.18.0.1/32 via 198.18.0.1 dev utun3 <span class="comment">#接受转换后的198.18.0.1，由于最长前缀匹配</span></span><br></pre></td></tr></table></figure>

<p>明显有代理死循环问题，如何解决？？？</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">shaojiemike@shaojiemikedeMacBook-Air ~/github/hugoMinos (main*) [10:59:32]</span><br><span class="line">&gt; ip route get 198.18.0.42</span><br><span class="line">198.18.0.42 via 198.18.0.1 dev utun3  src 198.18.0.1</span><br><span class="line">shaojiemike@shaojiemikedeMacBook-Air ~/github/hugoMinos (main*) [10:59:38]</span><br><span class="line">&gt; ip route get 198.18.0.1</span><br><span class="line">198.18.0.1 dev utun3  src 198.18.0.1</span><br></pre></td></tr></table></figure>

<h2 id="Wireguard-环境配置"><a href="#Wireguard-环境配置" class="headerlink" title="Wireguard 环境配置"></a>Wireguard 环境配置</h2><p>wireguard-go: 安装客户端 wg-quick up config<br>wireguard-tools: 安装服务端 wg</p>
<h2 id="Wireguard-常见命令"><a href="#Wireguard-常见命令" class="headerlink" title="Wireguard 常见命令"></a>Wireguard 常见命令</h2><ul>
<li>启动<code>wg-quick up wg1</code></li>
<li>关闭<code>wg-quick down wg1</code></li>
<li>查看状态 <code>wg</code>显示全部，或者<code>wg show wg1</code>显示wg1</li>
</ul>
<h2 id="wireguard开机启动"><a href="#wireguard开机启动" class="headerlink" title="wireguard开机启动"></a>wireguard开机启动</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable wg-quick@wg1 --now</span><br></pre></td></tr></table></figure>

<h2 id="使用wireguard-代理ipv6请求"><a href="#使用wireguard-代理ipv6请求" class="headerlink" title="使用wireguard 代理ipv6请求"></a>使用wireguard 代理ipv6请求</h2><ul>
<li><a target="_blank" rel="noopener" href="https://icloudnative.io/posts/wireguard-docs-practice/#ipv6">WireGuard 也支持 IPv6</a>。OpenWRT 服务端，当然要allowed ip <code>fd00::aaaa:5/128</code>、</li>
<li>注意：这是伪需求，为什么ipv6的流量需要走ipv6，不走wg，每个机器可以获得独立的公网ipv6，对于PT做种是很好的。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">brainiac1<span class="comment"># cat wg-tsj.conf</span></span><br><span class="line">[Interface]</span><br><span class="line">PrivateKey = xxx</span><br><span class="line">ListenPort = 51828</span><br><span class="line">Address = 10.0.233.7/32, fd00::aaaa:5/128</span><br><span class="line">Table = 51820</span><br><span class="line"><span class="comment">#DNS = 1.1.1.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用iptable修改ipv6的路由规则</span></span><br><span class="line">PostUp   = /sbin/ip -4 route replace default dev %i table default metric 1</span><br><span class="line">PostUp   = /sbin/ip -6 route replace default dev %i table default metric 1</span><br><span class="line">PostDown = /sbin/ip -4 route delete  default dev %i table default metric 1</span><br><span class="line">PostDown = /sbin/ip -6 route delete  default dev %i table default metric 1</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line"><span class="comment">#AllowedIPs = 0.0.0.0/0,::/0</span></span><br><span class="line">PublicKey = xxx</span><br><span class="line">AllowedIPs = 0.0.0.0/1, 128.0.0.0/1</span><br><span class="line">Endpoint = 4.shaojiemike.top:51822</span><br><span class="line">PersistentKeepalive = 30</span><br></pre></td></tr></table></figure>

<h2 id="两次wireguard上网"><a href="#两次wireguard上网" class="headerlink" title="两次wireguard上网"></a>两次wireguard上网</h2><p>修改<code>sysctl.conf</code>文件的<code>net.ipv4.ip_forward</code>参数。其值为0,说明禁止进行IP转发；如果是1,则说明IP转发功能已经打开。</p>
<p>需要执行指令<code>sysctl -p</code> 后新的配置才会生效。</p>
<h3 id="两台机器的wireguard配置"><a href="#两台机器的wireguard配置" class="headerlink" title="两台机器的wireguard配置"></a>两台机器的wireguard配置</h3><p>注意中间需要NAT转换, 相当于把kunpeng机器的请求，隐藏成snode6的请求。在后一次wireguard转发时，就不会被过滤掉。</p>
<p><img src="https://pic.shaojiemike.top/img/20221031233739.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PostUp   = iptables -t nat -A POSTROUTING -s 10.1.0.0/24 ! -o %i -j MASQUERADE</span><br><span class="line">PostDown = iptables -t nat -D POSTROUTING -s 10.1.0.0/24 ! -o %i -j MASQUERADE || true</span><br></pre></td></tr></table></figure>

<h2 id="机器（Nas）使用Wireguard上网"><a href="#机器（Nas）使用Wireguard上网" class="headerlink" title="机器（Nas）使用Wireguard上网"></a>机器（Nas）使用Wireguard上网</h2><h3 id="问题场景"><a href="#问题场景" class="headerlink" title="问题场景"></a>问题场景</h3><p>由于换了wg服务端，导致nas变成闭环的网络了。最后是通过群晖助手(Synology Assistant &#x2F; Web Assistant)的设置静态ip才连接上机器，但是iptable被设置乱了。</p>
<p>??? failure “Synology Assistant can not find nas”</p>
<p>静态连接上机器，首先在网页管理页面切换成DHCP（静态ip的DNS解析有误），iptable变成如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sh-4.4<span class="comment"># ip ro</span></span><br><span class="line">default via 222.195.90.254 dev eth0  src 222.195.90.2</span><br><span class="line">10.0.233.0/24 dev wg1  proto kernel  scope <span class="built_in">link</span>  src 10.0.233.3</span><br><span class="line">222.195.90.0/24 dev eth0  proto kernel  scope <span class="built_in">link</span>  src 222.195.90.2</span><br><span class="line"></span><br><span class="line">sh-4.4<span class="comment"># ip ro s t eth0-table</span></span><br><span class="line">222.195.90.0/24 via 222.195.90.2 dev eth0</span><br></pre></td></tr></table></figure>

<p>注意iptable的修改是实时生效的。</p>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>为了让nas上网我们需要满足两点</p>
<ol>
<li>本地ssh eth0的222.195.90.2能访问机器(优先级更高)</li>
<li>其余网络走wg</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重要项如下</span></span><br><span class="line">sh-4.4<span class="comment"># ip rule</span></span><br><span class="line">3:      from 222.195.90.2 lookup eth0-table (ping 和 ssh ip 222.195.90.2的会使用这个规则)</span><br><span class="line">32766:  from all lookup main (ping 和 ssh 其余ip 比如wg的10.0.233.3的会使用这个规则)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 设置本地ssh eth0的222.195.90.2的高优先级，不至于开启wg断开ssh</span></span><br><span class="line"><span class="comment"># 使用命令添加： ip ro add default via 222.195.90.254 dev eth0 table eth0-table</span></span><br><span class="line">sh-4.4<span class="comment"># ip route show table eth0-table</span></span><br><span class="line">default via 222.195.90.254 dev eth0</span><br><span class="line">222.195.90.0/24 via 222.195.90.2 dev eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 为了使得除开本地ssh网络走wg，需要删除屏蔽default的wg的DHCP(如果提前删，导致机器ssh连接不上了，重新插拔网线，让DHCP重新配置)：</span></span><br><span class="line"><span class="comment"># 使用命令添加：ip ro d default via 222.195.90.254 dev eth0  src 222.195.90.2 table main，</span></span><br><span class="line"><span class="comment"># 3. 防止服务端重启，Nas的wg客户端失联</span></span><br><span class="line"><span class="comment"># 使用命令添加：ip ro a 114.214.233.0/24 via 222.195.90.254 dev eth0  src 222.195.90.2 table main </span></span><br><span class="line"><span class="comment"># 4. 测试： ping域名能正常运行</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其余方法：为了使得除开本地ssh网络走wg，也可以不删除，在DHCP的前面添加wg的网络通路</span></span><br><span class="line"><span class="comment"># 使用命令添加： ip ro add default dev wg1  proto kernel  scope link  src 10.0.233.3 table main</span></span><br><span class="line">sh-4.4<span class="comment"># ip r s t main</span></span><br><span class="line">default dev wg1  proto kernel  scope <span class="built_in">link</span>  src 10.0.233.3</span><br></pre></td></tr></table></figure>

<p>使用wg1配置如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sh-4.4<span class="comment"># cat /etc/wireguard/wg1.conf</span></span><br><span class="line">[Interface]</span><br><span class="line">PrivateKey = xxx</span><br><span class="line">ListenPort = xxx</span><br><span class="line">Address = 10.0.xxx.xxx/24</span><br><span class="line"></span><br><span class="line">Table = 51820</span><br><span class="line">PostUp   = /sbin/ip -4 route replace default dev %i table default metric 1</span><br><span class="line">PostDown = /sbin/ip -4 route delete  default dev %i table default metric 1</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line">PublicKey = xxx</span><br><span class="line">AllowedIPs = 0.0.0.0/1, 128.0.0.0/1</span><br><span class="line">Endpoint = 114.xxx.xxx.xxx:xxx</span><br><span class="line">PersistentKeepalive = 25</span><br></pre></td></tr></table></figure>

<h3 id="问题：服务端重启，Nas的wg客户端失联"><a href="#问题：服务端重启，Nas的wg客户端失联" class="headerlink" title="问题：服务端重启，Nas的wg客户端失联"></a>问题：服务端重启，Nas的wg客户端失联</h3><p>要保留没有wg的时候访问服务端的eth0(114.214.233.xxx)的通路</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sh-4.4<span class="comment"># ip ro s t main</span></span><br><span class="line">···</span><br><span class="line">114.214.233.0/24 via 222.195.90.254 dev eth0  src 222.195.90.2</span><br><span class="line">···</span><br></pre></td></tr></table></figure>

<h2 id="来自eth0的ssh与ping请求原路返回"><a href="#来自eth0的ssh与ping请求原路返回" class="headerlink" title="来自eth0的ssh与ping请求原路返回"></a>来自eth0的ssh与ping请求原路返回</h2><h3 id="源地址为自身IP的包走学校的路由器"><a href="#源地址为自身IP的包走学校的路由器" class="headerlink" title="源地址为自身IP的包走学校的路由器"></a>源地址为自身IP的包走学校的路由器</h3><p>目的：需要ssh和ping ipv4成功</p>
<p>修改<code>netplan</code>的配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaojiemike @ node5 in ~ [22:29:11]</span></span><br><span class="line">$ <span class="built_in">cat</span> /etc/netplan/acsa.yaml</span><br><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    eno0:</span><br><span class="line">      dhcp4: <span class="literal">false</span></span><br><span class="line">      dhcp6: <span class="literal">false</span></span><br><span class="line">      accept-ra: <span class="literal">false</span></span><br><span class="line">      addresses:</span><br><span class="line">        - 202.38.73.217/24</span><br><span class="line">        - 2001:da8:d800:730::217/64</span><br><span class="line">      gateway4: 202.38.73.254</span><br><span class="line">      gateway6: 2001:da8:d800:730::1</span><br><span class="line">      nameservers:</span><br><span class="line">        addresses:</span><br><span class="line">          - 202.38.64.1</span><br><span class="line">      routing-policy:</span><br><span class="line">        - from: 202.38.73.217</span><br><span class="line">          table: 1</span><br><span class="line">          priority: 2</span><br><span class="line">      routes:</span><br><span class="line">        - to: 0.0.0.0/0</span><br><span class="line">          via: 202.38.73.254</span><br><span class="line">          table: 1</span><br><span class="line"></span><br><span class="line"><span class="variable">$netplan</span> apply</span><br></pre></td></tr></table></figure>

<p><code>routing-policy</code>会产生</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaojiemike @ node5 in ~ [22:30:33]</span></span><br><span class="line">$ ip rule</span><br><span class="line">0:      from all lookup <span class="built_in">local</span></span><br><span class="line">2:      from 202.38.73.217 lookup 1</span><br><span class="line">32766:  from all lookup main</span><br><span class="line">32767:  from all lookup default</span><br><span class="line"><span class="comment"># 也可以手动添加</span></span><br><span class="line">ip rule add from 202.38.73.217 table 1 pref 2</span><br><span class="line">或者</span><br><span class="line">ip rule add from 202.38.73.217 lookup 1 pref 2</span><br></pre></td></tr></table></figure>

<p>由于2优先级高，使得ping和ssh的返回信包(源地址为自身机器IP的包)走table1 规则，而不是走</p>
<p><code>routes</code>使得所有的table1都会走学校的路由器(202.38.73.254)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip route show table 1</span><br><span class="line">default via 202.38.73.254 dev eno0 proto static</span><br><span class="line"><span class="comment"># 也可以通过`ip route add`</span></span><br><span class="line">$ ip route add default via 202.38.73.254 dev eno0 proto static table 1</span><br></pre></td></tr></table></figure>

<h3 id="衍生问题：网络请求的源地址不是自己吗？怎么确定的"><a href="#衍生问题：网络请求的源地址不是自己吗？怎么确定的" class="headerlink" title="衍生问题：网络请求的源地址不是自己吗？怎么确定的"></a>衍生问题：网络请求的源地址不是自己吗？怎么确定的</h3><p>开启wg后，网络请求源地址变成了<code>10.0.33.2</code>。不是<code>202.38.73.217</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@node5:/home/shaojiemike# ip ro</span><br><span class="line">10.0.33.0/24 dev wg2 proto kernel scope link src 10.0.33.2</span><br></pre></td></tr></table></figure>

<p>但是外界ping的是<code>202.38.73.217</code>。返回包交换所以会产生源地址为<code>202.38.73.217</code>的包</p>
<h2 id="wireguard-实现翻墙"><a href="#wireguard-实现翻墙" class="headerlink" title="wireguard 实现翻墙"></a>wireguard 实现翻墙</h2><ul>
<li>WireGuard 在国内网络环境下会遇到一个致命的问题：UDP 封锁&#x2F;限速。虽然通过 WireGuard 可以在隧道内传输任何基于 IP 的协议（TCP、UDP、ICMP、SCTP、IPIP、GRE 等），但 WireGuard 隧道本身是通过 UDP 协议进行通信的，而国内运营商根本没有能力和精力根据 TCP 和 UDP 的不同去深度定制不同的 QoS 策略，几乎全部采取一刀切的手段：<strong>对 UDP 进行限速甚至封锁。</strong></li>
<li>虽然对 UDP 不友好，但却无力深度检测 TCP 连接的真实性。</li>
<li>将 UDP 连接伪装成 TCP 连接不就蒙混过关了。目前支持将 UDP 流量伪装成 TCP 流量的主流工具是 udp2raw，但是有一款更强大的新工具： <a target="_blank" rel="noopener" href="https://icloudnative.io/posts/wireguard-over-tcp-using-phantun/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">Phantun</a>。</li>
</ul>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://icloudnative.io/posts/wireguard-over-tcp-using-phantun/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">WireGuard 基础教程：使用 Phantun 将 WireGuard 的 UDP 流量伪装成 TCP</a></p>
<p><a target="_blank" rel="noopener" href="https://nordvpn.com/zh-tw/blog/vpn-xieyi/">https://nordvpn.com/zh-tw/blog/vpn-xieyi/</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.mozcp.com/wireguard-usage/">https://blog.mozcp.com/wireguard-usage/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-26T16:00:00.000Z" title="6/26/2023, 4:00:00 PM">2023-06-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.264Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Architecture/">Architecture</a></span><span class="level-item">13 minutes read (About 1908 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/26/Work/Programming/2.1-Assembly/assembly/">Assembly X86</a></p><div class="content"><p>关于X86 与 arm的寄存器的区别写在了arm那篇下</p>
<h2 id="IDA-analysis"><a href="#IDA-analysis" class="headerlink" title="IDA analysis"></a>IDA analysis</h2><p><img src="https://pic.shaojiemike.top/img/20211118221425.png"></p>
<h2 id="word-dword-qword"><a href="#word-dword-qword" class="headerlink" title="word&#x2F; dword&#x2F; qword"></a>word&#x2F; dword&#x2F; qword</h2><p>In x86 terminology&#x2F;documentation, a “word” is 16 bits </p>
<p>x86 word &#x3D; 2 bytes</p>
<p>x86 dword &#x3D; 4 bytes (double word)</p>
<p>x86 qword &#x3D; 8 bytes (quad word)</p>
<p>x86 double-quad or xmmword &#x3D; 16 bytes, e.g. movdqa xmm0, [rdi].</p>
<h2 id="常见X86汇编"><a href="#常见X86汇编" class="headerlink" title="常见X86汇编"></a>常见X86汇编</h2><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/X86_instruction_listings">https://en.wikipedia.org/wiki/X86_instruction_listings</a></p>
<p><a target="_blank" rel="noopener" href="https://www.felixcloutier.com/x86/">https://www.felixcloutier.com/x86/</a></p>
<p><a target="_blank" rel="noopener" href="https://officedaytime.com/simd512e/">https://officedaytime.com/simd512e/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">官方手册第一个4800页</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SHR	    # Shift right (unsigned shift right)</span><br><span class="line">SAL       # Shift Arithmetically left (signed shift left)</span><br><span class="line">lea       # Load Effective Address, like mov but not change Flags, can store in any register, three opts</span><br><span class="line">imul      # Signed multiply</span><br><span class="line">movslq    # Move doubleword to quadword with sign-extension.</span><br><span class="line">movl $0x46dd0bfe, 0x804a1dc #将数值0x46dd0bfe放入0x804a1dc的地址中</span><br><span class="line">movl 0x46dd0bfe, 0x804a1dc #将0x46dd0bfe地址里的内容放入0x804a1dc地址中</span><br></pre></td></tr></table></figure>

<h3 id="lea-leaq"><a href="#lea-leaq" class="headerlink" title="lea &amp; leaq"></a>lea &amp; leaq</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lea    -0xc(%ebp),%eax</span><br><span class="line">mov    %eax,0x8(%esp) #常见于scanf第三个参数，lea传结果写入地址</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// x is %rdi, result is %rax 就是计算地址，没有寻址操作</span><br><span class="line">lea    0x0(,%rdi,8),%rax //result = x * 8;</span><br><span class="line">lea    0x4b(,%rdi),%rax //result = x + 0x4b;</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20220112101023.png"></p>
<h3 id="call-ret"><a href="#call-ret" class="headerlink" title="call &amp; ret"></a>call &amp; ret</h3><ul>
<li><code>Call 地址</code>：返回地址入栈（等价于“<code>Push %eip，mov 地址，%eip</code>”；注意eip指向下一条尚未执行的指令）</li>
<li><code>ret</code>：从栈中弹出地址，并跳到那个地址（<code>pop %eip</code>）</li>
</ul>
<h3 id="leave"><a href="#leave" class="headerlink" title="leave"></a>leave</h3><p><code>leave</code>：使栈做好返回准备，等价于</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov %ebp，%esp</span><br><span class="line">pop %ebp</span><br></pre></td></tr></table></figure>

<h3 id="compare-order"><a href="#compare-order" class="headerlink" title="compare order"></a>compare order</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmpl   $0x5,$0x1</span><br><span class="line">jle    8048bc5 # Jump if Less or Equal 会触发，前面的 1&lt;=5</span><br></pre></td></tr></table></figure>
<h3 id="X86-load-store"><a href="#X86-load-store" class="headerlink" title="X86 load store"></a>X86 load store</h3><p>X86 不像 ARM有专门的<code>ldr</code>， <code>str</code>指令。是通过mov实现的</p>
<p><code>movswl (%rdi), %eax</code> sign-extending load from word (w) to dword (l). Intel <code>movsx eax, word [rdi]</code></p>
<h3 id="AVX"><a href="#AVX" class="headerlink" title="AVX"></a>AVX</h3><p><a target="_blank" rel="noopener" href="https://docs.oracle.com/cd/E36784_01/html/E36859/gntbd.html">https://docs.oracle.com/cd/E36784_01/html/E36859/gntbd.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vxorpd   XORPD</span><br><span class="line">Bitwise Logical XOR for Double-Precision Floating-Point Values</span><br><span class="line"></span><br><span class="line">vxorps   XORPS</span><br><span class="line">Bitwise Logical XOR for Single-Precision Floating-Point Values</span><br><span class="line"></span><br><span class="line">vmovaps  MOVAPS</span><br><span class="line">Move Aligned Packed Single-Precision Floating-Point Values</span><br></pre></td></tr></table></figure>

<h3 id="test-jump"><a href="#test-jump" class="headerlink" title="test &amp; jump"></a>test &amp; jump</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test    al, al</span><br><span class="line">jne     0x1000bffcc</span><br></pre></td></tr></table></figure>

<p>The <code>test</code> instruction performs a logical and of the two operands and sets the CPU flags register according to the result (which is not stored anywhere). If <code>al</code> is zero, the anded result is zero and that sets the Z flag. If <code>al</code> is nonzero, it clears the Z flag. (Other flags, such as Carry, oVerflow, Sign, Parity, etc. are affected too, but this code has no instruction testing them.)</p>
<p>The <code>jne</code> instruction alters EIP if the Z flag is not set. There is another mnemonic for the same operation called <code>jnz</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test   %eax,%eax</span><br><span class="line">jg     &lt;phase_4+0x35&gt; # eax &amp; eax &gt; 0 jump</span><br></pre></td></tr></table></figure>

<p>注意 <code>cmp</code>不等于 <code>test</code></p>
<p>The <code>TEST</code> operation sets the flags <code>CF</code> and <code>OF</code> to zero.</p>
<p>The <code>SF</code> is set to the MSB(most significant bit) of the result of the <code>AND</code>.</p>
<p>If the result of the <code>AND</code> is 0, the <code>ZF</code> is set to 1, otherwise set to 0.</p>
<h3 id="kinds-of-jump"><a href="#kinds-of-jump" class="headerlink" title="kinds of jump"></a>kinds of jump</h3><p><img src="https://pic.shaojiemike.top/img/20211111094314.png"></p>
<p>AT&amp;T syntax <code>jmpq *0x402390(,%rax,8)</code> into INTEL-syntax: <code>jmp [RAX*8 + 0x402390]</code>.</p>
<h3 id="ja-VS-jg"><a href="#ja-VS-jg" class="headerlink" title="ja VS jg"></a>ja VS jg</h3><p><code>JUMP IF ABOVE</code> AND <code>JUMP IF GREATER</code></p>
<p><code>ja</code> jumps if <code>CF = 0</code> and <code>ZF = 0</code> (unsigned Above: no carry and not equal)</p>
<p><code>jg</code> jumps if <code>SF = OF</code> and <code>ZF = 0</code> (signed Greater, excluding equal)</p>
<h3 id="FLAGS"><a href="#FLAGS" class="headerlink" title="FLAGS"></a>FLAGS</h3><p><code>cmp</code> performs a <code>sub</code> (but does not keep the result).</p>
<p><code>cmp eax, ebx</code></p>
<p>Let’s do the same by hand:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">reg     hex value   binary value  </span><br><span class="line"></span><br><span class="line">eax = 0xdeadc0de    ‭11011110101011011100000011011110‬</span><br><span class="line">ebx = 0x1337ca5e    ‭00010011001101111100101001011110‬</span><br><span class="line"> -    ----------</span><br><span class="line">res   0xCB75F680    11001011011101011111011010000000 </span><br></pre></td></tr></table></figure>

<p>The flags are set as follows:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">OF (overflow) : did bit 31 change      -&gt; no</span><br><span class="line">SF (sign)     : is bit 31 set          -&gt; yes</span><br><span class="line">CF (carry)    : is abs(ebx) &lt; abs(eax) -&gt; no  </span><br><span class="line">ZF (zero)     : is result zero         -&gt; no</span><br><span class="line">PF (parity)   : is parity of LSB even  -&gt; no (archaic)</span><br><span class="line">AF (Adjust)   : overflow in bits 0123  -&gt; archaic, for BCD only.</span><br></pre></td></tr></table></figure>

<h3 id="Carry-Flag"><a href="#Carry-Flag" class="headerlink" title="Carry Flag"></a>Carry Flag</h3><p><strong>Carry Flag</strong> is a flag set when:</p>
<p>a) two unsigned numbers were added and the result is larger than “capacity” of register where it is saved.</p>
<p>Ex: we wanna add two 8 bit numbers and save result in 8 bit register. In your example: 255 + 9 &#x3D; 264 which is more that 8 bit register can store. So the value “8” will be saved there (264 &amp; 255 &#x3D; 8) and CF flag will be set.</p>
<p>b) two unsigned numbers were subtracted and we subtracted the bigger one from the smaller one.</p>
<p>Ex: 1-2 will give you 255 in result and CF flag will be set.</p>
<p><strong>Auxiliary Flag</strong> is used as CF but when working with BCD. So AF will be set when we have overflow or underflow on in BCD calculations. For example: considering 8 bit ALU unit, Auxiliary flag is set when there is carry from 3rd bit to 4th bit i.e. carry from lower nibble to higher nibble. (Wiki link)</p>
<p><strong>Overflow Flag</strong> is used as CF but when we work on signed numbers.</p>
<p>Ex we wanna add two 8 bit signed numbers: 127 + 2. the result is 129 but it is too much for 8bit signed number, so OF will be set.</p>
<p>Similar when the result is too small like -128 - 1 &#x3D; -129 which is out of scope for 8 bit signed numbers.</p>
<h2 id="register-signed-unsigned"><a href="#register-signed-unsigned" class="headerlink" title="register signed &amp; unsigned"></a>register signed &amp; unsigned</h2><p><strong>Positive or negative</strong><br>The CPU does not know (or care) whether a number is positive or negative. The only person who knows is you. If you test <strong>SF</strong> and <strong>OF</strong>, then you treat the number as signed. If you only test <strong>CF</strong> then you treat the number as unsigned.<br>In order to help you the processor keeps track of all flags at once. You decide which flags to test and by doing so, you decide how to interpret the numbers.</p>
<h2 id="register-multiply"><a href="#register-multiply" class="headerlink" title="register multiply"></a>register multiply</h2><p>The computer makes use of <strong>binary multiplication(AND)</strong>, followed by <strong>bit shift</strong> (in the direction in which the multiplication proceeds), followed by <strong>binary addition(OR)</strong>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1100100</span><br><span class="line">0110111</span><br><span class="line">=======</span><br><span class="line">0000000</span><br><span class="line">-1100100</span><br><span class="line">--1100100</span><br><span class="line">---0000000</span><br><span class="line">----1100100</span><br><span class="line">-----1100100</span><br><span class="line">------1100100</span><br><span class="line">==============</span><br><span class="line">1010101111100</span><br><span class="line"></span><br><span class="line">100 = 1.1001 * 2^6</span><br><span class="line">55  = 1.10111* 2^5</span><br><span class="line">100 * 55 -&gt; 1.1001 * 1.10111 * 2^(6+5)</span><br></pre></td></tr></table></figure>

<p>for more:</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/3060064/how-computer-multiplies-2-numbers">How computer multiplies 2 numbers?</a><br>And:<br><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Binary_multiplier">Binary multiplier - Wikipedia</a></p>
<h2 id="Memory-and-Addressing-Modes"><a href="#Memory-and-Addressing-Modes" class="headerlink" title="Memory and Addressing Modes"></a>Memory and Addressing Modes</h2><h3 id="声明静态代码区域"><a href="#声明静态代码区域" class="headerlink" title="声明静态代码区域"></a>声明静态代码区域</h3><p><strong>DB, DW, and DD</strong> can be used to declare one, two, and four byte data locations,</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 基本例子</span><br><span class="line">.DATA		</span><br><span class="line">var	DB <span class="number">64</span>  	; Declare a byte, referred to as location var, containing the value <span class="number">64.</span></span><br><span class="line">var2	DB ?	; Declare an uninitialized byte, referred to as location var2.</span><br><span class="line">DB <span class="number">10</span>	; Declare a byte with no label, containing the value <span class="number">10.</span> Its location is var2 + <span class="number">1.</span></span><br><span class="line">X	DW ?	; Declare a <span class="number">2</span>-byte uninitialized value, referred to as location X.</span><br><span class="line">Y	DD <span class="number">30000</span>    	; Declare a <span class="number">4</span>-byte value, referred to as location Y, initialized to <span class="number">30000.</span></span><br></pre></td></tr></table></figure>

<p>数组的声明，The <strong>DUP</strong> directive tells the assembler to duplicate an expression a given number of times. For example, 4 DUP(2) is equivalent to 2, 2, 2, 2.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Z	DD 1, 2, 3	; Declare three 4-byte values, initialized to 1, 2, and 3. The value of location Z + 8 will be 3.</span><br><span class="line">bytes  	DB 10 DUP(?)	; Declare 10 uninitialized bytes starting at location bytes.</span><br><span class="line">arr	DD 100 DUP(0)    	; Declare 100 4-byte words starting at location arr, all initialized to 0</span><br><span class="line">str	DB &#x27;hello&#x27;,0	; Declare 6 bytes starting at the address str, initialized to the ASCII character values for hello and the null (0) byte.</span><br></pre></td></tr></table></figure>

<h3 id="寻址"><a href="#寻址" class="headerlink" title="寻址"></a>寻址</h3><p>32位X86机器寻址支持</p>
<ol>
<li>最多支持32位寄存器和32位有符号常数相加</li>
<li>其中一个寄存器可以再乘上 2，4，8</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># right</span><br><span class="line">mov eax, [ebx]	; Move the 4 bytes in memory at the address contained in EBX into EAX</span><br><span class="line">mov [var], ebx	; Move the contents of EBX into the 4 bytes at memory address var. (Note, var is a 32-bit constant).</span><br><span class="line">mov eax, [esi-4]	; Move 4 bytes at memory address ESI + (-4) into EAX</span><br><span class="line">mov [esi+eax], cl	; Move the contents of CL into the byte at address ESI+EAX</span><br><span class="line">mov edx, [esi+4*ebx]    	; Move the 4 bytes of data at address ESI+4*EBX into EDX</span><br><span class="line"></span><br><span class="line"># wrong and reason</span><br><span class="line">mov eax, [ebx-ecx]	; Can only add register values</span><br><span class="line">mov [eax+esi+edi], ebx    	; At most 2 registers in address computation</span><br></pre></td></tr></table></figure>

<h3 id="指定存储在地址的数据大小"><a href="#指定存储在地址的数据大小" class="headerlink" title="指定存储在地址的数据大小"></a>指定存储在地址的数据大小</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov BYTE PTR [ebx], 2	; Move 2 into the single byte at the address stored in EBX.</span><br><span class="line">mov WORD PTR [ebx], 2	; Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in EBX.</span><br><span class="line">mov DWORD PTR [ebx], 2    	; Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in EBX.</span><br></pre></td></tr></table></figure>

<h2 id="汇编寄存器顺序，作用方向"><a href="#汇编寄存器顺序，作用方向" class="headerlink" title="汇编寄存器顺序，作用方向"></a>汇编寄存器顺序，作用方向</h2><p>这和汇编器语法有关：</p>
<h3 id="X86-instructions"><a href="#X86-instructions" class="headerlink" title="X86 instructions"></a>X86 instructions</h3><p>For instructions with two operands, the first (lefthand) operand is the <strong>source</strong> operand, and the second (righthand) operand is the <strong>destination</strong> operand (that is, source-&gt;destination).</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov eax, ebx — copy the value in ebx into eax</span><br><span class="line">add eax, 10 — EAX ← EAX + 10</span><br></pre></td></tr></table></figure>

<h3 id="AT-T-syntax"><a href="#AT-T-syntax" class="headerlink" title="AT&amp;T syntax"></a>AT&amp;T syntax</h3><p>AT&amp;T Syntax is an assembly syntax used in UNIX environments, that originates from <strong>AT&amp;T Bell Labs</strong>. It is descended from the MIPS assembly syntax. (AT&amp;T, American Telephone &amp; Telegraph)</p>
<p>AT&amp;T Syntax is an assembly syntax used mostly in <strong>UNIX</strong> environments or by tools like <strong>gcc</strong> that originated in that environment.</p>
<p><img src="https://pic.shaojiemike.top/img/20211007205016.png"></p>
<p>语法特点：<a target="_blank" rel="noopener" href="https://stackoverflow.com/tags/att/info">https://stackoverflow.com/tags/att/info</a></p>
<p>需要注意的：</p>
<ol>
<li>Operands are in <strong>destination-last</strong> order</li>
<li><strong>Register</strong> names are prefixed with <code>%</code>, and <strong>immediates</strong> are prefixed with <code>$</code><ol>
<li><code>sub $24, %rsp</code> reserves 24 bytes on the stack.</li>
</ol>
</li>
<li><strong>Operand-size</strong> is indicated with a <code>b/w/l/q</code> suffix on the mnemonic<ol>
<li><code>addb $1, byte_table(%rdi)</code> increment a byte in a static table.</li>
<li>The mov suffix (b, w, l, or q) indicates how many bytes are being copied (1, 2, 4, or 8 respectively)</li>
<li><img src="https://i.loli.net/2021/10/22/DQeC8qVm3s9MKzR.png"></li>
</ol>
</li>
<li><code>imul $13, 16(%rdi, %rcx, 4),  %eax</code> 32-bit load from <code>rdi + rcx&lt;&lt;2 + 16</code>, multiply that by 13, put the result in <code>%eax</code>. <strong>Intel</strong> <code>imul eax, [16 + rdi + rcx*4], 13</code>.</li>
<li><code>movswl (%rdi), %eax</code> sign-extending load from word (w) to dword (l). Intel <code>movsx eax, word [rdi]</code>.</li>
</ol>
<h3 id="Intel-syntax-used-in-Intel-AMD-manuals"><a href="#Intel-syntax-used-in-Intel-AMD-manuals" class="headerlink" title="Intel syntax  (used in Intel&#x2F;AMD manuals)."></a>Intel syntax  (used in Intel&#x2F;AMD manuals).</h3><p>The Intel assembler(icc,icpc我猜) uses the <strong>opposite</strong> order (destination&lt;-source) for operands.<br><img src="https://pic.shaojiemike.top/img/20211007204947.png"></p>
<p>语法特点： <a target="_blank" rel="noopener" href="https://stackoverflow.com/tags/intel-syntax/info">https://stackoverflow.com/tags/intel-syntax/info</a></p>
<h3 id="RISC-V"><a href="#RISC-V" class="headerlink" title="RISC-V"></a>RISC-V</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">beq rs1, rs2, Label #RISC-V</span><br><span class="line">SW rs2, imm(rs1)  # Mem[rs1+imm]=rs2 ,汇编将访存放在最后</span><br><span class="line">add rd, rs1, rs2  # rd = rs1 + rs2</span><br></pre></td></tr></table></figure>

<h3 id="反汇编器"><a href="#反汇编器" class="headerlink" title="反汇编器"></a>反汇编器</h3><p>但是这个语法不是很重要，因为decompiler有选项控制语法</p>
<p><code>objdump</code> has <code>-Mintel</code> flag, <code>gdb</code> has <code>set disassembly-flavor intel</code> option.</p>
<p> <code>gcc -masm=intel -S</code> or <code>objdump -drwC -Mintel</code>.</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.cs.virginia.edu/~evans/cs216/guides/x86.html">https://www.cs.virginia.edu/~evans/cs216/guides/x86.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-22T16:00:00.000Z" title="6/22/2023, 4:00:00 PM">2023-06-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.272Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/network/">network</a></span><span class="level-item">4 minutes read (About 668 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/22/Work/network/0-basic/localhost/">Localhost</a></p><div class="content"><h2 id="环回地址"><a href="#环回地址" class="headerlink" title="环回地址"></a>环回地址</h2><ul>
<li>环回地址，是指不离开主机的数据包(也就是说，这些数据包不会通过外部网络接口)。<ul>
<li>任何发往环回地址的数据包，其处理都在 TCP&#x2F;IP 协议叠的链路层中实现的。这些数据包不会向下交由网卡（NIC）或者设备驱动程序处理，既不应在电脑系统以外出现，也不可经路由器转发。</li>
<li>环回地址是主机用于向自身发送通信的一个特殊地址，帮助我们在同一台主机上实现client和server的功能。</li>
<li>运用本地环回机制，便可在主机上运行网络服务，期间不须安装实体网络接口卡，也无须将该服务开放予主机所在网络。</li>
</ul>
</li>
</ul>
<h2 id="localhost"><a href="#localhost" class="headerlink" title="localhost"></a>localhost</h2><ul>
<li>localhost 是一个别名，用于指代为环回保留的 IP 地址(环回地址)。<ul>
<li>IPv4使用 A 类地址的最后一个块（从 127.0.0.1 到 127.255.255）<ul>
<li>发送到这些地址（127.0.0.1 到 127.255.255.255）的所有数据包都会返回本机。</li>
</ul>
</li>
<li>而IPv6保留第一个（0:0:0:0:0:0:0:1 - 或 : :1）作为其环回地址。</li>
</ul>
</li>
</ul>
<h2 id="0-0-0-0-任意ip"><a href="#0-0-0-0-任意ip" class="headerlink" title="0.0.0.0 任意ip"></a>0.0.0.0 任意ip</h2><ul>
<li>0.0.0.0并不是一个真实的的IP地址，它表示本机中所有的IPV4地址。</li>
<li>监听0.0.0.0的端口，就是监听本机中所有IP的端口。</li>
<li>0.0.0.0是不能被ping通的。</li>
</ul>
<h2 id="localhost-与-127-0-0-1区别"><a href="#localhost-与-127-0-0-1区别" class="headerlink" title="localhost 与 127.0.0.1区别"></a>localhost 与 127.0.0.1区别</h2><ul>
<li>localhost(本地主机)不是专门指 127.0.0.1，而是指为环回保留的整个 IP 地址范围。<ul>
<li>注意你不能总是使用127.0.0.1进行环回。<ul>
<li>仅限 IPv6 的系统不会响应此类请求，因为它们的 localhost 链接到地址::1。</li>
<li>修改<code>/etc/hosts</code>文件即可修改环回的地址。但是十分不建议这样做，很可能导致本地服务崩溃</li>
</ul>
</li>
</ul>
</li>
<li>请求的发送方式不同???<ul>
<li>127.0.0.1是通过网卡传输，依赖网卡，并受到网络防火墙和网卡相关的限制。</li>
<li>localhost不会解析成ip，也不会占用网卡、网络资源。一般设置程序时本地服务用localhost是最好的。</li>
</ul>
</li>
</ul>
<h2 id="如何将环回地址某端口上的服务映射到外部网络接口"><a href="#如何将环回地址某端口上的服务映射到外部网络接口" class="headerlink" title="如何将环回地址某端口上的服务映射到外部网络接口"></a>如何将环回地址某端口上的服务映射到外部网络接口</h2><ul>
<li>可以使用ssh转发<code>ssh -L 1313:localhost:8020 shaojiemike@202.38.72.23</code>将服务器<code>localhost:1313</code>上的内容转发到本地8020端口</li>
<li><code>hugo server -D -d ~/test/public</code>默认会部署在localhost上<ul>
<li>解决办法<code>hugo server --bind=202.38.72.23 --baseURL=http://202.38.72.23:1313 -D -d ~/test/public</code></li>
</ul>
</li>
</ul>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://blog.nnwk.net/article/107">https://blog.nnwk.net/article/107</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-20T16:00:00.000Z" title="6/20/2023, 4:00:00 PM">2023-06-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.252Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Values/">Values</a></span><span class="level-item">8 minutes read (About 1160 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/20/Thinking/4-viewOnOthers/4.1-game/">UnimportantView: Game</a></p><div class="content"><h2 id="关于偏好的循环"><a href="#关于偏好的循环" class="headerlink" title="关于偏好的循环"></a>关于偏好的循环</h2><p>!!! question “轮回与回旋镖：小别胜新婚”</p>
<pre><code>我发现我陷入了一种循环：

正向：

1. 美术音乐和玩法的新鲜感：一开始游戏新鲜内容好奇，然后在新鲜内容耗尽时。
2. 成就感
3. 史诗故事感（真实代入感），和领悟
4. 刺激感？（不适用我这里

反向：

5. 日常的枯燥的刷任务积累，实在令人厌烦。
6. PVP的队友的争吵和失败的挫败感也会大幅降低游玩意愿
</code></pre>
<p>!!! tip “关于PVP 和 PVE”</p>
<pre><code>如果在游玩的时候，如果没有对面是电脑的想法，任务的难度就是**合适的，有趣的，或者有挑战**的。

如果意识到了NPC反应的**模板化，枯燥化，简单化**的PVE就不行。 PVP可以避免这三点，但是组队的门槛、队内的矛盾、和失利会带来反向效果。

比如GTA5 online通关之后，上线之后所有东西都尝试过后，就没有留恋的意思了。除非将NPC接入AI并且动态调节难度，就可以避免这点。
</code></pre>
<h2 id="如何筛选适合的游戏"><a href="#如何筛选适合的游戏" class="headerlink" title="如何筛选适合的游戏"></a>如何筛选适合的游戏</h2><p>现状：游玩时间少，时间碎片化，无规律</p>
<ul>
<li>游玩体验一定要舒适<ul>
<li>体验的主线内容：真实的幻想世界<ul>
<li>轻松快乐的主线剧情体验，(-20 ~ 35) <ul>
<li>一起提供代入感和沉浸式的游玩体验</li>
<li>无剧情该项为0</li>
<li>扣分：枯燥拖沓的演出(-10)</li>
<li>加分：刺激有趣的剧情表演(+10)、诙谐的台本(+5),令人有所感悟的主线故事(+15)、动容的NPC故事(+5)</li>
</ul>
</li>
<li>有趣新颖的玩法(30)<ul>
<li>新鲜玩法(15)</li>
<li>眼前一亮的细节(5)</li>
<li>足够深的游戏内容，来随意探索;(10)<ul>
<li>或者足够精致宏大的单机主线内容(FF,大镖客2)</li>
</ul>
</li>
</ul>
</li>
<li>精致华丽的美术(30)<ul>
<li>交互界面UI(3)</li>
<li>开放世界风景(7) 震撼华丽的大场景可以弥补角色喜爱塑造的缺失</li>
<li>令人喜爱的角色(15)</li>
<li>动听的音乐(5)</li>
</ul>
</li>
</ul>
</li>
<li>日常周常体验(40)<ul>
<li>耗时&#x2F;门槛(20)：<ul>
<li>无需投入大量前期时间才能正常体验<ul>
<li>经验训练技巧</li>
<li>前置任务过多</li>
</ul>
</li>
<li>没有强制的任务指标来限制&#x2F;延长在线时长</li>
</ul>
</li>
<li>收获感(10)：投入有回报(货币)、提升(数值)</li>
<li>新鲜感(10)：有Rougelike元素，避免无聊</li>
</ul>
</li>
<li>手游根据逼氪程度减分<ul>
<li>200以上减5；1000以上减10</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="适合的类型："><a href="#适合的类型：" class="headerlink" title="适合的类型："></a>适合的类型：</h2><ul>
<li>合家欢小游戏(主玩法，轻竞技)：<ul>
<li>蛋仔、任系游戏（惊奇）</li>
</ul>
</li>
<li>主剧情的单机RPG游戏<ul>
<li>王国之泪，星际争霸（金手指）</li>
</ul>
</li>
<li>主美术的二次元轻度手游<ul>
<li>铁道</li>
</ul>
</li>
<li>网状叙事的电影史<ul>
<li>博德之门3</li>
</ul>
</li>
</ul>
<h2 id="不适合的类型："><a href="#不适合的类型：" class="headerlink" title="不适合的类型："></a>不适合的类型：</h2><ul>
<li>有紧迫任务目标的游戏（大量限时任务的网游）</li>
<li>快乐建立在胜负上的竞技类游戏(PVP游戏)</li>
</ul>
<h2 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h2><!-- ![](https://pic.shaojiemike.top/img/20230501102804.png) -->

<p><img src="https://pic.shaojiemike.top/img/20230621212739.png"></p>
<h3 id="231221-少女前线2-追放"><a href="#231221-少女前线2-追放" class="headerlink" title="231221 少女前线2 追放"></a>231221 少女前线2 追放</h3><p>首先，我没有玩过少前1，和战棋类游戏，和偏写实的剧情。</p>
<ol>
<li>剧情与主线： <ol>
<li>沉浸感低：<strong>谜语人</strong>，各种看不到的名词。我不知道是为了装逼还是少前1的基本概念。好的游戏，都不会在玩家理解上制造问题。</li>
<li>个人感觉<strong>写实的剧情</strong>立意不足，和目的性，意义行解释不清楚，导致游玩时，感觉动力不足。 由于本人并不喜欢打杀。我玩游戏也是认真玩的，如果剧情感觉不够恢弘，写实的枪战细节剧情感觉不是很动人。(可能是玄幻和幻想游戏玩多了，写实类剧情完全没接触过)，需要<strong>平衡好真实感与现实的繁琐程度</strong></li>
</ol>
</li>
<li>美术<ol>
<li>UI简洁好看</li>
<li><strong>好但可以更好</strong>，人物, 闪电姐的脸总感觉怪怪的胖胖的。黑丝等拟真质感确实不错。但是人物服饰什么的都是冷淡风，只能说之后的潜力很大。（比如像 尘白禁区泳装一样。</li>
</ol>
</li>
<li>玩法<ol>
<li><strong>好但可以更好</strong>，利用地形杀，和道具之类的。（有潜力</li>
</ol>
</li>
</ol>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无

</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-15T16:00:00.000Z" title="6/15/2023, 4:00:00 PM">2023-06-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.256Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">13 minutes read (About 1920 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/15/Work/HPC/0-overview/optimizationOutline/">Optimization Outline</a></p><div class="content"><h2 id="Sun’s-常见超线性加速的情况"><a href="#Sun’s-常见超线性加速的情况" class="headerlink" title="Sun’s 常见超线性加速的情况"></a>Sun’s 常见超线性加速的情况</h2><p><a target="_blank" rel="noopener" href="http://www.cs.iit.edu/%7Esun/cs546.html#materials">http://www.cs.iit.edu/%7Esun/cs546.html#materials</a></p>
<p><a target="_blank" rel="noopener" href="https://annals-csis.org/Volume_8/pliks/498.pdf">https://annals-csis.org/Volume_8/pliks/498.pdf</a></p>
<p>Superlinear Speedup in HPC Systems: why and when?</p>
<ol>
<li>Cache size increased 多核的cache总size增加<ol>
<li>在大多数的并行计算系统中，每个处理器都有少量的高速缓存，当某一问题执行在大量的处理器上，而所需要的数据都放在高速缓存中时，由于数据的复用，总的计算时间趋于减少，如果由于这种高速缓存效应补偿了由于通信造成的额外开销，就有可能造成超线性加速比。</li>
</ol>
</li>
<li>Overhead reduced 锁减少，粒度变小</li>
<li>Latency hidden 数据预取更多了</li>
<li>Randomized algorithms<ol>
<li>在某些并行搜索算法中，允许不同的处理器在不同的分支方向上同时搜索，当某一处理器一旦迅速的找到了解，它就向其余的处理器发出中止搜索的信号，这就会提前取消那些在串行算法中所做的无谓的搜索分枝，从而出现超线性加速比现象</li>
</ol>
</li>
<li>Mathematical inefficiency of the serial algorithm 改并行算法</li>
<li>Higher memory consumption access cost for in sequantial processing</li>
</ol>
<h2 id="应用优化前提"><a href="#应用优化前提" class="headerlink" title="应用优化前提"></a>应用优化前提</h2><ol>
<li><p>迭代进行 ：分析程序最大热点(perf,vtune工具)-&gt;优化该热点—&gt;分析程序最大热点-&gt;……</p>
</li>
<li><p>自顶向下分析优化程序热点的思路</p>
<ol>
<li>全局算法的调研、理解、总体设计改进</li>
<li>程序任务划分，并行各部分模块</li>
<li>仔细分析热点的kernel循环</li>
</ol>
</li>
<li><p>基本了解物理数学背景公式</p>
</li>
<li><p>阅读代码，明白实现</p>
<ol>
<li>从main函数开始看的都是大撒比，没错，说的就是我</li>
<li>带着问题看，才能快速抓住重点</li>
</ol>
</li>
<li><p>建议串行直接用vtune判断算法热点和时间</p>
<ol>
<li>粗略判断热点</li>
<li>加入<strong>各部分热点的时间输出</strong> (必需的:积极的正向反馈，会提高积极性和理清思路)</li>
</ol>
</li>
<li><p>寻找合适的<strong>大例子</strong></p>
</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line">itime = omp_get_wtime();</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;\nTime taken is %f&quot;</span>,omp_get_wtime()-itime);</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>运行n次求得平均值; 或者对不同大小的例子在不同参数下的效果拉图对比<ol>
<li>单机不同数量多核，同机器的不同编译器，不同核心kernel&#x2F;CPU</li>
<li>warmup&#x3D;10 loop&#x3D;50 先热身10次，然后循环10次</li>
</ol>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./SLIC_0805_3 |tee 3.log &amp;&amp; ./SLIC_0805_3 |tee 3.log &amp;&amp; ./SLIC_0805_3 |tee 3.log</span><br></pre></td></tr></table></figure>

<p><img src="https://pic.shaojiemike.top/img/20210909155842.png"><br>7. 每次优化基给予正确性的评价，并对负优化进行解释。</p>
<ol>
<li>查看汇编</li>
<li>基本并行加速实现后，vtune检查<strong>访存</strong>,或者用Intel advisor的Roofline Model来分析。</li>
<li>新函数用 <code>utils.cpp</code>和 <code>utils.h</code>写</li>
</ol>
<h2 id="应用类型及其常见优化"><a href="#应用类型及其常见优化" class="headerlink" title="应用类型及其常见优化"></a>应用类型及其常见优化</h2><ol>
<li>计算密集<ol>
<li>采用适合并行平台的算法</li>
<li>CPU核数利用率<ol>
<li>多进程<ol>
<li>进程池动态调度</li>
</ol>
</li>
<li>多线程(对于特别小的例子，一个cpu的核就够用了)<ol>
<li>线程亲和性</li>
<li>线程动态调度</li>
</ol>
</li>
</ol>
</li>
<li>向量化率(提高单次计算量)SIMD<ol>
<li>自动向量化提升有限吗？怎么写出好让编译器自动向量化的代码<ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zyl910/?type=blog">https://blog.csdn.net/zyl910/?type=blog</a> SIMD测试比较</li>
</ol>
</li>
<li>pragma omp parallel for simd</li>
<li>循环展开，凑够无依赖计算，填满流水线avx512的宽度(8个float)</li>
<li>intrins接口手动向量化</li>
<li>注意边界，不足8个单独计算</li>
<li>手动向量化avx2一般会快一些</li>
<li><img src="https://pic.shaojiemike.top/img/20211001225407.png"></li>
</ol>
</li>
<li>降低计算量技巧<ol>
<li><a target="_blank" rel="noopener" href="https://developer.51cto.com/article/710503.html">其他各种小技巧</a></li>
<li>使用掩码代替分支判断<ol>
<li>增A：<code>|A</code> 删A：<code>&amp;（~A）</code>判断：<code>&amp;A!=0</code></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zyl910/article/details/7345655">https://blog.csdn.net/zyl910/article/details/7345655</a></li>
</ol>
</li>
<li>替换if <code>tmp[i][j] = (!(cnt^3))||((a[i][j]&amp;1)&amp;&amp;(!(cnt^4)));</code></li>
<li>使用乘法代替除法</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35580883/article/details/78318142">位运算实现整数绝对值</a><ol>
<li><a target="_blank" rel="noopener" href="http://www.cppblog.com/SmartPtr/archive/2007/07/05/27552.aspx">位运算实现浮点数绝对值</a></li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/cncnlg/article/details/42784739">位运算实现整数MaxMin</a></li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1802321">位运算求二进制内1的个数</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/lady_killer9/article/details/88067317">位运算代替乘除2运算</a></li>
<li><img src="https://pic.shaojiemike.top/img/20211001230813.png"></li>
<li>重新划分去除乘除，小代价是归约一下sigma<img src="https://pic.shaojiemike.top/img/20211001231708.png"></li>
</ol>
</li>
<li>混合精度(降低部分精度，降低计算量)</li>
<li>数据重用(不重复计算，降低计算量)</li>
</ol>
</li>
<li>访存密集<ol>
<li>vtune memory access分析，提高cpu访存带宽，优化2CPU通信<ol>
<li>store与load比stream慢很多<ol>
<li>原因store是将要写的数据load到缓存里，然后修改。而stream是直接写内存。</li>
</ol>
</li>
<li><img src="https://pic.shaojiemike.top/img/B(EWVUD74G@%60$H8%7BT)J5GBR.png"></li>
<li><img src="https://pic.shaojiemike.top/img/Z%606%5BUK5MOU@%60BCQBKRE9UJR.png"></li>
</ol>
</li>
<li>计算分块<ol>
<li>根据L1的大小设置块大小<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MiB = Mebibyte = 1024 KB,</span><br><span class="line">KiB = Kibibyte = 1024 Bytes,</span><br><span class="line">MB = Megabyte = 1,000 KB,</span><br><span class="line">KB = Kilobyte = 1,000 Bytes</span><br></pre></td></tr></table></figure></li>
<li>double 8 bytes</li>
</ol>
</li>
<li>改变数据结构优化访存(提高cache命中率)<ol>
<li>不合理的数据结构定义，导致数据存储不连续。通过改变数据结构，通过内存指针访问连续地址</li>
</ol>
</li>
<li>强制使用静态链接库glibc</li>
<li>访存局部性原理(提高cache命中率)<ol>
<li>c语言先行后列</li>
<li>循环拆分、循环重组</li>
</ol>
</li>
<li>根据cache空间，以及cache策略，进行cache数据预取，</li>
<li>计算融合(减少访存次数)<ol>
<li>计算结果及时使用，去除中间结果的存储访问时间</li>
<li>将多个循环整合为一个</li>
</ol>
</li>
<li>对于对同一个地址的连续读写依赖，采取pingpong-buffer来两个分治</li>
<li>申请空间<ol>
<li><img src="https://pic.shaojiemike.top/img/20210828120805.png"></li>
</ol>
</li>
</ol>
</li>
<li>负载均衡(并行划分)<ol>
<li><img src="https://pic.shaojiemike.top/img/20210828105142.png"></li>
<li>对不同的数据量进行不同的策略，比如数据特别少，单cpu反而最快。</li>
<li>二维的图，无脑按照y划分就行。<ol>
<li>合并的时候，按照并查集（1.维护顺序 2.有代表性）</li>
</ol>
</li>
<li>针对数据规模，是否要并行。</li>
</ol>
</li>
<li>IO密集<ol>
<li>并行读取</li>
<li>内存硬盘化</li>
</ol>
</li>
<li>通讯密集<ol>
<li>IB网通信</li>
<li>改变通信结构</li>
<li>打包发送</li>
<li>希尔伯特划分（一维二维）</li>
</ol>
</li>
<li>编译选项<ol>
<li>O3优化,ipo过程优化,fp-model fast&#x3D;2加速浮点计算</li>
</ol>
</li>
<li>其他未分类<ol>
<li><img src="https://pic.shaojiemike.top/img/20210828120944.png"></li>
</ol>
</li>
</ol>
<h2 id="还没来得及看的优化"><a href="#还没来得及看的优化" class="headerlink" title="还没来得及看的优化"></a>还没来得及看的优化</h2><p>Software optimization resources ：<a target="_blank" rel="noopener" href="https://www.agner.org/optimize/">https://www.agner.org/optimize/</a></p>
<h2 id="AMD-罗马米兰平台优化"><a href="#AMD-罗马米兰平台优化" class="headerlink" title="AMD 罗马米兰平台优化"></a>AMD 罗马米兰平台优化</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19q4y197uX?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV19q4y197uX?spm_id_from=333.999.0.0</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vU4y1u7nL?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1vU4y1u7nL?spm_id_from=333.999.0.0</a><br><img src="https://pic.shaojiemike.top/img/20211026172536.png"><br><img src="https://pic.shaojiemike.top/img/20211026172201.png"><br><img src="https://pic.shaojiemike.top/img/20211026172231.png"><br><img src="https://pic.shaojiemike.top/img/20211026172128.png"></p>
<h2 id="常见的参数"><a href="#常见的参数" class="headerlink" title="常见的参数"></a>常见的参数</h2><p>2 sockets cpu latency : 50&#x2F;60</p>
<p>core memory bandwidth ：20GB&#x2F;s</p>
<h2 id="样例图片"><a href="#样例图片" class="headerlink" title="样例图片"></a>样例图片</h2><ol>
<li>不合理数据结构,和合理的数据结构<br><img src="https://pic.shaojiemike.top/img/$%7DL9FL9$GN)0F1X@WZW~J9U.png"><br><img src="https://pic.shaojiemike.top/img/23.png"></li>
<li>编译选项<br><img src="https://pic.shaojiemike.top/img/2333.png"><br><img src="https://pic.shaojiemike.top/img/1232333.png"></li>
</ol>
<h2 id="性能-功耗-与容错"><a href="#性能-功耗-与容错" class="headerlink" title="性能 功耗 与容错"></a>性能 功耗 与容错</h2><p>陈子忠 教授( 美国加州大学河滨分校 ) 230616报告</p>
<ol>
<li>多核的出现，单核能耗与频率三次方成正比，难以压住散热</li>
<li>在已知调度时间复杂度估计的情况下，降低频率DVFS延长执行能大幅度节约功耗。同理提升频率也行。</li>
<li>纠错：检查点机制，中间验证算法复杂度比计算算法复杂度低。</li>
</ol>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p><a target="_blank" rel="noopener" href="https://johnysswlab.com/">https://johnysswlab.com/</a></p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>太糊了<br><img src="https://pic.shaojiemike.top/img/20211001235425.png"></p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>因为参加2021 IPCC,观看B站视频，学到很多特地总结一下</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Dv411p7ay">https://www.bilibili.com/video/BV1Dv411p7ay</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-14T16:00:00.000Z" title="6/14/2023, 4:00:00 PM">2023-06-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.268Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/math/">math</a></span><span class="level-item">an hour read (About 8867 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/14/Work/math/probabilityTheory/">Probability Theory</a></p><div class="content"><h2 id="常用离散分布"><a href="#常用离散分布" class="headerlink" title="常用离散分布"></a>常用离散分布</h2><h3 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h3><p>二项分布（Binomial Distribution）是概率论中常见的离散概率分布，用于描述在n重伯努利实验中成功事件发生的次数。</p>
<p>n重伯努利实验是指进行了n次独立重复的伯努利试验。伯努利试验是一种只有两个可能结果的随机试验，通常称为成功（S）和失败（F）。每次试验成功的概率为p，失败的概率为1-p。特点是每次试验只有两种可能的结果，通常表示为成功和失败。</p>
<p>在二项分布中，我们关注的是在<strong>n次独立重复试验</strong>中成功事件发生的次数（记为X），其中每次试验成功的概率为p。二项分布的概率质量函数可以表示为：</p>
<p>$$P(X &#x3D; k) &#x3D; C(n, k) * p^k * (1-p)^{n-k}$$</p>
<p>P(X &#x3D; k)表示在n次试验中成功事件发生k次的概率。</p>
<h3 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h3><p>泊松分布（Poisson Distribution）是一种离散概率分布，用于描述在一段<strong>固定时间或空间内随机事件发生的次数</strong>。它的特点是事件发生的次数是离散的且无限可数，且事件发生的概率在整个时间或空间内是恒定的。</p>
<p>在泊松分布中，我们关注的是在给定的时间或空间内，事件发生的次数（记为X）。泊松分布的概率质量函数可以表示为：</p>
<p>$$P(X &#x3D; k) &#x3D; (λ^k * e^{-λ}) &#x2F; k!$$</p>
<p>其中，P(X &#x3D; k)表示在给定时间或空间内事件发生k次的概率。λ是事件发生的平均次数，即单位时间或空间内事件发生的平均频率。e是自然对数的底数，k!表示k的阶乘。</p>
<p>泊松分布常用于描述稀有事件的发生情况，例如单位时间内电话呼叫次数、单位面积内放射性粒子的撞击次数等。通过泊松分布，我们可以计算在给定平均发生率下，事件发生特定次数的概率，从而进行概率推断和预测。</p>
<h3 id="超几何分布"><a href="#超几何分布" class="headerlink" title="超几何分布"></a>超几何分布</h3><p>超几何分布（Hypergeometric Distribution）是一种离散概率分布，用于描述从<strong>有限总体中进行抽样时，抽取的样本中具有某种特征的个数的分布</strong>。它与二项分布相似，但有一些关键区别。</p>
<p>在超几何分布中，我们考虑从总体中抽取固定大小的样本，总体中有M个具有某种特征的元素和N-M个没有该特征的元素。我们关注的是在抽样过程中，样本中具有该特征的元素的个数（记为X）。</p>
<p>超几何分布的概率质量函数可以表示为：</p>
<p>$$P(X &#x3D; k) &#x3D; (C(M, k) * C(N-M, n-k)) &#x2F; C(N, n)$$</p>
<p>其中，P(X &#x3D; k)表示样本中具有该特征的元素个数为k的概率。C(M, k)表示在M个具有该特征的元素中选择k个元素的组合数，C(N-M, n-k)表示在N-M个没有该特征的元素中选择n-k个元素的组合数，C(N, n)表示在总体中选择n个元素的组合数。</p>
<p>超几何分布常用于从有限总体中进行抽样，并研究样本中某种特征的出现情况。它的特点是，随着抽样数量的增加，成功事件的概率不再是恒定的，因为每次抽样都会影响总体中元素的可选性。通过超几何分布，我们可以计算在给定总体和抽样大小的情况下，样本中具有该特征的元素个数的概率分布。</p>
<h3 id="几何分布"><a href="#几何分布" class="headerlink" title="几何分布"></a>几何分布</h3><p>几何分布描述的是在独立重复试验中，<strong>第一次成功事件A发生所需的试验次数</strong>。每次试验都有成功（S）和失败（F）两种可能结果，且成功概率为p。几何分布的概率质量函数可以表示为：</p>
<p>$$P(X &#x3D; k) &#x3D; (1 - p)^{k-1} * p$$</p>
<p>其中，P(X &#x3D; k)表示第一次成功事件发生在第k次试验的概率。</p>
<h3 id="负二项分布（帕斯卡分布"><a href="#负二项分布（帕斯卡分布" class="headerlink" title="负二项分布（帕斯卡分布)"></a>负二项分布（帕斯卡分布)</h3><p>负二项分布描述的是在独立重复试验中，成功事件发生r次所需的试验次数。每次试验都有成功（S）和失败（F）两种可能结果，且成功概率为p。负二项分布的概率质量函数可以表示为：</p>
<p>$$P(X &#x3D; k) &#x3D; C(k-1, r-1) * (1 - p)^{k-r} * p^r$$</p>
<p>其中，P(X &#x3D; k)表示成功事件发生r次在第k次试验的概率。C(k-1, r-1)表示组合数，表示在前k-1次试验中取r-1次成功的组合数。</p>
<h2 id="常用连续分布"><a href="#常用连续分布" class="headerlink" title="常用连续分布"></a>常用连续分布</h2><p>常用密度函数表示</p>
<h3 id="正态分布（高斯分布）"><a href="#正态分布（高斯分布）" class="headerlink" title="正态分布（高斯分布）"></a>正态分布（高斯分布）</h3><p>正态分布，也称为高斯分布（Gaussian Distribution），是统计学中最重要且广泛应用的连续概率分布之一。</p>
<p>正态分布的概率密度函数（Probability Density Function, PDF）可以用以下公式表示：</p>
<p>$$f(x) &#x3D; (1 &#x2F; (σ * \sqrt{2π})) * exp(-(x-μ)^2 &#x2F; (2σ^2))$$</p>
<p>其中，f(x)表示随机变量X的概率密度函数。μ表示分布的均值（期望值），σ表示标准差，π表示圆周率，exp表示自然对数的指数函数。</p>
<p>正态分布具有以下特点：</p>
<ul>
<li>对称性：正态分布的概率密度函数是关于均值对称的，呈现出钟形曲线的形状。</li>
<li>唯一性：正态分布由其均值和标准差唯一确定。</li>
<li>中心极限定理：许多随机现象的总体分布趋向于正态分布，尤其在样本量足够大时。</li>
<li>68-95-99.7规则：在正态分布中，约有68%的数据落在均值的一个标准差范围内，约有95%的数据落在两个标准差范围内，约有99.7%的数据落在三个标准差范围内。</li>
</ul>
<h3 id="均匀分布"><a href="#均匀分布" class="headerlink" title="均匀分布"></a>均匀分布</h3><p>均匀分布（Uniform Distribution）是一种简单而常见的概率分布，它在指定的区间内的取值具有相等的概率。在均匀分布中，每个可能的取值都具有相同的概率密度。</p>
<p>均匀分布的概率密度函数（Probability Density Function, PDF）可以用以下公式表示：</p>
<p>f(x) &#x3D; 1 &#x2F; (b - a)，如果 <code>a ≤ x ≤ b</code><br>f(x) &#x3D; 0，其他情况</p>
<p>其中，f(x)表示随机变量X的概率密度函数。a和b分别表示分布的下限和上限。</p>
<h3 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h3><p>指数分布（Exponential Distribution）是一种连续概率分布，常用于描述事件发生的时间间隔。它是一种特殊的连续随机变量的分布，具有单峰、右偏的特点。</p>
<p>指数分布的概率密度函数（Probability Density Function, PDF）可以用以下公式表示：</p>
<p><code>f(x) = λ * exp(-λx)</code>，如果 x ≥ 0<br><code>f(x) = 0</code>，其他情况</p>
<p>其中，f(x)表示随机变量X的概率密度函数，λ是分布的参数，被称为率参数。</p>
<p>指数分布具有以下特点：</p>
<ul>
<li>单峰性：指数分布的概率密度函数是单峰的，峰值出现在0点，随着时间的增长逐渐减小。</li>
<li>无记忆性：指数分布具有无记忆性的特性，即给定已经等待了一段时间，再等待更多的时间的概率与刚开始等待的概率是相同的。这是指数分布与其他分布不同的重要特点。</li>
</ul>
<p>指数分布在实际应用中具有广泛的应用。例如，它常用于描述随机事件的<strong>到达时间、服务时间、寿命</strong>等。在可靠性工程和排队论中，指数分布经常用于模拟和分析各种事件的发生和持续时间。</p>
<h3 id="伽马分布"><a href="#伽马分布" class="headerlink" title="伽马分布"></a>伽马分布</h3><p>伽马分布（Gamma Distribution）是一种连续概率分布，它常用于描述正数随机变量的分布，如事件的等待时间、寿命等。伽马分布是指数分布的推广形式，它可以具有更灵活的形状。</p>
<p>伽马分布的概率密度函数（Probability Density Function, PDF）可以用以下公式表示：</p>
<p>$$ f(x) &#x3D; (1 &#x2F; (Γ(k) * θ^k)) * x^{k-1} * exp(-x&#x2F;θ)$$，如果 x ≥ 0<br>0，其他情况</p>
<p>其中，f(x)表示随机变量X的概率密度函数，k和θ是分布的参数，k被称为形状参数，θ被称为尺度参数，<code>Γ(k)</code>表示伽马函数（Gamma function）。</p>
<p>伽马分布具有以下特点：</p>
<ul>
<li>随机变量为正数：伽马分布的取值范围为正数，不包括0及负数。</li>
<li>形状灵活：通过调节形状参数k，可以改变伽马分布的形状。当k为整数时，伽马分布退化为Erlang分布。</li>
<li>可以用于建模持续时间：伽马分布常用于建模持续时间，如等待时间、寿命等，特别是当事件的发生率不是恒定的情况下。</li>
</ul>
<p>伽马分布在实际应用中具有广泛的应用。例如，在可靠性工程中，它常用于描述零部件的寿命和故障时间。在金融领域，伽马分布被用于模拟和分析资产价格的变动。</p>
<h3 id="贝塔分布"><a href="#贝塔分布" class="headerlink" title="贝塔分布"></a>贝塔分布</h3><p>贝塔分布（Beta Distribution）是一种连续概率分布，它定义在<strong>区间[0, 1]上</strong>，并且常用于描述概率分布、比例、概率参数等随机变量的分布。</p>
<p>贝塔分布的概率密度函数（Probability Density Function, PDF）可以用以下公式表示：</p>
<p>$$f(x) &#x3D; (x^{α-1} * (1-x)^{β-1}) &#x2F; B(α, β)$$，如果 0 ≤ x ≤ 1<br>0，其他情况</p>
<p>其中，f(x)表示随机变量X的概率密度函数，α和β是分布的两个形状参数，<code>B(α, β)</code>表示贝塔函数（Beta function）。</p>
<p>贝塔分布具有以下特点：</p>
<ul>
<li>取值范围：贝塔分布的取值范围为区间[0, 1]，对应于概率或比例的取值范围。</li>
<li>形状灵活：通过调节形状参数α和β的值，可以改变贝塔分布的形状，使其适应不同的数据分布。</li>
<li>可以用于建模随机概率：贝塔分布常用于建模随机概率、比例等，例如二项分布中的成功概率、伯努利分布中的参数等。</li>
</ul>
<p>贝塔分布在实际应用中具有广泛的应用。它常被用于贝叶斯统计推断、可靠性分析、A&#x2F;B测试、市场份额预测等领域。此外，贝塔分布还与其他概率分布有着密切的关联，例如伯努利分布、二项分布和贝叶斯推断中的共轭先验分布等。</p>
<h2 id="三大抽样分布"><a href="#三大抽样分布" class="headerlink" title="三大抽样分布"></a>三大抽样分布</h2><ul>
<li>卡方分布（Chi-Square Distribution）：卡方分布是一种连续概率分布，用于描述<strong>随机变量的平方和</strong>的分布。</li>
<li>F分布是一种连续概率分布，用于描述两个独立正态分布<strong>方差比</strong>的分布。</li>
<li>t分布（t-Distribution）：t分布是一种连续概率分布，用于描述小样本情况下样本均值的分布。与正态分布相比，t分布的尖峰更高、尾部更厚，适用于<strong>样本容量较小</strong>或总体方差未知的情况。</li>
</ul>
<h2 id="随机过程"><a href="#随机过程" class="headerlink" title="随机过程"></a>随机过程</h2><h3 id="泊松过程"><a href="#泊松过程" class="headerlink" title="泊松过程"></a>泊松过程</h3><p>泊松过程（Poisson Process）是一种随机过程，用于描述在固定时间间隔内随机事件发生的模式。泊松过程的关键特征是事件在时间上的独立性和固定的平均发生率。它可以用于建模各种事件的发生，例如电话呼叫到达、事故发生、信号传输等。</p>
<h3 id="马尔科夫"><a href="#马尔科夫" class="headerlink" title="马尔科夫"></a>马尔科夫</h3><h4 id="马尔可夫性质"><a href="#马尔可夫性质" class="headerlink" title="马尔可夫性质"></a>马尔可夫性质</h4><p>当一个随机过程其<strong>未来</strong>状态的条件概率分布仅依赖于<strong>当前</strong>状态；换句话说，在给定现在状态时，它与过去状态（即该过程的历史路径）是条件独立的，那么此随机过程即具有马尔可夫性质。</p>
<h4 id="马尔可夫链、过程"><a href="#马尔可夫链、过程" class="headerlink" title="马尔可夫链、过程"></a>马尔可夫链、过程</h4><p>马尔可夫链（Markov Chain, MC）是概率论和数理统计中具有马尔可夫性质（Markov property）且存在于离散的指数集（index set）和状态空间（state space）内的随机过程（stochastic process）</p>
<p>适用于连续指数集的马尔可夫链被称为马尔可夫过程（Markov process）</p>
<h4 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h4><p>马尔可夫决策过程（Markov Decision Process, MDP）是序贯决策（sequential decision）的数学模型，用于在系统状态具有马尔可夫性质的环境中模拟智能体可实现的随机性策略与回报<img src="https://pic.shaojiemike.top/img/20220130201230.png"></p>
<h3 id="平稳过程"><a href="#平稳过程" class="headerlink" title="平稳过程"></a>平稳过程</h3><p>平稳过程（Stationary Process）是一种随机过程，其统计特性在时间上保持不变。具体而言，一个平稳过程在不同时间段内具有相同的概率分布和统计特性，如均值、方差和自协方差。</p>
<h3 id="布朗运动"><a href="#布朗运动" class="headerlink" title="布朗运动"></a>布朗运动</h3><p>布朗运动（Brownian Motion），也被称为维纳过程（Wiener Process），是一种随机过程，以英国生物学家罗伯特·布朗（Robert Brown）的名字命名。布朗运动是一种连续时间、连续空间的随机运动，它在各个时间点上的位置是随机的。</p>
<p>布朗运动的特点包括：</p>
<ul>
<li>随机性：布朗运动的运动路径是随机的，不可预测的。在每个时间点上，粒子的位置随机地变化。</li>
<li>连续性：布朗运动在连续的时间和空间上进行。粒子在任意瞬时的位置是连续变化的。</li>
<li>马尔可夫性：布朗运动满足马尔可夫性质，即未来的运动只与当前的位置有关，而与过去的运动路径无关。</li>
<li>独立增量：布朗运动的位置变化是具有独立增量的，即在不同时间段上的位置变化是相互独立的。</li>
</ul>
<p>布朗运动在物理学、金融学、生物学等领域具有广泛的应用。它可以用来描述微粒在流体中的扩散、金融市场中的价格变动、细胞内分子的运动等随机现象。布朗运动的数学描述采用随机微分方程，其中包括随机增量项，用来表示随机性和不确定性。</p>
<h3 id="鞅过程"><a href="#鞅过程" class="headerlink" title="鞅过程"></a>鞅过程</h3><p>鞅过程（Martingale Process）是一种随机过程，它在概率论和数学金融领域中具有重要的应用。鞅过程是一种随机变量序列，它满足一定的条件，其中最重要的性质是<strong>条件期望的无偏性</strong>。</p>
<p>具体而言，设{X(t), t ≥ 0}是一个随机过程，定义在一个概率空间上，关于时间t的随机变量。如果对于任意的s ≤ t，条件期望E[X(t) | X(s)]等于X(s)，即 <code>E[X(t) | X(s)] = X(s)</code>，那么这个随机过程被称为鞅过程。</p>
<p>换句话说，鞅过程在任意时刻的当前值的条件期望等于过去时刻的值，表明鞅过程在平均意义上不随时间变化而漂移。</p>
<p>一个典型的实际案例是赌博游戏中的赌徒之行。</p>
<p>假设有一个赌徒在每轮游戏中抛掷硬币，正面朝上赢得1单位的奖励，反面朝上输掉1单位的赌注。我们可以用一个鞅过程来描述赌徒的资金变化。假设赌徒的初始资金为0单位，并且在每轮游戏中抛硬币的结果是一个独立的随机事件。赌徒的资金变化可以表示为一个鞅过程<code>&#123;X(t), t ≥ 0&#125;</code>，其中X(t)表示赌徒在时间t时的资金。</p>
<p>在这个例子中，条件期望的无偏性意味着在任意时刻t，赌徒的当前资金的条件期望等于过去时刻的资金，即 <code>E[X(t) | X(s)] = X(s)</code>，其中s ≤ t。<br>这意味着赌徒在每轮游戏中没有系统性地赢或输。无论他之前的赢利或亏损情况如何，当前的资金预期值等于他之前的资金。</p>
<p>鞅过程在金融市场建模、随机控制理论、概率论等领域有广泛的应用。它在金融中可以用来描述资产价格的动态演化、期权定价、风险度量等。在概率论中，鞅过程是一类重要的随机过程，其具有丰富的性质和数学结构，被广泛研究和应用。</p>
<h2 id="大数定理，中心极限定理"><a href="#大数定理，中心极限定理" class="headerlink" title="大数定理，中心极限定理"></a>大数定理，中心极限定理</h2><h3 id="大数定理"><a href="#大数定理" class="headerlink" title="大数定理"></a>大数定理</h3><p>大数定理（Law of Large Numbers）是概率论中的一条重要定理，描述了随机变量序列的均值的收敛性质。它指出，当随机变量的样本容量足够大时，样本均值将接近于随机变量的期望值。</p>
<h3 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h3><p>中心极限定理（Central Limit Theorem）是概率论和统计学中的重要结果之一。它描述了在一定条件下，当独立随机变量的数量足够大时，它们的平均值的分布将近似于正态分布。</p>
<p>中心极限定理的主要内容如下：</p>
<p>假设有n个独立随机变量X1, X2, …, Xn，它们具有相同的分布和参数。这些随机变量的和S_n &#x3D; X1 + X2 + … + Xn的分布在n趋近于无穷大时，以及适当的标准化后，将近似于正态分布。</p>
<p>具体而言，当n足够大时，S_n的近似分布可以用正态分布来描述。</p>
<h2 id="参数估计-概率分布模型"><a href="#参数估计-概率分布模型" class="headerlink" title="参数估计(概率分布模型)"></a>参数估计(概率分布模型)</h2><p>在参数估计中，确实需要事先假设或确定一个概率分布模型(注意不是确定的模型，不然可以根据结果直接算出参数)。参数估计的前提是我们假设观测数据来自于某个特定的概率分布，而我们的目标是估计这个概率分布中的未知参数。</p>
<p>具体来说，参数估计的过程通常包括以下步骤：</p>
<ul>
<li>假设概率分布模型：我们需要根据问题的特点和领域知识，假设观测数据符合某个特定的概率分布模型，例如正态分布、泊松分布、伽马分布等。这个假设是基于对问题的理解和经验的。</li>
<li>确定参数：在所假设的概率分布模型中，可能存在一个或多个未知参数，我们需要明确这些参数，并确定我们想要估计的参数。</li>
<li>收集观测数据：根据实际情况，我们收集一组观测数据，作为对概率分布中参数的估计依据。</li>
<li>构建估计方法：根据所选的概率分布模型和参数，我们构建相应的估计方法，例如最大似然估计、矩估计等。</li>
<li>估计参数：利用观测数据和估计方法，计算出对未知参数的估计值。</li>
</ul>
<p>需要注意的是，参数估计的准确性和可靠性依赖于所假设的概率分布模型的正确性和数据的充分性。如果所假设的概率分布模型与实际情况不符，或者观测数据过少或存在较大的噪声，估计结果可能会出现偏差或不准确的情况。</p>
<p>因此，在参数估计之前，我们需要对问题进行合理的假设和模型选择，并在数据收集和估计方法的过程中考虑到模型假设的合理性和数据的质量。</p>
<h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><p>贝叶斯定理是概率论中的一个基本定理，描述了在观测到新的证据（观测数据）后，如何更新对某个事件的概率估计。</p>
<p>假设有两个事件 A 和 B，其中事件 A 是我们要推断或估计的事件，而事件 B 是观测到的证据。贝叶斯定理表述如下：</p>
<p><code>P(A|B) = (P(B|A) * P(A)) / P(B)</code></p>
<p>其中：</p>
<ul>
<li><code>P(A|B)</code> 是在观测到事件 B 后事件 A 发生的条件概率，也称为后验概率。</li>
<li><code>P(B|A)</code> 是在事件 A 发生的条件下观测到事件 B 的概率，也称为似然函数。</li>
<li><code>P(A)</code> 是事件 A 的先验概率，即在观测到事件 B 之前对事件 A 发生的估计。</li>
<li><code>P(B)</code> 是事件 B 的边际概率，即观测到事件 B 的概率。</li>
</ul>
<p>贝叶斯定理的核心思想是通过观测到的证据（事件 B），更新对事件 A 的概率估计。它将先验概率和似然函数结合起来，得到后验概率。具体而言，贝叶斯定理可以用于根据已知信息更新模型参数、进行推断、进行分类等。</p>
<p>贝叶斯定理在贝叶斯统计学中具有重要的应用，它允许我们利用已有知识（先验）和新的证据（似然函数）来更新对未知事件的估计（后验）。通过不断地更新先验概率，我们可以根据新的观测数据获得更准确和可靠的后验概率估计。</p>
<h3 id="先验分布-后验概率分布"><a href="#先验分布-后验概率分布" class="headerlink" title="先验分布 后验概率分布"></a>先验分布 后验概率分布</h3><p>在贝叶斯统计中，先验分布和后验概率分布是两个关键概念，用于描述我们对参数的初始信念和通过观测数据更新后的信念。</p>
<ul>
<li>先验分布（Prior Distribution）：先验分布是在观测数据之前对参数的分布做出的<strong>假设或先验信念</strong>。它反映了我们在观测数据之前对参数可能取值的主观或客观的认识。先验分布通常用一个概率分布函数来表示，例如贝塔分布、高斯分布等。先验分布可以看作是参数的<strong>初始猜测</strong>，它对参数的可能取值进行了一定的限制或权重。</li>
<li>后验概率分布（Posterior Probability Distribution）：后验概率分布是在观测到数据后，通过贝叶斯定理将先验分布与似然函数结合起来得到的参数分布。它表示了在考虑观测数据之后，对参数取值的更新后的概率分布。后验概率分布结合了先验信息和观测数据的信息，提供了对参数的更准确估计，并反映了参数的不确定性程度。</li>
</ul>
<p>先验分布和后验概率分布之间的关系可以用贝叶斯定理来表示：</p>
<p><code>后验概率分布 ∝ 先验分布 × 似然函数</code></p>
<p>其中，似然函数描述了观测数据出现的可能性。通过将先验分布与观测数据的似然函数相乘，并进行适当的归一化，可以得到后验概率分布。</p>
<p>贝叶斯统计的核心思想是通过不断地更新先验分布，利用观测数据提供的信息，得到后验概率分布，并在此基础上做出推断和决策。先验分布提供了先验知识和信念，而后验概率分布则是在<strong>考虑观测数据后对参数的更新和修正</strong>。</p>
<h3 id="点估计与无偏性"><a href="#点估计与无偏性" class="headerlink" title="点估计与无偏性"></a>点估计与无偏性</h3><p>点估计（Point Estimation）是参数估计的一种方法，它通过使用样本数据来估计总体参数的具体值。点估计的目标是找到一个单一的估计值，作为对未知参数的最佳猜测。</p>
<p>无偏性是点估计的性质之一。一个无偏估计是指在重复抽样的情况下，<strong>估计值的期望</strong>等于被估计参数的真实值。换句话说，如果一个估计值的期望与真实参数值相等，则该估计值是无偏的。</p>
<h3 id="矩估计"><a href="#矩估计" class="headerlink" title="矩估计"></a>矩估计</h3><ul>
<li>使用使用样本矩来逼近&#x2F;替代总体矩，从而得到参数的估计值。<ul>
<li>样本矩（Sample Moments）：样本矩是根据从总体中抽取的样本数据计算得出的统计量。常见的样本矩包括样本均值、样本方差、样本偏度、样本峰度等。</li>
</ul>
</li>
</ul>
<h3 id="最大似然估计与EM算法"><a href="#最大似然估计与EM算法" class="headerlink" title="最大似然估计与EM算法"></a>最大似然估计与EM算法</h3><ul>
<li>最大似然估计(maximum likelihood estimation，MLE)，或者最大对数似然：<ul>
<li>简单来说：估计的是已知概率分布模型的参数值，输入是测试的结果&#x2F;样本。简单来说，模型已定，参数未知下，用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！</li>
</ul>
</li>
</ul>
<p>最大似然估计的基本思想是，在给定观测数据的情况下，寻找使得观测数据的联合概率密度函数（或概率质量函数）最大化的参数值。具体步骤包括以下几个步骤：</p>
<ul>
<li>建立概率模型：首先需要确定一个适当的概率模型，假设观测数据满足某个概率分布，如正态分布、泊松分布等。</li>
<li>构建似然函数：根据概率模型，将观测数据的联合概率密度函数（或概率质量函数）表示为参数的函数，即似然函数。似然函数描述了在给定参数值的情况下，观测数据出现的可能性。</li>
<li>寻找最大似然估计：通过优化方法（如求导、迭代算法等），找到使得似然函数最大化的参数值。最大似然估计的目标是寻找最可能产生观测数据的参数值，使得观测数据的出现概率最大化。</li>
</ul>
<p>最大似然估计具有一些良好的性质，例如在大样本下，最大似然估计的估计值具有<strong>渐近正态分布</strong>，且具有一致性和渐进有效性等特性。最大似然估计在统计学和机器学习等领域中广泛应用，用于估计参数、构建模型和进行推断。</p>
<ul>
<li>EM算法（Expectation-Maximization Algorithm）是一种迭代优化算法，用于在存在隐变量或缺失数据的统计模型中进行参数估计。它通过交替进行两个步骤：E步（Expectation Step）和M步（Maximization Step），以最大化似然函数或完成参数的最大似然估计。</li>
</ul>
<p>EM算法的基本思想是通过引入隐变量，将含有缺失数据的问题转化为完全数据的问题。具体步骤如下：</p>
<ul>
<li>初始化参数：首先需要对模型的参数进行初始化。</li>
<li>E步（Expectation Step）：在E步中，根据当前参数的估计值，计算隐变量的后验概率（或期望），即给定观测数据下隐变量的分布。这一步利用当前参数的估计值进行”填补”缺失数据或估计隐变量的取值。</li>
<li>M步（Maximization Step）：在M步中，根据E步得到的隐变量后验概率，重新估计模型的参数。这一步通过最大化完全数据的对数似然函数来更新参数的估计值。</li>
<li>迭代更新：重复进行E步和M步，直到参数的估计值收敛或满足停止准则。</li>
</ul>
<p>EM算法通过迭代的方式逐步优化参数的估计值，使得在每次迭代中似然函数都得到增大，从而逐渐逼近最优参数值。由于每次迭代中的E步和M步都可以分别求解，因此EM算法在理论上保证了在每一步都能得到似然函数的增加。然而，EM算法并不能保证收敛到全局最优解，可能陷入局部最优解。</p>
<p>EM算法在许多统计学和机器学习问题中都有广泛的应用，特别是在存在隐变量的概率模型、混合模型、高斯混合模型等领域中。它为解决这些问题提供了一种有效的参数估计方法。</p>
<h3 id="最小方差无偏估计"><a href="#最小方差无偏估计" class="headerlink" title="最小方差无偏估计"></a>最小方差无偏估计</h3><ul>
<li>对于小样本， 无偏估计使用<strong>最小方差</strong>，对于有偏估计常使用<strong>均方误差</strong>。<ul>
<li>有偏估计是指在统计学中，估计量的期望值不等于被估计参数的真实值。换句话说，有偏估计会在估计过程中引入一定的系统性偏差。</li>
<li>我的理解, 你设计的模型，就不是真实的(也无法保证)，自然就从根本上不完全准确，有系统性偏差，所以常用均方误差。</li>
</ul>
</li>
</ul>
<h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>频率学派和贝叶斯学派是统计学中两种不同的观点或方法论。</p>
<p>频率学派（Frequentist Approach）注重使用频率或概率的概念进行推断和估计。在频率学派中，参数被视为固定但未知的，通过基于样本数据的统计量来推断参数的值。频率学派强调利用大量的重复抽样来研究统计性质，并通过估计量的偏差、方差和置信区间等指标来评估估计的准确性和可靠性。</p>
<p>贝叶斯学派（Bayesian Approach）则采用贝叶斯定理和概率论的观点来进行推断和估计。在贝叶斯学派中，参数被视为随机变量，其先验分布和样本数据的条件下的后验分布共同决定了参数的估计。贝叶斯学派注重将<strong>先验知识或信念</strong>结合到推断过程中，并使用后验分布来提供关于参数的概率分布以及置信区间等信息。</p>
<p>贝叶斯估计是贝叶斯学派中一种参数估计的方法。它利用贝叶斯定理计算参数的后验分布，并将后验分布作为参数的估计。贝叶斯估计不仅考虑了样本数据的信息，还结合了<strong>先验知识或信念</strong>，因此可以提供更全面和灵活的估计结果。贝叶斯估计还可以通过调整先验分布的参数或选择不同的先验分布来灵活地处理不同的问题和背景。</p>
<p>需要注意的是，频率学派和贝叶斯学派并不是相互排斥的，它们是统计学中不同的方法论和观点，各自有其适用的领域和优势。在实际应用中，可以根据问题的特点、数据的性质以及研究目的来选择适合的学派和方法。</p>
<h3 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h3><p>区间估计是统计学中一种参数估计的方法，用于估计未知参数的范围或区间。与点估计不同，区间估计提供了一个范围，该范围内有一定的置信度（置信水平）包含了真实参数值。</p>
<p>区间估计的基本思想是通过样本数据来构建一个区间，该区间涵盖了真实参数值的可能范围。在频率学派中，常用的区间估计方法包括置信区间。置信区间是基于样本数据计算出来的一个区间，其具体形式为”估计值 ± 误差”，其中误差由抽样误差和估计误差组成。</p>
<p>置信区间的置信水平表示该区间在重复抽样中包含真实参数值的概率。例如，95%的置信水平意味着在多次重复抽样中，有95%的置信区间会包含真实参数值。</p>
<p>区间估计的优势在于提供了对未知参数范围的估计，并提供了对估计结果的不确定性的量化。它能够更全面地反映估计的可靠性，并且可以与其他区间进行比较，进行统计推断和假设检验等。</p>
<p>需要注意的是，区间估计并不提供关于真实参数值的具体点估计，而是提供了一个范围。不同的置信水平会得到不同宽度的区间，较高的置信水平通常会导致较宽的区间。在应用中，选择适当的置信水平需要权衡估计的准确性和置信区间的宽度。</p>
<h2 id="方差回归与回归分析"><a href="#方差回归与回归分析" class="headerlink" title="方差回归与回归分析"></a>方差回归与回归分析</h2><h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无

</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-13T16:00:00.000Z" title="6/13/2023, 4:00:00 PM">2023-06-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.256Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">39 minutes read (About 5894 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/13/Work/Artificial%20Intelligence/framework/pytorch/">Pytorch</a></p><div class="content"><p>（本人是rookie，纯小白~</p>
<h2 id="什么是-PyTorch"><a href="#什么是-PyTorch" class="headerlink" title="什么是 PyTorch?"></a>什么是 PyTorch?</h2><p>PyTorch 是一个基于 Python 的科学计算包，主要定位两类人群：</p>
<ol>
<li>NumPy 的替代品，可以利用 GPU 的性能进行计算。</li>
<li>深度学习研究平台拥有足够的灵活性和速度</li>
</ol>
<h2 id="Pytorch简介"><a href="#Pytorch简介" class="headerlink" title="Pytorch简介"></a>Pytorch简介</h2><p>要介绍PyTorch之前，不得不说一下Torch。</p>
<p>Torch是一个有大量机器学习算法支持的科学计算框架，是一个与Numpy类似的张量（Tensor） 操作库，其特点是特别灵活，但因其采用了小众的编程语言是Lua，所以流行度不高，这也就有了PyTorch的出现。所以其实Torch是 PyTorch的前身，它们的底层语言相同，只是使用了不同的上层包装语言。</p>
<p>PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。它主要由Facebookd的人工智能小组开发，不仅能够 实现强大的GPU加速，同时还支持<strong>动态神经网络</strong>，这一点是现在很多主流框架如TensorFlow都不支持的。 PyTorch提供了两个高级功能：</p>
<ul>
<li>具有强大的GPU加速的张量计算（如Numpy）</li>
<li>包含自动求导系统的深度神经网络</li>
</ul>
<p>TensorFlow和Caffe都是命令式的编程语言，而且是静态的，首先必须构建一个神经网络，然后一次又一次使用相同的结构，如果想要改变网络的结构，就必须从头开始。</p>
<p>但是对于PyTorch，通过反向求导技术，可以让你零延迟地任意<strong>改变神经网络</strong>的行为，而且其实现速度 快。正是这一灵活性是PyTorch对比TensorFlow的最大优势。</p>
<p>所以，总结一下PyTorch的优点：</p>
<ul>
<li>支持GPU</li>
<li>灵活，支持动态神经网络</li>
<li>底层代码易于理解</li>
<li>命令式体验</li>
<li>自定义扩展</li>
</ul>
<p>当然，现今任何一个深度学习框架都有其缺点，PyTorch也不例外，对比TensorFlow，其全面性处于劣势，目前PyTorch</p>
<ul>
<li>还不支持快速傅里 叶、沿维翻转张量和检查无穷与非数值张量；</li>
<li>针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；</li>
<li>其次因为这个框 架较新，使得他的社区没有那么强大，在文档方面其C库大多数没有文档。</li>
</ul>
<h2 id="安装和使用"><a href="#安装和使用" class="headerlink" title="安装和使用"></a>安装和使用</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a target="_blank" rel="noopener" href="https://pytorch.org/">https://pytorch.org/</a> 选择对应cuda版本下载即可</p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import print_function</span><br><span class="line">import torch</span><br></pre></td></tr></table></figure>

<h2 id="数据类型和操作"><a href="#数据类型和操作" class="headerlink" title="数据类型和操作"></a>数据类型和操作</h2><h3 id="Tensor-张量"><a href="#Tensor-张量" class="headerlink" title="Tensor(张量)"></a>Tensor(张量)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个5x3矩阵，不初始化。基本是0，或者+-10^-4之类</span></span><br><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 构造一个随机初始化的矩阵：范围[0,1)</span></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 构造一个随机int初始化的矩阵：范围[3,10)，大小2*2</span></span><br><span class="line">torch.randint(<span class="number">3</span>, <span class="number">10</span>, (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">tensor([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>]])</span><br><span class="line"><span class="comment"># 构造一个矩阵全为 0，而且数据类型是 long.</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"><span class="comment"># 直接使用数据 1*2维 </span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 裁取已有tensor 5*3的元素</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)   </span><br><span class="line"><span class="comment"># 已有tensor元素全部随机化</span></span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>) </span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接矩阵，不同维度 Concatenates </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">0</span>)</span><br><span class="line"><span class="comment"># torch.cat([input]*100)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="comment"># 相同大小对应位置相乘</span></span><br><span class="line">x = torch.tensor([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">1</span> / <span class="number">5</span>, <span class="number">2</span>]])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(torch.prod(x, <span class="number">0</span>))  <span class="comment"># product along 0th axis</span></span><br><span class="line">tensor([[<span class="number">5.0000</span>, <span class="number">6.0000</span>],</span><br><span class="line">        [<span class="number">0.2000</span>, <span class="number">2.0000</span>]])</span><br><span class="line">tensor([ <span class="number">1.</span>, <span class="number">12.</span>])</span><br><span class="line"><span class="comment"># 转置 指定维度transpose() 和 permute()</span></span><br><span class="line">x.t()   </span><br><span class="line"><span class="comment"># 横向纵向复制拓展</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.expand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.expand(-<span class="number">1</span>, <span class="number">4</span>)   <span class="comment"># -1 means not changing the size of that dimension</span></span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>]])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出第二列的数据</span></span><br><span class="line"><span class="built_in">print</span>(x[:, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 维度信息 输出是一个元组，所以它支持左右的元组操作。</span></span><br><span class="line"><span class="built_in">print</span>(x.size())</span><br><span class="line"><span class="comment"># 改变一个 tensor 的大小或者形状</span></span><br><span class="line"><span class="comment"># reshape也行 https://blog.csdn.net/Flag_ing/article/details/109129752</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>)  <span class="comment"># -1位置的取值是从其他维度推断出来的</span></span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size()) <span class="comment"># torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加法</span></span><br><span class="line">z=x+y</span><br><span class="line">z=torch.add(x, y)</span><br><span class="line">y.add_(x)  <span class="comment"># adds x to y</span></span><br></pre></td></tr></table></figure>

<p>注意 任何使张量会发生变化的操作都有一个前缀 ‘_‘。例如：<br>x.copy_(y), x.t_(), 将会改变 x</p>
<h2 id="PyTorch-自动微分"><a href="#PyTorch-自动微分" class="headerlink" title="PyTorch 自动微分"></a>PyTorch 自动微分</h2><p>autograd 包是 PyTorch 中所有神经网络的核心。</p>
<p>autograd 软件包为 Tensors 上的所有操作提供自动微分。它是一个由运行定义的框架，这意味着以代码运行方式定义你的后向传播，并且每次迭代都可以不同。</p>
<h3 id="TENSOR"><a href="#TENSOR" class="headerlink" title="TENSOR"></a>TENSOR</h3><p>torch.Tensor 是包的核心类。</p>
<p>如果将其属性 .requires_grad 设置为 True，则会开始跟踪针对 tensor 的所有操作。.requires_grad_( … ) 会改变张量的 requires_grad 标记。输入的标记默认为 False ，如果没有提供相应的参数。</p>
<p>完成计算后，您可以调用 .backward() 来自动计算所有梯度。</p>
<p>该张量的梯度将累积到 .grad 属性中。要停止 tensor 历史记录的跟踪，您可以调用 .detach()，它将其与计算历史记录分离，并防止将来的计算被跟踪。要停止跟踪历史记录（和使用内存），您还可以将代码块使用 with torch.no_grad(): 包装起来。</p>
<p>在评估模型时，这是特别有用，因为模型在训练阶段具有 requires_grad &#x3D; True 的可训练参数有利于调参，但在评估阶段我们不需要梯度。(???)</p>
<p>另一个重要的类是Function。Tensor 和 Function 互相连接并构建一个非循环图，它保存整个完整的计算过程的历史信息。</p>
<p>每个张量都有一个 .grad_fn 属性保存着创建了张量的 Function 的引用，（如果用户自己创建张量，则g rad_fn 是 None ）。</p>
<h3 id="计算导数"><a href="#计算导数" class="headerlink" title="计算导数"></a>计算导数</h3><p>你可以调用 Tensor.backward()。如果 Tensor 是标量（即它包含一个元素数据），则不需要指定任何参数backward()，但是如果它有更多元素，则需要指定一个gradient 参数来指定张量的形状。</p>
<h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建一个张量，设置 requires_grad=True 来跟踪与它相关的计算</span></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 操作张量</span></span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="comment"># 后向传播，因为输出包含了一个标量，out.backward() 等同于out.backward(torch.tensor(1.))。</span></span><br><span class="line">out.backward()</span><br><span class="line"><span class="comment"># 打印梯度 d(out)/dx</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[4.5000, 4.5000],</span></span><br><span class="line"><span class="comment">#        [4.5000, 4.5000]])</span></span><br></pre></td></tr></table></figure>

<p>原理：<br>最终Loss的值，网络结构（部分偏导数），当前训练的值。三者共同决定了梯度。这意味着在Batch使用时，假如将网络复制多遍（包括初始训练参数也一样），对于总的Loss来训练得到的参数是完全相同的。<br><img src="https://pic.shaojiemike.top/img/20220412204304.png"></p>
<h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p>y 不再是一个标量。torch.autograd 不能够直接计算整个雅可比，但是如果我们只想要雅可比向量积，只需要简单的传递向量给 backward 作为参数。(??? 雅可比向量积有什么用)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="comment"># tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])</span></span><br></pre></td></tr></table></figure>

<h2 id="神经网络的训练"><a href="#神经网络的训练" class="headerlink" title="神经网络的训练"></a>神经网络的训练</h2><h3 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h3><p>一个简单的前馈神经网络，它接收输入，让输入一个接着一个的通过一些层，最后给出输出。<br><img src="https://pic.shaojiemike.top/img/20220412211523.png"><br>通过 torch.nn 包来构建。一个 nn.Module 包括层和一个方法 forward(input) 它会返回输出(output)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 习惯上，将包含可训练参数的结构，声明在__init__里</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">num_flat_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<p>一个模型可训练的参数可以通过调用 net.parameters() 返回：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(params))</span><br><span class="line"><span class="built_in">print</span>(params[<span class="number">0</span>].size())  <span class="comment"># conv1&#x27;s .weight</span></span><br></pre></td></tr></table></figure>

<h3 id="运行一次网络"><a href="#运行一次网络" class="headerlink" title="运行一次网络"></a>运行一次网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure>

<h3 id="反向传播计算各个位置梯度"><a href="#反向传播计算各个位置梯度" class="headerlink" title="反向传播计算各个位置梯度"></a>反向传播计算各个位置梯度</h3><p>把所有参数梯度缓存器置零，用<strong>随机的梯度</strong>来反向传播</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>一个损失函数需要一对输入：模型输出和目标，然后计算一个值来评估输出距离目标有多远。</p>
<p>有一些不同的损失函数在 nn 包中。一个简单的损失函数就是 nn.MSELoss ，这计算了均方误差。</p>
<p>可以调用包，也可以自己设计。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">target = torch.randn(<span class="number">10</span>)  <span class="comment"># 随便一个目标</span></span><br><span class="line">target = target.view(<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># make it the same shape as output</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br></pre></td></tr></table></figure>

<h3 id="使用loss反向传播更新梯度"><a href="#使用loss反向传播更新梯度" class="headerlink" title="使用loss反向传播更新梯度"></a>使用loss反向传播更新梯度</h3><p>查看梯度记录的地方</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d</span><br><span class="line">      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</span><br><span class="line">      -&gt; MSELoss</span><br><span class="line">      -&gt; loss</span><br></pre></td></tr></table></figure>

<p>当我们调用 loss.backward()，整个图都会微分，而且所有的在图中的requires_grad&#x3D;True 的张量将会让他们的 grad 张量累计梯度。</p>
<p>为了实现反向传播损失，我们所有需要做的事情仅仅是使用 loss.backward()。你需要清空现存的梯度，要不然将会和现存(上一轮)的梯度累计到一起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()     <span class="comment"># zeroes the gradient buffers of all parameters</span></span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>

<p>查看某处梯度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure>

<h3 id="使用梯度和各种方法优化器更新参数"><a href="#使用梯度和各种方法优化器更新参数" class="headerlink" title="使用梯度和各种方法优化器更新参数"></a>使用梯度和各种方法优化器更新参数</h3><p>最简单的更新规则就是随机梯度下降。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight = weight - learning_rate * gradient</span><br></pre></td></tr></table></figure>

<p>我们可以使用 python 来实现这个规则：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data * learning_rate)</span><br></pre></td></tr></table></figure>

<p>尽管如此，如果你是用神经网络，你想使用不同的更新规则，类似于 SGD, Nesterov-SGD, Adam, RMSProp, 等。为了让这可行，我们建立了一个小包：torch.optim 实现了所有的方法。使用它非常的简单。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># create your optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in your training loop:</span></span><br><span class="line">optimizer.zero_grad()   <span class="comment"># zero the gradient buffers</span></span><br><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()    <span class="comment"># Does the update</span></span><br></pre></td></tr></table></figure>

<h3 id="上面是一次训练"><a href="#上面是一次训练" class="headerlink" title="上面是一次训练"></a>上面是一次训练</h3><p>一般是按照一次多少batch训练，训练10次等.</p>
<p>或者考虑loss 稳定后结束，一般不使用loss小于某个值（因为不知道loss阈值是多少）</p>
<p>或许可以考虑K折交叉检验法（k-fold cross validation）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="测试单个任务"><a href="#测试单个任务" class="headerlink" title="测试单个任务"></a>测试单个任务</h3><p>分类任务，取最高的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = net(images)</span><br><span class="line">_, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="测试总误差"><a href="#测试总误差" class="headerlink" title="测试总误差"></a>测试总误差</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>

<h2 id="各种初学者问题"><a href="#各种初学者问题" class="headerlink" title="各种初学者问题"></a>各种初学者问题</h2><h3 id="In-place-正确性检查"><a href="#In-place-正确性检查" class="headerlink" title="In-place 正确性检查"></a>In-place 正确性检查</h3><p>所有的Variable都会记录用在他们身上的 in-place operations。如果pytorch检测到variable在一个Function中已经被保存用来backward，但是之后它又被in-place operations修改。当这种情况发生时，在backward的时候，pytorch就会报错。这种机制保证了，如果你用了in-place operations，但是在backward过程中没有报错，那么梯度的计算就是正确的。</p>
<h3 id="对于不需要自动微分"><a href="#对于不需要自动微分" class="headerlink" title="对于不需要自动微分"></a>对于不需要自动微分</h3><p>&#x3D;不需要计算梯度&#x3D;手动计算值的</p>
<p>使用 <code>someTensor.detach()</code> 来更新</p>
<h2 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h2><h3 id="欠拟合和过拟合判断"><a href="#欠拟合和过拟合判断" class="headerlink" title="欠拟合和过拟合判断"></a>欠拟合和过拟合判断</h3><ol>
<li>训练集和测试集都不好——欠拟合</li>
<li>训练集好，测试集不好——过拟合</li>
</ol>
<h3 id="多通道"><a href="#多通道" class="headerlink" title="多通道"></a>多通道</h3><p>一般是任务特征很多维度时，拓展描述参数用的。</p>
<p>比如：图像一般包含三个通道&#x2F;三种原色（红色、绿色和蓝色）。 实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量。所以第三维通过通道表示。</p>
<p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html">https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html</a></p>
<h3 id="多通道举例说明"><a href="#多通道举例说明" class="headerlink" title="多通道举例说明"></a>多通道举例说明</h3><p><img src="https://pic.shaojiemike.top/img/20220412211523.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>) <span class="comment"># 输入通道1，输出通道6，卷积核 5*5</span></span><br></pre></td></tr></table></figure>

<p>$$<br>28&#x3D;32-5+1<br>$$</p>
<p>初始1通道变6通道，意味着对初始的A数据，有6个初始值不同的5*5卷积核操作，产生6张图。需要参数6*5*5.</p>
<p>初始6通道变16通道，相当于将6通道变1通道，重复16次。6通道变1通道，通过6张图与由6个5*5卷积核组成的卷积核组作用，生成6张图，然后简单相加，变成1张。需要总参数16*6*5*5*5。相当于下图某些数据变成6和16：</p>
<p><img src="https://pic.shaojiemike.top/img/20220413151558.png"></p>
<h3 id="BatchSize"><a href="#BatchSize" class="headerlink" title="BatchSize"></a>BatchSize</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34886403/article/details/82558399">https://blog.csdn.net/qq_34886403/article/details/82558399</a></p>
<ol>
<li>Batch Size定义：一次训练所选取的样本数。</li>
<li>由于矩阵操作，增加batch&#x2F;行号。每行经过同一个网络，引起的就是输出行号增加。只需要对每行单独计算出来的误差进行sum或者mean得到一个误差值，就可以反向传播，训练参数。<ol start="4">
<li>简单来说就是平均了一个batch数据的影响，不会出现离谱的波动，方向比较准确。</li>
</ol>
</li>
<li>Batch Size的大小影响模型的优化程度和速度。同时其直接影响到GPU内存的使用情况，假如你GPU内存不大，该数值最好设置小一点。<ol>
<li>没有Batch Size，梯度准确，只适用于小样本数据库</li>
<li>Batch Size增大，梯度变准确。但是单个epoch的迭代次数减少了，参数的调整也慢了，假如要达到相同的识别精度，需要更多的epoch。</li>
<li>Batch Size再增大，梯度已经非常准确，再增加Batch Size也没有用</li>
</ol>
</li>
<li>虽然Batch Size增大，一遍的总次数变少，单步计算量增加。但是由于GPU并行操作，单步时间不会增加太多。</li>
</ol>
<h3 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h3><p>Batch Normalization是将各层的输入进行归一化，使训练过程更快、更稳定的一种技术。在实践中，它是一个额外的层，我们通常添加在计算(卷积)层之后，在非线性(激活函数)之前。也有更先进的，比如layernorm。</p>
<p>BN层只是效果会变好，因为感受到了细节。不是有batch一定有BN层的意思。</p>
<p><img src="https://pic.shaojiemike.top/img/20220413153945.png"></p>
<h2 id="各种不同的Loss"><a href="#各种不同的Loss" class="headerlink" title="各种不同的Loss"></a>各种不同的Loss</h2><h3 id="交叉熵和加权交叉熵"><a href="#交叉熵和加权交叉熵" class="headerlink" title="交叉熵和加权交叉熵"></a>交叉熵和加权交叉熵</h3><p>多用于多分类任务，预测值是每一类各自的概率。label为特定的类别<br><img src="https://pic.shaojiemike.top/img/20220420111008.png"><br>torch.nn.NLLLOSS通常不被独立当作损失函数，而需要和softmax、log等运算组合当作损失函数。</p>
<p>torch.nn.CrossEntropyLoss相当于softmax + log + nllloss。</p>
<p><img src="https://pic.shaojiemike.top/img/20220420111137.png"></p>
<p>预测的概率大于1明显不符合预期，可以使用softmax归一，取log后是交叉熵，取负号是为了符合loss越小，预测概率越大。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 4类权重是 1， 10， 100， 100 一般是与样本占比成反比</span><br><span class="line">criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array([1,10,100,100])).float() ,reduction=&#x27;sum&#x27;)</span><br></pre></td></tr></table></figure>
<ul>
<li>size_average（该参数不建议使用，后续版本可能被废弃），该参数指定loss是否在一个Batch内平均，即是否除以N。默认为True</li>
<li>reduce (该参数不建议使用，后续版本可能会废弃)，首先说明该参数与size_average冲突，当该参数指定为False时size_average不生效，该参数默认为True。reduce为False时，对batch内的每个样本单独计算loss，loss的返回值Shape为[N],每一个数对应一个样本的loss。reduce为True时，根据size_average决定对N个样本的loss进行求和还是平均，此时返回的loss是一个数。</li>
<li>reduction 该参数在新版本中是为了取代size_average和reduce参数的。<ul>
<li>它共有三种选项’mean’，’sum’和’none’。</li>
<li>‘mean’为默认情况，表明对N个样本的loss进行求平均之后返回(相当于reduce&#x3D;True，size_average&#x3D;True);</li>
<li>‘sum’指对n个样本的loss求和(相当于reduce&#x3D;True，size_average&#x3D;False);</li>
<li>‘none’表示直接返回n分样本的loss(相当于reduce&#x3D;False)</li>
</ul>
</li>
</ul>
<h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>相对于加权交叉熵不仅权重不需要计算，自动通过概率算，而且gamma&#x3D;2按照平方缩小了，大样本的影响。</p>
<p><img src="https://pic.shaojiemike.top/img/20220420114232.png"></p>
<p>“蓝”线代表交叉熵损失。X轴即“预测为真实标签的概率”（为简单起见，将其称为pt）。举例来说，假设模型预测某物是自行车的概率为0.6，而它确实是自行车， 在这种情况下的pt为0.6。</p>
<p>Y轴是给定pt后Focal loss和CE的loss的值。</p>
<p>从图像中可以看出，当模型预测为真实标签的概率为0.6左右时，交叉熵损失仍在0.5左右。因此，为了在训练过程中减少损失，我们的模型将必须以更高的概率来预测到真实标签。换句话说，交叉熵损失要求模型对自己的预测非常有信心。但这也同样会给模型表现带来负面影响。</p>
<p>深度学习模型会变得过度自信, 因此模型的泛化能力会下降.</p>
<p>当使用γ&gt; 1的Focal Loss可以减少“分类得好的样本”或者说“模型预测正确概率大”的样本的训练损失，而对于“难以分类的示例”，比如预测概率小于0.5的，则不会减小太多损失。因此，在数据类别不平衡的情况下，会让模型的注意力放在稀少的类别上，因为这些类别的样本见过的少，比较难分。</p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1669261">https://cloud.tencent.com/developer/article/1669261</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34914551/article/details/105393989">https://blog.csdn.net/qq_34914551/article/details/105393989</a></p>
<p><a target="_blank" rel="noopener" href="https://ptorch.com/news/253.html">https://ptorch.com/news/253.html</a></p>
<h2 id="Pytorch-nn常用函数"><a href="#Pytorch-nn常用函数" class="headerlink" title="Pytorch.nn常用函数"></a>Pytorch.nn常用函数</h2><h3 id="torch-nn-Linear"><a href="#torch-nn-Linear" class="headerlink" title="torch.nn.Linear"></a>torch.nn.Linear</h3><p>$$<br>y&#x3D;x*A^T+b<br>$$</p>
<p>设置网络中的<strong>全连接层</strong>的，需要注意在二维图像处理的任务中，全连接层的输入与输出一般都设置为二维张量，形状通常为[batch_size, size]，不同于卷积层要求输入输出是四维张量。</p>
<p><code>in_features</code>指的是输入的二维张量的大小，即输入的[batch_size, size]中的size。</p>
<p><code>out_features</code>指的是输出的二维张量的大小，即输出的二维张量的形状为[batch_size，output_size]，当然，它也代表了该全连接层的神经元个数。</p>
<h3 id="torch-nn-ReLU"><a href="#torch-nn-ReLU" class="headerlink" title="torch.nn.ReLU()"></a>torch.nn.ReLU()</h3><p>$$<br>ReLU(x)&#x3D;(x)^+&#x3D;max(0,x)<br>$$</p>
<h3 id="torch-nn-Sigmoid"><a href="#torch-nn-Sigmoid" class="headerlink" title="torch.nn.Sigmoid"></a>torch.nn.Sigmoid</h3><p>$$<br>Sigmoid(x)&#x3D;σ(x)&#x3D; \frac{1}{1+exp(−x)}<br>$$</p>
<ol>
<li>torch.nn.Sigmoid()<ol>
<li>是一个类。在定义模型的初始化方法中使用，需要在_init__中定义，然后再使用。</li>
</ol>
</li>
<li>torch.nn.functional.sigmoid():<ol>
<li>可以直接在forward()里使用。eg.<code>A=F.sigmoid(x)</code></li>
</ol>
</li>
</ol>
<h3 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h3><p>cat是concatnate的意思：拼接，联系在一起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C = torch.cat( (A,B),<span class="number">0</span> )  <span class="comment">#按维数0拼接（竖着拼）</span></span><br><span class="line">C = torch.cat( (A,B),<span class="number">1</span> )  <span class="comment">#按维数1拼接（横着拼）</span></span><br></pre></td></tr></table></figure>

<h3 id="torch-nn-BatchNorm2d"><a href="#torch-nn-BatchNorm2d" class="headerlink" title="torch.nn.BatchNorm2d"></a>torch.nn.BatchNorm2d</h3><p>num_features – C from an expected input of size (N, C, H, W)</p>
<h3 id="torch-nn-BatchNorm1d"><a href="#torch-nn-BatchNorm1d" class="headerlink" title="torch.nn.BatchNorm1d"></a>torch.nn.BatchNorm1d</h3><p>Input: (N, C) or (N, C, L), where NN is the batch size, C is the number of features or channels, and L is the sequence length</p>
<p>Output: (N, C) or (N, C, L) (same shape as input)</p>
<h3 id="Softmax函数和Sigmoid函数的区别"><a href="#Softmax函数和Sigmoid函数的区别" class="headerlink" title="Softmax函数和Sigmoid函数的区别"></a>Softmax函数和Sigmoid函数的区别</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356976844">https://zhuanlan.zhihu.com/p/356976844</a></p>
<h2 id="保存与读取"><a href="#保存与读取" class="headerlink" title="保存与读取"></a>保存与读取</h2><p>Save on GPU, Load on GPU<br>Save:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<p>Load:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&quot;cuda&quot;)</span><br><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.to(device)</span><br><span class="line"># Make sure to call input = input.to(device) on any input tensors that you feed to the model</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>

<p>Remember that you must call <code>model.eval()</code> to set <strong>dropout and batch normalization layers</strong> to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.</p>
<h2 id="误差的表示"><a href="#误差的表示" class="headerlink" title="误差的表示"></a>误差的表示</h2><h2 id="训练参数怎么保存和读取"><a href="#训练参数怎么保存和读取" class="headerlink" title="训练参数怎么保存和读取"></a>训练参数怎么保存和读取</h2><h2 id="怎么表示数据"><a href="#怎么表示数据" class="headerlink" title="怎么表示数据"></a>怎么表示数据</h2><h2 id="怎么反向梯度法训练"><a href="#怎么反向梯度法训练" class="headerlink" title="怎么反向梯度法训练"></a>怎么反向梯度法训练</h2><h2 id="怎么使用GPU，怎么多GPU"><a href="#怎么使用GPU，怎么多GPU" class="headerlink" title="怎么使用GPU，怎么多GPU"></a>怎么使用GPU，怎么多GPU</h2><p>在GPU上训练 就像你怎么把一个张量转移到GPU上一样，你要将神经网络转到GPU上。 如果CUDA可以用，让我们首先定义下我们的设备为第一个可见的cuda设备。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assume that we are on a CUDA machine, then this should print a CUDA device:</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(device) <span class="comment"># cuda:0</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net=Net()</span><br><span class="line">net.to(device)</span><br><span class="line">outputs = net(inputs)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>

<h3 id="多GPU"><a href="#多GPU" class="headerlink" title="多GPU"></a>多GPU</h3><p>如果你想要来看到大规模加速，使用你的所有GPU，请查看：数据并行性（<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html%EF%BC%89%E3%80%82PyTorch">https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html）。PyTorch</a> 60 分钟入门教程：数据并行处理</p>
<p><a target="_blank" rel="noopener" href="http://pytorchchina.com/2018/12/11/optional-data-parallelism/">http://pytorchchina.com/2018/12/11/optional-data-parallelism/</a></p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><h3 id="网络结构可视化"><a href="#网络结构可视化" class="headerlink" title="网络结构可视化"></a>网络结构可视化</h3><p>自动<br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch">https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch</a></p>
<p>或者手动drawio</p>
<h2 id="误差实时可视化TensorBoard"><a href="#误差实时可视化TensorBoard" class="headerlink" title="误差实时可视化TensorBoard"></a>误差实时可视化TensorBoard</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/sddai/p/14516691.html">https://www.cnblogs.com/sddai/p/14516691.html</a></p>
<p>原理： 通过读取保存的log文件来可视化数据</p>
<h3 id="标量可视化"><a href="#标量可视化" class="headerlink" title="标量可视化"></a>标量可视化</h3><p>记录数据，默认在当前目录下一个名为’runs&#x2F;‘的文件夹中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写log的东西</span></span><br><span class="line">log_writer = SummaryWriter(<span class="string">&#x27;./path/to/log&#x27;</span>)</span><br><span class="line"><span class="comment"># 第一个参数是名称，第二个参数是y值，第三个参数是x值。</span></span><br><span class="line">log_writer.add_scalar(<span class="string">&#x27;Loss/train&#x27;</span>, <span class="built_in">float</span>(loss), epoch)</span><br></pre></td></tr></table></figure>

<p>运行 <code>tensorboard --logdir=runs/ --port 8123</code> 在某端口打开，比如 <code>https://127.0.0.1:6006</code></p>
<h3 id="网络结构可视化-1"><a href="#网络结构可视化-1" class="headerlink" title="网络结构可视化"></a>网络结构可视化</h3><p>在tensorboard的基础上使用tensorboardX</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from tensorboardX import SummaryWriter</span><br><span class="line"></span><br><span class="line">with SummaryWriter(comment=&#x27;LeNet&#x27;) as w:</span><br><span class="line">    w.add_graph(net, (net_input, ))</span><br></pre></td></tr></table></figure>

<h3 id="PR曲线"><a href="#PR曲线" class="headerlink" title="PR曲线"></a>PR曲线</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/b876144622/article/details/80009867">什么是PR曲线</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log_writer.add_pr_curve(&quot;pr_curve&quot;, label_batch, predict, epoch)</span><br></pre></td></tr></table></figure>

<p>x，y轴分别是recall和precision。应该有可能有矛盾的数据，或者网络分不开，<a target="_blank" rel="noopener" href="https://blog.csdn.net/u013249853/article/details/96132766?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_aa&utm_relevant_index=2">对于不同的阈值，可以划分出PR图。</a></p>
<p>与ROC曲线左上凸不同的是，PR曲线是右上凸效果越好。</p>
<h2 id="怎么分布式并行"><a href="#怎么分布式并行" class="headerlink" title="怎么分布式并行"></a>怎么分布式并行</h2><h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ol>
<li>矩阵或者向量的使用</li>
<li>optimizer.step()    # Does the update会自动循环吗？什么误差什么时候训练完毕呢？</li>
</ol>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>社会计算实验二，关于Meetup数据的预测性问题的解决</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://pytorch-cn.readthedocs.io/zh/latest/">https://pytorch-cn.readthedocs.io/zh/latest/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.pytorch123.com/">https://www.pytorch123.com/</a></p>
<p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html">https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html</a></p>
<p>Exploring the Impact of Dynamic Mutual Influence on Social Event<br>Participation</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-03T16:00:00.000Z" title="6/3/2023, 4:00:00 PM">2023-06-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.252Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Algorithms/">Algorithms</a></span><span class="level-item">16 minutes read (About 2454 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/03/Work/Algorithms/algorithm/">Algorithm: leetcode</a></p><div class="content"><h2 id="渐进符号"><a href="#渐进符号" class="headerlink" title="渐进符号"></a>渐进符号</h2><h2 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h2><p><img src="https://pic.shaojiemike.top/img/20230604160214.png"></p>
<ul>
<li>排序算法的稳定性：排序前后相同元素的相对位置不变，则称排序算法是稳定的；否则排序算法是不稳定的。</li>
<li>计数排序 中 k是数据出现的范围</li>
<li>基数排序时间复杂度为O(N*M)，其中N为数据个数，M为数据位数。</li>
</ul>
<h3 id="按照实现方法分类"><a href="#按照实现方法分类" class="headerlink" title="按照实现方法分类"></a>按照实现方法分类</h3><ul>
<li><p>选择排序</p>
<ul>
<li>直接选择排序：N轮，每轮变小的范围内找到最小值，然后与第i个交换。</li>
<li>堆排序：<ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/chengxiao/p/6129630.html">最大堆与数组的映射关系</a> 大顶堆：<code>arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2]</code>  </li>
<li>维护每轮范围变小的堆，每次将最大的堆顶移动到最后。每次维护堆需要O(logn)交换，把pop上来的小元素沉底到叶节点。</li>
<li>初始建堆需要O(nlogn)</li>
</ul>
</li>
</ul>
</li>
<li><p>插入排序</p>
<ul>
<li>直接插入：N轮，每轮从i开始向前插入（移动来交换），直到插入到合适的位置</li>
<li>希尔排序: 希尔排序是插入排序改良的算法，<ul>
<li>希尔排序步长从大到小调整，第一次循环后面元素逐个和前面元素按间隔步长进行比较并交换，</li>
<li>直至步长为1，步长选择是关键。</li>
</ul>
</li>
</ul>
</li>
<li><p>交换排序</p>
<ul>
<li>冒泡排序：冒泡N轮，每轮变小的范围内确定最后一个。</li>
<li>快速排序：在数组中随机选一个数（默认数组首个&#x2F;末尾元素），数组中小于等于此数的放在左边部分(<strong>交换到前面的排列</strong>)，大于此数的放在右边部分，这个操作确保了这个数是处于正确位置的，再对左边部分数组和右边部分数组递归调用快速排序，重复这个过程。</li>
</ul>
</li>
<li><p>分治合并</p>
<ul>
<li>归并排序： 首先让数组中的每一个数单独成为长度为1的区间，然后两两一组有序合并，得到长度为2的有序区间，依次合并进行得到长度为4、8、16的区间，直到合成整个区间。</li>
</ul>
</li>
<li><p>计数排序：数据出现的范围k &lt;&lt; O(n)时，或者k&#x3D;O(n)都可以采用该方法。</p>
</li>
<li><p>基数排序：对数据的每一位(共M位)从低位到高位进行stableSort。大部分时候选择计数排序O(N+k)。总时间复杂度O(M*(N+k))</p>
</li>
<li><p>桶排序：类似计数排序的思想，但是一般是对于区间等分为桶。桶内可以采用插入排序。n个元素n个桶，数学期望是O(n)</p>
</li>
</ul>
<h3 id="堆排序代码细节"><a href="#堆排序代码细节" class="headerlink" title="堆排序代码细节"></a>堆排序代码细节</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">heapSort</span><span class="params">(<span class="type">int</span> array[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="comment">//先建立堆</span></span><br><span class="line">    <span class="keyword">for</span> (i=n/<span class="number">2</span>;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">HeapAdjust</span>(array,i,n);<span class="comment">//从下向上，从右向左调整</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//交换最大堆顶，重复n次</span></span><br><span class="line">    <span class="keyword">for</span>( i=n;i&gt;<span class="number">1</span>;i--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">swap</span>(array, <span class="number">1</span>, i);</span><br><span class="line">        <span class="built_in">HeapAdjust</span>(array, <span class="number">1</span>, i<span class="number">-1</span>);<span class="comment">//从上到下，从左向右调整</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HeapAdjust</span><span class="params">(<span class="type">int</span> array[], <span class="type">int</span> s, <span class="type">int</span> n )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i,temp;</span><br><span class="line">    temp = array[s];</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">2</span>*s;i&lt;=n;i*=<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;n&amp;&amp;array[i]&lt;array[i+<span class="number">1</span>])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//交换左右子树最大的那个</span></span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(temp&gt;=array[i])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//找到了插入的合适的位置，子节点更小，父节点更大</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将节点向上移动</span></span><br><span class="line">        array[s]=array[i];</span><br><span class="line">        s=i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将最顶部插入到合适的位置</span></span><br><span class="line">    array[s]=temp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> array[], <span class="type">int</span> i, <span class="type">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> temp;</span><br><span class="line">    temp=array[i];</span><br><span class="line">    array[i]=array[j];</span><br><span class="line">    array[j]=temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="排序相关的问题"><a href="#排序相关的问题" class="headerlink" title="排序相关的问题"></a>排序相关的问题</h3><ul>
<li>既然时间复杂度堆排序、归并排序好于快排，为什么C++的qsort使用的是快排<ul>
<li>快速排序访存更友好，堆排序访问是跳跃的</li>
<li>对于同样的数据，排序过程中，堆排序算法的数据交换次数多于快排<ul>
<li>堆排序建立堆，与堆顶的交换，很多时候都是无用功</li>
</ul>
</li>
<li>在数据量小的时候快速排序当属第一，堆排序最差，但随着数据的不断增大归并排序的性能会逐步赶上并超过快速排序，性能成为三种算法之首。</li>
</ul>
</li>
<li>C++ 的 stable_sort 是基于归并排序的</li>
</ul>
<h2 id="LeetCode-常见算法"><a href="#LeetCode-常见算法" class="headerlink" title="LeetCode 常见算法"></a>LeetCode 常见算法</h2><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><p>拓扑排序常用来确定一个依赖关系集(图关系)中，事物发生的顺序。</p>
<p>带信号量判断的无依赖队列来实现，入队无依赖集合，出队的无依赖元素(add to result)去除后续元素的依赖信号量，信号量为0代表无依赖，可以入队。</p>
<h3 id="无环图（树图）中最长距离"><a href="#无环图（树图）中最长距离" class="headerlink" title="无环图（树图）中最长距离"></a>无环图（树图）中最长距离</h3><p>找到图中距离最远的两个节点与它们之间的路径：</p>
<p>以任意节点 pp 出现，利用广度优先搜索或者深度优先搜索找到以 pp 为起点的最长路径的终点 xx；</p>
<p>以节点 xx 出发，找到以 xx 为起点的最长路径的终点 yy；</p>
<p>xx 到 yy 之间的路径即为图中的最长路径，找到路径的中间节点即为根节点。</p>
<h3 id="树状数组"><a href="#树状数组" class="headerlink" title="树状数组"></a>树状数组</h3><p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/circle/article/9ixykn/">https://leetcode-cn.com/circle/article/9ixykn/</a></p>
<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/range-sum-query-mutable/">https://leetcode-cn.com/problems/range-sum-query-mutable/</a></p>
<h3 id="广度搜索确定图中各点对0点最近距离"><a href="#广度搜索确定图中各点对0点最近距离" class="headerlink" title="广度搜索确定图中各点对0点最近距离"></a>广度搜索确定图中各点对0点最近距离</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//input [[0,1],[1,2]]</span></span><br><span class="line"><span class="comment">//维护</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&gt; adj(n); <span class="comment">//先找出每个点的有关边</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt; <span class="title function_">visit</span><span class="params">(n, <span class="literal">false</span>)</span>;   <span class="comment">//维护已访问元素</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">queue</span>&lt;<span class="type">int</span>&gt; qu;</span><br><span class="line"></span><br><span class="line">qu.emplace(<span class="number">0</span>);</span><br><span class="line">visit[<span class="number">0</span>] = <span class="literal">true</span>;</span><br><span class="line"><span class="type">int</span> dist = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (!qu.empty()) &#123;</span><br><span class="line">    <span class="type">int</span> sz = qu.size();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; sz; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> curr = qu.front();</span><br><span class="line">        qu.pop();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp; v : adj[curr]) &#123;</span><br><span class="line">            <span class="keyword">if</span> (visit[v]) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            qu.emplace(v);</span><br><span class="line">            <span class="comment">//对应处理</span></span><br><span class="line">            visit[v] = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dist++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2进制数表示子集合"><a href="#2进制数表示子集合" class="headerlink" title="2进制数表示子集合"></a>2进制数表示子集合</h3><p>对集合大小为n，可以用大于等于0小于<code>1&lt;&lt;n</code>的<code>2^n-1</code>个数字来表示子集。</p>
<p>但是对每个子集都会单独计算，有重复。 不如用按每位是否存在回溯</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">2044</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">countMaxOrSubsets</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&amp; nums)</span> &#123;</span><br><span class="line">        <span class="type">int</span> maxOr = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> n: nums)&#123;</span><br><span class="line">            maxOr = n | maxOr;</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(nums, maxOr, <span class="number">0</span> , <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> maxOr, <span class="type">int</span> idx, <span class="type">int</span> cur)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (cur == maxOr)&#123;</span><br><span class="line">            ans += <span class="number">1</span> &lt;&lt; (nums.size()-idx);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (idx == nums.size())&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        dfs(nums, maxOr, idx+<span class="number">1</span>, cur | nums[idx]);</span><br><span class="line">        dfs(nums, maxOr, idx+<span class="number">1</span>, cur);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2进制表示使用状态true-false"><a href="#2进制表示使用状态true-false" class="headerlink" title="2进制表示使用状态true false"></a>2进制表示使用状态true false</h3><p>int 可以表示32个元素的使用情况</p>
<p><a target="_blank" rel="noopener" href="https://leetcode.cn/problems/can-i-win/">https://leetcode.cn/problems/can-i-win/</a></p>
<h3 id="前缀和和差分"><a href="#前缀和和差分" class="headerlink" title="前缀和和差分"></a>前缀和和差分</h3><p><code>前缀和</code><br>和<code>差分</code><br>是一组互逆的方法；他们的关系和<code>积分</code><br>与<code>求导</code><br>实质是一样的。前缀和可以帮我们通过预处理快速的求出区间的和；差分则可以快速帮助我们记录区间的修改。</p>
<p>将区间前一个加一，最后一个减一实现。</p>
<p>leetcode 798</p>
<h3 id="预处理查询的数组"><a href="#预处理查询的数组" class="headerlink" title="预处理查询的数组"></a>预处理查询的数组</h3><p>通过预处理记录信息来减少查询的时间</p>
<p>leetcode 2055</p>
<h3 id="二分法"><a href="#二分法" class="headerlink" title="二分法"></a>二分法</h3><p>二分寻找满足条件的最小整数,  注意<code>left + 1 &lt; right</code>和<code>s &gt;= cars</code></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">while</span> (left + <span class="number">1</span> &lt; right) &#123; <span class="comment">// 开区间</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> mid = (left + right) / <span class="number">2</span>, s = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> r : ranks)</span><br><span class="line">        s += <span class="built_in">sqrt</span>(mid / r);</span><br><span class="line">    (s &gt;= cars ? right : left) = mid;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 作者：灵茶山艾府</span></span><br><span class="line"><span class="comment">// 链接：https://leetcode.cn/problems/minimum-time-to-repair-cars/solutions/2177199/er-fen-da-an-pythonjavacgo-by-endlessche-keqf/</span></span><br><span class="line"><span class="comment">// 来源：力扣（LeetCode）</span></span><br><span class="line"><span class="comment">// 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span></span><br></pre></td></tr></table></figure>

<h3 id="直接模拟"><a href="#直接模拟" class="headerlink" title="直接模拟"></a>直接模拟</h3><p>最常用的方法</p>
<h3 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h3><p>根据设定的哈希函数H（key）和处理冲突方法将一组关键字映象到一个有限的地址区间上的算法。也称为散列算法、杂凑算法。</p>
<h4 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h4><p>一般有：开放定址法、链地址法（拉链法）、再哈希法、建立公共溢出区</p>
<h2 id="LeetCode-代码优化加速"><a href="#LeetCode-代码优化加速" class="headerlink" title="LeetCode 代码优化加速"></a>LeetCode 代码优化加速</h2><h3 id="cin-tie与sync-with-stdio加速输入输出"><a href="#cin-tie与sync-with-stdio加速输入输出" class="headerlink" title="cin.tie与sync_with_stdio加速输入输出"></a>cin.tie与sync_with_stdio加速输入输出</h3><p>std::ios::sync_with_stdio(); 是一个“是否兼容stdio”的开关，C++为了兼容C，保证程序在使用了std::printf和std::cout的时候不发生混乱，将输出流绑到了一起。也就是 C++标准streams(cin,cout,cerr…) 与相应的C标准程序库文件(stdin,stdout,stderr)同步，使用相同的 stream 缓冲区。<br>默认是同步的，但由于同步会带来某些不必要的负担，因此该函数作用是使得用户可以自行取消同步。</p>
<p>cin.tie(NULL) 取消 cin 和 cout 的绑定。</p>
<p>这对于输入数据个数<strong>在10^5以上的程序十分有效</strong>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> x = []() &#123;</span><br><span class="line">    <span class="built_in">std</span>::ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;();</span><br><span class="line"><span class="comment">// or</span></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="keyword">auto</span> io_sync_off = []() &#123;</span><br><span class="line">    <span class="built_in">std</span>::ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span>.tie(nullptr);</span><br><span class="line">    <span class="keyword">return</span> nullptr;</span><br><span class="line">&#125;();</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> init = []() &#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(nullptr);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;();</span><br></pre></td></tr></table></figure>

<h3 id="问题拆分循环调用"><a href="#问题拆分循环调用" class="headerlink" title="问题拆分循环调用"></a>问题拆分循环调用</h3><p>不如从底层动态规划合并，不要嵌套函数调用，还可以用二维数据，数据局部性较好。</p>
<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/optimal-division/submissions/">https://leetcode-cn.com/problems/optimal-division/submissions/</a></p>
<h3 id="不一定要执着数据只遍历一遍"><a href="#不一定要执着数据只遍历一遍" class="headerlink" title="不一定要执着数据只遍历一遍"></a>不一定要执着数据只遍历一遍</h3><p>可以将复杂的一次遍历，拆开成两次遍历，一次处理数据并存储，一次遍历统计。速度反而会快</p>
<h3 id="简单递归循环"><a href="#简单递归循环" class="headerlink" title="简单递归循环"></a>简单递归循环</h3><p>用while代替函数递归调用，eg二分法</p>
<h3 id="减少if语句"><a href="#减少if语句" class="headerlink" title="减少if语句"></a>减少if语句</h3><p>可以保存分支的值来实现(1748)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">//0ms</span><br><span class="line">int sumOfUnique(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line"> int state[101]&#123;&#125;, ans = 0, d[101]&#123;1,-1&#125;;</span><br><span class="line"> for(int x: nums) ans += d[state[x]++] * x;</span><br><span class="line"> return ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//4ms</span><br><span class="line">int sumOfUnique(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line"> array&lt;char,101&gt; isshowed &#123;&#125;;</span><br><span class="line"> int sum=0;</span><br><span class="line"> for(auto&amp; num:nums)&#123;</span><br><span class="line">  if(isshowed[num]==0)&#123;</span><br><span class="line">   isshowed[num]=1;</span><br><span class="line">   sum+=num;</span><br><span class="line">  &#125;else if(isshowed[num]==1)&#123;</span><br><span class="line">   isshowed[num]=2;</span><br><span class="line">   sum-=num;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> return sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="通过判断筛选掉"><a href="#通过判断筛选掉" class="headerlink" title="通过判断筛选掉"></a>通过判断筛选掉</h3><p>无用的遍历计算(1219)</p>
<h3 id="减少for循环"><a href="#减少for循环" class="headerlink" title="减少for循环"></a>减少for循环</h3><p>循环展开，只有一两种情况就不要写for循环了</p>
<h2 id="注意的细节"><a href="#注意的细节" class="headerlink" title="注意的细节"></a>注意的细节</h2><h3 id="计算防止溢出"><a href="#计算防止溢出" class="headerlink" title="计算防止溢出"></a>计算防止溢出</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int middle = left + ((right - left) / 2);// 防止溢出 等同于(left + right)/2</span><br></pre></td></tr></table></figure>

<h3 id="转化成加减，而不用乘法"><a href="#转化成加减，而不用乘法" class="headerlink" title="转化成加减，而不用乘法"></a>转化成加减，而不用乘法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A &lt; B/2</span><br><span class="line">变成</span><br><span class="line">A &lt; B-A</span><br></pre></td></tr></table></figure>

<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://oi-wiki.org/dp/basic/">https://oi-wiki.org/dp/basic/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/azl397985856/leetcode/blob/master/thinkings/dynamic-programming.md">https://github.com/azl397985856/leetcode/blob/master/thinkings/dynamic-programming.md</a></p>
<p>作者：AC_OIer<br>链接：<a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/the-number-of-good-subsets/solution/gong-shui-san-xie-zhuang-ya-dp-yun-yong-gz4w5/">https://leetcode-cn.com/problems/the-number-of-good-subsets/solution/gong-shui-san-xie-zhuang-ya-dp-yun-yong-gz4w5/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-03T16:00:00.000Z" title="6/3/2023, 4:00:00 PM">2023-06-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-28T14:04:36.260Z" title="1/28/2024, 2:04:36 PM">2024-01-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Operating-system/">Operating system</a></span><span class="level-item">23 minutes read (About 3463 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/03/Work/Operating%20system/lock/">Lock</a></p><div class="content"><h2 id="互斥与同步的实现和使用"><a href="#互斥与同步的实现和使用" class="headerlink" title="互斥与同步的实现和使用"></a>互斥与同步的实现和使用</h2><p>在进程&#x2F;线程并发执行的过程中，进程&#x2F;线程之间存在协作的关系，例如有互斥、同步的关系。</p>
<p>为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p>
<ul>
<li><p>锁：加锁、解锁操作；</p>
<ul>
<li>自旋锁(spin lock， 忙等待锁)，基于原子操作指令 —— 测试和置位（Test-and-Set）指令</li>
<li>无等待锁：思想，把当前线程放入到锁的等待队列，然后执行调度程序</li>
</ul>
</li>
<li><p>信号量：P、V 操作；</p>
</li>
</ul>
<p>这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步。</p>
<h2 id="锁相关问题"><a href="#锁相关问题" class="headerlink" title="锁相关问题"></a>锁相关问题</h2><ol start="6">
<li>共享内存加锁之后释放锁，别的进程是如何知道锁释放的<ol>
<li>常用的方法是在共享内存中设置<strong>标志位或信号量</strong>等，并在共享内存中保证这个标志位或信号量只有在锁被释放时才会被更新。这样，其它进程可以通过<strong>轮询或者等待通知</strong>的方式来获取锁并开始修改共享内存，从而避免冲突。在共享内存中设置的标志位或信号量通常需要原子操作的支持，以确保并发修改时的正确性。<ol>
<li>轮询：轮询是指线程反复检查某个条件是否成立，直到条件成立为止。在锁机制中，当一个线程持有锁时，其他线程会不断地轮询锁的状态，直到该锁被释放。这种方式的优点是实现简单，不需要额外的通知机制，缺点是占用CPU资源，效率较低。</li>
<li>等待通知：等待通知是指线程在某个条件不满足时挂起等待，当条件满足时由其他线程通知它继续执行。在锁机制中，当一个线程持有锁时，其他线程会进入等待状态，直到该锁被释放，此时其他线程会被通知并继续执行。这种方式的优点是占用CPU资源少，效率高，缺点是实现稍微复杂一些，需要额外的通知机制。</li>
</ol>
</li>
<li>另外，也可以使用一个中央锁服务器或者等待队列来管理锁，当一个进程获取锁时，会向中央锁服务器或等待队列发出请求，直到锁被成功获取，并在共享内存中记录锁的状态。当锁被释放时，中央锁服务器或等待队列会通知其它进程，并让其它进程开始自由修改共享内存。</li>
</ol>
</li>
<li>如何保证操作的原子性<ol>
<li>操作系统提供的原子操作：一些操作系统会提供线程安全的原子操作接口，如Compare-And-Swap（CAS）等，它们能够确保指令的原子性，从而保证线程安全。</li>
<li>事务：事务是指一组操作被视为一个不可分割的操作序列，要么全部执行成功，要么全部失败，具有原子性和一致性保证。常用于数据库操作等场景。</li>
<li>锁机制：锁机制是一种常用的多线程同步机制，能够确保同一时刻只有一个线程（或进程）可以访问共享资源，从而保证原子性。</li>
</ol>
</li>
<li>如何避免死锁<ol>
<li>避免使用多把锁并且同时持有多个锁。当需要持有多个锁时，可以通过加锁的顺序来避免死锁。如果所有可能的锁按照固定的顺序加锁，那么可以避免死锁。</li>
<li>设置请求超时时间。当一个进程请求锁时，如果在超时时间内没有获得锁，可以释放之前持有的锁，并尝试重新获取。这样可以避免某一个进程一直持有锁而导致死锁。</li>
<li>引入随机性。在获取锁的时候加入一些随机因素，让不同的程序在不同的时间获取锁。这样可以防止程序之间在自己的重试过程中的饥饿状态导致的死锁。</li>
</ol>
</li>
</ol>
<h2 id="RedStar-小红书-笔试"><a href="#RedStar-小红书-笔试" class="headerlink" title="RedStar (小红书) 笔试"></a>RedStar (小红书) 笔试</h2><h3 id="图中有依赖的任务的，需要几个信号量来实现同步"><a href="#图中有依赖的任务的，需要几个信号量来实现同步" class="headerlink" title="图中有依赖的任务的，需要几个信号量来实现同步"></a>图中有依赖的任务的，需要几个信号量来实现同步</h3><p>如<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45385429/article/details/115250919">CSDN</a>，有一条依赖线，需要一个信号量</p>
<p>在使用信号量(Semaphore)进行线程同步时,P(proberen)和V(verhogen)操作是非常重要的概念。</p>
<ol>
<li>P操作（也称为Wait操作或Down操作）：</li>
</ol>
<ul>
<li>表示获取或等待信号量。</li>
<li>如果信号量内部计数值大于0,获取信号量并将计数值减1。</li>
<li>如果计数值等于0,线程将等待,直到计数值大于0。如果信号量的值大于0，表示资源可用，进程可以继续执行。如果信号量的值为0，表示资源不可用，P操作将阻塞（即等待）进程，直到该信号量的值大于0为止。</li>
</ul>
<p>伪代码表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">P(S):</span><br><span class="line">  while S &lt;= 0:</span><br><span class="line">    // 等待，直到S大于0</span><br><span class="line">  S = S - 1</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>V操作（也称为Signal操作或Up操作）：</li>
</ol>
<ul>
<li>表示释放或增加信号量。</li>
<li>将信号量内部计数值加1。</li>
<li>如果存在等待线程,唤醒其中一个线程继续执行。</li>
</ul>
<p>伪代码表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">V(S):</span><br><span class="line">  S = S + 1</span><br></pre></td></tr></table></figure>

<p>P和V操作保证了对共享资源的互斥访问。</p>
<p>一个线程使用P操作等待获取信号量,V操作在使用完共享资源后释放信号量。</p>
<p>信号量的值通常用于控制共享资源的数量，它可以是<strong>非负整数</strong>。当信号量被初始化为1时，称为二进制信号量（Binary Semaphore），因为它只能取0或1的值，通常用于实现互斥访问临界区。如果信号量的值大于1，称为计数信号量，可用于限制对资源的并发访问数。</p>
<p>在实际编程中，P操作和V操作通常是原子操作，确保在多线程或多进程环境下的正确同步和竞争条件的安全处理。</p>
<h2 id="TP-link笔试"><a href="#TP-link笔试" class="headerlink" title="TP-link笔试"></a>TP-link笔试</h2><p>设计的程序在多个CPU上运行时，不应使用哪个实现多个CPU间的数据访问同步？</p>
<ul>
<li><p>自旋锁(spinlock): 多线程同步的一种忙等待锁，线程反复检查锁变量是否可用。</p>
<ul>
<li>优点：避免了操作系统进程调度和线程切换，所以自旋锁通常适用在时间比较短的情况下。由于这个原因，操作系统的内核经常使用自旋锁。</li>
<li>缺点：如果长时间上锁的话，自旋锁会非常耗费性能，它阻止了其他线程的运行和调度<ul>
<li>线程持有锁的时间越长，则持有该锁的线程将被 OS(Operating System) 调度程序中断的风险越大。</li>
</ul>
</li>
<li>解决办法： TicketLock 是采用排队叫号的机制。CLHLock和MCSLock通过链表的方式避免了减少了处理器缓存同步，极大的提高了性能，区别在于CLHLock是通过轮询其前驱节点的状态，而MCS则是查看当前节点的锁状态。</li>
</ul>
</li>
<li><p>互斥锁(mutex)：把自己阻塞起来（内核态和用户态之间的切换进入阻塞状态，可能上下文切换），等待重新调度请求。</p>
<ul>
<li>互斥锁的实现<ol>
<li>软件实现：软件互斥锁需要借助操作系统提供的原子操作（如Compare-And-Swap，CAS）来实现 优点是灵活性高 缺点是性能较低，</li>
<li>CAS操作需要三个参数，内存地址A，期望值V，新值N。执行过程如下：<ul>
<li>读取内存地址A的原始值，保存在临时变量Value中</li>
<li>比较Value和期待值V是否相等，如果相等则将内存地址A的值更新为新值N</li>
<li>如果内存地址A的值已经被其他线程改变，则不进行更新操作</li>
</ul>
</li>
</ol>
<ul>
<li>TAS（test and set）<ul>
<li>一个TAS指令包括两个子步骤，把给定的内存地址设置为1，然后返回之前的旧值。</li>
</ul>
<ol start="2">
<li>硬件实现：硬件互斥锁使用计算机硬件提供的特殊指令（如锁总线指令）来实现。当线程要获取锁时，它会发出一个锁总线指令，这个指令会占用系统总线，使得其他CPU无法读写内存。<ol>
<li>当lock前缀指令执行时，它将锁定处理器总线，确保其他处理器无法同时访问同一内存区域，</li>
</ol>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p>读写锁（ReadWrite Lock）</p>
<ul>
<li>在读操作和写操作之间提供了更细粒度的同步控制。</li>
<li>多个线程可以同时获取读锁，但只有一个线程能够获取写锁。<ul>
<li>读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态</li>
<li>规则<ul>
<li>当读写锁在写加锁模式下，任何试图对这个锁进行加锁的线程都会被阻塞，直到写进程对其解锁。</li>
<li>当读写锁在读加锁模式先，任何线程都可以对其进行读加锁操作，但是所有试图进行写加锁操作的线程都会被阻塞，直到所有的读线程都解锁。</li>
</ul>
</li>
</ul>
</li>
<li>缺点：当读者源源不断到来的时候，写者总是得不到读写锁，就会造成不公平的状态。<ul>
<li>避免方法： 当处于读模式的读写锁接收到一个试图对其进行写模式加锁操作时，便会阻塞后面对其进行读模式加锁操作的线程。这样等到已经加读模式的锁解锁后，写进程能够访问此锁保护的资源。</li>
</ul>
</li>
<li>优点：<ul>
<li>读写锁可以提高并发性，允许多个线程同时读取数据，而只有在需要修改数据时才会互斥。</li>
<li>适合对数据结构读的次数远远大于写的情况。</li>
</ul>
</li>
</ul>
</li>
<li><p>RCU（Read-Copy-Update）</p>
<ul>
<li>对读写锁的一种改进。适用于读多写少场景的数据同步机制。</li>
<li>具体内容<ul>
<li>并发读取数据不再需要加锁</li>
<li>写数据时，RCU机制通过创建一个副本来实现读写分离，确保在更新过程中没有线程正在读取旧的数据。<ul>
<li>写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。</li>
<li>读者必须提供一个信号给写者以便写者能够确定数据可以被安全地释放或修改的时机。</li>
<li>有一个专门的垃圾收集器来探测读者的信号，一旦所有的读者都已经发送信号告知它们都不在使用被RCU保护的数据结构，垃圾收集器就调用回调函数完成最后的数据释放或修改操作。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>悲观锁</p>
<ol>
<li><strong>读</strong>写操作时，需要预先加锁，防止其他进程对资源的访问。</li>
<li>通过<strong>互斥锁（Mutex）和信号量（Semaphore）</strong>来实现。</li>
</ol>
</li>
<li><p>乐观锁</p>
<ol>
<li>在读取或修改共享资源时，并不先进行加锁操作，而是先读取资源，然后在对资源进行写操作时再进行一次比较，看看在这个时间间隔内是否发生了竞争。如果没有发生竞争，就可以将更新后的值写入共享资源，并结束操作；如果发生了竞争，则需要放弃本次更新，并进行重试</li>
<li>通过<strong>版本号</strong>的方式来实现。在共享资源中记录该资源的版本号，当一个进程想要修改共享资源时，需要先获取当前资源的版本号。如果当前版本号与自己保存的版本号相符，说明没有其他进程在这段时间内修改该资源，则可以进行写操作；如果版本号已经发生变化，则说明有其他进程对该资源进行了修改，当前进程需要放弃本次写操作，更新版本号，重新获取新的资源，并重新执行操作。</li>
</ol>
</li>
</ul>
<p>下面回答部分<strong>来自ChatGPT-3.5</strong>，暂时没有校验其可靠性(看上去貌似说得通)。</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.cswiki.top/pages/f398f1/#blocking-i-o">https://www.cswiki.top/pages/f398f1/#blocking-i-o</a></p>
<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_15437629/article/details/79116590">https://blog.csdn.net/qq_15437629/article/details/79116590</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161936748">https://zhuanlan.zhihu.com/p/161936748</a></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/20/">Previous</a></div><div class="pagination-next"><a href="/page/22/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/20/">20</a></li><li><a class="pagination-link is-current" href="/page/21/">21</a></li><li><a class="pagination-link" href="/page/22/">22</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/39/">39</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">388</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">487</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">39</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Thinking/"><span class="level-start"><span class="level-item">Thinking</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">51</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-27T08:35:33.000Z">2024-01-27</time></p><p class="title"><a href="/2024/01/27/Work/Artificial%20Intelligence/Basic/AIComputeMachine/">AI Compute Machine</a></p><p class="categories"><a href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-25T03:20:42.000Z">2024-01-25</time></p><p class="title"><a href="/2024/01/25/OutOfWork/5-VideoEntertainment/AnimeSuperResolutionFrame/">Anime Super Resolution to 4K &amp; Interpolation to 120 fps</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-13T14:32:40.000Z">2024-01-13</time></p><p class="title"><a href="/2024/01/13/Thinking/2-courage2move/SocialScience/">Social Science</a></p><p class="categories"><a href="/categories/Thinking/">Thinking</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-13T12:15:22.000Z">2024-01-13</time></p><p class="title"><a href="/2024/01/13/Work/Architecture/FPGA/">FPGA</a></p><p class="categories"><a href="/categories/toLearn/">toLearn</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-13T08:02:52.000Z">2024-01-13</time></p><p class="title"><a href="/2024/01/13/Work/Architecture/workloadPriority/">Workload Characterization &amp; Priority &amp; Scheduler to CPU/GPU/PIM</a></p><p class="categories"><a href="/categories/Architecture/">Architecture</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">235</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2024 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>