<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Hexo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hexo"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hexo"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Hexo"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="Hexo"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"Hexo","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Hexo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-16T16:00:00.000Z" title="5/16/2022, 4:00:00 PM">2022-05-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.560Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">a minute read (About 169 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/16/Work/Programming/2-languageGrammar/htmlCssScss/">HtmlCssScss</a></p><div class="content"><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><h3 id="字体居中"><a href="#字体居中" class="headerlink" title="字体居中"></a>字体居中</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;p style=&quot;text-align:center;&quot;&gt;123&lt;/p&gt;</span><br></pre></td></tr></table></figure>
<h3 id="周围阴影"><a href="#周围阴影" class="headerlink" title="周围阴影"></a>周围阴影</h3><p>模拟光线射在对象上产生的阴影</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text-shadow: (inset) 20px -19px 30px transparent;</span><br></pre></td></tr></table></figure>
<ol>
<li>inset 若指定，阴影在字体里</li>
<li><code>&lt;offset-x&gt; &lt;offset-y&gt;</code> 光照产生阴影的上下左右</li>
<li><code>&lt;blur-radius&gt;</code> 阴影轮廓模糊正值，0为阴影边缘清晰<!-- 4. `<blur-radius>` 可选，默认为0. 正值放大阴影 --></li>
<li><code>color</code> 颜色，允许透明色</li>
</ol>
<h2 id="位置"><a href="#位置" class="headerlink" title="位置"></a>位置</h2><h3 id="水平居中"><a href="#水平居中" class="headerlink" title="水平居中"></a>水平居中</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">display: inline</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220517153027.png"><br>方法一:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">position: absolute;</span><br><span class="line">left: 50%;</span><br><span class="line">top: 50%;</span><br></pre></td></tr></table></figure>

<h2 id="颜色的表示"><a href="#颜色的表示" class="headerlink" title="颜色的表示"></a>颜色的表示</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#888</span><br><span class="line">rgba(red, green, blue, alpha) # 最后一个是透明度 0-1之间</span><br><span class="line">black</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-14T16:00:00.000Z" title="5/14/2022, 4:00:00 PM">2022-05-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.552Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">14 minutes read (About 2081 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/14/Work/HPC/cuda/nvidiaOptimize/">Nvidia Optimize</a></p><div class="content"><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ol>
<li>General optimization guidance<ol>
<li>Coalescing memory operations</li>
<li>Occupancy and latency hiding</li>
<li>Using shared memory</li>
</ol>
</li>
<li>Example 1: transpose<ol>
<li>Coalescing and bank conflict avoidance</li>
</ol>
</li>
<li>Example 2: efficient parallel reductions<ol>
<li>Using peak performance metrics to guide optimization</li>
<li>Avoiding SIMD divergence &amp; bank conflicts</li>
<li>Loop unrolling</li>
<li>Using template parameters to write general-yet-optimized code</li>
<li>Algorithmic strategy: Cost efficiency</li>
</ol>
</li>
</ol>
<h2 id="专业术语-terminology"><a href="#专业术语-terminology" class="headerlink" title="专业术语 terminology"></a>专业术语 terminology</h2><ol>
<li>Thread : 并行的基本单位<ol>
<li>但是创建和切换的成本比CPU小多了</li>
</ol>
</li>
<li>Warp: 一堆能硬件物理支持并行的线程(SIMD)</li>
<li>Thread Block: 在一个SM(multiprocessor) 里共享shared memory的一堆线程</li>
</ol>
<h2 id="CUDA-优化策略"><a href="#CUDA-优化策略" class="headerlink" title="CUDA 优化策略"></a>CUDA 优化策略</h2><h3 id="GPU的优化算法"><a href="#GPU的优化算法" class="headerlink" title="GPU的优化算法"></a>GPU的优化算法</h3><ol>
<li>最大化并行独立性</li>
<li>最大化计算密度</li>
<li>减少数据传输<ol>
<li>数据可以直接在GPU生成。</li>
<li>一次大传输也比分开的小批次快</li>
</ol>
</li>
</ol>
<h3 id="访存连续性"><a href="#访存连续性" class="headerlink" title="访存连续性"></a>访存连续性</h3><ol>
<li>对齐(Starting address for a region must be a multiple of region size)集体访问，有数量级的差异Coalesced</li>
<li><strong>Optimize for spatial locality in cached texture memory</strong> ???</li>
<li>避免bank conflict</li>
</ol>
<h3 id="利用好Shared-Memory"><a href="#利用好Shared-Memory" class="headerlink" title="利用好Shared Memory"></a>利用好Shared Memory</h3><ol>
<li>比globalMemory快百倍</li>
<li>可以来避免 non-Coalesced access</li>
<li>SM的线程可以共享</li>
<li><strong>Use one &#x2F; a few threads to load &#x2F; compute data shared by all threads</strong></li>
</ol>
<h3 id="占用率高不一定是好事"><a href="#占用率高不一定是好事" class="headerlink" title="占用率高不一定是好事"></a>占用率高不一定是好事</h3><p>占用率是指每个多处理器（Streaming Multiprocessor，SM）的实际的活动warps数量与最大理论的warps数量的比率。<br>高的占用率不一定能提升性能，因为这一般意味着每个线程分配的寄存器和shared memory变少。但低的占用率会导致内存延迟无法隐藏。</p>
<p>实际需要计算每个线程大概需要的shared memory和register数量</p>
<h4 id="实际例子测试-待研究"><a href="#实际例子测试-待研究" class="headerlink" title="实际例子测试-待研究"></a>实际例子测试-待研究</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4541313.html">https://www.cnblogs.com/1024incn/p/4541313.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4545265.html">https://www.cnblogs.com/1024incn/p/4545265.html</a></p>
<h2 id="优化实例1-矩阵转置"><a href="#优化实例1-矩阵转置" class="headerlink" title="优化实例1 - 矩阵转置"></a>优化实例1 - 矩阵转置</h2><p>通过SMEM实现coalescing access</p>
<p>原本代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">_global__ void transpose_naive(float *odata, float *idata, int width, int height)</span><br><span class="line">&#123;</span><br><span class="line">   unsigned int xIndex = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">   unsigned int yIndex = blockDim.y * blockIdx.y + threadIdx.y;</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      unsigned int index_in = xIndex + width * yIndex;</span><br><span class="line">      unsigned int index_out = yIndex + height * xIndex;</span><br><span class="line">      odata[index_out] = idata[index_in]; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思想：将大矩阵划分成方块，并且存储在SMEM里。不仅SMEM速度更快，而且每行元素个数变少，跨行访问的间距变小，局部性增强。而且对于大矩阵加速效果会更明显。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void transpose(float *odata, float *idata, int width, int height)</span><br><span class="line">&#123;</span><br><span class="line">   __shared__ float block[BLOCK_DIM*BLOCK_DIM];</span><br><span class="line">   unsigned int xBlock = blockDim.x * blockIdx.x;</span><br><span class="line">   unsigned int yBlock = blockDim.y * blockIdx.y;</span><br><span class="line">   unsigned int xIndex = xBlock + threadIdx.x;</span><br><span class="line">   unsigned int yIndex = yBlock + threadIdx.y;</span><br><span class="line">   unsigned int index_out, index_transpose;</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">   &#123;</span><br><span class="line">      unsigned int index_in = width * yIndex + xIndex;</span><br><span class="line">      unsigned int index_block = threadIdx.y * BLOCK_DIM + threadIdx.x;</span><br><span class="line">      block[index_block] = idata[index_in];</span><br><span class="line">      index_transpose = threadIdx.x * BLOCK_DIM + threadIdx.y;</span><br><span class="line">      index_out = height * (xBlock + threadIdx.y) + yBlock + threadIdx.x;</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">   if (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">      odata[index_out] = block[index_transpose]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="coalescing-access"><a href="#coalescing-access" class="headerlink" title="coalescing access"></a>coalescing access</h3><p>when Block&#x2F;tile dimensions are multiples of 16 ???</p>
<h3 id="关于bank-conflict"><a href="#关于bank-conflict" class="headerlink" title="关于bank conflict"></a>关于bank conflict</h3><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/">https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/</a></p>
<p>对于一个32 × 32个元素的共享内存块，一列数据中的所有元素都映射到相同的SMEM bank ，导致bank conflict 的最坏情况:读取一列数据会导致32路的存储库冲突。</p>
<p>幸运的是，只需要将tile的元素宽度改为33，而不是32就行。</p>
<h2 id="优化实例2-数据归约"><a href="#优化实例2-数据归约" class="headerlink" title="优化实例2 - 数据归约"></a>优化实例2 - 数据归约</h2><p>具体问题：将长数组的所有元素，归约求和为一个结果</p>
<h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3><p>为了避免全局同步的巨大开销，采取分级归约<br><img src="https://pic.shaojiemike.top/img/20220515105630.png"></p>
<p>由于归约的计算密度低<br>1 flop per element loaded (bandwidth-optimal)</p>
<p>所以优化目标是将访存带宽用满。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">384-bit memory interface, 900 MHz DDR</span><br><span class="line">384 * 1800 / 8 = 86.4 GB/s</span><br></pre></td></tr></table></figure>

<h3 id="step0-baseline-Interleaved-Addressing-交错-间隔寻址"><a href="#step0-baseline-Interleaved-Addressing-交错-间隔寻址" class="headerlink" title="step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址"></a>step0 : baseline - Interleaved Addressing 交错&#x2F;间隔寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce0(int *g_idata, int *g_odata) &#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   // each thread loads one element from global to shared mem</span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">   sdata[tid] = g_idata[i];</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   // do reduction in shared mem</span><br><span class="line">   for(unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">      if (tid % (s) == 0) &#123;</span><br><span class="line">         sdata[tid] += sdata[tid + s];</span><br><span class="line">      &#125;</span><br><span class="line">      __syncthreads();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   // write result for this block to global mem</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515150953.png"><br>工作的线程越来越少。一开始是全部，最后一次只有thread0.</p>
<h3 id="Step1-使用连续的index"><a href="#Step1-使用连续的index" class="headerlink" title="Step1 : 使用连续的index"></a>Step1 : 使用连续的index</h3><p>Just replace divergent branch With strided index and non-divergent branch，但是会带来bank conflict。</p>
<p>原理和Warp发射有关，假如在这里每个Warp并行的线程是2。一个Warp运行耗时为T.</p>
<p>Step0: 4+4+2+1&#x3D;11T</p>
<p>Step1: 4+2+1+1&#x3D;8T</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123;</span><br><span class="line">   int index = 2 * s * tid;</span><br><span class="line">   if (index &lt; blockDim.x) &#123;</span><br><span class="line">      sdata[index] += sdata[index + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515144525.png"><br><img src="https://pic.shaojiemike.top/img/20220515151516.png"></p>
<h3 id="Step2-连续寻址"><a href="#Step2-连续寻址" class="headerlink" title="Step2: 连续寻址"></a>Step2: 连续寻址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=blockDim.x/2; s&gt;0; s&gt;&gt;=1) &#123;</span><br><span class="line">   if (tid &lt; s) &#123;</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   &#125;</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原本寻址<img src="https://pic.shaojiemike.top/img/20220515151840.png"></p>
<p>现在寻址有一边连续了<br><img src="https://pic.shaojiemike.top/img/20220515151937.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20220515152034.png"></p>
<h3 id="Step3-弥补浪费的线程"><a href="#Step3-弥补浪费的线程" class="headerlink" title="Step3 : 弥补浪费的线程"></a>Step3 : 弥补浪费的线程</h3><p>方法： 在load SMEM的时候提前做一次规约加法，通过减少一半的block数，将原本两个block里的值load+add存储在sum里。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// perform first level of reduction,</span><br><span class="line">// reading from global memory, writing to shared memory</span><br><span class="line">unsigned int tid = threadIdx.x;</span><br><span class="line">unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;</span><br><span class="line">sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515152704.png"></p>
<h3 id="step4-Unrolling-the-Last-Warp"><a href="#step4-Unrolling-the-Last-Warp" class="headerlink" title="step4 : Unrolling the Last Warp"></a>step4 : Unrolling the Last Warp</h3><p>当s&lt; 32的时候，就只有一个Warp工作了。</p>
<p>使用warp的SIMD还省去了<code>__syncthreads()</code>的麻烦</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for (unsigned int s=blockDim.x/2; s&gt;32; s&gt;&gt;=1) </span><br><span class="line">&#123;</span><br><span class="line">   if (tid &lt; s)</span><br><span class="line">      sdata[tid] += sdata[tid + s];</span><br><span class="line">   __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line">if (tid &lt; 32)</span><br><span class="line">&#123;</span><br><span class="line">   sdata[tid] += sdata[tid + 32]; </span><br><span class="line">   sdata[tid] += sdata[tid + 16]; </span><br><span class="line">   sdata[tid] += sdata[tid + 8]; </span><br><span class="line">   sdata[tid] += sdata[tid + 4]; </span><br><span class="line">   sdata[tid] += sdata[tid + 2]; </span><br><span class="line">   sdata[tid] += sdata[tid + 1]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了保持整洁，最后一个if还做了无效的计算。eg, Warp里的最后一个线程只有第一句命令有用。<br><img src="https://pic.shaojiemike.top/img/20220515162352.png"></p>
<h3 id="Step5-根据blockSize完全展开for和去除代码"><a href="#Step5-根据blockSize完全展开for和去除代码" class="headerlink" title="Step5 : 根据blockSize完全展开for和去除代码"></a>Step5 : 根据blockSize完全展开for和去除代码</h3><p>由于for循环里是二分的，而且小于32的单独处理了，导致for循环里实际运行代码最多就3句。</p>
<p>利用代码模板和编译器的自动优化实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce5(int *g_idata, int *g_odata)</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515163110.png"></p>
<p>红色代码会在编译时自动优化。<br><img src="https://pic.shaojiemike.top/img/20220515163243.png"></p>
<h3 id="step6-：归并算法优化"><a href="#step6-：归并算法优化" class="headerlink" title="step6 ：归并算法优化"></a>step6 ：归并算法优化</h3><p>加速级联？？</p>
<p>Cost&#x3D; processors × time complexity</p>
<p>我们知道N个元素直接二叉树归约是O(log N)<br>时间 Cost&#x3D;N*O(log N).</p>
<p>但是假如只有P个线程先做N&#x2F;P的串行加法, 然后是log(P)的归约。<br>总cost&#x3D;P(N&#x2F;P+log(P))</p>
<p>当P&#x3D;N&#x2F;log(N), cost&#x3D;O(N)</p>
<p>each thread should sum O(log n) elements来设置</p>
<p>比如，1024 or 2048 elements per block vs. 256 线程。每个sum n&#x3D;4个元素。 具体参数要perf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">unsigned int tid = threadIdx.x;</span><br><span class="line">unsigned int i = blockIdx.x*(blockSize*2) + threadIdx.x;</span><br><span class="line">unsigned int gridSize = blockSize*2*gridDim.x;</span><br><span class="line">sdata[tid] = 0;</span><br><span class="line">while (i &lt; n) &#123;</span><br><span class="line">   sdata[tid] += g_idata[i] + g_idata[i+blockSize];</span><br><span class="line">   i += gridSize;</span><br><span class="line">&#125;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p><img src="https://pic.shaojiemike.top/img/20220515171758.png"></p>
<h3 id="final-code"><a href="#final-code" class="headerlink" title="final code"></a>final code</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce6(int *g_idata, int *g_odata, unsigned int n)</span><br><span class="line">&#123;</span><br><span class="line">   extern __shared__ int sdata[];</span><br><span class="line"></span><br><span class="line">   unsigned int tid = threadIdx.x;</span><br><span class="line">   unsigned int i = blockIdx.x*(blockSize*2) + tid;</span><br><span class="line">   unsigned int gridSize = blockSize*2*gridDim.x;</span><br><span class="line">   sdata[tid] = 0;</span><br><span class="line"></span><br><span class="line">   do &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; while (i &lt; n);</span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   if (blockSize &gt;= 512) &#123; if (tid &lt; 256) &#123; sdata[tid] += sdata[tid + 256]; &#125; __syncthreads(); &#125;</span><br><span class="line">   if (blockSize &gt;= 256) &#123; if (tid &lt; 128) &#123; sdata[tid] += sdata[tid + 128]; &#125; __syncthreads(); &#125;</span><br><span class="line">   if (blockSize &gt;= 128) &#123; if (tid &lt; 64) &#123; sdata[tid] += sdata[tid + 64]; &#125; __syncthreads(); &#125;</span><br><span class="line"></span><br><span class="line">   if (tid &lt; 32) &#123;</span><br><span class="line">      if (blockSize &gt;= 64) sdata[tid] += sdata[tid + 32];</span><br><span class="line">      if (blockSize &gt;= 32) sdata[tid] += sdata[tid + 16];</span><br><span class="line">      if (blockSize &gt;= 16) sdata[tid] += sdata[tid + 8];</span><br><span class="line">      if (blockSize &gt;= 8) sdata[tid] += sdata[tid + 4];</span><br><span class="line">      if (blockSize &gt;= 4) sdata[tid] += sdata[tid + 2];</span><br><span class="line">      if (blockSize &gt;= 2) sdata[tid] += sdata[tid + 1];</span><br><span class="line">   &#125;</span><br><span class="line">   if (tid == 0) g_odata[blockIdx.x] = sdata[0];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="关于if语句的补充"><a href="#关于if语句的补充" class="headerlink" title="关于if语句的补充"></a>关于if语句的补充</h2><p>有if语句是没问题的，只要运行的时候全部执行if或者else就行。不要有些执行if，有些执行else，这才会等待。<img src="https://pic.shaojiemike.top/img/20220515153440.png"></p>
<p>说不定也不是全部执行if或者else就行，只需要连续32个Thread Index，是相同的执行就行。（猜想，需要测试。</p>
<h2 id="关于延迟隐藏"><a href="#关于延迟隐藏" class="headerlink" title="关于延迟隐藏"></a>关于延迟隐藏</h2><p>通过增加block里的线程数，并且同时读取来隐藏延迟。 不仅可以隐藏Global Memory的延迟，还可以隐藏写后读的延迟</p>
<p><img src="https://pic.shaojiemike.top/img/20220515181043.png"></p>
<h3 id="线程资源查看"><a href="#线程资源查看" class="headerlink" title="线程资源查看"></a>线程资源查看</h3><p>线程太多会导致分配到每一个的寄存器和SMEM变少</p>
<p>通过编译时加<code>-cubin</code>选项，<code>.cubin</code>文件前几行会显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">architecture &#123;sm_10&#125;</span><br><span class="line">abiversion &#123;0&#125;</span><br><span class="line">modname &#123;cubin&#125;</span><br><span class="line">code &#123;</span><br><span class="line">   name = BlackScholesGPU</span><br><span class="line">   lmem = 0    # per thread local memory</span><br><span class="line">   smem = 68   # per thread block shared memory</span><br><span class="line">   reg = 20    # per thread registers</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf">https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf</a></p>
<p>类似的cuda优化资料有09年的， 清华 邓仰东 cuda lecture pdf <a target="_blank" rel="noopener" href="https://download.csdn.net/download/yujia269/4203734%E3%80%82">https://download.csdn.net/download/yujia269/4203734。</a> 注意也是参考的上面Nvidia的这个。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-12T01:18:42.000Z" title="5/12/2022, 1:18:42 AM">2022-05-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.572Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">3 minutes read (About 424 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/12/Work/software/perf/nvprof/">Nvprof</a></p><div class="content"><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ which nvprof </span><br><span class="line">/usr/local/cuda/bin/nvprof</span><br></pre></td></tr></table></figure>

<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><h3 id="摘要模式"><a href="#摘要模式" class="headerlink" title="摘要模式"></a>摘要模式</h3><p>命令行直接运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="跟踪API"><a href="#跟踪API" class="headerlink" title="跟踪API"></a>跟踪API</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvprof --print-gpu-trace ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="保存在log里"><a href="#保存在log里" class="headerlink" title="保存在log里"></a>保存在log里</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/nvprof --log-file a.log --metrics achieved_occupancy /staff/shaojiemike/github/cutests/22-commonstencil/common</span><br></pre></td></tr></table></figure>

<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ol>
<li>nsight可以直接在远程机器上运行<ol>
<li>ssh -X host</li>
<li>.ssh&#x2F;config<ol>
<li>add</li>
<li>XAuthLocation &#x2F;opt&#x2F;X11&#x2F;bin&#x2F;xauth #for macbookAir</li>
<li>ForwardX11Trusted yes</li>
<li>ForwardX11 yes</li>
</ol>
</li>
</ol>
</li>
<li>Visual Profiler也可以ssh直接连接远程机器</li>
<li>或者导出分析结果以便可视化, 在Visual Profiler使用</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvprof --export-profile timeline.prof &lt;app&gt; &lt;app args&gt;</span><br><span class="line">nvprof --analysis-metrics -o  nbody-analysis.nvprof ./myApp</span><br></pre></td></tr></table></figure>

<h3 id="profile-kernel"><a href="#profile-kernel" class="headerlink" title="profile kernel"></a>profile kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/cuda/bin/ncu -k stencil_kernel -s 0 -c 1 /staff/shaojiemike/github/cutests/22-commonstencil/best</span><br></pre></td></tr></table></figure>

<p>ncu-ui是可视化界面，但是没弄懂</p>
<h2 id="带宽profile"><a href="#带宽profile" class="headerlink" title="带宽profile"></a>带宽profile</h2><h3 id="上限测量"><a href="#上限测量" class="headerlink" title="上限测量"></a>上限测量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:02:08]                                                                                                                                                                      $ ./bin/x86_64/linux/release/bandwidthTest                                                                                                                                                                                           [CUDA Bandwidth Test] - Starting...                                                                                                                                                                                                  Running on...                                                                                                                                                                                                                                                                                                                                                                                                                                                              Device 0: Tesla P40                                                                                                                                                                                                                  Quick Mode                                                                                                                                                                                                                                                                                                                                                                                                                                                                Host to Device Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     11.8                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Host Bandwidth, 1 Device(s)                                                                                                                                                                                                PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     13.0                                                                                                                                                                                                                                                                                                                                                                                                                                       Device to Device Bandwidth, 1 Device(s)                                                                                                                                                                                              PINNED Memory Transfers                                                                                                                                                                                                                Transfer Size (Bytes)        Bandwidth(GB/s)                                                                                                                                                                                         32000000                     244.3                                                                                                                                                                                                                                                                                                                                                                                                                                     Result = PASS                                                                                                                                                                                                                                                                                                                                                                                                                                                             NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.                                                                                                                                                                                       # shaojiemike @ snode0 in ~/github/cuda-samples-11.0 [16:03:24]                                                                                                                                                                      $ ./bin/x86_64/linux/release/p2pBandwidthLatencyTest        </span><br></pre></td></tr></table></figure>

<h3 id="实际值"><a href="#实际值" class="headerlink" title="实际值"></a>实际值</h3><p>nvprof通过指定与dram，L1或者L2 的metrics来实现。具体解释可以参考<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">官网</a></p>
<p>在 Maxwell 和之后的架构中 L1 和 SMEM 合并</p>
<table>
<thead>
<tr>
<th>Metric Name</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>achieved_occupancy</td>
<td>活跃cycle是 Warps 活跃的比例</td>
</tr>
<tr>
<td>dram_read_throughput</td>
<td></td>
</tr>
<tr>
<td>dram_utilization</td>
<td>在0到10的范围内，相对于峰值利用率，设备内存的利用率水平</td>
</tr>
<tr>
<td>shared_load_throughput</td>
<td></td>
</tr>
<tr>
<td>shared_utilization</td>
<td></td>
</tr>
<tr>
<td>l2_utilization</td>
<td></td>
</tr>
</tbody></table>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-06T11:59:48.000Z" title="5/6/2022, 11:59:48 AM">2022-05-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.560Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/toLearn/">toLearn</a></span><span class="level-item">a few seconds read (About 41 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/06/Work/Programming/2-languageGrammar/php/">Php</a></p><div class="content"><h2 id="enable-php-curl-extension"><a href="#enable-php-curl-extension" class="headerlink" title="enable php curl extension"></a>enable php curl extension</h2><h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无

</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-03T16:00:00.000Z" title="5/3/2022, 4:00:00 PM">2022-05-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.544Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">a few seconds read (About 58 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/03/OutOfWork/3-homepage/blogBuilder/3-hugo/">Hugo</a></p><div class="content"><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hugo new posts/hugo.md</span><br><span class="line"></span><br><span class="line"># 预览</span><br><span class="line">hugo server -D -d ./tmp</span><br><span class="line"># or</span><br><span class="line">hugo server --buildDrafts ./tmp</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-27T16:00:00.000Z" title="4/27/2022, 4:00:00 PM">2022-04-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.576Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/toLearn/">toLearn</a></span><span class="level-item">2 minutes read (About 337 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/27/diary/3-EfficientLife/presentation/">Presentation</a></p><div class="content"><h2 id="目前的缺点"><a href="#目前的缺点" class="headerlink" title="目前的缺点"></a>目前的缺点</h2><ol>
<li>湖南口音严重</li>
<li>声音听上去紧张，节奏很快，吐字不清。</li>
</ol>
<h2 id="PPT展示的注意事项"><a href="#PPT展示的注意事项" class="headerlink" title="PPT展示的注意事项"></a>PPT展示的注意事项</h2><h3 id="PPT制作"><a href="#PPT制作" class="headerlink" title="PPT制作"></a>PPT制作</h3><ol>
<li>注意条理，和各页PPT的联系、衔接话语</li>
<li>多图，少数据和大段文字。只有关键数据和文字来辅助观点说明。图形转换的小动画效果也很好</li>
<li>看情况，讲主题的由来，和最后的展望、改进</li>
<li>（讲论文）注意作者，机构，会议和时间</li>
</ol>
<h3 id="演讲"><a href="#演讲" class="headerlink" title="演讲"></a>演讲</h3><ol>
<li>清晰，有条理的通过感谢(可视化，比喻，具体的有趣例子说明)来传递核心观点</li>
<li>注意侧重，(最后展示或者外行科普，而不是学术研讨)讲好的部分，局限性和不足之处就没必要讲了</li>
<li>激光笔来引导听众注意</li>
</ol>
<h2 id="ETH-Writing-Resources-good-paper"><a href="#ETH-Writing-Resources-good-paper" class="headerlink" title="ETH Writing Resources&#x2F;good paper"></a>ETH Writing Resources&#x2F;good paper</h2><p><img src="https://pic.shaojiemike.top/shaojiemike/2023/11/08a195953d6ec3853192780e262eba74.png"></p>
<ul>
<li>A paper is the artwork of a researcher.It is important to treat it that way and be very thorough with it.</li>
</ul>
<h3 id="Keep-in-mind"><a href="#Keep-in-mind" class="headerlink" title="Keep in mind"></a>Keep in mind</h3><ol>
<li>解释背景</li>
<li>由大到小，自顶向下，</li>
<li>简明扼要的谈论问题</li>
<li>短句为主</li>
<li>现在时态为主</li>
<li>名词单数表述</li>
<li>优先级结构清晰</li>
<li>title abstract intro 是最重要的</li>
<li>用主动时态，而不是被动式</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-23T16:00:00.000Z" title="4/23/2022, 4:00:00 PM">2022-04-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.568Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/network/">network</a></span><span class="level-item">10 minutes read (About 1530 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/23/Work/network/example/tcpdump/">Tcpdump &amp; wireshark</a></p><div class="content"><h2 id="命令行查看当前机器公网ip"><a href="#命令行查看当前机器公网ip" class="headerlink" title="命令行查看当前机器公网ip"></a>命令行查看当前机器公网ip</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; curl myip.ipip.net</span><br><span class="line">当前 IP：<span class="number">117.136</span><span class="number">.101</span><span class="number">.72</span>  来自于：中国 安徽   移动</span><br></pre></td></tr></table></figure>
<h2 id="检测机器端口开放"><a href="#检测机器端口开放" class="headerlink" title="检测机器端口开放"></a>检测机器端口开放</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 网页服务直接下载检查内容</span><br><span class="line">wget 4.shaojiemike.top:28096</span><br><span class="line"># -z 选项指示 nc 仅扫描打开的端口，而不发送任何数据，并且 -v 用于获取更多详细信息。</span><br><span class="line">nc -z -v 4.shaojiemike.top 28096</span><br></pre></td></tr></table></figure>
<p>或者扫描指定端口</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># IPV6 也行</span><br><span class="line">$ nmap -6 -p 8096 2001:da8:d800:611:5464:f7ab:9560:a646</span><br><span class="line">Starting Nmap 7.80 ( https://nmap.org ) at 2023-01-04 19:33 CST</span><br><span class="line">Nmap scan report for 2001:da8:d800:611:5464:f7ab:9560:a646</span><br><span class="line">Host is up (0.00099s latency).</span><br><span class="line"></span><br><span class="line">PORT     STATE SERVICE</span><br><span class="line">8096/tcp open  unknown</span><br><span class="line"></span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 0.05 seconds</span><br><span class="line"></span><br><span class="line">$ nmap -p 28096 4.shaojiemike.top</span><br><span class="line">Starting Nmap 7.80 ( https://nmap.org ) at 2023-01-04 19:19 CST</span><br><span class="line">Nmap scan report for 4.shaojiemike.top (114.214.181.97)</span><br><span class="line">Host is up (0.0011s latency).</span><br><span class="line"></span><br><span class="line">PORT      STATE SERVICE</span><br><span class="line">28096/tcp open  unknown</span><br><span class="line"></span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 0.05 seconds</span><br></pre></td></tr></table></figure>
<p>全部端口，但是会很慢。50分钟</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nmap -sT -p- 4.shaojiemike.top</span><br></pre></td></tr></table></figure>

<h2 id="wireshark"><a href="#wireshark" class="headerlink" title="wireshark"></a>wireshark</h2><h3 id="显示过滤"><a href="#显示过滤" class="headerlink" title="显示过滤"></a>显示过滤</h3><p>上方的过滤窗口</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tcp.port==80&amp;&amp;(ip.dst==192.168.1.2||ip.dst==192.168.1.3)</span><br><span class="line"></span><br><span class="line">ip.addr ==192.168.1.1 //显示所有目标或源地址是192.168.1.1的数据包</span><br><span class="line">eth.addr== 80:f6:2e:ce:3f:00 //根据MAC地址过滤，详见“wireshark过滤MAC地址/物理地址”</span><br><span class="line">tcp.port==23</span><br></pre></td></tr></table></figure>
<h3 id="捕捉过滤"><a href="#捕捉过滤" class="headerlink" title="捕捉过滤"></a>捕捉过滤</h3><p>抓包前在capture option中设置，仅捕获符合条件的包，可以避免产生较大的捕获文件和内存占用，但不能完整的复现测试时的网络环境。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">host 192.168.1.1 //抓取192.168.1.1 收到和发出的所有数据包</span><br><span class="line">src host 192.168.1.1 //源地址，192.168.1.1发出的所有数据包</span><br><span class="line">dst host 192.168.1.1 //目标地址，192.168.1.1收到的所有数据包</span><br></pre></td></tr></table></figure>

<h3 id="color-含义"><a href="#color-含义" class="headerlink" title="color 含义"></a>color 含义</h3><p><img src="https://pic.shaojiemike.top/img/20221118093115.png"></p>
<h2 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h2><p>传统命令行抓包工具</p>
<h2 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h2><p><strong>注意过滤规则间的and</strong></p>
<ol>
<li><code>-nn</code> :<ol>
<li>单个 n 表示不解析域名，直接显示 IP；</li>
<li>两个 n 表示不解析域名和端口。</li>
<li>方便查看 IP 和端口号，</li>
<li>不需要域名解析会非常高效。</li>
</ol>
</li>
<li><code>-i</code> 指定网卡 <code>-D</code>查看网卡</li>
<li><code>-v</code>，<code>-vv</code> 和 <code>-vvv</code> 来显示更多的详细信息</li>
<li><code>port 80</code> 抓取 80 端口上的流量，通常是 HTTP。在前面加<code>src</code>,<code>dst</code>限定词<ol>
<li><code>tcpudmp -i eth0 -n arp host 192.168.199</code> 抓取192.168.199.* 网段的arp协议包，arp可以换为tcp,udp等。</li>
</ol>
</li>
<li><code>-A</code>,<code>-X</code>,<code>-xx</code>会逐渐显示包内容更多信息</li>
<li><code>-e</code> : 显示数据链路层信息。<ol>
<li>默认情况下 tcpdump 不会显示数据链路层信息，使用 -e 选项可以显示源和目的 MAC 地址，以及 VLAN tag 信息。</li>
</ol>
</li>
</ol>
<h2 id="输出说明"><a href="#输出说明" class="headerlink" title="输出说明"></a>输出说明</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.106.56166 &gt; 124.192.132.54.80</span><br></pre></td></tr></table></figure>

<ol>
<li>ip 是 192.168.1.106，源端口是 56166，</li>
<li>目的地址是 124.192.132.54，目的端口是 80。</li>
<li><code>&gt;</code> 符号代表数据的方向。</li>
</ol>
<h3 id="Flags"><a href="#Flags" class="headerlink" title="Flags"></a>Flags</h3><p>常见的三次握手 TCP 报文的 Flags:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[S] : SYN（开始连接）</span><br><span class="line">[.] : 没有 Flag</span><br><span class="line">[P] : PSH（推送数据）</span><br><span class="line">[F] : FIN （结束连接）</span><br><span class="line">[R] : RST（重置连接）</span><br></pre></td></tr></table></figure>

<h3 id="常见用途"><a href="#常见用途" class="headerlink" title="常见用途"></a>常见用途</h3><ol>
<li>根据目的IP，筛选网络经过的网卡和端口</li>
<li>能抓各种协议的包比如<a target="_blank" rel="noopener" href="https://linux.cn/article-10191-1.html">ping</a>，ssh</li>
</ol>
<h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl --trace-ascii - www.github.com</span><br></pre></td></tr></table></figure>

<p>github ip 为 20.205.243.166</p>
<p>ifconfig显示 <code>ibs5</code>的网卡有21TB的带宽上限，肯定是IB卡了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo tcpdump -i ibs5 &#x27;((tcp) and (host 20.205.243.166))&#x27;</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on ibs5, link-type LINUX_SLL (Linux cooked v1), capture size 262144 bytes</span><br><span class="line">15:53:53.848619 IP snode0.59878 &gt; 20.205.243.166.http: Flags [S], seq 879685062, win 64128, options [mss 2004,sackOK,TS val 4096492456 ecr 0,nop,wscale 7], length 0</span><br><span class="line">15:53:53.952705 IP 20.205.243.166.http &gt; snode0.59878: Flags [S.], seq 1917452372, ack 879685063, win 65535, options [mss 1436,sackOK,TS val 1127310087 ecr 4096492456,nop,wscale 10], length 0</span><br><span class="line">15:53:53.952728 IP snode0.59878 &gt; 20.205.243.166.http: Flags [.], ack 1, win 501, options [nop,nop,TS val 4096492560 ecr 1127310087], length 0</span><br><span class="line">15:53:53.953208 IP snode0.59878 &gt; 20.205.243.166.http: Flags [P.], seq 1:79, ack 1, win 501, options [nop,nop,TS val 4096492561 ecr 1127310087], length 78: HTTP: GET / HTTP/1.1</span><br><span class="line">15:53:54.058654 IP 20.205.243.166.http &gt; snode0.59878: Flags [P.], seq 1:89, ack 79, win 64, options [nop,nop,TS val 1127310193 ecr 4096492561], length 88: HTTP: HTTP/1.1 301 Moved Permanently</span><br><span class="line">15:53:54.058668 IP snode0.59878 &gt; 20.205.243.166.http: Flags [.], ack 89, win 501, options [nop,nop,TS val 4096492666 ecr 1127310193], length 0</span><br><span class="line">15:53:54.059092 IP snode0.59878 &gt; 20.205.243.166.http: Flags [F.], seq 79, ack 89, win 501, options [nop,nop,TS val 4096492667 ecr 1127310193], length 0</span><br><span class="line">15:53:54.162608 IP 20.205.243.166.http &gt; snode0.59878: Flags [F.], seq 89, ack 80, win 64, options [nop,nop,TS val 1127310297 ecr 4096492667], length 0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tcpdump -i ibs5 -nn -vvv -e &#x27;((port 80) and (tcp) and (host 20.205.243.166))&#x27;                                                                                                                                                 tcpdump: listening on ibs5, link-type LINUX_SLL (Linux cooked v1), capture size 262144 bytes</span><br><span class="line">16:09:38.743478 Out ethertype IPv4 (0x0800), length 76: (tos 0x0, ttl 64, id 15215, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    10.1.13.50.38376 &gt; 20.205.243.166.80: Flags [S], cksum 0x1fd5 (incorrect -&gt; 0x98b6), seq 1489092902, win 64128, options [mss 2004,sackOK,TS val 4097437351 ecr 0,nop,wscale 7], length 0</span><br><span class="line">16:09:38.848164  In ethertype IPv4 (0x0800), length 76: (tos 0x0, ttl 48, id 0, offset 0, flags [DF], proto TCP (6), length 60)</span><br><span class="line">    20.205.243.166.80 &gt; 10.1.13.50.38376: Flags [S.], cksum 0x69ba (correct), seq 3753100548, ack 1489092903, win 65535, options [mss 1436,sackOK,TS val 3712395681 ecr 4097437351,nop,wscale 10], length 0</span><br><span class="line">16:09:38.848212 Out ethertype IPv4 (0x0800), length 68: (tos 0x0, ttl 64, id 15216, offset 0, flags [DF], proto TCP (6), length 52)</span><br><span class="line">    10.1.13.50.38376 &gt; 20.205.243.166.80: Flags [.], cksum 0x1fcd (incorrect -&gt; 0x9613), seq 1, ack 1, win 501, options [nop,nop,TS val 4097437456 ecr 3712395681], length 0</span><br><span class="line">16:09:38.848318 Out ethertype IPv4 (0x0800), length 146: (tos 0x0, ttl 64, id 15217, offset 0, flags [DF], proto TCP (6), length 130)</span><br><span class="line">    10.1.13.50.38376 &gt; 20.205.243.166.80: Flags [P.], cksum 0x201b (incorrect -&gt; 0x9f0a), seq 1:79, ack 1, win 501, options [nop,nop,TS val 4097437456 ecr 3712395681], length 78: HTTP, length: 78</span><br><span class="line">        GET / HTTP/1.1</span><br><span class="line">        Host: www.github.com</span><br><span class="line">        User-Agent: curl/7.68.0</span><br><span class="line">        Accept: */*</span><br><span class="line"></span><br><span class="line">16:09:38.954152  In ethertype IPv4 (0x0800), length 156: (tos 0x0, ttl 48, id 45056, offset 0, flags [DF], proto TCP (6), length 140)</span><br><span class="line">    20.205.243.166.80 &gt; 10.1.13.50.38376: Flags [P.], cksum 0x024d (correct), seq 1:89, ack 79, win 64, options [nop,nop,TS val 3712395786 ecr 4097437456], length 88: HTTP, length: 88</span><br><span class="line">        HTTP/1.1 301 Moved Permanently</span><br><span class="line">        Content-Length: 0</span><br><span class="line">        Location: https://www.github.com/</span><br><span class="line"></span><br><span class="line">16:09:38.954207 Out ethertype IPv4 (0x0800), length 68: (tos 0x0, ttl 64, id 15218, offset 0, flags [DF], proto TCP (6), length 52)</span><br><span class="line">    10.1.13.50.38376 &gt; 20.205.243.166.80: Flags [.], cksum 0x1fcd (incorrect -&gt; 0x949a), seq 79, ack 89, win 501, options [nop,nop,TS val 4097437562 ecr 3712395786], length 0</span><br><span class="line">16:09:38.954884 Out ethertype IPv4 (0x0800), length 68: (tos 0x0, ttl 64, id 15219, offset 0, flags [DF], proto TCP (6), length 52)</span><br><span class="line">    10.1.13.50.38376 &gt; 20.205.243.166.80: Flags [F.], cksum 0x1fcd (incorrect -&gt; 0x9498), seq 79, ack 89, win 501, options [nop,nop,TS val 4097437563 ecr 3712395786], length 0</span><br><span class="line">16:09:39.060177  In ethertype IPv4 (0x0800), length 68: (tos 0x0, ttl 48, id 45057, offset 0, flags [DF], proto TCP (6), length 52)</span><br><span class="line">    20.205.243.166.80 &gt; 10.1.13.50.38376: Flags [F.], cksum 0x95e2 (correct), seq 89, ack 80, win 64, options [nop,nop,TS val 3712395892 ecr 4097437563], length 0</span><br><span class="line">16:09:39.060221 Out ethertype IPv4 (0x0800), length 68: (tos 0x0, ttl 64, id 15220, offset 0, flags [DF], proto TCP (6), length 52)</span><br><span class="line">    10.1.13.50.38376 &gt; 20.205.243.166.80: Flags [.], cksum 0x1fcd (incorrect -&gt; 0x93c4), seq 80, ack 90, win 501, options [nop,nop,TS val 4097437668 ecr 3712395892], length 0</span><br><span class="line">16:09:46.177269 Out ethertype IPv4 (0x0800), length 76: (tos 0x0, ttl 64, id 38621, offset 0, flags [DF], proto TCP (6), length 60)</span><br></pre></td></tr></table></figure>

<p>snode0 ip 是 10.1.13.50</p>
<h2 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h2><p>mtr &#x3D; traceroute+ping</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ traceroute www.baid.com</span><br><span class="line">traceroute to www.baidu.com (182.61.200.6), 30 hops max, 60 byte packets                                                                                                                                                           </span><br><span class="line">1  acsa-nfs (10.1.13.1)  0.179 ms  0.180 ms  0.147 ms                                                                                                                                                                            </span><br><span class="line">2  192.168.252.1 (192.168.252.1)  2.016 ms  1.954 ms  1.956 ms                                                                                                                                                                   </span><br><span class="line">3  202.38.75.254 (202.38.75.254)  4.942 ms  3.941 ms  4.866 ms   </span><br></pre></td></tr></table></figure>

<p>traceroute命令用于显示数据包到主机间的路径。</p>
<h2 id="NETWORKMANAGER-管理"><a href="#NETWORKMANAGER-管理" class="headerlink" title="NETWORKMANAGER 管理"></a>NETWORKMANAGER 管理</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in /etc/NetworkManager [16:49:55]</span><br><span class="line">$ nmcli general status</span><br><span class="line">STATE         CONNECTIVITY  WIFI-HW  WIFI     WWAN-HW  WWAN</span><br><span class="line">disconnected  unknown       enabled  enabled  enabled  enabled</span><br><span class="line"></span><br><span class="line"># shaojiemike @ snode0 in /etc/NetworkManager [16:50:40]</span><br><span class="line">$ nmcli connection show</span><br><span class="line">NAME                     UUID                                  TYPE        DEVICE</span><br><span class="line">InfiniBand connection 1  7edf4eea-0591-48ba-868a-e66e8cb720ce  infiniband  --</span><br></pre></td></tr></table></figure>

<p>好像之前使用过的样子。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># shaojiemike @ snode0 in /etc/NetworkManager [16:56:36] C:127</span><br><span class="line">$ service network-manager status</span><br><span class="line">● NetworkManager.service - Network Manager</span><br><span class="line">     Loaded: loaded (/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled)</span><br><span class="line">     Active: active (running) since Mon 2022-03-14 11:52:06 CST; 1 months 10 days ago</span><br><span class="line">       Docs: man:NetworkManager(8)</span><br><span class="line">   Main PID: 1339 (NetworkManager)</span><br><span class="line">      Tasks: 3 (limit: 154500)</span><br><span class="line">     Memory: 12.0M</span><br><span class="line">     CGroup: /system.slice/NetworkManager.service</span><br><span class="line">             └─1339 /usr/sbin/NetworkManager --no-daemon</span><br><span class="line"></span><br><span class="line">Warning: some journal files were not opened due to insufficient permissions.</span><br></pre></td></tr></table></figure>

<p>应该是这个 <a target="_blank" rel="noopener" href="https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm/">Secure site-to-site connection with Linux IPsec VPN</a> 来设置的</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>FJW说所有网络都是通过NFS一起出去的</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-23T16:00:00.000Z" title="4/23/2022, 4:00:00 PM">2022-04-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.572Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">2 minutes read (About 272 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/23/Work/software/linux/servers/">Servers</a></p><div class="content"><h2 id="通过IPMI芯片的静态IP远程重启和配置机器"><a href="#通过IPMI芯片的静态IP远程重启和配置机器" class="headerlink" title="通过IPMI芯片的静态IP远程重启和配置机器"></a>通过IPMI芯片的静态IP远程重启和配置机器</h2><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1448642">https://cloud.tencent.com/developer/article/1448642</a></p>
<h2 id="Group"><a href="#Group" class="headerlink" title="Group"></a>Group</h2><h3 id="当前组"><a href="#当前组" class="headerlink" title="当前组"></a>当前组</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shaojiemike@snode6:~$ groups shaojiemike</span><br><span class="line">shaojiemike : staff sudo</span><br></pre></td></tr></table></figure>

<h3 id="所有组"><a href="#所有组" class="headerlink" title="所有组"></a>所有组</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/group</span><br></pre></td></tr></table></figure>

<h2 id="User"><a href="#User" class="headerlink" title="User"></a>User</h2><h3 id="whoami"><a href="#whoami" class="headerlink" title="whoami"></a>whoami</h3><h3 id="一般用户位置"><a href="#一般用户位置" class="headerlink" title="一般用户位置"></a>一般用户位置</h3><p>&#x2F;etc&#x2F;passwd</p>
<h3 id="LDAP教程"><a href="#LDAP教程" class="headerlink" title="LDAP教程"></a>LDAP教程</h3><p>如果发现自己不在&#x2F;etc&#x2F;passwd里，很可能使用了ldap 集中身份认证。可以在多台机器上实现分布式账号登录，用同一个账号。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getent passwd </span><br></pre></td></tr></table></figure>

<h2 id="first-reboot-server"><a href="#first-reboot-server" class="headerlink" title="first reboot server"></a>first reboot server</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ctrl + alt + F3     <span class="meta">#jump into command <span class="keyword">line</span></span></span><br><span class="line">login</span><br><span class="line">su - &#123;user-name&#125;</span><br><span class="line">sudo -s</span><br><span class="line">sudo -i</span><br><span class="line"># If invoked without a user name, su defaults to becoming the superuser</span><br><span class="line">ip a |less          <span class="meta">#check ip address fjw弄了静态IP就没这个问题了</span></span><br></pre></td></tr></table></figure>

<h2 id="限制当前shell用户爆内存"><a href="#限制当前shell用户爆内存" class="headerlink" title="限制当前shell用户爆内存"></a>限制当前shell用户爆内存</h2><p>宕机一般是爆内存，进程分配肯定会注意不超过物理核个数。</p>
<p>在zshrc里写入 25*1024*1024 &#x3D; 25GB的内存上限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit -v 26214400</span><br></pre></td></tr></table></figure>
<p>当前shell程序超内存，会输出<code>Memory Error</code>结束。</p>
<h3 id="测试读取200GB大文件到内存"><a href="#测试读取200GB大文件到内存" class="headerlink" title="测试读取200GB大文件到内存"></a>测试读取200GB大文件到内存</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with open(&quot;/home/shaojiemike/test/DynamoRIO/OpenBLASRawAssembly/openblas_utest.log&quot;, &#x27;r&#x27;) as f:</span><br><span class="line">    data= f.readlines()</span><br><span class="line">    print(len(data))</span><br></pre></td></tr></table></figure>

<p>有文章说<a target="_blank" rel="noopener" href="https://icode.best/i/70572540707312">Linux有些版本内核会失效</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-13T13:39:29.000Z" title="4/13/2022, 1:39:29 PM">2022-04-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.552Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">22 minutes read (About 3279 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/13/Work/Artificial%20Intelligence/PyTorchGeometric/">PyTorchGeometric</a></p><div class="content"><h2 id="PyTorch-Geometric-Liberty"><a href="#PyTorch-Geometric-Liberty" class="headerlink" title="PyTorch Geometric Liberty"></a>PyTorch Geometric Liberty</h2><p>PyG是一个基于PyTorch的用于处理不规则数据（比如图）的库，或者说是一个用于在图等数据上快速实现表征学习的框架。它的运行速度很快，训练模型速度可以达到DGL（Deep Graph Library ）v0.2 的40倍（数据来自论文）。除了出色的运行速度外，PyG中也集成了很多论文中提出的方法（GCN,SGC,GAT,SAGE等等）和常用数据集。因此对于复现论文来说也是相当方便。</p>
<p>经典的库才有函数可以支持，自己的模型，自己根据自动微分实现。还要自己写GPU并行。</p>
<p>MessagePassing 是网络交互的核心</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="数据怎么存储"><a href="#数据怎么存储" class="headerlink" title="数据怎么存储"></a>数据怎么存储</h3><p>torch_geometric.data.Data (下面简称Data) 用于构建图</p>
<ol>
<li>每个节点的特征 x<ol>
<li>形状是[num_nodes, num_node_features]。</li>
</ol>
</li>
<li>节点之间的边 edge_index<ol>
<li>形状是 [2, num_edges]</li>
</ol>
</li>
<li>节点的标签 y<ol>
<li>假如有。形状是[num_nodes, *]</li>
</ol>
</li>
<li>边的特征 edge_attr<ol>
<li>[num_edges, num_edge_features]</li>
</ol>
</li>
</ol>
<h3 id="数据支持自定义"><a href="#数据支持自定义" class="headerlink" title="数据支持自定义"></a>数据支持自定义</h3><p>通过data.face来扩展Data</p>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><p>在 PyG 中，我们使用的不是这种写法，而是在get()函数中根据 index 返回torch_geometric.data.Data类型的数据，在Data里包含了数据和 label。</p>
<h3 id="数据处理的例子"><a href="#数据处理的例子" class="headerlink" title="数据处理的例子"></a>数据处理的例子</h3><p><img src="https://pic.shaojiemike.top/img/20220413165624.png"><br>由于是无向图，因此有 4 条边：(0 -&gt; 1), (1 -&gt; 0), (1 -&gt; 2), (2 -&gt; 1)。每个节点都有自己的特征。上面这个图可以使用 <code>torch_geometric.data.Data</code>来表示如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch_geometric.data import Data</span><br><span class="line"># 由于是无向图，因此有 4 条边：(0 -&gt; 1), (1 -&gt; 0), (1 -&gt; 2), (2 -&gt; 1)</span><br><span class="line">edge_index = torch.tensor([[0, 1, 1, 2],</span><br><span class="line">                           [1, 0, 2, 1]], dtype=torch.long)</span><br><span class="line"># 节点的特征                         </span><br><span class="line">x = torch.tensor([[-1], [0], [1]], dtype=torch.float)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index)</span><br></pre></td></tr></table></figure>

<p>注意edge_index中边的存储方式，有两个list，第 1 个list是边的起始点，第 2 个list是边的目标节点。注意与下面的存储方式的区别。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch_geometric.data import Data</span><br><span class="line"></span><br><span class="line">edge_index = torch.tensor([[0, 1],</span><br><span class="line">                           [1, 0],</span><br><span class="line">                           [1, 2],</span><br><span class="line">                           [2, 1]], dtype=torch.long)</span><br><span class="line">x = torch.tensor([[-1], [0], [1]], dtype=torch.float)</span><br><span class="line"></span><br><span class="line">data = Data(x=x, edge_index=edge_index.t().contiguous())</span><br></pre></td></tr></table></figure>

<p>这种情况edge_index需要先转置然后使用contiguous()方法。关于contiguous()函数的作用，查看 PyTorch中的contiguous。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> InMemoryDataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyOwnDataset</span>(<span class="title class_ inherited__">InMemoryDataset</span>): <span class="comment"># or (Dataset)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, transform=<span class="literal">None</span>, pre_transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MyOwnDataset, self).__init__(root, transform, pre_transform)</span><br><span class="line">        self.data, self.slices = torch.load(self.processed_paths[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回一个包含没有处理的数据的名字的list。如果你只有一个文件，那么它返回的list将只包含一个元素。事实上，你可以返回一个空list，然后确定你的文件在后面的函数process()中。</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">raw_file_names</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;some_file_1&#x27;</span>, <span class="string">&#x27;some_file_2&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 很像上一个函数，它返回一个包含所有处理过的数据的list。在调用process()这个函数后，通常返回的list只有一个元素，它只保存已经处理过的数据的名字。</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">processed_file_names</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">&#x27;data.pt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="comment"># Download to `self.raw_dir`. or just pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整合你的数据成一个包含data的list。然后调用 self.collate()去计算将用DataLodadr的片段。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># Read data into huge `Data` list.</span></span><br><span class="line">        data_list = [...]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_filter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list [data <span class="keyword">for</span> data <span class="keyword">in</span> data_list <span class="keyword">if</span> self.pre_filter(data)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pre_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data_list = [self.pre_transform(data) <span class="keyword">for</span> data <span class="keyword">in</span> data_list]</span><br><span class="line"></span><br><span class="line">        data, slices = self.collate(data_list)</span><br><span class="line">        torch.save((data, slices), self.processed_paths[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>DataLoader 这个类允许你通过batch的方式feed数据。创建一个DotaLoader实例，可以简单的指定数据集和你期望的batch size。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loader = DataLoader(dataset, batch_size=512, shuffle=True)</span><br></pre></td></tr></table></figure>

<p>DataLoader的每一次迭代都会产生一个Batch对象。它非常像Data对象。但是带有一个‘batch’属性。它指明了了对应图上的节点连接关系。因为DataLoader聚合来自不同图的的batch的x,y 和edge_index，所以GNN模型需要batch信息去知道那个节点属于哪一图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for batch in loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; Batch(x=[1024, 21], edge_index=[2, 1568], y=[512], batch=[1024])</span><br></pre></td></tr></table></figure>

<h2 id="MessagePassing-核心"><a href="#MessagePassing-核心" class="headerlink" title="MessagePassing(核心)"></a>MessagePassing(核心)</h2><p><img src="https://pic.shaojiemike.top/img/20220413214848.png"><br>其中，x 表示表格节点的 embedding，e 表示边的特征，ϕ 表示 message 函数，□ 表示聚合 aggregation 函数，γ 表示 update 函数。上标表示层的 index，比如说，当 k &#x3D; 1 时，x 则表示所有输入网络的图结构的数据。</p>
<p>为了实现这个，我们需要定义：</p>
<ol>
<li>message<ol>
<li>定义了对于每个节点对 (xi,xj)，怎样生成信息（message）。</li>
</ol>
</li>
<li>update</li>
<li>aggregation scheme</li>
<li>propagate(edge_index, size&#x3D;None, **kwargs)<ol>
<li>这个函数最终会按序调用 message、aggregate 和 update 函数。</li>
</ol>
</li>
<li>update(aggr_out, **kwargs)<ol>
<li>这个函数利用聚合好的信息（message）更新每个节点的 embedding。</li>
</ol>
</li>
</ol>
<h3 id="propagate-edge-index-Union-torch-Tensor-torch-sparse-tensor-SparseTensor-size-Optional-Tuple-int-int-None-kwargs"><a href="#propagate-edge-index-Union-torch-Tensor-torch-sparse-tensor-SparseTensor-size-Optional-Tuple-int-int-None-kwargs" class="headerlink" title="propagate(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Optional[Tuple[int, int]] &#x3D; None, **kwargs)"></a>propagate(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Optional[Tuple[int, int]] &#x3D; None, **kwargs)</h3><ol>
<li>edge_index (Tensor or SparseTensor)<ol>
<li>输入的边的信息，定义底层图形连接&#x2F;消息传递流。</li>
<li>torch.LongTensor类型<ol>
<li>its shape must be defined as <code>[2, num_messages]</code>, where messages from nodes in <code>edge_index[0]</code> are sent to nodes in <code>edge_index[1]</code></li>
</ol>
</li>
<li>torch_sparse.SparseTensor类型<ol>
<li>its sparse indices (row, col) should relate to row &#x3D; edge_index[1] and col &#x3D; edge_index[0].</li>
</ol>
</li>
</ol>
</li>
<li>也不一定是方形节点矩阵。x&#x3D;(x_N, x_M).</li>
</ol>
<h3 id="MessagePassing-message-…"><a href="#MessagePassing-message-…" class="headerlink" title="MessagePassing.message(…)"></a>MessagePassing.message(…)</h3><p>会根据 flow&#x3D;“source_to_target”和if flow&#x3D;“target_to_source”或者x_i,x_j,来区分处理的边。</p>
<p>x_j表示提升张量，它包含每个边的源节点特征，即每个节点的邻居。通过在变量名后添加_i或_j，可以自动提升节点特征。事实上，任何张量都可以通过这种方式转换，只要它们包含源节点或目标节点特征。</p>
<p>_j表示每条边的起点，_i表示每条边的终点。x_j表示的就是每条边起点的x值（也就是Feature）。如果你手动加了别的内容，那么它的_j, _i也会自动进行处理，这个自己稍微单步执行一下就知道了</p>
<p>在实现message的时候，节点特征会自动map到各自的source and target nodes。</p>
<h3 id="aggregate-inputs-torch-Tensor-index-torch-Tensor-ptr-Optional-torch-Tensor-None-dim-size-Optional-int-None-aggr-Optional-str-None-→-torch-Tensor"><a href="#aggregate-inputs-torch-Tensor-index-torch-Tensor-ptr-Optional-torch-Tensor-None-dim-size-Optional-int-None-aggr-Optional-str-None-→-torch-Tensor" class="headerlink" title="aggregate(inputs: torch.Tensor, index: torch.Tensor, ptr: Optional[torch.Tensor] &#x3D; None, dim_size: Optional[int] &#x3D; None, aggr: Optional[str] &#x3D; None) → torch.Tensor"></a>aggregate(inputs: torch.Tensor, index: torch.Tensor, ptr: Optional[torch.Tensor] &#x3D; None, dim_size: Optional[int] &#x3D; None, aggr: Optional[str] &#x3D; None) → torch.Tensor</h3><p>aggregation scheme 只需要设置参数就好，“add”, “mean”, “min”, “max” and “mul” operations</p>
<h3 id="MessagePassing-update-aggr-out-…"><a href="#MessagePassing-update-aggr-out-…" class="headerlink" title="MessagePassing.update(aggr_out, …)"></a>MessagePassing.update(aggr_out, …)</h3><p>aggregation 输出作为第一个参数，后面的参数是 propagate()的</p>
<h3 id="实现GCN-例子"><a href="#实现GCN-例子" class="headerlink" title="实现GCN 例子"></a>实现GCN 例子</h3><p>$$<br>\mathbf{x}<em>i^{(k)} &#x3D; \sum</em>{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot \left( \mathbf{\Theta}^{\top} \cdot \mathbf{x}_j^{(k-1)} \right)<br>$$</p>
<p>该式子先将周围的节点与权重矩阵\theta相乘, 然后通过节点的度degree正则化，最后相加</p>
<p>步骤可以拆分如下</p>
<ol>
<li>添加self-loop 到邻接矩阵（Adjacency Matrix）。</li>
<li>节点特征的线性变换。</li>
<li>计算归一化系数</li>
<li>Normalize 节点特征。</li>
<li>sum相邻节点的feature（“add”聚合）。</li>
</ol>
<p>步骤1 和 2 需要在message passing 前被计算好。 3 - 5 可以torch_geometric.nn.MessagePassing 类。</p>
<p>添加self-loop的目的是让featrue在聚合的过程中加入当前节点自己的feature，没有self-loop聚合的就只有邻居节点的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(aggr=<span class="string">&#x27;add&#x27;</span>)  <span class="comment"># &quot;Add&quot; aggregation (Step 5).</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.<span class="built_in">pow</span>(-<span class="number">0.5</span>)</span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] = <span class="number">0</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j, norm</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(-<span class="number">1</span>, <span class="number">1</span>) * x_j</span><br></pre></td></tr></table></figure>

<p>所有的逻辑代码都在forward()里面，当我们调用propagate()函数之后，它将会在内部调用message()和update()。</p>
<h3 id="使用-GCN-的例子"><a href="#使用-GCN-的例子" class="headerlink" title="使用 GCN 的例子"></a>使用 GCN 的例子</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv = GCNConv(16, 32)</span><br><span class="line">x = conv(x, edge_index)</span><br></pre></td></tr></table></figure>

<h3 id="SAGE的例子"><a href="#SAGE的例子" class="headerlink" title="SAGE的例子"></a>SAGE的例子</h3><p><img src="https://pic.shaojiemike.top/img/20220413232648.png"><br>聚合函数（aggregation）我们用最大池化（max pooling），这样上述公示中的 AGGREGATE 可以写为：<br><img src="https://pic.shaojiemike.top/img/20220413232702.png"><br>上述公式中，对于每个邻居节点，都和一个 weighted matrix 相乘，并且加上一个 bias，传给一个激活函数。相关代码如下(对应第二个图)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(SAGEConv, self).__init__(aggr=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, in_channels]</span></span><br><span class="line"> </span><br><span class="line">        x_j = self.lin(x_j)</span><br><span class="line">        x_j = self.act(x_j)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> x_j</span><br></pre></td></tr></table></figure>

<p>对于 update 方法，我们需要聚合更新每个节点的 embedding，然后加上权重矩阵和偏置(对应第一个图第二行)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">        self.update_act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out, x</span>):</span><br><span class="line">        <span class="comment"># aggr_out has shape [N, out_channels]</span></span><br><span class="line">      </span><br><span class="line">        new_embedding = torch.cat([aggr_out, x], dim=<span class="number">1</span>)</span><br><span class="line">        new_embedding = self.update_lin(new_embedding)</span><br><span class="line">        new_embedding = torch.update_act(new_embedding)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> new_embedding</span><br></pre></td></tr></table></figure>

<p>综上所述，SageConv 层的定于方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential <span class="keyword">as</span> Seq, Linear, ReLU</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> remove_self_loops, add_self_loops</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SAGEConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(SAGEConv, self).__init__(aggr=<span class="string">&#x27;max&#x27;</span>) <span class="comment">#  &quot;Max&quot; aggregation.</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.act = torch.nn.ReLU()</span><br><span class="line">        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">        self.update_act = torch.nn.ReLU()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line">      </span><br><span class="line">        <span class="comment"># Removes every self-loop in the graph given by edge_index, so that (i,i)∉E for every i ∈ V.</span></span><br><span class="line">        edge_index, _ = remove_self_loops(edge_index)</span><br><span class="line">        <span class="comment"># Adds a self-loop (i,i)∈ E to every node i ∈ V in the graph given by edge_index</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, size=(x.size(<span class="number">0</span>), x.size(<span class="number">0</span>)), x=x)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="comment"># x_j has shape [E, in_channels]</span></span><br><span class="line"> </span><br><span class="line">        x_j = self.lin(x_j)</span><br><span class="line">        x_j = self.act(x_j)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> x_j</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out, x</span>):</span><br><span class="line">        <span class="comment"># aggr_out has shape [N, out_channels]</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">        new_embedding = torch.cat([aggr_out, x], dim=<span class="number">1</span>)</span><br><span class="line">      </span><br><span class="line">        new_embedding = self.update_lin(new_embedding)</span><br><span class="line">        new_embedding = self.update_act(new_embedding)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> new_embedding</span><br></pre></td></tr></table></figure>

<h2 id="batch的实现"><a href="#batch的实现" class="headerlink" title="batch的实现"></a>batch的实现</h2><p>GNN的batch实现和传统的有区别。</p>
<h3 id="zzq的观点"><a href="#zzq的观点" class="headerlink" title="zzq的观点"></a>zzq的观点</h3><p>将网络复制batch次，batchSize的数据产生batchSize个Loss。通过Sum或者Max处理Loss，整体同时更新所有的网络参数。至于网络中循环输入和输出的H^(t-1)和H^t。（感觉直接平均就行了。</p>
<p>有几个可能的问题</p>
<ol>
<li>网络中参数不是线性层，CNN这种的网络。pytorch会自动并行吗？还需要手动</li>
<li>还有个问题，如果你还想用PyG的X和edge。并不能额外拓展维度。</li>
</ol>
<h3 id="图像和语言处理领域的传统基本思路："><a href="#图像和语言处理领域的传统基本思路：" class="headerlink" title="图像和语言处理领域的传统基本思路："></a>图像和语言处理领域的传统基本思路：</h3><p>通过 rescaling or padding(填充) 将相同大小的网络复制，来实现新添加维度。而新添加维度的大小就是batch_size。</p>
<p>但是由于图神经网络的特殊性：边和节点的表示。传统的方法要么不可行，要么会有数据的重复表示产生的大量内存消耗。</p>
<h2 id="ADVANCED-MINI-BATCHING-in-PyG"><a href="#ADVANCED-MINI-BATCHING-in-PyG" class="headerlink" title="ADVANCED MINI-BATCHING in PyG"></a>ADVANCED MINI-BATCHING in PyG</h2><p>为此引入了ADVANCED MINI-BATCHING来实现对大量数据的并行。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html">https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html</a></p>
<h3 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h3><ol>
<li>邻接矩阵以对角线的方式堆叠(创建包含多个孤立子图的巨大图)</li>
<li>节点和目标特征只是在节点维度中串联???<br><img src="https://pic.shaojiemike.top/img/20220417155734.png"></li>
</ol>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol>
<li>依赖message passing 方案的GNN operators不需要修改，因为消息仍然不能在属于不同图的两个节点之间交换。</li>
<li>没有计算或内存开销。例如，此batching 过程完全可以在不填充节点或边特征的情况下工作。请注意，邻接矩阵没有额外的内存开销，因为它们以稀疏方式保存，只保存非零项，即边。</li>
</ol>
<h3 id="torch-geometric-loader-DataLoader"><a href="#torch-geometric-loader-DataLoader" class="headerlink" title="torch_geometric.loader.DataLoader"></a>torch_geometric.loader.DataLoader</h3><p>可以实现将多个图batch成一个大图。 通过重写collate()来实现，并继承了pytorch的所有参数，比如num_workers.</p>
<p>在合并的时候，除开edge_index [2, num_edges]通过增加第二维度。其余（节点）都是增加第一维度的个数。</p>
<h3 id="最重要的作用"><a href="#最重要的作用" class="headerlink" title="最重要的作用"></a>最重要的作用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 原本是[2*4]</span><br><span class="line"># 自己实现的话，是直接连接</span><br><span class="line"> &gt;&gt;&gt; tensor([[0, 0, 1, 1, 0, 0, 1, 1],</span><br><span class="line">             [0, 1, 1, 2, 0, 1, 1, 2]])</span><br><span class="line"># 会修改成新的边</span><br><span class="line"> print(batch.edge_index)</span><br><span class="line"> &gt;&gt;&gt; tensor([[0, 0, 1, 1, 2, 2, 3, 3],</span><br><span class="line">             [0, 1, 1, 2, 3, 4, 4, 5]])</span><br></pre></td></tr></table></figure>

<h3 id="torch-geometric-loader-DataLoader-例子1"><a href="#torch-geometric-loader-DataLoader-例子1" class="headerlink" title="torch_geometric.loader.DataLoader 例子1"></a>torch_geometric.loader.DataLoader 例子1</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from torch_geometric.data import Data</span><br><span class="line">from torch_geometric.loader import DataLoader</span><br><span class="line"></span><br><span class="line">data_list = [Data(...), ..., Data(...)]</span><br><span class="line">loader = DataLoader(data_list, batch_size=32)</span><br></pre></td></tr></table></figure>
<h3 id="torch-geometric-loader-DataLoader-例子2"><a href="#torch-geometric-loader-DataLoader-例子2" class="headerlink" title="torch_geometric.loader.DataLoader 例子2"></a>torch_geometric.loader.DataLoader 例子2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from torch_geometric.datasets import TUDataset</span><br><span class="line">from torch_geometric.loader import DataLoader</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;, use_node_attr=True)</span><br><span class="line">loader = DataLoader(dataset, batch_size=32, shuffle=True)</span><br><span class="line"></span><br><span class="line">for batch in loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])</span><br><span class="line"></span><br><span class="line">    batch.num_graphs</span><br><span class="line">    &gt;&gt;&gt; 32</span><br></pre></td></tr></table></figure>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-13T07:48:56.000Z" title="4/13/2022, 7:48:56 AM">2022-04-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-12T16:08:25.548Z" title="11/12/2023, 4:08:25 PM">2023-11-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></span><span class="level-item">10 minutes read (About 1448 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/13/Work/Artificial%20Intelligence/GNN/">GNN</a></p><div class="content"><h2 id="图神经网络（Graph-Neural-Networks，GNN）以及特点"><a href="#图神经网络（Graph-Neural-Networks，GNN）以及特点" class="headerlink" title="图神经网络（Graph Neural Networks，GNN）以及特点"></a>图神经网络（Graph Neural Networks，GNN）以及特点</h2><ol>
<li>GNN可以分析对象之间的关系，来实现精准的推荐</li>
<li>问题<ol>
<li>因为图是不规则的，每个图都有一个大小可变的无序节点，图中的每个节点都有不同数量的相邻节点，导致卷积等操作不适合图。</li>
<li>现有深度学习算法的一个核心假设是数据样本之间彼此独立。对于图来说，每个数据样本（节点）都会有边与图中其他实数据样本（节点）相关，这些信息可用于捕获实例之间的相互依赖关系。</li>
</ol>
</li>
</ol>
<h3 id="图嵌入-网络嵌入"><a href="#图嵌入-网络嵌入" class="headerlink" title="图嵌入 &amp; 网络嵌入"></a>图嵌入 &amp; 网络嵌入</h3><p>图神经网络的研究与图嵌入（对图嵌入不了解的读者可以参考我的这篇文章《图嵌入综述》）或网络嵌入密切相关。</p>
<p>真实的图（网络）往往是高维、难以处理的，图嵌入的目标是发现高维图的低维向量表示。<br><img src="https://pic.shaojiemike.top/img/20220413160235.png"></p>
<h2 id="图分析任务"><a href="#图分析任务" class="headerlink" title="图分析任务"></a>图分析任务</h2><ol>
<li>节点分类，</li>
<li>链接预测，</li>
<li>聚类，</li>
<li>可视化</li>
</ol>
<h2 id="图神经网络分类"><a href="#图神经网络分类" class="headerlink" title="图神经网络分类"></a>图神经网络分类</h2><ol>
<li>图卷积网络（Graph Convolution Networks，GCN）</li>
<li>图注意力网络（Graph Attention Networks）<ol>
<li>图注意力网络（GAT）是一种基于空间的图卷积网络，它的注意机制是在聚合特征信息时，将注意机制用于确定节点邻域的权重。</li>
</ol>
</li>
<li>图自编码器（ Graph Autoencoders）</li>
<li>图生成网络（ Graph Generative Networks） </li>
<li>图时空网络（Graph Spatial-temporal Networks）。</li>
</ol>
<h2 id="图卷积网络（Graph-Convolution-Networks，GCN）"><a href="#图卷积网络（Graph-Convolution-Networks，GCN）" class="headerlink" title="图卷积网络（Graph Convolution Networks，GCN）"></a>图卷积网络（Graph Convolution Networks，GCN）</h2><p>GCN可谓是图神经网络的“开山之作”，它首次将图像处理中的卷积操作简单的用到图结构数据处理中来，并且给出了具体的推导，这里面涉及到复杂的谱图理论。推导过程还是比较复杂的，然而最后的结果却非常简单。<br><img src="https://pic.shaojiemike.top/img/20220413161948.png"></p>
<p>聚合邻居节点的特征然后做一个线性变换吗？没错，确实是这样，同时为了使得GCN能够捕捉到K-hop的邻居节点的信息，作者还堆叠多层GCN layers，如堆叠K层有：<br><img src="https://pic.shaojiemike.top/img/20220413162146.png"></p>
<h2 id="经典的简单几类"><a href="#经典的简单几类" class="headerlink" title="经典的简单几类"></a>经典的简单几类</h2><h3 id="Semi-supervised-learning-for-node-level-classification："><a href="#Semi-supervised-learning-for-node-level-classification：" class="headerlink" title="Semi-supervised learning for node-level classification："></a>Semi-supervised learning for node-level classification：</h3><p>给定一个网络，其中部分节点被标记，其他节点未标记，ConvGNNs可以学习一个鲁棒模型，有效地识别未标记节点的类标签。为此，可以通过叠加一对图卷积层，然后是用于多类分类的softmax层来构建端到端框架。见图(a)</p>
<p><img src="https://pic.shaojiemike.top/img/20220413162934.png"></p>
<h3 id="Supervised-learning-for-graph-level-classification："><a href="#Supervised-learning-for-graph-level-classification：" class="headerlink" title="Supervised learning for graph-level classification："></a>Supervised learning for graph-level classification：</h3><p>图级分类的目的是预测整个图的类标签。该任务的端到端学习可以结合图卷积层、图池层和&#x2F;或readout层来实现。图卷积层负责精确的高级节点表示，图池层则扮演下采样的角色，每次都将每个图粗化成一个子结构。readout层将每个图的节点表示折叠成一个图表示。通过在图表示中应用一个多层感知器和一个softmax层，我们可以建立一个端到端图分类框架。见图(b)</p>
<p><img src="https://pic.shaojiemike.top/img/20220413163014.png"></p>
<h3 id="Unsupervised-learning-for-graph-embedding："><a href="#Unsupervised-learning-for-graph-embedding：" class="headerlink" title="Unsupervised learning for graph embedding："></a>Unsupervised learning for graph embedding：</h3><p>当图中没有可用的类标签时，我们可以学习在端到端框架中以完全无监督的方式嵌入图。这些算法以两种方式利用边缘级信息。一种简单的方法是采用自编码器框架，编码器使用图卷积层将图嵌入到潜在表示中，在潜在表示上使用解码器重构图结构。另一种常用的方法是利用负采样方法(negative sampling)，即对图中有链接的部分节点对进行负采样，而对图中有链接的节点对进行正采样。然后应用逻辑回归层对的正负配对进行区分。见图(c)</p>
<p>图自动编码器(Graph autoencoders, GAEs)是一种无监督学习框架，它将node或者graph编码成一个潜在的向量空间，并从编码的信息重构图数据。该算法用于学习network embedding和图生成分布。对于network embedding，GAEs通过重构图的邻接矩阵等图结构信息来学习潜在节点表示。对于图的生成，有的方法是一步一步生成图的节点和边，有的方法是一次性输出整个图。</p>
<p><img src="https://pic.shaojiemike.top/img/20220413163158.png"></p>
<h3 id="时空图神经网络-Spatial-temporal-graph-neural-network-STGNNs"><a href="#时空图神经网络-Spatial-temporal-graph-neural-network-STGNNs" class="headerlink" title="时空图神经网络(Spatial-temporal graph neural network, STGNNs)"></a>时空图神经网络(Spatial-temporal graph neural network, STGNNs)</h3><p>旨在从时空图中学习隐藏的模式，在交通速度预测、驾驶员操纵预测和人类行为识别等多种应用中发挥着越来越重要的作用。STGNNs的核心思想是同时考虑空间依赖和时间依赖。目前的许多方法都是通过图卷积来捕获与RNNs或CNNs的空间依赖关系，从而对时间依赖关系进行建模。下图是STGNNs流程图模型。</p>
<p><img src="https://pic.shaojiemike.top/img/20220413163213.png"></p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/136521625">https://zhuanlan.zhihu.com/p/136521625</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75307407">https://zhuanlan.zhihu.com/p/75307407</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/PSrgm7frsXIobSrlcoCWxw">https://mp.weixin.qq.com/s/PSrgm7frsXIobSrlcoCWxw</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/142948273">https://zhuanlan.zhihu.com/p/142948273</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.huaweicloud.com/hero/forum.php?mod=viewthread&tid=109580">https://developer.huaweicloud.com/hero/forum.php?mod=viewthread&amp;tid=109580</a></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/24/">Previous</a></div><div class="pagination-next"><a href="/page/26/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/24/">24</a></li><li><a class="pagination-link is-current" href="/page/25/">25</a></li><li><a class="pagination-link" href="/page/26/">26</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/34/">34</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">337</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">470</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">46</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-12T15:27:51.000Z">2023-11-12</time></p><p class="title"><a href="/2023/11/12/OutOfWork/3-homepage/themeConfiguration/hexo-icarus/">Hexo Icarus Theme configuration</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-12T08:04:51.000Z">2023-11-12</time></p><p class="title"><a href="/2023/11/12/OutOfWork/2-selfLearning/AI-tools/openFreeMultimodelAITools/">Open &amp;Free Multimodel AI Tools</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-12T07:41:03.000Z">2023-11-12</time></p><p class="title"><a href="/2023/11/12/diary/3-EfficientLife/teamCooperation/">Team Cooperation</a></p><p class="categories"><a href="/categories/thinking/">thinking</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-11T09:55:04.000Z">2023-11-11</time></p><p class="title"><a href="/2023/11/11/OutOfWork/3-homepage/blogBuilder/hexo/">Hexo</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-11T00:19:53.000Z">2023-11-11</time></p><p class="title"><a href="/2023/11/11/OutOfWork/3-homepage/deployment/mediawiki2local/">Deploy Mediawiki to localhost</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">198</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Hexo" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>