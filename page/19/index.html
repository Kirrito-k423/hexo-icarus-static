<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>SHAOJIE&#039;S BOOK</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SHAOJIE&#039;S BOOK"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SHAOJIE&#039;S BOOK"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SHAOJIE&#039;S BOOK"><meta property="og:url" content="http://icarus.shaojiemike.top/"><meta property="og:site_name" content="SHAOJIE&#039;S BOOK"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://icarus.shaojiemike.top/img/og_image.png"><meta property="article:author" content="Shaojie Tan"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://icarus.shaojiemike.top/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://icarus.shaojiemike.top"},"headline":"SHAOJIE'S BOOK","image":["http://icarus.shaojiemike.top/img/og_image.png"],"author":{"@type":"Person","name":"Shaojie Tan"},"publisher":{"@type":"Organization","name":"SHAOJIE'S BOOK","logo":{"@type":"ImageObject","url":"http://icarus.shaojiemike.top/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-13T16:00:00.000Z" title="6/13/2023, 4:00:00 PM">2023-06-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.257Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Programming/">Programming</a></span><span class="level-item">39 minutes read (About 5894 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/13/Work/Artificial%20Intelligence/pytorch/">Pytorch</a></p><div class="content"><p>（本人是rookie，纯小白~</p>
<h2 id="什么是-PyTorch"><a href="#什么是-PyTorch" class="headerlink" title="什么是 PyTorch?"></a>什么是 PyTorch?</h2><p>PyTorch 是一个基于 Python 的科学计算包，主要定位两类人群：</p>
<ol>
<li>NumPy 的替代品，可以利用 GPU 的性能进行计算。</li>
<li>深度学习研究平台拥有足够的灵活性和速度</li>
</ol>
<h2 id="Pytorch简介"><a href="#Pytorch简介" class="headerlink" title="Pytorch简介"></a>Pytorch简介</h2><p>要介绍PyTorch之前，不得不说一下Torch。</p>
<p>Torch是一个有大量机器学习算法支持的科学计算框架，是一个与Numpy类似的张量（Tensor） 操作库，其特点是特别灵活，但因其采用了小众的编程语言是Lua，所以流行度不高，这也就有了PyTorch的出现。所以其实Torch是 PyTorch的前身，它们的底层语言相同，只是使用了不同的上层包装语言。</p>
<p>PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。它主要由Facebookd的人工智能小组开发，不仅能够 实现强大的GPU加速，同时还支持<strong>动态神经网络</strong>，这一点是现在很多主流框架如TensorFlow都不支持的。 PyTorch提供了两个高级功能：</p>
<ul>
<li>具有强大的GPU加速的张量计算（如Numpy）</li>
<li>包含自动求导系统的深度神经网络</li>
</ul>
<p>TensorFlow和Caffe都是命令式的编程语言，而且是静态的，首先必须构建一个神经网络，然后一次又一次使用相同的结构，如果想要改变网络的结构，就必须从头开始。</p>
<p>但是对于PyTorch，通过反向求导技术，可以让你零延迟地任意<strong>改变神经网络</strong>的行为，而且其实现速度 快。正是这一灵活性是PyTorch对比TensorFlow的最大优势。</p>
<p>所以，总结一下PyTorch的优点：</p>
<ul>
<li>支持GPU</li>
<li>灵活，支持动态神经网络</li>
<li>底层代码易于理解</li>
<li>命令式体验</li>
<li>自定义扩展</li>
</ul>
<p>当然，现今任何一个深度学习框架都有其缺点，PyTorch也不例外，对比TensorFlow，其全面性处于劣势，目前PyTorch</p>
<ul>
<li>还不支持快速傅里 叶、沿维翻转张量和检查无穷与非数值张量；</li>
<li>针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；</li>
<li>其次因为这个框 架较新，使得他的社区没有那么强大，在文档方面其C库大多数没有文档。</li>
</ul>
<h2 id="安装和使用"><a href="#安装和使用" class="headerlink" title="安装和使用"></a>安装和使用</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a target="_blank" rel="noopener" href="https://pytorch.org/">https://pytorch.org/</a> 选择对应cuda版本下载即可</p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import print_function</span><br><span class="line">import torch</span><br></pre></td></tr></table></figure>

<h2 id="数据类型和操作"><a href="#数据类型和操作" class="headerlink" title="数据类型和操作"></a>数据类型和操作</h2><h3 id="Tensor-张量"><a href="#Tensor-张量" class="headerlink" title="Tensor(张量)"></a>Tensor(张量)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个5x3矩阵，不初始化。基本是0，或者+-10^-4之类</span></span><br><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 构造一个随机初始化的矩阵：范围[0,1)</span></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 构造一个随机int初始化的矩阵：范围[3,10)，大小2*2</span></span><br><span class="line">torch.randint(<span class="number">3</span>, <span class="number">10</span>, (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">tensor([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>]])</span><br><span class="line"><span class="comment"># 构造一个矩阵全为 0，而且数据类型是 long.</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"><span class="comment"># 直接使用数据 1*2维 </span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 裁取已有tensor 5*3的元素</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)   </span><br><span class="line"><span class="comment"># 已有tensor元素全部随机化</span></span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>) </span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接矩阵，不同维度 Concatenates </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">0</span>)</span><br><span class="line"><span class="comment"># torch.cat([input]*100)</span></span><br><span class="line">tensor([[ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>],</span><br><span class="line">        [ <span class="number">0.6580</span>, -<span class="number">1.0969</span>, -<span class="number">0.4614</span>],</span><br><span class="line">        [-<span class="number">0.1034</span>, -<span class="number">0.5790</span>,  <span class="number">0.1497</span>]])</span><br><span class="line"><span class="comment"># 相同大小对应位置相乘</span></span><br><span class="line">x = torch.tensor([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">1</span> / <span class="number">5</span>, <span class="number">2</span>]])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(torch.prod(x, <span class="number">0</span>))  <span class="comment"># product along 0th axis</span></span><br><span class="line">tensor([[<span class="number">5.0000</span>, <span class="number">6.0000</span>],</span><br><span class="line">        [<span class="number">0.2000</span>, <span class="number">2.0000</span>]])</span><br><span class="line">tensor([ <span class="number">1.</span>, <span class="number">12.</span>])</span><br><span class="line"><span class="comment"># 转置 指定维度transpose() 和 permute()</span></span><br><span class="line">x.t()   </span><br><span class="line"><span class="comment"># 横向纵向复制拓展</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.expand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.expand(-<span class="number">1</span>, <span class="number">4</span>)   <span class="comment"># -1 means not changing the size of that dimension</span></span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>,  <span class="number">3</span>]])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出第二列的数据</span></span><br><span class="line"><span class="built_in">print</span>(x[:, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 维度信息 输出是一个元组，所以它支持左右的元组操作。</span></span><br><span class="line"><span class="built_in">print</span>(x.size())</span><br><span class="line"><span class="comment"># 改变一个 tensor 的大小或者形状</span></span><br><span class="line"><span class="comment"># reshape也行 https://blog.csdn.net/Flag_ing/article/details/109129752</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>)  <span class="comment"># -1位置的取值是从其他维度推断出来的</span></span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size()) <span class="comment"># torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加法</span></span><br><span class="line">z=x+y</span><br><span class="line">z=torch.add(x, y)</span><br><span class="line">y.add_(x)  <span class="comment"># adds x to y</span></span><br></pre></td></tr></table></figure>

<p>注意 任何使张量会发生变化的操作都有一个前缀 ‘_‘。例如：<br>x.copy_(y), x.t_(), 将会改变 x</p>
<h2 id="PyTorch-自动微分"><a href="#PyTorch-自动微分" class="headerlink" title="PyTorch 自动微分"></a>PyTorch 自动微分</h2><p>autograd 包是 PyTorch 中所有神经网络的核心。</p>
<p>autograd 软件包为 Tensors 上的所有操作提供自动微分。它是一个由运行定义的框架，这意味着以代码运行方式定义你的后向传播，并且每次迭代都可以不同。</p>
<h3 id="TENSOR"><a href="#TENSOR" class="headerlink" title="TENSOR"></a>TENSOR</h3><p>torch.Tensor 是包的核心类。</p>
<p>如果将其属性 .requires_grad 设置为 True，则会开始跟踪针对 tensor 的所有操作。.requires_grad_( … ) 会改变张量的 requires_grad 标记。输入的标记默认为 False ，如果没有提供相应的参数。</p>
<p>完成计算后，您可以调用 .backward() 来自动计算所有梯度。</p>
<p>该张量的梯度将累积到 .grad 属性中。要停止 tensor 历史记录的跟踪，您可以调用 .detach()，它将其与计算历史记录分离，并防止将来的计算被跟踪。要停止跟踪历史记录（和使用内存），您还可以将代码块使用 with torch.no_grad(): 包装起来。</p>
<p>在评估模型时，这是特别有用，因为模型在训练阶段具有 requires_grad &#x3D; True 的可训练参数有利于调参，但在评估阶段我们不需要梯度。(???)</p>
<p>另一个重要的类是Function。Tensor 和 Function 互相连接并构建一个非循环图，它保存整个完整的计算过程的历史信息。</p>
<p>每个张量都有一个 .grad_fn 属性保存着创建了张量的 Function 的引用，（如果用户自己创建张量，则g rad_fn 是 None ）。</p>
<h3 id="计算导数"><a href="#计算导数" class="headerlink" title="计算导数"></a>计算导数</h3><p>你可以调用 Tensor.backward()。如果 Tensor 是标量（即它包含一个元素数据），则不需要指定任何参数backward()，但是如果它有更多元素，则需要指定一个gradient 参数来指定张量的形状。</p>
<h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建一个张量，设置 requires_grad=True 来跟踪与它相关的计算</span></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 操作张量</span></span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="comment"># 后向传播，因为输出包含了一个标量，out.backward() 等同于out.backward(torch.tensor(1.))。</span></span><br><span class="line">out.backward()</span><br><span class="line"><span class="comment"># 打印梯度 d(out)/dx</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[4.5000, 4.5000],</span></span><br><span class="line"><span class="comment">#        [4.5000, 4.5000]])</span></span><br></pre></td></tr></table></figure>

<p>原理：<br>最终Loss的值，网络结构（部分偏导数），当前训练的值。三者共同决定了梯度。这意味着在Batch使用时，假如将网络复制多遍（包括初始训练参数也一样），对于总的Loss来训练得到的参数是完全相同的。<br><img src="https://pic.shaojiemike.top/img/20220412204304.png"></p>
<h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p>y 不再是一个标量。torch.autograd 不能够直接计算整个雅可比，但是如果我们只想要雅可比向量积，只需要简单的传递向量给 backward 作为参数。(??? 雅可比向量积有什么用)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="comment"># tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])</span></span><br></pre></td></tr></table></figure>

<h2 id="神经网络的训练"><a href="#神经网络的训练" class="headerlink" title="神经网络的训练"></a>神经网络的训练</h2><h3 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h3><p>一个简单的前馈神经网络，它接收输入，让输入一个接着一个的通过一些层，最后给出输出。<br><img src="https://pic.shaojiemike.top/img/20220412211523.png"><br>通过 torch.nn 包来构建。一个 nn.Module 包括层和一个方法 forward(input) 它会返回输出(output)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 习惯上，将包含可训练参数的结构，声明在__init__里</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">num_flat_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<p>一个模型可训练的参数可以通过调用 net.parameters() 返回：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(params))</span><br><span class="line"><span class="built_in">print</span>(params[<span class="number">0</span>].size())  <span class="comment"># conv1&#x27;s .weight</span></span><br></pre></td></tr></table></figure>

<h3 id="运行一次网络"><a href="#运行一次网络" class="headerlink" title="运行一次网络"></a>运行一次网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure>

<h3 id="反向传播计算各个位置梯度"><a href="#反向传播计算各个位置梯度" class="headerlink" title="反向传播计算各个位置梯度"></a>反向传播计算各个位置梯度</h3><p>把所有参数梯度缓存器置零，用<strong>随机的梯度</strong>来反向传播</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>一个损失函数需要一对输入：模型输出和目标，然后计算一个值来评估输出距离目标有多远。</p>
<p>有一些不同的损失函数在 nn 包中。一个简单的损失函数就是 nn.MSELoss ，这计算了均方误差。</p>
<p>可以调用包，也可以自己设计。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">target = torch.randn(<span class="number">10</span>)  <span class="comment"># 随便一个目标</span></span><br><span class="line">target = target.view(<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># make it the same shape as output</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br></pre></td></tr></table></figure>

<h3 id="使用loss反向传播更新梯度"><a href="#使用loss反向传播更新梯度" class="headerlink" title="使用loss反向传播更新梯度"></a>使用loss反向传播更新梯度</h3><p>查看梯度记录的地方</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d</span><br><span class="line">      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</span><br><span class="line">      -&gt; MSELoss</span><br><span class="line">      -&gt; loss</span><br></pre></td></tr></table></figure>

<p>当我们调用 loss.backward()，整个图都会微分，而且所有的在图中的requires_grad&#x3D;True 的张量将会让他们的 grad 张量累计梯度。</p>
<p>为了实现反向传播损失，我们所有需要做的事情仅仅是使用 loss.backward()。你需要清空现存的梯度，要不然将会和现存(上一轮)的梯度累计到一起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()     <span class="comment"># zeroes the gradient buffers of all parameters</span></span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>

<p>查看某处梯度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure>

<h3 id="使用梯度和各种方法优化器更新参数"><a href="#使用梯度和各种方法优化器更新参数" class="headerlink" title="使用梯度和各种方法优化器更新参数"></a>使用梯度和各种方法优化器更新参数</h3><p>最简单的更新规则就是随机梯度下降。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight = weight - learning_rate * gradient</span><br></pre></td></tr></table></figure>

<p>我们可以使用 python 来实现这个规则：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data * learning_rate)</span><br></pre></td></tr></table></figure>

<p>尽管如此，如果你是用神经网络，你想使用不同的更新规则，类似于 SGD, Nesterov-SGD, Adam, RMSProp, 等。为了让这可行，我们建立了一个小包：torch.optim 实现了所有的方法。使用它非常的简单。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># create your optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in your training loop:</span></span><br><span class="line">optimizer.zero_grad()   <span class="comment"># zero the gradient buffers</span></span><br><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()    <span class="comment"># Does the update</span></span><br></pre></td></tr></table></figure>

<h3 id="上面是一次训练"><a href="#上面是一次训练" class="headerlink" title="上面是一次训练"></a>上面是一次训练</h3><p>一般是按照一次多少batch训练，训练10次等.</p>
<p>或者考虑loss 稳定后结束，一般不使用loss小于某个值（因为不知道loss阈值是多少）</p>
<p>或许可以考虑K折交叉检验法（k-fold cross validation）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="测试单个任务"><a href="#测试单个任务" class="headerlink" title="测试单个任务"></a>测试单个任务</h3><p>分类任务，取最高的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = net(images)</span><br><span class="line">_, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="测试总误差"><a href="#测试总误差" class="headerlink" title="测试总误差"></a>测试总误差</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>

<h2 id="各种初学者问题"><a href="#各种初学者问题" class="headerlink" title="各种初学者问题"></a>各种初学者问题</h2><h3 id="In-place-正确性检查"><a href="#In-place-正确性检查" class="headerlink" title="In-place 正确性检查"></a>In-place 正确性检查</h3><p>所有的Variable都会记录用在他们身上的 in-place operations。如果pytorch检测到variable在一个Function中已经被保存用来backward，但是之后它又被in-place operations修改。当这种情况发生时，在backward的时候，pytorch就会报错。这种机制保证了，如果你用了in-place operations，但是在backward过程中没有报错，那么梯度的计算就是正确的。</p>
<h3 id="对于不需要自动微分"><a href="#对于不需要自动微分" class="headerlink" title="对于不需要自动微分"></a>对于不需要自动微分</h3><p>&#x3D;不需要计算梯度&#x3D;手动计算值的</p>
<p>使用 <code>someTensor.detach()</code> 来更新</p>
<h2 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h2><h3 id="欠拟合和过拟合判断"><a href="#欠拟合和过拟合判断" class="headerlink" title="欠拟合和过拟合判断"></a>欠拟合和过拟合判断</h3><ol>
<li>训练集和测试集都不好——欠拟合</li>
<li>训练集好，测试集不好——过拟合</li>
</ol>
<h3 id="多通道"><a href="#多通道" class="headerlink" title="多通道"></a>多通道</h3><p>一般是任务特征很多维度时，拓展描述参数用的。</p>
<p>比如：图像一般包含三个通道&#x2F;三种原色（红色、绿色和蓝色）。 实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量。所以第三维通过通道表示。</p>
<p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html">https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html</a></p>
<h3 id="多通道举例说明"><a href="#多通道举例说明" class="headerlink" title="多通道举例说明"></a>多通道举例说明</h3><p><img src="https://pic.shaojiemike.top/img/20220412211523.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>) <span class="comment"># 输入通道1，输出通道6，卷积核 5*5</span></span><br></pre></td></tr></table></figure>

<p>$$<br>28&#x3D;32-5+1<br>$$</p>
<p>初始1通道变6通道，意味着对初始的A数据，有6个初始值不同的5*5卷积核操作，产生6张图。需要参数6*5*5.</p>
<p>初始6通道变16通道，相当于将6通道变1通道，重复16次。6通道变1通道，通过6张图与由6个5*5卷积核组成的卷积核组作用，生成6张图，然后简单相加，变成1张。需要总参数16*6*5*5*5。相当于下图某些数据变成6和16：</p>
<p><img src="https://pic.shaojiemike.top/img/20220413151558.png"></p>
<h3 id="BatchSize"><a href="#BatchSize" class="headerlink" title="BatchSize"></a>BatchSize</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34886403/article/details/82558399">https://blog.csdn.net/qq_34886403/article/details/82558399</a></p>
<ol>
<li>Batch Size定义：一次训练所选取的样本数。</li>
<li>由于矩阵操作，增加batch&#x2F;行号。每行经过同一个网络，引起的就是输出行号增加。只需要对每行单独计算出来的误差进行sum或者mean得到一个误差值，就可以反向传播，训练参数。<ol start="4">
<li>简单来说就是平均了一个batch数据的影响，不会出现离谱的波动，方向比较准确。</li>
</ol>
</li>
<li>Batch Size的大小影响模型的优化程度和速度。同时其直接影响到GPU内存的使用情况，假如你GPU内存不大，该数值最好设置小一点。<ol>
<li>没有Batch Size，梯度准确，只适用于小样本数据库</li>
<li>Batch Size增大，梯度变准确。但是单个epoch的迭代次数减少了，参数的调整也慢了，假如要达到相同的识别精度，需要更多的epoch。</li>
<li>Batch Size再增大，梯度已经非常准确，再增加Batch Size也没有用</li>
</ol>
</li>
<li>虽然Batch Size增大，一遍的总次数变少，单步计算量增加。但是由于GPU并行操作，单步时间不会增加太多。</li>
</ol>
<h3 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h3><p>Batch Normalization是将各层的输入进行归一化，使训练过程更快、更稳定的一种技术。在实践中，它是一个额外的层，我们通常添加在计算(卷积)层之后，在非线性(激活函数)之前。也有更先进的，比如layernorm。</p>
<p>BN层只是效果会变好，因为感受到了细节。不是有batch一定有BN层的意思。</p>
<p><img src="https://pic.shaojiemike.top/img/20220413153945.png"></p>
<h2 id="各种不同的Loss"><a href="#各种不同的Loss" class="headerlink" title="各种不同的Loss"></a>各种不同的Loss</h2><h3 id="交叉熵和加权交叉熵"><a href="#交叉熵和加权交叉熵" class="headerlink" title="交叉熵和加权交叉熵"></a>交叉熵和加权交叉熵</h3><p>多用于多分类任务，预测值是每一类各自的概率。label为特定的类别<br><img src="https://pic.shaojiemike.top/img/20220420111008.png"><br>torch.nn.NLLLOSS通常不被独立当作损失函数，而需要和softmax、log等运算组合当作损失函数。</p>
<p>torch.nn.CrossEntropyLoss相当于softmax + log + nllloss。</p>
<p><img src="https://pic.shaojiemike.top/img/20220420111137.png"></p>
<p>预测的概率大于1明显不符合预期，可以使用softmax归一，取log后是交叉熵，取负号是为了符合loss越小，预测概率越大。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 4类权重是 1， 10， 100， 100 一般是与样本占比成反比</span><br><span class="line">criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array([1,10,100,100])).float() ,reduction=&#x27;sum&#x27;)</span><br></pre></td></tr></table></figure>
<ul>
<li>size_average（该参数不建议使用，后续版本可能被废弃），该参数指定loss是否在一个Batch内平均，即是否除以N。默认为True</li>
<li>reduce (该参数不建议使用，后续版本可能会废弃)，首先说明该参数与size_average冲突，当该参数指定为False时size_average不生效，该参数默认为True。reduce为False时，对batch内的每个样本单独计算loss，loss的返回值Shape为[N],每一个数对应一个样本的loss。reduce为True时，根据size_average决定对N个样本的loss进行求和还是平均，此时返回的loss是一个数。</li>
<li>reduction 该参数在新版本中是为了取代size_average和reduce参数的。<ul>
<li>它共有三种选项’mean’，’sum’和’none’。</li>
<li>‘mean’为默认情况，表明对N个样本的loss进行求平均之后返回(相当于reduce&#x3D;True，size_average&#x3D;True);</li>
<li>‘sum’指对n个样本的loss求和(相当于reduce&#x3D;True，size_average&#x3D;False);</li>
<li>‘none’表示直接返回n分样本的loss(相当于reduce&#x3D;False)</li>
</ul>
</li>
</ul>
<h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>相对于加权交叉熵不仅权重不需要计算，自动通过概率算，而且gamma&#x3D;2按照平方缩小了，大样本的影响。</p>
<p><img src="https://pic.shaojiemike.top/img/20220420114232.png"></p>
<p>“蓝”线代表交叉熵损失。X轴即“预测为真实标签的概率”（为简单起见，将其称为pt）。举例来说，假设模型预测某物是自行车的概率为0.6，而它确实是自行车， 在这种情况下的pt为0.6。</p>
<p>Y轴是给定pt后Focal loss和CE的loss的值。</p>
<p>从图像中可以看出，当模型预测为真实标签的概率为0.6左右时，交叉熵损失仍在0.5左右。因此，为了在训练过程中减少损失，我们的模型将必须以更高的概率来预测到真实标签。换句话说，交叉熵损失要求模型对自己的预测非常有信心。但这也同样会给模型表现带来负面影响。</p>
<p>深度学习模型会变得过度自信, 因此模型的泛化能力会下降.</p>
<p>当使用γ&gt; 1的Focal Loss可以减少“分类得好的样本”或者说“模型预测正确概率大”的样本的训练损失，而对于“难以分类的示例”，比如预测概率小于0.5的，则不会减小太多损失。因此，在数据类别不平衡的情况下，会让模型的注意力放在稀少的类别上，因为这些类别的样本见过的少，比较难分。</p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1669261">https://cloud.tencent.com/developer/article/1669261</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34914551/article/details/105393989">https://blog.csdn.net/qq_34914551/article/details/105393989</a></p>
<p><a target="_blank" rel="noopener" href="https://ptorch.com/news/253.html">https://ptorch.com/news/253.html</a></p>
<h2 id="Pytorch-nn常用函数"><a href="#Pytorch-nn常用函数" class="headerlink" title="Pytorch.nn常用函数"></a>Pytorch.nn常用函数</h2><h3 id="torch-nn-Linear"><a href="#torch-nn-Linear" class="headerlink" title="torch.nn.Linear"></a>torch.nn.Linear</h3><p>$$<br>y&#x3D;x*A^T+b<br>$$</p>
<p>设置网络中的<strong>全连接层</strong>的，需要注意在二维图像处理的任务中，全连接层的输入与输出一般都设置为二维张量，形状通常为[batch_size, size]，不同于卷积层要求输入输出是四维张量。</p>
<p><code>in_features</code>指的是输入的二维张量的大小，即输入的[batch_size, size]中的size。</p>
<p><code>out_features</code>指的是输出的二维张量的大小，即输出的二维张量的形状为[batch_size，output_size]，当然，它也代表了该全连接层的神经元个数。</p>
<h3 id="torch-nn-ReLU"><a href="#torch-nn-ReLU" class="headerlink" title="torch.nn.ReLU()"></a>torch.nn.ReLU()</h3><p>$$<br>ReLU(x)&#x3D;(x)^+&#x3D;max(0,x)<br>$$</p>
<h3 id="torch-nn-Sigmoid"><a href="#torch-nn-Sigmoid" class="headerlink" title="torch.nn.Sigmoid"></a>torch.nn.Sigmoid</h3><p>$$<br>Sigmoid(x)&#x3D;σ(x)&#x3D; \frac{1}{1+exp(−x)}<br>$$</p>
<ol>
<li>torch.nn.Sigmoid()<ol>
<li>是一个类。在定义模型的初始化方法中使用，需要在_init__中定义，然后再使用。</li>
</ol>
</li>
<li>torch.nn.functional.sigmoid():<ol>
<li>可以直接在forward()里使用。eg.<code>A=F.sigmoid(x)</code></li>
</ol>
</li>
</ol>
<h3 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h3><p>cat是concatnate的意思：拼接，联系在一起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C = torch.cat( (A,B),<span class="number">0</span> )  <span class="comment">#按维数0拼接（竖着拼）</span></span><br><span class="line">C = torch.cat( (A,B),<span class="number">1</span> )  <span class="comment">#按维数1拼接（横着拼）</span></span><br></pre></td></tr></table></figure>

<h3 id="torch-nn-BatchNorm2d"><a href="#torch-nn-BatchNorm2d" class="headerlink" title="torch.nn.BatchNorm2d"></a>torch.nn.BatchNorm2d</h3><p>num_features – C from an expected input of size (N, C, H, W)</p>
<h3 id="torch-nn-BatchNorm1d"><a href="#torch-nn-BatchNorm1d" class="headerlink" title="torch.nn.BatchNorm1d"></a>torch.nn.BatchNorm1d</h3><p>Input: (N, C) or (N, C, L), where NN is the batch size, C is the number of features or channels, and L is the sequence length</p>
<p>Output: (N, C) or (N, C, L) (same shape as input)</p>
<h3 id="Softmax函数和Sigmoid函数的区别"><a href="#Softmax函数和Sigmoid函数的区别" class="headerlink" title="Softmax函数和Sigmoid函数的区别"></a>Softmax函数和Sigmoid函数的区别</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356976844">https://zhuanlan.zhihu.com/p/356976844</a></p>
<h2 id="保存与读取"><a href="#保存与读取" class="headerlink" title="保存与读取"></a>保存与读取</h2><p>Save on GPU, Load on GPU<br>Save:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<p>Load:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&quot;cuda&quot;)</span><br><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.to(device)</span><br><span class="line"># Make sure to call input = input.to(device) on any input tensors that you feed to the model</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>

<p>Remember that you must call <code>model.eval()</code> to set <strong>dropout and batch normalization layers</strong> to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.</p>
<h2 id="误差的表示"><a href="#误差的表示" class="headerlink" title="误差的表示"></a>误差的表示</h2><h2 id="训练参数怎么保存和读取"><a href="#训练参数怎么保存和读取" class="headerlink" title="训练参数怎么保存和读取"></a>训练参数怎么保存和读取</h2><h2 id="怎么表示数据"><a href="#怎么表示数据" class="headerlink" title="怎么表示数据"></a>怎么表示数据</h2><h2 id="怎么反向梯度法训练"><a href="#怎么反向梯度法训练" class="headerlink" title="怎么反向梯度法训练"></a>怎么反向梯度法训练</h2><h2 id="怎么使用GPU，怎么多GPU"><a href="#怎么使用GPU，怎么多GPU" class="headerlink" title="怎么使用GPU，怎么多GPU"></a>怎么使用GPU，怎么多GPU</h2><p>在GPU上训练 就像你怎么把一个张量转移到GPU上一样，你要将神经网络转到GPU上。 如果CUDA可以用，让我们首先定义下我们的设备为第一个可见的cuda设备。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assume that we are on a CUDA machine, then this should print a CUDA device:</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(device) <span class="comment"># cuda:0</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net=Net()</span><br><span class="line">net.to(device)</span><br><span class="line">outputs = net(inputs)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>

<h3 id="多GPU"><a href="#多GPU" class="headerlink" title="多GPU"></a>多GPU</h3><p>如果你想要来看到大规模加速，使用你的所有GPU，请查看：数据并行性（<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html%EF%BC%89%E3%80%82PyTorch">https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html）。PyTorch</a> 60 分钟入门教程：数据并行处理</p>
<p><a target="_blank" rel="noopener" href="http://pytorchchina.com/2018/12/11/optional-data-parallelism/">http://pytorchchina.com/2018/12/11/optional-data-parallelism/</a></p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><h3 id="网络结构可视化"><a href="#网络结构可视化" class="headerlink" title="网络结构可视化"></a>网络结构可视化</h3><p>自动<br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch">https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch</a></p>
<p>或者手动drawio</p>
<h2 id="误差实时可视化TensorBoard"><a href="#误差实时可视化TensorBoard" class="headerlink" title="误差实时可视化TensorBoard"></a>误差实时可视化TensorBoard</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/sddai/p/14516691.html">https://www.cnblogs.com/sddai/p/14516691.html</a></p>
<p>原理： 通过读取保存的log文件来可视化数据</p>
<h3 id="标量可视化"><a href="#标量可视化" class="headerlink" title="标量可视化"></a>标量可视化</h3><p>记录数据，默认在当前目录下一个名为’runs&#x2F;‘的文件夹中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写log的东西</span></span><br><span class="line">log_writer = SummaryWriter(<span class="string">&#x27;./path/to/log&#x27;</span>)</span><br><span class="line"><span class="comment"># 第一个参数是名称，第二个参数是y值，第三个参数是x值。</span></span><br><span class="line">log_writer.add_scalar(<span class="string">&#x27;Loss/train&#x27;</span>, <span class="built_in">float</span>(loss), epoch)</span><br></pre></td></tr></table></figure>

<p>运行 <code>tensorboard --logdir=runs/ --port 8123</code> 在某端口打开，比如 <code>https://127.0.0.1:6006</code></p>
<h3 id="网络结构可视化-1"><a href="#网络结构可视化-1" class="headerlink" title="网络结构可视化"></a>网络结构可视化</h3><p>在tensorboard的基础上使用tensorboardX</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from tensorboardX import SummaryWriter</span><br><span class="line"></span><br><span class="line">with SummaryWriter(comment=&#x27;LeNet&#x27;) as w:</span><br><span class="line">    w.add_graph(net, (net_input, ))</span><br></pre></td></tr></table></figure>

<h3 id="PR曲线"><a href="#PR曲线" class="headerlink" title="PR曲线"></a>PR曲线</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/b876144622/article/details/80009867">什么是PR曲线</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log_writer.add_pr_curve(&quot;pr_curve&quot;, label_batch, predict, epoch)</span><br></pre></td></tr></table></figure>

<p>x，y轴分别是recall和precision。应该有可能有矛盾的数据，或者网络分不开，<a target="_blank" rel="noopener" href="https://blog.csdn.net/u013249853/article/details/96132766?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_aa&utm_relevant_index=2">对于不同的阈值，可以划分出PR图。</a></p>
<p>与ROC曲线左上凸不同的是，PR曲线是右上凸效果越好。</p>
<h2 id="怎么分布式并行"><a href="#怎么分布式并行" class="headerlink" title="怎么分布式并行"></a>怎么分布式并行</h2><h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ol>
<li>矩阵或者向量的使用</li>
<li>optimizer.step()    # Does the update会自动循环吗？什么误差什么时候训练完毕呢？</li>
</ol>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>社会计算实验二，关于Meetup数据的预测性问题的解决</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://pytorch-cn.readthedocs.io/zh/latest/">https://pytorch-cn.readthedocs.io/zh/latest/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.pytorch123.com/">https://www.pytorch123.com/</a></p>
<p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html">https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html</a></p>
<p>Exploring the Impact of Dynamic Mutual Influence on Social Event<br>Participation</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-03T16:00:00.000Z" title="6/3/2023, 4:00:00 PM">2023-06-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.253Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Algorithms/">Algorithms</a></span><span class="level-item">16 minutes read (About 2454 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/03/Work/Algorithms/algorithm/">Algorithm: leetcode</a></p><div class="content"><h2 id="渐进符号"><a href="#渐进符号" class="headerlink" title="渐进符号"></a>渐进符号</h2><h2 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h2><p><img src="https://pic.shaojiemike.top/img/20230604160214.png"></p>
<ul>
<li>排序算法的稳定性：排序前后相同元素的相对位置不变，则称排序算法是稳定的；否则排序算法是不稳定的。</li>
<li>计数排序 中 k是数据出现的范围</li>
<li>基数排序时间复杂度为O(N*M)，其中N为数据个数，M为数据位数。</li>
</ul>
<h3 id="按照实现方法分类"><a href="#按照实现方法分类" class="headerlink" title="按照实现方法分类"></a>按照实现方法分类</h3><ul>
<li><p>选择排序</p>
<ul>
<li>直接选择排序：N轮，每轮变小的范围内找到最小值，然后与第i个交换。</li>
<li>堆排序：<ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/chengxiao/p/6129630.html">最大堆与数组的映射关系</a> 大顶堆：<code>arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2]</code>  </li>
<li>维护每轮范围变小的堆，每次将最大的堆顶移动到最后。每次维护堆需要O(logn)交换，把pop上来的小元素沉底到叶节点。</li>
<li>初始建堆需要O(nlogn)</li>
</ul>
</li>
</ul>
</li>
<li><p>插入排序</p>
<ul>
<li>直接插入：N轮，每轮从i开始向前插入（移动来交换），直到插入到合适的位置</li>
<li>希尔排序: 希尔排序是插入排序改良的算法，<ul>
<li>希尔排序步长从大到小调整，第一次循环后面元素逐个和前面元素按间隔步长进行比较并交换，</li>
<li>直至步长为1，步长选择是关键。</li>
</ul>
</li>
</ul>
</li>
<li><p>交换排序</p>
<ul>
<li>冒泡排序：冒泡N轮，每轮变小的范围内确定最后一个。</li>
<li>快速排序：在数组中随机选一个数（默认数组首个&#x2F;末尾元素），数组中小于等于此数的放在左边部分(<strong>交换到前面的排列</strong>)，大于此数的放在右边部分，这个操作确保了这个数是处于正确位置的，再对左边部分数组和右边部分数组递归调用快速排序，重复这个过程。</li>
</ul>
</li>
<li><p>分治合并</p>
<ul>
<li>归并排序： 首先让数组中的每一个数单独成为长度为1的区间，然后两两一组有序合并，得到长度为2的有序区间，依次合并进行得到长度为4、8、16的区间，直到合成整个区间。</li>
</ul>
</li>
<li><p>计数排序：数据出现的范围k &lt;&lt; O(n)时，或者k&#x3D;O(n)都可以采用该方法。</p>
</li>
<li><p>基数排序：对数据的每一位(共M位)从低位到高位进行stableSort。大部分时候选择计数排序O(N+k)。总时间复杂度O(M*(N+k))</p>
</li>
<li><p>桶排序：类似计数排序的思想，但是一般是对于区间等分为桶。桶内可以采用插入排序。n个元素n个桶，数学期望是O(n)</p>
</li>
</ul>
<h3 id="堆排序代码细节"><a href="#堆排序代码细节" class="headerlink" title="堆排序代码细节"></a>堆排序代码细节</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">heapSort</span><span class="params">(<span class="type">int</span> array[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="comment">//先建立堆</span></span><br><span class="line">    <span class="keyword">for</span> (i=n/<span class="number">2</span>;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">HeapAdjust</span>(array,i,n);<span class="comment">//从下向上，从右向左调整</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//交换最大堆顶，重复n次</span></span><br><span class="line">    <span class="keyword">for</span>( i=n;i&gt;<span class="number">1</span>;i--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">swap</span>(array, <span class="number">1</span>, i);</span><br><span class="line">        <span class="built_in">HeapAdjust</span>(array, <span class="number">1</span>, i<span class="number">-1</span>);<span class="comment">//从上到下，从左向右调整</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HeapAdjust</span><span class="params">(<span class="type">int</span> array[], <span class="type">int</span> s, <span class="type">int</span> n )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i,temp;</span><br><span class="line">    temp = array[s];</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">2</span>*s;i&lt;=n;i*=<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;n&amp;&amp;array[i]&lt;array[i+<span class="number">1</span>])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//交换左右子树最大的那个</span></span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(temp&gt;=array[i])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//找到了插入的合适的位置，子节点更小，父节点更大</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将节点向上移动</span></span><br><span class="line">        array[s]=array[i];</span><br><span class="line">        s=i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将最顶部插入到合适的位置</span></span><br><span class="line">    array[s]=temp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> array[], <span class="type">int</span> i, <span class="type">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> temp;</span><br><span class="line">    temp=array[i];</span><br><span class="line">    array[i]=array[j];</span><br><span class="line">    array[j]=temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="排序相关的问题"><a href="#排序相关的问题" class="headerlink" title="排序相关的问题"></a>排序相关的问题</h3><ul>
<li>既然时间复杂度堆排序、归并排序好于快排，为什么C++的qsort使用的是快排<ul>
<li>快速排序访存更友好，堆排序访问是跳跃的</li>
<li>对于同样的数据，排序过程中，堆排序算法的数据交换次数多于快排<ul>
<li>堆排序建立堆，与堆顶的交换，很多时候都是无用功</li>
</ul>
</li>
<li>在数据量小的时候快速排序当属第一，堆排序最差，但随着数据的不断增大归并排序的性能会逐步赶上并超过快速排序，性能成为三种算法之首。</li>
</ul>
</li>
<li>C++ 的 stable_sort 是基于归并排序的</li>
</ul>
<h2 id="LeetCode-常见算法"><a href="#LeetCode-常见算法" class="headerlink" title="LeetCode 常见算法"></a>LeetCode 常见算法</h2><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><p>拓扑排序常用来确定一个依赖关系集(图关系)中，事物发生的顺序。</p>
<p>带信号量判断的无依赖队列来实现，入队无依赖集合，出队的无依赖元素(add to result)去除后续元素的依赖信号量，信号量为0代表无依赖，可以入队。</p>
<h3 id="无环图（树图）中最长距离"><a href="#无环图（树图）中最长距离" class="headerlink" title="无环图（树图）中最长距离"></a>无环图（树图）中最长距离</h3><p>找到图中距离最远的两个节点与它们之间的路径：</p>
<p>以任意节点 pp 出现，利用广度优先搜索或者深度优先搜索找到以 pp 为起点的最长路径的终点 xx；</p>
<p>以节点 xx 出发，找到以 xx 为起点的最长路径的终点 yy；</p>
<p>xx 到 yy 之间的路径即为图中的最长路径，找到路径的中间节点即为根节点。</p>
<h3 id="树状数组"><a href="#树状数组" class="headerlink" title="树状数组"></a>树状数组</h3><p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/circle/article/9ixykn/">https://leetcode-cn.com/circle/article/9ixykn/</a></p>
<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/range-sum-query-mutable/">https://leetcode-cn.com/problems/range-sum-query-mutable/</a></p>
<h3 id="广度搜索确定图中各点对0点最近距离"><a href="#广度搜索确定图中各点对0点最近距离" class="headerlink" title="广度搜索确定图中各点对0点最近距离"></a>广度搜索确定图中各点对0点最近距离</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//input [[0,1],[1,2]]</span></span><br><span class="line"><span class="comment">//维护</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&gt; adj(n); <span class="comment">//先找出每个点的有关边</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt; <span class="title function_">visit</span><span class="params">(n, <span class="literal">false</span>)</span>;   <span class="comment">//维护已访问元素</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">queue</span>&lt;<span class="type">int</span>&gt; qu;</span><br><span class="line"></span><br><span class="line">qu.emplace(<span class="number">0</span>);</span><br><span class="line">visit[<span class="number">0</span>] = <span class="literal">true</span>;</span><br><span class="line"><span class="type">int</span> dist = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (!qu.empty()) &#123;</span><br><span class="line">    <span class="type">int</span> sz = qu.size();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; sz; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> curr = qu.front();</span><br><span class="line">        qu.pop();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp; v : adj[curr]) &#123;</span><br><span class="line">            <span class="keyword">if</span> (visit[v]) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            qu.emplace(v);</span><br><span class="line">            <span class="comment">//对应处理</span></span><br><span class="line">            visit[v] = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dist++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2进制数表示子集合"><a href="#2进制数表示子集合" class="headerlink" title="2进制数表示子集合"></a>2进制数表示子集合</h3><p>对集合大小为n，可以用大于等于0小于<code>1&lt;&lt;n</code>的<code>2^n-1</code>个数字来表示子集。</p>
<p>但是对每个子集都会单独计算，有重复。 不如用按每位是否存在回溯</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">2044</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">countMaxOrSubsets</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&amp; nums)</span> &#123;</span><br><span class="line">        <span class="type">int</span> maxOr = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> n: nums)&#123;</span><br><span class="line">            maxOr = n | maxOr;</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(nums, maxOr, <span class="number">0</span> , <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> maxOr, <span class="type">int</span> idx, <span class="type">int</span> cur)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (cur == maxOr)&#123;</span><br><span class="line">            ans += <span class="number">1</span> &lt;&lt; (nums.size()-idx);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (idx == nums.size())&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        dfs(nums, maxOr, idx+<span class="number">1</span>, cur | nums[idx]);</span><br><span class="line">        dfs(nums, maxOr, idx+<span class="number">1</span>, cur);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2进制表示使用状态true-false"><a href="#2进制表示使用状态true-false" class="headerlink" title="2进制表示使用状态true false"></a>2进制表示使用状态true false</h3><p>int 可以表示32个元素的使用情况</p>
<p><a target="_blank" rel="noopener" href="https://leetcode.cn/problems/can-i-win/">https://leetcode.cn/problems/can-i-win/</a></p>
<h3 id="前缀和和差分"><a href="#前缀和和差分" class="headerlink" title="前缀和和差分"></a>前缀和和差分</h3><p><code>前缀和</code><br>和<code>差分</code><br>是一组互逆的方法；他们的关系和<code>积分</code><br>与<code>求导</code><br>实质是一样的。前缀和可以帮我们通过预处理快速的求出区间的和；差分则可以快速帮助我们记录区间的修改。</p>
<p>将区间前一个加一，最后一个减一实现。</p>
<p>leetcode 798</p>
<h3 id="预处理查询的数组"><a href="#预处理查询的数组" class="headerlink" title="预处理查询的数组"></a>预处理查询的数组</h3><p>通过预处理记录信息来减少查询的时间</p>
<p>leetcode 2055</p>
<h3 id="二分法"><a href="#二分法" class="headerlink" title="二分法"></a>二分法</h3><p>二分寻找满足条件的最小整数,  注意<code>left + 1 &lt; right</code>和<code>s &gt;= cars</code></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">while</span> (left + <span class="number">1</span> &lt; right) &#123; <span class="comment">// 开区间</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> mid = (left + right) / <span class="number">2</span>, s = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> r : ranks)</span><br><span class="line">        s += <span class="built_in">sqrt</span>(mid / r);</span><br><span class="line">    (s &gt;= cars ? right : left) = mid;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 作者：灵茶山艾府</span></span><br><span class="line"><span class="comment">// 链接：https://leetcode.cn/problems/minimum-time-to-repair-cars/solutions/2177199/er-fen-da-an-pythonjavacgo-by-endlessche-keqf/</span></span><br><span class="line"><span class="comment">// 来源：力扣（LeetCode）</span></span><br><span class="line"><span class="comment">// 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span></span><br></pre></td></tr></table></figure>

<h3 id="直接模拟"><a href="#直接模拟" class="headerlink" title="直接模拟"></a>直接模拟</h3><p>最常用的方法</p>
<h3 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h3><p>根据设定的哈希函数H（key）和处理冲突方法将一组关键字映象到一个有限的地址区间上的算法。也称为散列算法、杂凑算法。</p>
<h4 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h4><p>一般有：开放定址法、链地址法（拉链法）、再哈希法、建立公共溢出区</p>
<h2 id="LeetCode-代码优化加速"><a href="#LeetCode-代码优化加速" class="headerlink" title="LeetCode 代码优化加速"></a>LeetCode 代码优化加速</h2><h3 id="cin-tie与sync-with-stdio加速输入输出"><a href="#cin-tie与sync-with-stdio加速输入输出" class="headerlink" title="cin.tie与sync_with_stdio加速输入输出"></a>cin.tie与sync_with_stdio加速输入输出</h3><p>std::ios::sync_with_stdio(); 是一个“是否兼容stdio”的开关，C++为了兼容C，保证程序在使用了std::printf和std::cout的时候不发生混乱，将输出流绑到了一起。也就是 C++标准streams(cin,cout,cerr…) 与相应的C标准程序库文件(stdin,stdout,stderr)同步，使用相同的 stream 缓冲区。<br>默认是同步的，但由于同步会带来某些不必要的负担，因此该函数作用是使得用户可以自行取消同步。</p>
<p>cin.tie(NULL) 取消 cin 和 cout 的绑定。</p>
<p>这对于输入数据个数<strong>在10^5以上的程序十分有效</strong>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> x = []() &#123;</span><br><span class="line">    <span class="built_in">std</span>::ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;();</span><br><span class="line"><span class="comment">// or</span></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="keyword">auto</span> io_sync_off = []() &#123;</span><br><span class="line">    <span class="built_in">std</span>::ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span>.tie(nullptr);</span><br><span class="line">    <span class="keyword">return</span> nullptr;</span><br><span class="line">&#125;();</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> init = []() &#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(nullptr);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;();</span><br></pre></td></tr></table></figure>

<h3 id="问题拆分循环调用"><a href="#问题拆分循环调用" class="headerlink" title="问题拆分循环调用"></a>问题拆分循环调用</h3><p>不如从底层动态规划合并，不要嵌套函数调用，还可以用二维数据，数据局部性较好。</p>
<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/optimal-division/submissions/">https://leetcode-cn.com/problems/optimal-division/submissions/</a></p>
<h3 id="不一定要执着数据只遍历一遍"><a href="#不一定要执着数据只遍历一遍" class="headerlink" title="不一定要执着数据只遍历一遍"></a>不一定要执着数据只遍历一遍</h3><p>可以将复杂的一次遍历，拆开成两次遍历，一次处理数据并存储，一次遍历统计。速度反而会快</p>
<h3 id="简单递归循环"><a href="#简单递归循环" class="headerlink" title="简单递归循环"></a>简单递归循环</h3><p>用while代替函数递归调用，eg二分法</p>
<h3 id="减少if语句"><a href="#减少if语句" class="headerlink" title="减少if语句"></a>减少if语句</h3><p>可以保存分支的值来实现(1748)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">//0ms</span><br><span class="line">int sumOfUnique(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line"> int state[101]&#123;&#125;, ans = 0, d[101]&#123;1,-1&#125;;</span><br><span class="line"> for(int x: nums) ans += d[state[x]++] * x;</span><br><span class="line"> return ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//4ms</span><br><span class="line">int sumOfUnique(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line"> array&lt;char,101&gt; isshowed &#123;&#125;;</span><br><span class="line"> int sum=0;</span><br><span class="line"> for(auto&amp; num:nums)&#123;</span><br><span class="line">  if(isshowed[num]==0)&#123;</span><br><span class="line">   isshowed[num]=1;</span><br><span class="line">   sum+=num;</span><br><span class="line">  &#125;else if(isshowed[num]==1)&#123;</span><br><span class="line">   isshowed[num]=2;</span><br><span class="line">   sum-=num;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> return sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="通过判断筛选掉"><a href="#通过判断筛选掉" class="headerlink" title="通过判断筛选掉"></a>通过判断筛选掉</h3><p>无用的遍历计算(1219)</p>
<h3 id="减少for循环"><a href="#减少for循环" class="headerlink" title="减少for循环"></a>减少for循环</h3><p>循环展开，只有一两种情况就不要写for循环了</p>
<h2 id="注意的细节"><a href="#注意的细节" class="headerlink" title="注意的细节"></a>注意的细节</h2><h3 id="计算防止溢出"><a href="#计算防止溢出" class="headerlink" title="计算防止溢出"></a>计算防止溢出</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int middle = left + ((right - left) / 2);// 防止溢出 等同于(left + right)/2</span><br></pre></td></tr></table></figure>

<h3 id="转化成加减，而不用乘法"><a href="#转化成加减，而不用乘法" class="headerlink" title="转化成加减，而不用乘法"></a>转化成加减，而不用乘法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A &lt; B/2</span><br><span class="line">变成</span><br><span class="line">A &lt; B-A</span><br></pre></td></tr></table></figure>

<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://oi-wiki.org/dp/basic/">https://oi-wiki.org/dp/basic/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/azl397985856/leetcode/blob/master/thinkings/dynamic-programming.md">https://github.com/azl397985856/leetcode/blob/master/thinkings/dynamic-programming.md</a></p>
<p>作者：AC_OIer<br>链接：<a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/the-number-of-good-subsets/solution/gong-shui-san-xie-zhuang-ya-dp-yun-yong-gz4w5/">https://leetcode-cn.com/problems/the-number-of-good-subsets/solution/gong-shui-san-xie-zhuang-ya-dp-yun-yong-gz4w5/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-03T16:00:00.000Z" title="6/3/2023, 4:00:00 PM">2023-06-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.261Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Operating-system/">Operating system</a></span><span class="level-item">23 minutes read (About 3463 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/03/Work/Operating%20system/lock/">Lock</a></p><div class="content"><h2 id="互斥与同步的实现和使用"><a href="#互斥与同步的实现和使用" class="headerlink" title="互斥与同步的实现和使用"></a>互斥与同步的实现和使用</h2><p>在进程&#x2F;线程并发执行的过程中，进程&#x2F;线程之间存在协作的关系，例如有互斥、同步的关系。</p>
<p>为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p>
<ul>
<li><p>锁：加锁、解锁操作；</p>
<ul>
<li>自旋锁(spin lock， 忙等待锁)，基于原子操作指令 —— 测试和置位（Test-and-Set）指令</li>
<li>无等待锁：思想，把当前线程放入到锁的等待队列，然后执行调度程序</li>
</ul>
</li>
<li><p>信号量：P、V 操作；</p>
</li>
</ul>
<p>这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步。</p>
<h2 id="锁相关问题"><a href="#锁相关问题" class="headerlink" title="锁相关问题"></a>锁相关问题</h2><ol start="6">
<li>共享内存加锁之后释放锁，别的进程是如何知道锁释放的<ol>
<li>常用的方法是在共享内存中设置<strong>标志位或信号量</strong>等，并在共享内存中保证这个标志位或信号量只有在锁被释放时才会被更新。这样，其它进程可以通过<strong>轮询或者等待通知</strong>的方式来获取锁并开始修改共享内存，从而避免冲突。在共享内存中设置的标志位或信号量通常需要原子操作的支持，以确保并发修改时的正确性。<ol>
<li>轮询：轮询是指线程反复检查某个条件是否成立，直到条件成立为止。在锁机制中，当一个线程持有锁时，其他线程会不断地轮询锁的状态，直到该锁被释放。这种方式的优点是实现简单，不需要额外的通知机制，缺点是占用CPU资源，效率较低。</li>
<li>等待通知：等待通知是指线程在某个条件不满足时挂起等待，当条件满足时由其他线程通知它继续执行。在锁机制中，当一个线程持有锁时，其他线程会进入等待状态，直到该锁被释放，此时其他线程会被通知并继续执行。这种方式的优点是占用CPU资源少，效率高，缺点是实现稍微复杂一些，需要额外的通知机制。</li>
</ol>
</li>
<li>另外，也可以使用一个中央锁服务器或者等待队列来管理锁，当一个进程获取锁时，会向中央锁服务器或等待队列发出请求，直到锁被成功获取，并在共享内存中记录锁的状态。当锁被释放时，中央锁服务器或等待队列会通知其它进程，并让其它进程开始自由修改共享内存。</li>
</ol>
</li>
<li>如何保证操作的原子性<ol>
<li>操作系统提供的原子操作：一些操作系统会提供线程安全的原子操作接口，如Compare-And-Swap（CAS）等，它们能够确保指令的原子性，从而保证线程安全。</li>
<li>事务：事务是指一组操作被视为一个不可分割的操作序列，要么全部执行成功，要么全部失败，具有原子性和一致性保证。常用于数据库操作等场景。</li>
<li>锁机制：锁机制是一种常用的多线程同步机制，能够确保同一时刻只有一个线程（或进程）可以访问共享资源，从而保证原子性。</li>
</ol>
</li>
<li>如何避免死锁<ol>
<li>避免使用多把锁并且同时持有多个锁。当需要持有多个锁时，可以通过加锁的顺序来避免死锁。如果所有可能的锁按照固定的顺序加锁，那么可以避免死锁。</li>
<li>设置请求超时时间。当一个进程请求锁时，如果在超时时间内没有获得锁，可以释放之前持有的锁，并尝试重新获取。这样可以避免某一个进程一直持有锁而导致死锁。</li>
<li>引入随机性。在获取锁的时候加入一些随机因素，让不同的程序在不同的时间获取锁。这样可以防止程序之间在自己的重试过程中的饥饿状态导致的死锁。</li>
</ol>
</li>
</ol>
<h2 id="RedStar-小红书-笔试"><a href="#RedStar-小红书-笔试" class="headerlink" title="RedStar (小红书) 笔试"></a>RedStar (小红书) 笔试</h2><h3 id="图中有依赖的任务的，需要几个信号量来实现同步"><a href="#图中有依赖的任务的，需要几个信号量来实现同步" class="headerlink" title="图中有依赖的任务的，需要几个信号量来实现同步"></a>图中有依赖的任务的，需要几个信号量来实现同步</h3><p>如<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45385429/article/details/115250919">CSDN</a>，有一条依赖线，需要一个信号量</p>
<p>在使用信号量(Semaphore)进行线程同步时,P(proberen)和V(verhogen)操作是非常重要的概念。</p>
<ol>
<li>P操作（也称为Wait操作或Down操作）：</li>
</ol>
<ul>
<li>表示获取或等待信号量。</li>
<li>如果信号量内部计数值大于0,获取信号量并将计数值减1。</li>
<li>如果计数值等于0,线程将等待,直到计数值大于0。如果信号量的值大于0，表示资源可用，进程可以继续执行。如果信号量的值为0，表示资源不可用，P操作将阻塞（即等待）进程，直到该信号量的值大于0为止。</li>
</ul>
<p>伪代码表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">P(S):</span><br><span class="line">  while S &lt;= 0:</span><br><span class="line">    // 等待，直到S大于0</span><br><span class="line">  S = S - 1</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>V操作（也称为Signal操作或Up操作）：</li>
</ol>
<ul>
<li>表示释放或增加信号量。</li>
<li>将信号量内部计数值加1。</li>
<li>如果存在等待线程,唤醒其中一个线程继续执行。</li>
</ul>
<p>伪代码表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">V(S):</span><br><span class="line">  S = S + 1</span><br></pre></td></tr></table></figure>

<p>P和V操作保证了对共享资源的互斥访问。</p>
<p>一个线程使用P操作等待获取信号量,V操作在使用完共享资源后释放信号量。</p>
<p>信号量的值通常用于控制共享资源的数量，它可以是<strong>非负整数</strong>。当信号量被初始化为1时，称为二进制信号量（Binary Semaphore），因为它只能取0或1的值，通常用于实现互斥访问临界区。如果信号量的值大于1，称为计数信号量，可用于限制对资源的并发访问数。</p>
<p>在实际编程中，P操作和V操作通常是原子操作，确保在多线程或多进程环境下的正确同步和竞争条件的安全处理。</p>
<h2 id="TP-link笔试"><a href="#TP-link笔试" class="headerlink" title="TP-link笔试"></a>TP-link笔试</h2><p>设计的程序在多个CPU上运行时，不应使用哪个实现多个CPU间的数据访问同步？</p>
<ul>
<li><p>自旋锁(spinlock): 多线程同步的一种忙等待锁，线程反复检查锁变量是否可用。</p>
<ul>
<li>优点：避免了操作系统进程调度和线程切换，所以自旋锁通常适用在时间比较短的情况下。由于这个原因，操作系统的内核经常使用自旋锁。</li>
<li>缺点：如果长时间上锁的话，自旋锁会非常耗费性能，它阻止了其他线程的运行和调度<ul>
<li>线程持有锁的时间越长，则持有该锁的线程将被 OS(Operating System) 调度程序中断的风险越大。</li>
</ul>
</li>
<li>解决办法： TicketLock 是采用排队叫号的机制。CLHLock和MCSLock通过链表的方式避免了减少了处理器缓存同步，极大的提高了性能，区别在于CLHLock是通过轮询其前驱节点的状态，而MCS则是查看当前节点的锁状态。</li>
</ul>
</li>
<li><p>互斥锁(mutex)：把自己阻塞起来（内核态和用户态之间的切换进入阻塞状态，可能上下文切换），等待重新调度请求。</p>
<ul>
<li>互斥锁的实现<ol>
<li>软件实现：软件互斥锁需要借助操作系统提供的原子操作（如Compare-And-Swap，CAS）来实现 优点是灵活性高 缺点是性能较低，</li>
<li>CAS操作需要三个参数，内存地址A，期望值V，新值N。执行过程如下：<ul>
<li>读取内存地址A的原始值，保存在临时变量Value中</li>
<li>比较Value和期待值V是否相等，如果相等则将内存地址A的值更新为新值N</li>
<li>如果内存地址A的值已经被其他线程改变，则不进行更新操作</li>
</ul>
</li>
</ol>
<ul>
<li>TAS（test and set）<ul>
<li>一个TAS指令包括两个子步骤，把给定的内存地址设置为1，然后返回之前的旧值。</li>
</ul>
<ol start="2">
<li>硬件实现：硬件互斥锁使用计算机硬件提供的特殊指令（如锁总线指令）来实现。当线程要获取锁时，它会发出一个锁总线指令，这个指令会占用系统总线，使得其他CPU无法读写内存。<ol>
<li>当lock前缀指令执行时，它将锁定处理器总线，确保其他处理器无法同时访问同一内存区域，</li>
</ol>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p>读写锁（ReadWrite Lock）</p>
<ul>
<li>在读操作和写操作之间提供了更细粒度的同步控制。</li>
<li>多个线程可以同时获取读锁，但只有一个线程能够获取写锁。<ul>
<li>读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态</li>
<li>规则<ul>
<li>当读写锁在写加锁模式下，任何试图对这个锁进行加锁的线程都会被阻塞，直到写进程对其解锁。</li>
<li>当读写锁在读加锁模式先，任何线程都可以对其进行读加锁操作，但是所有试图进行写加锁操作的线程都会被阻塞，直到所有的读线程都解锁。</li>
</ul>
</li>
</ul>
</li>
<li>缺点：当读者源源不断到来的时候，写者总是得不到读写锁，就会造成不公平的状态。<ul>
<li>避免方法： 当处于读模式的读写锁接收到一个试图对其进行写模式加锁操作时，便会阻塞后面对其进行读模式加锁操作的线程。这样等到已经加读模式的锁解锁后，写进程能够访问此锁保护的资源。</li>
</ul>
</li>
<li>优点：<ul>
<li>读写锁可以提高并发性，允许多个线程同时读取数据，而只有在需要修改数据时才会互斥。</li>
<li>适合对数据结构读的次数远远大于写的情况。</li>
</ul>
</li>
</ul>
</li>
<li><p>RCU（Read-Copy-Update）</p>
<ul>
<li>对读写锁的一种改进。适用于读多写少场景的数据同步机制。</li>
<li>具体内容<ul>
<li>并发读取数据不再需要加锁</li>
<li>写数据时，RCU机制通过创建一个副本来实现读写分离，确保在更新过程中没有线程正在读取旧的数据。<ul>
<li>写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。</li>
<li>读者必须提供一个信号给写者以便写者能够确定数据可以被安全地释放或修改的时机。</li>
<li>有一个专门的垃圾收集器来探测读者的信号，一旦所有的读者都已经发送信号告知它们都不在使用被RCU保护的数据结构，垃圾收集器就调用回调函数完成最后的数据释放或修改操作。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>悲观锁</p>
<ol>
<li><strong>读</strong>写操作时，需要预先加锁，防止其他进程对资源的访问。</li>
<li>通过<strong>互斥锁（Mutex）和信号量（Semaphore）</strong>来实现。</li>
</ol>
</li>
<li><p>乐观锁</p>
<ol>
<li>在读取或修改共享资源时，并不先进行加锁操作，而是先读取资源，然后在对资源进行写操作时再进行一次比较，看看在这个时间间隔内是否发生了竞争。如果没有发生竞争，就可以将更新后的值写入共享资源，并结束操作；如果发生了竞争，则需要放弃本次更新，并进行重试</li>
<li>通过<strong>版本号</strong>的方式来实现。在共享资源中记录该资源的版本号，当一个进程想要修改共享资源时，需要先获取当前资源的版本号。如果当前版本号与自己保存的版本号相符，说明没有其他进程在这段时间内修改该资源，则可以进行写操作；如果版本号已经发生变化，则说明有其他进程对该资源进行了修改，当前进程需要放弃本次写操作，更新版本号，重新获取新的资源，并重新执行操作。</li>
</ol>
</li>
</ul>
<p>下面回答部分<strong>来自ChatGPT-3.5</strong>，暂时没有校验其可靠性(看上去貌似说得通)。</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.cswiki.top/pages/f398f1/#blocking-i-o">https://www.cswiki.top/pages/f398f1/#blocking-i-o</a></p>
<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_15437629/article/details/79116590">https://blog.csdn.net/qq_15437629/article/details/79116590</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161936748">https://zhuanlan.zhihu.com/p/161936748</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-30T16:00:00.000Z" title="5/30/2023, 4:00:00 PM">2023-05-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.261Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">24 minutes read (About 3665 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/30/Work/HPC/llvm-mca/LLVM-mca/">LLVM-MCA: docs</a></p><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>LLVM Machine Code Analyzer 是一种性能分析工具，它使用llvm中可用的信息（如调度模型）静态测量特定CPU中机器代码的性能。</p>
<p>性能是根据<strong>吞吐量</strong>和<strong>处理器资源消耗</strong>来衡量的。该工具目前适用于在后端中使用LLVM调度模型的处理器。</p>
<p>该工具的主要目标不仅是预测代码在目标上运行时的性能，还帮助诊断潜在的性能问题。</p>
<p>给定汇编代码，llvm-mca可以估计每个周期的指令数（IPC）以及硬件资源压力。分析和报告风格的灵感来自英特尔的IACA工具。</p>
<h3 id="github"><a href="#github" class="headerlink" title="github"></a>github</h3><p><a target="_blank" rel="noopener" href="https://github.com/llvm/llvm-project/tree/main/llvm/tools/llvm-mca">https://github.com/llvm/llvm-project/tree/main/llvm/tools/llvm-mca</a></p>
<h3 id="docs"><a href="#docs" class="headerlink" title="docs"></a>docs</h3><p><a target="_blank" rel="noopener" href="https://llvm.org/docs/CommandGuide/llvm-mca.html">https://llvm.org/docs/CommandGuide/llvm-mca.html</a></p>
<h2 id="options"><a href="#options" class="headerlink" title="options"></a>options</h2><h3 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a>architecture</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-mtriple=&lt;target triple&gt;</span><br><span class="line">    eg. -mtriple=x86_64-unknown-unknown</span><br><span class="line">-march=&lt;arch&gt;</span><br><span class="line">    Specify the architecture for which to analyze the code. It defaults to the host default target.</span><br><span class="line">-march=&lt;arch&gt;</span><br><span class="line">    Specify the architecture for which to analyze the code. It defaults to the host default target.</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看支持的arch</span></span><br><span class="line">llc --version</span><br><span class="line"><span class="comment"># 查看具体支持的CPU Architecture</span></span><br><span class="line">llc -march=x86 -mattr=<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<h3 id="output-report"><a href="#output-report" class="headerlink" title="output-report"></a>output-report</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-output-asm-variant=&lt;variant id&gt;</span><br><span class="line">    为工具生成的报告指定输出程序集变量。???</span><br><span class="line">-print-imm-hex</span><br><span class="line">    优先16进制输出。</span><br><span class="line">-json</span><br><span class="line">    除了瓶颈分析，基本都支持json格式输出视图</span><br><span class="line">-timeline</span><br><span class="line">    打印指令流水线情况</span><br></pre></td></tr></table></figure>

<h3 id="runtime-options"><a href="#runtime-options" class="headerlink" title="runtime options"></a>runtime options</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-dispatch=&lt;width&gt;</span><br><span class="line">    为处理器指定不同的调度宽度。调度宽度默认为处理器调度模型中的“IssueWidth”字段。</span><br><span class="line">-register-file-size=&lt;size&gt;</span><br><span class="line">    指定寄存器文件的大小。指定时，该项会限制可用于寄存器重命名的物理寄存器的数量。此标志的值为零意味着“无限数量的物理寄存器”。</span><br><span class="line">-iterations=&lt;number of iterations&gt;</span><br><span class="line">    指定要运行的迭代次数。如果此标志设置为 0，则该工具会将迭代次数设置为默认值（即 100）。</span><br><span class="line">-noalias=&lt;bool&gt;</span><br><span class="line">    loads and stores don’t alias</span><br><span class="line">-lqueue=&lt;load queue size&gt;</span><br><span class="line">-squeue=&lt;store queue size&gt;</span><br><span class="line">    在工具模拟的加载/存储单元中指定加载队列的大小。默认情况下，该工具假定加载队列中的条目数量不受限制。此标志的零值将被忽略，而是使用默认加载队列大小。</span><br><span class="line">-disable-cb</span><br><span class="line">    强制使用通用的 CustomBehaviour 和 InstrPostProcess 类，而不是使用目标特定的实现。通用类从不检测任何自定义危险或对指令进行任何后处理修改。</span><br></pre></td></tr></table></figure>

<h3 id="more-values-Info"><a href="#more-values-Info" class="headerlink" title="more values&#x2F;Info"></a>more values&#x2F;Info</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-resource-pressure</span><br><span class="line">    Enable the resource pressure view. This is enabled by default.</span><br><span class="line">-register-file-stats</span><br><span class="line">    启用注册文件使用统计。</span><br><span class="line">-dispatch-stats</span><br><span class="line">-scheduler-stats</span><br><span class="line">-retire-stats</span><br><span class="line">-instruction-info</span><br><span class="line">    启用额外的调度/发出/retire control unit统计。该视图收集和分析指令分派事件，以及静态/动态分派停顿事件。默认情况下禁用此视图。</span><br><span class="line">-show-encoding</span><br><span class="line">    打印指令16进制</span><br><span class="line">-all-stats</span><br><span class="line">-all-views</span><br><span class="line">-instruction-tables</span><br><span class="line">    这与资源压力视图不同，因为它不需要模拟代码。相反，它按顺序打印每个指令的资源压力的理论均匀分布。</span><br><span class="line">-bottleneck-analysis</span><br><span class="line">    打印有关影响吞吐量的瓶颈的信息。这种分析可能很昂贵，并且默认情况下是禁用的。瓶颈在摘要视图中突出显示。具有有序后端的处理器目前不支持瓶颈分析。???</span><br></pre></td></tr></table></figure>

<h2 id="实现逻辑"><a href="#实现逻辑" class="headerlink" title="实现逻辑"></a>实现逻辑</h2><p><img src="https://pic.shaojiemike.top/img/38FD1039D93F746E0A45477E84CF74A0.png"></p>
<h2 id="样例分析"><a href="#样例分析" class="headerlink" title="样例分析"></a>样例分析</h2><h3 id="quick-overview-of-the-performance-throughput"><a href="#quick-overview-of-the-performance-throughput" class="headerlink" title="quick overview of the performance throughput"></a>quick overview of the performance throughput</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Iterations:        300</span><br><span class="line">Instructions:      900</span><br><span class="line">Total Cycles:      610</span><br><span class="line">Total uOps:        900</span><br><span class="line"></span><br><span class="line">Dispatch Width:    2</span><br><span class="line">uOps Per Cycle:    1.48</span><br><span class="line">IPC:               1.48</span><br><span class="line">Block RThroughput: 2.0</span><br></pre></td></tr></table></figure>

<ol>
<li>IPC<ol>
<li>理论最大值是$$\frac{OneLoopInstructions}{Block_RThroughput}&#x3D;(OneLoopInstructions)*(Block_Throughput)$$</li>
</ol>
</li>
<li>uOps Per Cycle<ol>
<li>simulated micro opcodes (uOps)</li>
<li><strong>每个周期的simulated micro opcodes数</strong></li>
<li>在不考虑循环依赖的情况下，理论上最大值是$$\frac{OneLoopUOps}{Block_RThroughput}&#x3D;(OneLoopUOps)*(Block_Throughput)$$</li>
<li>A delta between Dispatch Width and this field is an indicator of a performance issue.</li>
<li>The delta between the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is an indicator of a performance bottleneck caused by the lack of hardware resources, and the Resource pressure view can help to identify the problematic resource usage.</li>
</ol>
</li>
<li>Dispatch Width<ol>
<li>发射到乱序后端的最大微指令操作数(the maximum number of micro opcodes&#x2F;uOps)？</li>
</ol>
</li>
<li>Block RThroughput (Block Reciprocal Throughput)<ol>
<li>在不考虑循环依赖的情况下，理论上的<strong>每次循环的最大block或者iterations数</strong></li>
<li>受限于dispatch rate和the availability of hardware resources.</li>
</ol>
</li>
</ol>
<h3 id="Instruction-info-view"><a href="#Instruction-info-view" class="headerlink" title="Instruction info view"></a>Instruction info view</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Instruction Info:</span><br><span class="line">[1]: #uOps</span><br><span class="line">[2]: Latency</span><br><span class="line">[3]: RThroughput</span><br><span class="line">[4]: MayLoad</span><br><span class="line">[5]: MayStore</span><br><span class="line">[6]: HasSideEffects (U)</span><br><span class="line"></span><br><span class="line">[1]    [2]    [3]    [4]    [5]    [6]    Instructions:</span><br><span class="line"> 1      2     1.00                        vmulps      %xmm0, %xmm1, %xmm2</span><br><span class="line"> 1      3     1.00                        vhaddps     %xmm2, %xmm2, %xmm3</span><br><span class="line"> 1      3     1.00                        vhaddps     %xmm3, %xmm3, %xmm4</span><br></pre></td></tr></table></figure>

<p>显示了指令里队列每条指令的<strong>延迟</strong>和<strong>吞吐量的倒数</strong>。</p>
<p>RThroughput是指令吞吐量的倒数。在不考虑循环依赖的情况下，吞吐量是<strong>单周期能执行的同类型指令的最大数量</strong>。</p>
<h3 id="Resource-pressure-view"><a href="#Resource-pressure-view" class="headerlink" title="Resource pressure view"></a>Resource pressure view</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Resources:</span><br><span class="line">[0]   - JALU0</span><br><span class="line">[1]   - JALU1</span><br><span class="line">[2]   - JDiv</span><br><span class="line">[3]   - JFPA</span><br><span class="line">[4]   - JFPM</span><br><span class="line">[5]   - JFPU0</span><br><span class="line">[6]   - JFPU1</span><br><span class="line">[7]   - JLAGU</span><br><span class="line">[8]   - JMul</span><br><span class="line">[9]   - JSAGU</span><br><span class="line">[10]  - JSTC</span><br><span class="line">[11]  - JVALU0</span><br><span class="line">[12]  - JVALU1</span><br><span class="line">[13]  - JVIMUL</span><br><span class="line"></span><br><span class="line">Resource pressure per iteration:</span><br><span class="line">[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    [10]   [11]   [12]   [13]</span><br><span class="line"> -      -      -     2.00   1.00   2.00   1.00    -      -      -      -      -      -      -</span><br><span class="line"></span><br><span class="line">Resource pressure by instruction:</span><br><span class="line">[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    [10]   [11]   [12]   [13]   Instructions:</span><br><span class="line"> -      -      -      -     1.00    -     1.00    -      -      -      -      -      -      -     vmulps      %xmm0, %xmm1, %xmm2</span><br><span class="line"> -      -      -     1.00    -     1.00    -      -      -      -      -      -      -      -     vhaddps     %xmm2, %xmm2, %xmm3</span><br><span class="line"> -      -      -     1.00    -     1.00    -      -      -      -      -      -      -      -     vhaddps     %xmm3, %xmm3, %xmm4</span><br></pre></td></tr></table></figure>

<p>每次循环或者每条指令执行，消耗的资源周期数。从而找到高资源占用的部分。</p>
<h3 id="Timeline-View"><a href="#Timeline-View" class="headerlink" title="Timeline View"></a>Timeline View</h3><p>可打印流水线情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Timeline view:</span><br><span class="line">                    012345</span><br><span class="line">Index     0123456789</span><br><span class="line"></span><br><span class="line">[0,0]     DeeER.    .    .   vmulps   %xmm0, %xmm1, %xmm2</span><br><span class="line">[0,1]     D==eeeER  .    .   vhaddps  %xmm2, %xmm2, %xmm3</span><br><span class="line">[0,2]     .D====eeeER    .   vhaddps  %xmm3, %xmm3, %xmm4</span><br><span class="line">[1,0]     .DeeE-----R    .   vmulps   %xmm0, %xmm1, %xmm2</span><br><span class="line">[1,1]     . D=eeeE---R   .   vhaddps  %xmm2, %xmm2, %xmm3</span><br><span class="line">[1,2]     . D====eeeER   .   vhaddps  %xmm3, %xmm3, %xmm4</span><br><span class="line">[2,0]     .  DeeE-----R  .   vmulps   %xmm0, %xmm1, %xmm2</span><br><span class="line">[2,1]     .  D====eeeER  .   vhaddps  %xmm2, %xmm2, %xmm3</span><br><span class="line">[2,2]     .   D======eeeER   vhaddps  %xmm3, %xmm3, %xmm4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Average Wait times (based on the timeline view):</span><br><span class="line">[0]: Executions</span><br><span class="line">[1]: Average time spent waiting in a scheduler&#x27;s queue</span><br><span class="line">[2]: Average time spent waiting in a scheduler&#x27;s queue while ready</span><br><span class="line">[3]: Average time elapsed from WB until retire stage</span><br><span class="line"></span><br><span class="line">      [0]    [1]    [2]    [3]</span><br><span class="line">0.     3     1.0    1.0    3.3       vmulps   %xmm0, %xmm1, %xmm2</span><br><span class="line">1.     3     3.3    0.7    1.0       vhaddps  %xmm2, %xmm2, %xmm3</span><br><span class="line">2.     3     5.7    0.0    0.0       vhaddps  %xmm3, %xmm3, %xmm4</span><br><span class="line">       3     3.3    0.5    1.4       &lt;total&gt;</span><br></pre></td></tr></table></figure>

<p>影响因素包括：</p>
<ol>
<li>数据冲突&#x2F;依赖：读后写，写后读依赖 。无法指令级并行，也可以通过寄存器重命名解决</li>
<li>结构冲突：占用发射位 或者 同一硬件</li>
<li>控制冲突：分支？</li>
<li>instructions must retire in program order, so [1,0] has to wait for [0,2] to be retired first</li>
</ol>
<h3 id="Bottleneck-Analysis"><a href="#Bottleneck-Analysis" class="headerlink" title="Bottleneck Analysis"></a>Bottleneck Analysis</h3><ul>
<li>可以分析出数据冲突&#x2F;依赖和结构冲突的影响大小</li>
<li>准确性取决于模拟和是否有对应CPU模型。</li>
<li>暂时不支持有序后端。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Cycles with backend pressure increase [ 91.52% ]</span><br><span class="line">Throughput Bottlenecks:</span><br><span class="line">  Resource Pressure       [ 0.01% ]</span><br><span class="line">  - SBPort0  [ 0.01% ]</span><br><span class="line">  - SBPort1  [ 0.01% ]</span><br><span class="line">  - SBPort5  [ 0.01% ]</span><br><span class="line">  Data Dependencies:      [ 91.51% ]</span><br><span class="line">  - Register Dependencies [ 91.51% ]</span><br><span class="line">  - Memory Dependencies   [ 10.76% ]</span><br></pre></td></tr></table></figure>

<ul>
<li>端口信息来自TableGen <code>llvm/lib/Target/X86/X86SchedSandyBridge.td</code></li>
<li>鲲鹏920的来自 <code>llvm/lib/Target/AArch64/AArch64SchedTSV110.td</code></li>
</ul>
<h3 id="额外信息"><a href="#额外信息" class="headerlink" title="额外信息"></a>额外信息</h3><ol>
<li>Dynamic Dispatch Stall Cycles</li>
<li>Dispatch Logic<ol>
<li>可以看出流水线发射满带宽或几条指令的时间占比</li>
</ol>
</li>
<li>Schedulers<ol>
<li>每个周期微指令发射数占比</li>
</ol>
</li>
<li>Scheduler’s queue usage<ol>
<li><p>执行时使用的平均或最大buffer entries (i.e., scheduler queue entries)</p>
</li>
<li><p>AMD Jaguar</p>
</li>
<li><pre><code>  JALU01 - A scheduler for ALU instructions.
  JFPU01 - A scheduler floating point operations.
  JLSAGU - A scheduler for address generation.
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">5. Retire Control Unit</span><br><span class="line">   1. 在一个周期里有多少指令retired的占比(好吧，感觉有语病)</span><br><span class="line">6. A re-order buffer (ROB) 的使用情况</span><br><span class="line">7. Register File statistics</span><br><span class="line">   1. physical register file (PRF)</span><br><span class="line">   2. floating-point registers (JFpuPRF)</span><br><span class="line">   3. integer registers (JIntegerPRF)</span><br><span class="line"></span><br><span class="line">## Instruction Flow</span><br><span class="line"></span><br><span class="line">llvm-mca 假设指令在模拟开始之前已经全部解码并放入队列中。因此，指令提取和解码阶段没有被计算。未考虑前端的性能瓶颈。此外，llvm-mca 不模拟分支预测。</span><br><span class="line"></span><br><span class="line">### Instruction Dispatch</span><br><span class="line"></span><br><span class="line">处理器的默认 dispatch width值等于LLVM’s scheduling model里的IssueWidth值。</span><br><span class="line"></span><br><span class="line">An instruction can be dispatched if:</span><br><span class="line"></span><br><span class="line">* The size of the **dispatch group** is smaller than processor’s dispatch width.</span><br><span class="line">* There are enough entries in the **reorder buffer**.</span><br><span class="line">* There are enough **physical registers** to do register renaming.</span><br><span class="line">* The schedulers are **not full**.</span><br><span class="line"></span><br><span class="line">reorder buffer负责跟踪命令，使之按照程序顺序retired结束。其默认值为 MicroOpBufferSize 。</span><br><span class="line"></span><br><span class="line">各种Buffered resources 被视作scheduler resources.</span><br><span class="line"></span><br><span class="line">### Instruction Issue</span><br><span class="line"></span><br><span class="line">每个处理器调度器实现一个指令缓冲区。指令必须在调度程序的缓冲区中等待，直到输入寄存器操作数可用。只有在那个时候，指令才符合执行的条件，并且可能会被发出（可能是乱序的）以供执行。 llvm-mca 在调度模型的帮助下计算指令延迟。</span><br><span class="line"></span><br><span class="line">llvm-mca 的调度器旨在模拟多处理器调度器。调度器负责跟踪数据依赖关系，并动态选择指令消耗哪些处理器资源。它将处理器资源单元和资源组的管理委托给资源管​​理器。资源管理器负责选择指令消耗的资源单元。例如，如果一条指令消耗了一个资源组的1cy，则资源管理器从该组中选择一个可用单元；默认情况下，资源管理器使用循环选择器来保证资源使用在组的所有单元之间均匀分配。</span><br><span class="line"></span><br><span class="line">llvm-mca’s scheduler internally groups instructions into three sets:</span><br><span class="line"></span><br><span class="line">* WaitSet: a set of instructions whose operands are not ready.</span><br><span class="line">* ReadySet: a set of instructions ready to execute.</span><br><span class="line">* IssuedSet: a set of instructions executing.</span><br><span class="line"></span><br><span class="line">### Write-Back and Retire Stage</span><br><span class="line"></span><br><span class="line"> retire control unit</span><br><span class="line"></span><br><span class="line">1. When instructions are executed,the flags the instruction as “ready to retire.”</span><br><span class="line">2. Instructions are retired in program order</span><br><span class="line">3. free the physical registers</span><br><span class="line"></span><br><span class="line">### Load/Store Unit and Memory Consistency Model</span><br><span class="line"></span><br><span class="line">load/store unit (LSUnit)用来模拟乱序memory操作</span><br><span class="line"></span><br><span class="line">The rules are:</span><br><span class="line"></span><br><span class="line">1. A younger load is allowed to pass an older load only if there are no intervening stores or barriers between the two loads.</span><br><span class="line">2. A younger load is allowed to pass an older store provided that the load does not alias with the store.</span><br><span class="line">3. A younger store is not allowed to pass an older store.不能交换顺序的意思</span><br><span class="line">4. A younger store is not allowed to pass an older load.</span><br><span class="line"></span><br><span class="line">假设 loads do not alias (-noalias=true) store operations.Under this assumption, younger loads are always allowed to pass older stores. ???</span><br><span class="line"></span><br><span class="line">LSUnit不打算跑alias analysis来预测何时load与store不相互alias???</span><br><span class="line"></span><br><span class="line">in the case of write-combining memory, rule 3 could be relaxed to allow reordering of non-aliasing store operations.???</span><br><span class="line"></span><br><span class="line">LSUnit不管的其余三点：</span><br><span class="line"></span><br><span class="line">1. The LSUnit does not know when store-to-load forwarding may occur.</span><br><span class="line">2. The LSUnit does not know anything about cache hierarchy and memory types.</span><br><span class="line">3. The LSUnit does not know how to identify serializing operations and memory fences.</span><br><span class="line">4. The LSUnit does not attempt to predict if a load or store hits or misses the L1 cache(不考虑cache命中，默认是命中L1,产生the load-to-use latency的最乐观开销)</span><br><span class="line"></span><br><span class="line">llvm-mca 不知道序列化操作或内存屏障之类的指令。 LSUnit 保守地假设同时具有“MayLoad”和未建模副作用的指令的行为类似于“软”load-barrier。这意味着，它在不强制刷新load队列的情况下序列化加载。类似地，“MayStore”和具有未建模副作用的指令被视为store障碍。完整的memory-barrier是具有未建模副作用的“MayLoad”和“MayStore”指令。LLVM的实现是不准确的，但这是我们目前使用 LLVM 中可用的当前信息所能做的最好的事情。</span><br><span class="line"></span><br><span class="line">load/store barrier会占用在load/store 队列里占用一项。</span><br><span class="line">当load/store barrier是其队列里oldest项时，其会被执行</span><br><span class="line"></span><br><span class="line">![](https://pic.shaojiemike.top/img/440472FD7AB14BC3C1F29BD2D565ACDF.png)</span><br><span class="line"></span><br><span class="line">### In-order Issue and Execute</span><br><span class="line"></span><br><span class="line">有序处理器被建模为单个 InOrderIssueStage 阶段。它绕过 Dispatch、Scheduler 和 Load/Store 单元。一旦它们的操作数寄存器可用并且满足资源要求，就会发出指令。根据LLVM的调度模型中IssueWidth参数的值，可以在一个周期内发出多条指令。一旦发出，指令就会被移到 IssuedInst 集，直到它准备好retire。 llvm-mca 确保按顺序提交写入。但是，如果 RetireOOO 属性for at least one of its writes为真，则允许指令提交写入并无序retire???</span><br><span class="line"></span><br><span class="line">## Custom Behaviour 自定义行为</span><br><span class="line"></span><br><span class="line">某些指令在该模型中并不能被准确的模拟。为了几条指令而修改模型不是个好的选择，一般通过**CustomBehaviour**类对某些指令进行特殊建模：自定义数据依赖，以及规避、单独处理特殊情况。</span><br><span class="line"></span><br><span class="line">为此，llvm-mca设置了一个通用的以及多个特殊的**CustomBehaviour**类。下面两种情况下会使用通用类：</span><br><span class="line"></span><br><span class="line">1. 开启了`-disable-cb`选项</span><br><span class="line">2. 不存在针对某目标的特殊类(通用类也做不了什么，我什么也做不到😥)</span><br><span class="line"></span><br><span class="line">但是注意目前只有in-order流水线实现了**CustomBehaviour**类，out-order流水线将来也会支持。</span><br><span class="line"></span><br><span class="line">该类主要通过`checkCustomHazard()`函数来实现，通过当前指令和真正流水线中执行的指令，来判断当前指令需要等待几个周期才能发射。</span><br><span class="line"></span><br><span class="line">如果想对没有实现的目标添加**CustomBehaviour**类，可以参考已有的实现，比如在`/llvm/lib/Target/AMDGPU/MCA/`目录下。</span><br><span class="line"></span><br><span class="line">## Custom Views 自定义视图</span><br><span class="line"></span><br><span class="line">关于自定义的视图的添加路径，如果**没有输出**从未在MC layer classes (MCSubtargetInfo, MCInstrInfo, etc.)里出现过的**新后端值**，请把实现加入`/tools/llvm-mca/View/`。相反，请加入`/lib/Target/&lt;TargetName&gt;/MCA/`目录。</span><br><span class="line"></span><br><span class="line">关于Custom Views所需内容，需要写特殊的**CustomBehaviour**类来覆写`CustomBehaviour::getViews()`函数，根据位置的不同还有三种实现`getStartViews(), getPostInstrInfoViews(),getEndViews()`。</span><br><span class="line"></span><br><span class="line">## 影响准确性的因素</span><br><span class="line"></span><br><span class="line">调度模型不仅用于计算指令延迟和吞吐量，还用于了解可用的处理器资源以及如何模拟它们。</span><br><span class="line"></span><br><span class="line">llvm mca进行分析的质量不可避免地受到**llvm中调度模型质量**的影响。</span><br><span class="line"></span><br><span class="line">## 功能（能估计的值</span><br><span class="line"></span><br><span class="line">1. IPC</span><br><span class="line">2. 硬件资源压力resource-pressure</span><br><span class="line">3. 一些额外Info？</span><br><span class="line">   1.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
 register-file-stats
 -dispatch-stats
 -scheduler-stats
 -retire-stats
 -instruction-info
 instruction-tables
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">4. 吞吐量瓶颈？</span><br><span class="line"></span><br><span class="line">### 支持对特定代码块的分析</span><br><span class="line"></span><br><span class="line">1. 汇编代码，支持命名和嵌套</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ol>
<h1 id="LLVM-MCA-BEGIN-block-name"><a href="#LLVM-MCA-BEGIN-block-name" class="headerlink" title="LLVM-MCA-BEGIN block-name"></a>LLVM-MCA-BEGIN block-name</h1><p> add %eax, %eax</p>
<h1 id="LLVM-MCA-END"><a href="#LLVM-MCA-END" class="headerlink" title="LLVM-MCA-END"></a>LLVM-MCA-END</h1> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2. 高级语言，通过内联汇编实现</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p> int foo(int a, int b) {<br>     __asm volatile(“# LLVM-MCA-BEGIN foo”);<br>     a +&#x3D; 42;<br>     __asm volatile(“# LLVM-MCA-END”);<br>     a *&#x3D; b;<br>     return a;<br> }</p>
<pre><code>
但是，这会干扰循环矢量化等优化，并可能对生成的代码产生影响。具体影响请对比汇编代码。
</code></pre>
</li>
</ol>
<h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><p>Google学术搜llvm-mca，一堆论文。但是不急着看，因为没有预备知识，没有问题的去看论文。效率和收获很低的，而且会看不懂。</p>
<h2 id="相关项目"><a href="#相关项目" class="headerlink" title="相关项目"></a>相关项目</h2><h3 id="mc-ruler"><a href="#mc-ruler" class="headerlink" title="mc-ruler"></a>mc-ruler</h3><p><a target="_blank" rel="noopener" href="https://github.com/jeremyong/mc_ruler#">mc-ruler</a>是整合了llvm-mca的cmake,可以打印指定部分的代码分析信息。如果之后要测试可能用得上。</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><ol>
<li>具体功能</li>
<li>llvm如何实现的，要看代码。</li>
</ol>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ol>
<li>(llvm-mca detects Intel syntax by the presence of an <strong>.intel_syntax</strong> directive at the beginning of the input. By default its output syntax matches that of its input.)</li>
<li>？？？的地方</li>
<li>大概看了一下功能，但是性能怎么对比呢。准确值是多少呢？<ol>
<li>arm kunpeng pmu-tools 实现</li>
</ol>
</li>
<li>每次的估计值会波动吗？</li>
</ol>
<p>如何和大神交流呢+提问的艺术</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-30T16:00:00.000Z" title="5/30/2023, 4:00:00 PM">2023-05-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.265Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Architecture/">Architecture</a></span><span class="level-item">11 minutes read (About 1699 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/30/Work/Programming/4-compile/llvmBackend/">llvm Backend</a></p><div class="content"><h2 id="llvm-后端-概述"><a href="#llvm-后端-概述" class="headerlink" title="llvm 后端 概述"></a>llvm 后端 概述</h2><ul>
<li>后端（backend）由一套<strong>分析</strong>和<strong>转换</strong>Pass组成，它们的任务是代码生成，即将LLVM中间表示（IR）变换为目标代码（或者汇编）。</li>
<li>LLVM支持广泛的目标：ARM，AArch64，Hexagon，MSP430，MIPS，Nvidia PTX，PowerPC，R600，SPARC，SystemZ，X86，和XCore。</li>
<li>所有这些后端共享一套共用的接口，它是目标无关代码生成器的一部分，以通用API的方法抽象化后端任务。每个目标必须特殊化代码生成通用类，以实现目标特定的行为。</li>
</ul>
<h3 id="后端的基本流程"><a href="#后端的基本流程" class="headerlink" title="后端的基本流程"></a>后端的基本流程</h3><ul>
<li>下图给出了将LLVM IR转换为目标汇编代码必需的步骤</li>
</ul>
<p><img src="https://pic.shaojiemike.top/img/20230523160158.png" alt="Backend"></p>
<ul>
<li>浅灰色的中间框，也叫super pass，是必需的，它们是后端的核心部分。</li>
<li>白色框所指示的，可以执行非必需的优化Pass以进一步改进翻译的质量。对于提高所生成的代码的效率更重要。<ul>
<li>比如<code>-O3</code>的优化，而且其顺序对结果也有影响。</li>
</ul>
</li>
</ul>
<p>详细解释各阶段：</p>
<ol>
<li>指令选择（Instruction Selection）：将三地址结构的LLVM IR变换为DAG（Directed Acyclic Graph）<ul>
<li>每个DAG能够表示单一基本块的计算。DAG内节点表示机器指令，边表示数据依赖关系。</li>
</ul>
</li>
<li>第1次指令调度（Instruction Scheduling），也称为前寄存器分配（RA）调度，对指令排序，同时尝试发现尽可能多的指令层次的并行。然后这些指令被变换为MachineInstr三地址表示。</li>
<li>寄存器分配（Register Allocation），它将无限的虚拟寄存器的引用转换为有限的目标特定的寄存器集，寄存器不够时挤出（spill）到内存。</li>
<li>第2次指令调度，也称为后寄存器分配（RA）调度。因为此时在这个点可获得真实的寄存器信息，某些类型寄存器存在额外的风险和延迟，它们可被用以改进指令顺序。</li>
<li>代码输出（Code Emission）阶段将指令从MachineInstr表示变换为MCInst实例。这种新的表示更适合汇编器和链接器，它有两种选择：输出汇编代码或者输出二进制块（blob）到一种特定的目标代码格式。</li>
</ol>
<h3 id="后端代码结构"><a href="#后端代码结构" class="headerlink" title="后端代码结构"></a>后端代码结构</h3><p>后端的实现分散在LLVM源代码树的不同目录中。代码生成背后的主要程序库位于lib目录和它的子文件夹CodeGen、MC、TableGen、和Target中， 具体参考<a target="_blank" rel="noopener" href="https://getting-started-with-llvm-core-libraries-zh-cn.readthedocs.io/zh_CN/latest/ch06.html#id4">文档</a></p>
<p>Tablegen位置在类似 <code>llvm/lib/Target/X86/X86.td</code>的地方</p>
<h2 id="llvm-编译优化"><a href="#llvm-编译优化" class="headerlink" title="llvm 编译优化"></a>llvm 编译优化</h2><ul>
<li>通过llvm的分析和转换Pass相结合实现的。</li>
<li>首先，通过分析Pass获取程序的一些特性和数据流等信息，例如控制流分析、数据流分析、依赖分析等。</li>
<li>然后，根据所得到的分析信息，llvm会执行转换Pass，对程序进行一系列的重构、优化和变换，例如常量传播、死代码消除、内联函数、循环展开等。</li>
</ul>
<h3 id="举例：O3优化实现"><a href="#举例：O3优化实现" class="headerlink" title="举例：O3优化实现"></a>举例：O3优化实现</h3><p>程序优化选项 -O3 是通过启用 LLVM Pass Manager 并按照顺序执行包含多个具体优化 Pass 的过程实现的。包括：</p>
<ol>
<li>函数内部优化 Pass，如内联、函数内联、无用函数清理、控制流扁平化；</li>
<li>函数间优化 Pass，如基于静态单走边分析的间接调用目标推导、函数每次调用的参数的重复计算消除、通过符号解析执行的函数简介化等。</li>
<li>模块优化 Pass，如死代码消除、全局优化、常量传播、数值宽化和窄化、整除优化等；</li>
<li>特定于架构的优化 Pass，包括指令调度和寄存器分配等。</li>
</ol>
<p>这些 Pass 的执行范围涵盖 LLVM IR 与 LLVM 后端。</p>
<h2 id="TableGen"><a href="#TableGen" class="headerlink" title="TableGen"></a>TableGen</h2><ul>
<li>LLVM的TableGen是一种表格驱动代码生成工具，主要用于生成汇编器、反汇编器、指令选择器、调度器等代码。</li>
<li>它使用基于LLVM IR的DSL(Domain-Specific Language)来描述目标指令集的特性和规则，然后将这些信息转换为C++代码。</li>
<li>使用TableGen可以将目标指令集的实现与源代码分离，从而提高代码的可读性和可维护性。</li>
</ul>
<p>TableGen的输入文件使用扩展名“<code>.td</code>”（TableGen的缩写），它们可以描述如下内容：</p>
<ol>
<li>Instruction Set Architecture (ISA) - 描述目标机的指令集特性，例如指令集架构、寄存器、寄存器类、操作数类型、地址模型、端对齐性等。</li>
<li>Selection DAG - 描述了如何将LLVM IR节点映射到目标机指令集的指令，例如指令的操作码、操作数、调用约定、指令延迟等。</li>
<li>Pattern Matching - 对匹配到的指令模板做出生成想要的IR节点的选择。</li>
<li>Instruction Scheduling - 描述调度器行为、指令之间的时间关系，以及如何将指令插入到调度图中的规则等。</li>
</ol>
<ul>
<li>TableGen自动化了目标机指令集的大部分工作，同时也使得自定义目标机变得相对容易。</li>
<li>该工具支持针对多种平台和编译器的后端代码生成。</li>
<li>对于嵌入式系统和非标准指令集架构等领域，TableGen有着广泛的应用。</li>
</ul>
<h3 id="相关的概念"><a href="#相关的概念" class="headerlink" title="相关的概念"></a>相关的概念</h3><ul>
<li>目标描述语言（Target Description Language，TDL）来定义目标架构特定的指令和寄存器。其中，TDL可用于目标架构中指令定义和寄存器定义的映射关系和动态生成机器指令的规则。</li>
</ul>
<h2 id="实践：llvm-IR-后端"><a href="#实践：llvm-IR-后端" class="headerlink" title="实践：llvm IR 后端"></a>实践：llvm IR 后端</h2><p>实现一个简单的LLVM IR后端，将LLVM IR转换为x86汇编代码，能line by line的输出。</p>
<p>参考LLVM官方文档中的“Writing an LLVM Backend”以及“TableGen Backends”</p>
<!-- 下面回答部分**来自ChatGPT-3.5**，暂时没有校验其可靠性(看上去貌似说得通)。 -->

<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://getting-started-with-llvm-core-libraries-zh-cn.readthedocs.io/zh_CN/latest/ch06.html#id2">https://getting-started-with-llvm-core-libraries-zh-cn.readthedocs.io/zh_CN/latest/ch06.html#id2</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-22T16:00:00.000Z" title="5/22/2023, 4:00:00 PM">2023-05-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.265Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Architecture/">Architecture</a></span><span class="level-item">11 minutes read (About 1584 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/22/Work/Programming/4-compile/llvmPass/">llvm Pass</a></p><div class="content"><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>Pass就是“遍历一遍IR，可以同时对它做一些操作”的意思。翻译成中文应该叫“传递”。</li>
<li>在实现上，LLVM的核心库中会给你一些 Pass类 去继承。你需要实现它的一些方法。<ul>
<li>ModulePass , CallGraphSCCPass, FunctionPass , or LoopPass, or RegionPass</li>
</ul>
</li>
<li>最后使用LLVM的编译器会把它翻译得到的IR传入Pass里，给你遍历和修改。</li>
</ul>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ol>
<li>插桩： 在Pass遍历LLVM IR的同时，自然就可以往里面插入新的代码。</li>
<li>机器无关的代码优化：编译原理一课说：IR在被翻译成机器码前会做一些机器无关的优化。 但是不同的优化方法之间需要解耦，所以自然要各自遍历一遍IR，实现成了一个个LLVM Pass。 最终，基于LLVM的编译器会在前端生成LLVM IR后调用一些LLVM Pass做机器无关优化， 然后再调用LLVM后端生成目标平台代码。</li>
<li>静态分析： 像VSCode的C&#x2F;C++插件就会用LLVM Pass来分析代码，提示可能的错误 (无用的变量、无法到达的代码等等)。</li>
</ol>
<h2 id="理解-llvm-Pass"><a href="#理解-llvm-Pass" class="headerlink" title="理解 llvm Pass"></a>理解 llvm Pass</h2><h3 id="理解Pass-API"><a href="#理解Pass-API" class="headerlink" title="理解Pass API"></a>理解Pass API</h3><p>　　Pass类是实现优化的主要资源。然而，我们从不直接使用它，而是通过清楚的子类使用它。当实现一个Pass时，你应该选择适合你的Pass的最佳粒度，适合此粒度的最佳子类，例如基于函数、模块、循环、强联通区域，等等。常见的这些子类如下：</p>
<ul>
<li><code>ModulePass</code>：这是最通用的Pass；它一次分析整个模块，函数的次序不确定。它不限定使用者的行为，允许删除函数和其它修改。为了使用它，你需要写一个类继承ModulePass，并重载runOnModule()方法。</li>
<li><code>FunctionPass</code>：这个子类允许一次处理一个函数，处理函数的次序不确定。这是应用最多的Pass类型。它禁止修改外部函数、删除函数、删除全局变量。为了使用它，需要写一个它的子类，重载runOnFunction()方法。</li>
<li><code>BasicBlockPass</code>：这个类的粒度是基本块。FunctionPass类禁止的修改在这里也是禁止的。它还禁止修改或者删除外部基本块。使用者需要写一个类继承BasicBlockPass，并重载它的runOnBasicBlock()方法。</li>
</ul>
<p>　　被重载的入口函数runOnModule()、runOnFunction()、runOnBasicBlock()返回布尔值false，如果被分析的单元（模块、函数和基本块）保持不变，否则返回布尔值true。</p>
<h3 id="Pass的执行顺序-依赖"><a href="#Pass的执行顺序-依赖" class="headerlink" title="Pass的执行顺序&#x2F;依赖"></a>Pass的执行顺序&#x2F;依赖</h3><ul>
<li>ChatGPT说默认顺序是：FunctionPass -&gt; Module Pass -&gt; LoopPass ?</li>
<li>当然我们是可以修改插入Pass的执行顺序的。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">char</span> PIMProf::AnnotationInjection::ID = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// 注册 llvm pass</span></span><br><span class="line"><span class="function"><span class="type">static</span> RegisterPass&lt;PIMProf::AnnotationInjection&gt; <span class="title">RegisterMyPass</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="string">&quot;AnnotationInjection&quot;</span>, <span class="string">&quot;Inject annotators to uniquely identify each basic block.&quot;</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">loadPass</span><span class="params">(<span class="type">const</span> PassManagerBuilder &amp;,</span></span></span><br><span class="line"><span class="params"><span class="function">                           legacy::PassManagerBase &amp;PM)</span> </span>&#123;</span><br><span class="line">    PM.<span class="built_in">add</span>(<span class="keyword">new</span> PIMProf::<span class="built_in">AnnotationInjection</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Ox 的代码 llvm pass 在EP_OptimizerLast 位置load</span></span><br><span class="line"><span class="function"><span class="type">static</span> RegisterStandardPasses <span class="title">clangtoolLoader_Ox</span><span class="params">(PassManagerBuilder::EP_OptimizerLast, loadPass)</span></span>;</span><br><span class="line"><span class="comment">// O0 的代码 llvm pass EP_EnabledOnOptLevel0 位置load</span></span><br><span class="line"><span class="function"><span class="type">static</span> RegisterStandardPasses <span class="title">clangtoolLoader_O0</span><span class="params">(PassManagerBuilder::EP_EnabledOnOptLevel0, loadPass)</span></span>;</span><br></pre></td></tr></table></figure>

<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol>
<li>编写LLVM pass代码</li>
<li>配置编译环境(cmake or make)</li>
<li>运行(opt or clang)</li>
</ol>
<h2 id="1-代码框架"><a href="#1-代码框架" class="headerlink" title="1 代码框架"></a>1 代码框架</h2><p>最简单框架hello.cpp如下，注意<code>Important</code>一定需要：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Pass.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/IR/Function.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Support/raw_ostream.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/IR/LegacyPassManager.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Transforms/IPO/PassManagerBuilder.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> llvm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"> <span class="comment">// Important</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Hello</span> : <span class="keyword">public</span> FunctionPass &#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">char</span> ID;</span><br><span class="line">    <span class="built_in">Hello</span>() : <span class="built_in">FunctionPass</span>(ID) &#123;&#125;</span><br><span class="line"> <span class="comment">// Important</span></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">runOnFunction</span><span class="params">(Function &amp;F)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">      <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;Hello: &quot;</span>;</span><br><span class="line">      <span class="built_in">errs</span>().<span class="built_in">write_escaped</span>(F.<span class="built_in">getName</span>()) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">char</span> Hello::ID = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Important:Register for opt</span></span><br><span class="line"><span class="function"><span class="type">static</span> RegisterPass&lt;Hello&gt; <span class="title">X</span><span class="params">(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;Hello World Pass&quot;</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Important:Register for clang</span></span><br><span class="line"><span class="function"><span class="type">static</span> RegisterStandardPasses <span class="title">Y</span><span class="params">(PassManagerBuilder::EP_EarlyAsPossible,</span></span></span><br><span class="line"><span class="params"><span class="function">  [](<span class="type">const</span> PassManagerBuilder &amp;Builder, legacy::PassManagerBase &amp;PM) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    PM.add(<span class="keyword">new</span> Hello());</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;)</span></span>;</span><br></pre></td></tr></table></figure>

<h2 id="2-编译动态库"><a href="#2-编译动态库" class="headerlink" title="2 编译动态库"></a>2 编译动态库</h2><h3 id="使用cmake"><a href="#使用cmake" class="headerlink" title="使用cmake"></a>使用cmake</h3><p>参考<a target="_blank" rel="noopener" href="https://llvm.org/docs/CMake.html#cmake-out-of-source-pass">官方文档</a>。</p>
<p>An example of a project layout is provided below.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;project <span class="built_in">dir</span>&gt;/</span><br><span class="line">    |</span><br><span class="line">    CMakeLists.txt</span><br><span class="line">    &lt;pass name&gt;/</span><br><span class="line">        |</span><br><span class="line">        CMakeLists.txt</span><br><span class="line">        Pass.cpp</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<p>Contents of <code>&lt;project dir&gt;/CMakeLists.txt</code>:</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(LLVM REQUIRED CONFIG)</span><br><span class="line"></span><br><span class="line"><span class="keyword">separate_arguments</span>(LLVM_DEFINITIONS_LIST NATIVE_COMMAND <span class="variable">$&#123;LLVM_DEFINITIONS&#125;</span>)</span><br><span class="line"><span class="keyword">add_definitions</span>(<span class="variable">$&#123;LLVM_DEFINITIONS_LIST&#125;</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;LLVM_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_subdirectory</span>(&lt;pass name&gt;)</span><br></pre></td></tr></table></figure>

<p>Contents of <code>&lt;project dir&gt;/&lt;pass name&gt;/CMakeLists.txt</code>:</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_library</span>(LLVMPassname MODULE Pass.cpp)</span><br></pre></td></tr></table></figure>

<p>运行cmake编译。产生<code>LLVMPassname.so</code>文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake .. &amp;&amp; make</span><br></pre></td></tr></table></figure>

<!-- 下面回答部分**来自ChatGPT-3.5**，暂时没有校验其可靠性(看上去貌似说得通)。 -->

<h3 id="使用命令行"><a href="#使用命令行" class="headerlink" title="使用命令行"></a>使用命令行</h3><p>请阅读<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/122522485">知乎的文章</a></p>
<h2 id="3-使用"><a href="#3-使用" class="headerlink" title="3 使用"></a>3 使用</h2><h3 id="opt加载Pass"><a href="#opt加载Pass" class="headerlink" title="opt加载Pass"></a>opt加载Pass</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clang -c -emit-llvm main.c -o main.bc <span class="comment"># 随意写一个C代码并编译到bc格式</span></span><br><span class="line">opt -load path/to/LLVMHello.so -hello main.bc -o /dev/null</span><br></pre></td></tr></table></figure>

<p>把源代码编译成IR代码，然后用opt运行Pass实在麻烦且无趣。</p>
<h3 id="clang加载Pass"><a href="#clang加载Pass" class="headerlink" title="clang加载Pass"></a>clang加载Pass</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clang -Xclang -load -Xclang path/to/LLVMHello.so main.c -o main</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">clang++ -Xclang -load -Xclang ./build/hello/libLLVMPassname.so test.cpp -o main</span><br></pre></td></tr></table></figure>

<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="插入代码"><a href="#插入代码" class="headerlink" title="插入代码"></a>插入代码</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">InjectSimMagic2</span><span class="params">(Module &amp;M, Instruction *insertPt, <span class="type">uint64_t</span> arg0, <span class="type">uint64_t</span> arg1, <span class="type">uint64_t</span> arg2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LLVMContext &amp;ctx = M.<span class="built_in">getContext</span>();</span><br><span class="line">    std::vector&lt;Type *&gt; argtype &#123;</span><br><span class="line">        Type::<span class="built_in">getInt64Ty</span>(ctx), Type::<span class="built_in">getInt64Ty</span>(ctx), Type::<span class="built_in">getInt64Ty</span>(ctx)</span><br><span class="line">    &#125;;</span><br><span class="line">    FunctionType *ty = FunctionType::<span class="built_in">get</span>(</span><br><span class="line">        Type::<span class="built_in">getVoidTy</span>(ctx), argtype, <span class="literal">false</span></span><br><span class="line">    );</span><br><span class="line">    <span class="comment">// template of Sniper&#x27;s SimMagic0</span></span><br><span class="line">    InlineAsm *ia = InlineAsm::<span class="built_in">get</span>(</span><br><span class="line">        ty,</span><br><span class="line">        <span class="string">&quot;\tmov $0, %rax \n&quot;</span></span><br><span class="line">        <span class="string">&quot;\tmov $1, %rbx \n&quot;</span></span><br><span class="line">        <span class="string">&quot;\tmov $2, %rcx \n&quot;</span></span><br><span class="line">        <span class="string">&quot;\txchg %bx, %bx\n&quot;</span>,</span><br><span class="line">        <span class="string">&quot;imr,imr,imr,~&#123;rax&#125;,~&#123;rbx&#125;,~&#123;rcx&#125;,~&#123;dirflag&#125;,~&#123;fpsr&#125;,~&#123;flags&#125;&quot;</span>,</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">    );</span><br><span class="line">    Value *val0 = ConstantInt::<span class="built_in">get</span>(IntegerType::<span class="built_in">get</span>(ctx, <span class="number">64</span>), arg0);</span><br><span class="line">    Value *val1 = ConstantInt::<span class="built_in">get</span>(IntegerType::<span class="built_in">get</span>(ctx, <span class="number">64</span>), arg1);</span><br><span class="line">    Value *val2 = ConstantInt::<span class="built_in">get</span>(IntegerType::<span class="built_in">get</span>(ctx, <span class="number">64</span>), arg2);</span><br><span class="line">    std::vector&lt;Value *&gt; arglist &#123;val0, val1, val2&#125;;</span><br><span class="line">    CallInst::<span class="built_in">Create</span>(</span><br><span class="line">            ia, arglist, <span class="string">&quot;&quot;</span>, insertPt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码使用内联汇编嵌入到 LLVM IR 中，指令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mov $0, %rax</span><br><span class="line">mov $1, %rbx</span><br><span class="line">mov $2, %rcx</span><br><span class="line">xchg %bx, %bx</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>mov $0, %rax 将立即数 arg0 装载到通用寄存器 %rax 中。</li>
<li>mov $1, %rbx 将立即数 arg1 装载到通用寄存器 %rbx 中。</li>
<li>mov $2, %rcx 将立即数 arg2 装载到通用寄存器 %rcx 中。</li>
<li>xchg %bx, %bx 是一条无操作指令，用于保证该汇编代码的原子性。</li>
</ul>
<h3 id="打印每个BBL内的汇编指令"><a href="#打印每个BBL内的汇编指令" class="headerlink" title="打印每个BBL内的汇编指令"></a>打印每个BBL内的汇编指令</h3><p>由于直接打印的是llvm IR的表示，想要打印特定架构比如x86的汇编代码，其实需要进行llvm后端的转换。（取巧，可执行文件反汇编，然后根据插入的汇编桩划分）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>复现PIMProf论文时，用到了使用 llvm pass来插入特殊汇编</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.llvm.org/docs/WritingAnLLVMPass.html">https://www.llvm.org/docs/WritingAnLLVMPass.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/122522485">https://zhuanlan.zhihu.com/p/122522485</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-20T16:00:00.000Z" title="5/20/2023, 4:00:00 PM">2023-05-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.265Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Architecture/">Architecture</a></span><span class="level-item">18 minutes read (About 2675 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/20/Work/Programming/2.1-Assembly/assemblyGNUFile/">GNU Assembly File</a></p><div class="content"><h2 id="GNU汇编语法"><a href="#GNU汇编语法" class="headerlink" title="GNU汇编语法"></a>GNU汇编语法</h2><h3 id="伪指令"><a href="#伪指令" class="headerlink" title="伪指令"></a>伪指令</h3><ul>
<li><strong>指示（Directives）</strong>: 以点号开始，用来指示对编译器，连接器，调试器有用的结构信息。指示本身不是汇编指令。</li>
</ul>
<table>
<thead>
<tr>
<th align="center">伪指令</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.file</td>
<td align="center">指定由哪个源文件生成的汇编代码。</td>
</tr>
<tr>
<td align="center">.data</td>
<td align="center">表示数据段(section)的开始地址</td>
</tr>
<tr>
<td align="center">.text</td>
<td align="center">指定下面的指令属于代码段。</td>
</tr>
<tr>
<td align="center">.string</td>
<td align="center">表示数据段中的字符串常量。</td>
</tr>
<tr>
<td align="center">.globl main</td>
<td align="center">指明标签main是一个可以在其它模块的代码中被访问的全局符号 。</td>
</tr>
<tr>
<td align="center">.align</td>
<td align="center">数据对齐指令</td>
</tr>
<tr>
<td align="center">.section</td>
<td align="center">段标记</td>
</tr>
<tr>
<td align="center">.type</td>
<td align="center">设置一个符号的属性值</td>
</tr>
</tbody></table>
<ul>
<li>语法：<code>.type name , description</code><ul>
<li>description取值如下：<ul>
<li><code>%function</code> 表示该符号用来表示一个函数名</li>
<li><code>%object</code> 表示该符号用来表示一个数据对象</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>至于其它的指示你可以忽略。</p>
<h2 id="实践：阅读汇编文件"><a href="#实践：阅读汇编文件" class="headerlink" title="实践：阅读汇编文件"></a>实践：阅读汇编文件</h2><p>从最简单的C文件入手</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行<code>gcc -S -O3 main.c -o main.s</code>，得到<code>main.s</code>文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"> .file &quot;simple.cpp&quot;</span><br><span class="line"> .text</span><br><span class="line"> .section .text.startup,&quot;ax&quot;,@progbits</span><br><span class="line"> .p2align 4</span><br><span class="line"> .globl main</span><br><span class="line"> .type main, @function</span><br><span class="line">main:</span><br><span class="line">.LFB0:</span><br><span class="line"> .cfi_startproc</span><br><span class="line"> endbr64</span><br><span class="line"> xorl %eax, %eax</span><br><span class="line"> ret</span><br><span class="line"> .cfi_endproc</span><br><span class="line">.LFE0:</span><br><span class="line"> .size main, .-main</span><br><span class="line"> .ident &quot;GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0&quot;</span><br><span class="line"> .section .note.GNU-stack,&quot;&quot;,@progbits</span><br><span class="line"> .section .note.gnu.property,&quot;a&quot;</span><br><span class="line"> .align 8</span><br><span class="line"> .long  1f - 0f</span><br><span class="line"> .long  4f - 1f</span><br><span class="line"> .long  5</span><br><span class="line">0:</span><br><span class="line"> .string  &quot;GNU&quot;</span><br><span class="line">1:</span><br><span class="line"> .align 8</span><br><span class="line"> .long  0xc0000002</span><br><span class="line"> .long  3f - 2f</span><br><span class="line">2:</span><br><span class="line"> .long  0x3</span><br><span class="line">3:</span><br><span class="line"> .align 8</span><br><span class="line">4:</span><br></pre></td></tr></table></figure>

<ul>
<li>下面回答<strong>来自ChatGPT-3.5</strong>，暂时没有校验其可靠性(看上去貌似说得通)。</li>
</ul>
<h3 id="section"><a href="#section" class="headerlink" title="section"></a>section</h3><ul>
<li><code>.section .rodata.str1.1,&quot;aMS&quot;,@progbits,1</code><ul>
<li><code>rodata.str1.1</code>是一个标号（label）, 意思是只读数据段的字符串常量</li>
<li><code>aMS</code>是一个属性值：<ul>
<li>可分配的（allocatable），即程序运行时需要动态分配空间才能分配该代码段，</li>
<li>不可执行 （M），</li>
<li>数据的类型为串（S）</li>
<li>其余属性值：对齐方式的通常为 b（byte对齐），w（word对齐），或者其他更大的对齐单位，例如 d（double word对齐）。</li>
</ul>
</li>
<li><code>@progbits</code>: 表示该段的类型是程序数据段（PROGBITS），这种类型的段包含程序的代码和数据。</li>
<li><code>1</code>: 表示该段的对齐方式是2^1 &#x3D; 2个字节（按字节对齐）。如果不写这个数字，默认对齐到当前机器的字长。</li>
</ul>
</li>
<li><code>.section .text.startup,&quot;ax&quot;,@progbits</code> 其中<code>ax</code>表示该段是可分配的（allocatable）和可执行的（executable）。</li>
<li>“<code>.section .note.GNU-stack</code>“指令用于告诉链接器是否允许在堆栈上执行代码。</li>
<li>“<code>.section .note.gnu.property</code>“指令用于指定一些属性，这里是一个GNU特性标记。</li>
</ul>
<h3 id="汇编的入口"><a href="#汇编的入口" class="headerlink" title="汇编的入口"></a>汇编的入口</h3><ul>
<li>汇编的执行流程：入口函数在哪里</li>
<li>入口函数在该文件中的名称为“main”，定义于“<code>.text.startup” section</code>，其首地址为“<code>.globl main</code>”。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.section .text.startup,&quot;ax&quot;,@progbits</span><br><span class="line">.p2align 4</span><br><span class="line">.globl main</span><br><span class="line">.type main, @function</span><br></pre></td></tr></table></figure>

<h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p><img src="https://pic.shaojiemike.top/img/20230521194515.png"></p>
<ul>
<li>为了确保这些初始化操作可以在程序启动时正确执行，编译器将把这些构造函数和析构函数的调用代码打包成若干个函数，统一放在名字为“<code>_GLOBAL__sub_I_xxx</code>”的section中。<ul>
<li>因为在C++程序编译后的二进制文件中，全局变量、静态变量和全局对象等信息都需要进行初始化操作，包括构造函数（初始化对象）和析构函数（清理对象）。</li>
<li>在这段汇编代码中，也就是那个”_GLOBAL__sub_I_main”函数，它是C++全局变量和静态变量的构造函数，它调用了预初始化函数 “<code>ios_base::Init()</code>“，并注册了一个在程序退出时调用的析构函数 “<code>__cxa_atexit</code>“。</li>
</ul>
</li>
<li>在”<code>.init_array</code>“ section中，定义了一个”_GLOBAL__sub_I_main”的地址，这是在程序启动时需要调用的所有C++全局和静态对象的初始化函数列表，编译器链接这个列表并在程序启动时依次调用这些初始化函数。</li>
<li>总之，这两个section的存在是为了保证C++全局变量和静态变量的正确初始化。</li>
</ul>
<p>其中四条指令都定义了一些符号或变量，并分配了一些内存空间，这些在程序里的意义如下：</p>
<ol>
<li>“<code>.quad _GLOBAL__sub_I_main</code>“:</li>
</ol>
<p>在程序启动时，将调用所有全局静态对象的构造函数。这些构造函数被放在一个名为”_GLOBAL__sub_I_xxx”的section中，而每个section都是由一个指向该section所有对象的地址列表所引用。这里的”.quad _GLOBAL__sub_I_main”是为了将”_GLOBAL__sub_I_main”函数的地址添加到该列表中。</p>
<ol start="2">
<li>“<code>.local _ZStL8__ioinit</code>“:</li>
</ol>
<p>这条指令定义了一个本地符号”_ZStL8__ioinit”，它表示C++标准输入输出的初始化过程。由于该符号是一个本地符号，所以只能在编辑该文件的当前单元中使用该符号。</p>
<ol start="3">
<li>“<code>.comm _ZStL8__ioinit,1,1</code>“:</li>
</ol>
<p>这条指令定义了一个名为”_ZStL8__ioinit”的未初始化的弱符号，并为该符号分配了1个大小的字节空间。这个弱符号定义了一个C++标准输入输出部分的全局状态对象。在全用动态库时，不同的动态库可能有自己的IO状态，所以为了确保C++输入输出的状态正确，需要为其指定一个单独的段来存储这些状态数据。在这里，”.comm _ZStL8__ioinit,1,1”将会为”_ZStL8__ioinit”符号分配一个字节大小的空间。</p>
<ol start="4">
<li>“<code>.hidden __dso_handle</code>“:</li>
</ol>
<p>这条指令定义了一个隐藏的符号 “__dso_handle”。这个符号是一个链接器生成的隐式变量，其定义了一个指向被当前动态库使用的全局数据对象的一个指针。该符号在被链接进来的库中是隐藏的，不会被其他库或者main函数本身调用，但是在main返回后，可以用来检查库是否已经被卸载。</p>
<h3 id="末尾的元数据"><a href="#末尾的元数据" class="headerlink" title="末尾的元数据"></a>末尾的元数据</h3><p><img src="https://pic.shaojiemike.top/img/20230521191453.png"></p>
<p>这段代码是一些特殊的指令和数据，主要是用于向可执行文件添加一些元数据（metadata）。这些元数据可能包含各种信息，如调试信息、特定平台的指令集支持等等。</p>
<p>具体来说：</p>
<ul>
<li>“.long”指令用于定义一个长整型数值，这里用来计算地址之间的差值。<ul>
<li>例如，第一行”<code>.long 1f - 0f</code>“建立了一个长整型数值，表示”1:”标签相对于当前指令地址（即0f）的偏移量。偏移量可以用来计算标签对应的指令地址，从而可用于跳转或计算指针偏移量。</li>
<li>“<code>4f - 1f</code>“，即”4:”标签相对于”1:”标签的偏移量；</li>
</ul>
</li>
<li>“<code>.long 0xc0000002</code>“表示这是一个特殊的属性标记，标识这个文件可以在Linux平台上执行。它是用来告诉操作系统这个程序是用特定指令集编译的。</li>
<li>“<code>.long 0x3</code>“表示另一个属性标记，表示这个文件可以加载到任意地址。</li>
</ul>
<p>总之，这些元数据可能对程序运行起到关键作用，但在大多数情况下可能都没有明显的作用，因此看起来没有用。</p>
<h2 id="比较汇编的debugging-symbols"><a href="#比较汇编的debugging-symbols" class="headerlink" title="比较汇编的debugging symbols"></a>比较汇编的debugging symbols</h2><p>执行<code>gcc -S -g testBigExe.cpp -o testDebug.s</code>，对比之前的汇编文件，由72行变成9760行。</p>
<ul>
<li><img src="https://pic.shaojiemike.top/img/20230521195333.png" alt="-g前后"></li>
</ul>
<h3 id="loc"><a href="#loc" class="headerlink" title=".loc"></a>.loc</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.LBE32:</span><br><span class="line"> .file 3 &quot;/usr/include/c++/9/bits/char_traits.h&quot;</span><br><span class="line"> .loc 3 342 2 is_stmt 1 view .LVU4</span><br><span class="line"> .loc 1 5 11 is_stmt 0 view .LVU5</span><br></pre></td></tr></table></figure>

<ul>
<li>第一行：<code>.loc 3 342 2</code> 表示当前指令对应的源代码文件ID为3，在第342行，第2列（其中第1列是行号，第2列是第几个字符），同时<code>is_stmt</code>为1表示这条指令是语句的起始位置。</li>
<li>第二行：<code>.loc 1 5 11</code> 表示当前指令对应的源代码文件ID为1，在第5行，第11列，同时<code>is_stmt</code>为0表示这条指令不是语句的起始位置。</li>
<li><code>view .LVU4</code> 表示当前指令所处的作用域（scope）是.LVU4。作用域是指该指令所在的函数、代码块等一段范围内的所有变量和对象的可见性。在这个例子中，.LVU4 是一个局部变量作用域，因为它是位于一个C++标准库头文件中的一个函数的起始位置。</li>
</ul>
<h3 id="debug-section"><a href="#debug-section" class="headerlink" title="debug section"></a>debug section</h3><p>新增的这些 section 存储了 DWARF 调试信息。DWARF（Debugging With Attributed Record Formats）是一种调试信息的标准格式，包括代码中的变量、类型、函数、源文件的映射关系，以及代码的编译相关信息等等。</p>
<p>具体来说，这些 section 存储的内容如下：</p>
<ul>
<li><code>.debug_info</code>：包含程序的调试信息，包括编译单元、类型信息、函数和变量信息等。</li>
<li><code>.debug_abbrev</code>：包含了 .debug_info 中使用到的所有缩写名称及其对应的含义，用于压缩格式和提高效率。</li>
<li><code>.debug_loc</code>：存储每个程序变量或表达式的地址范围及其地址寄存器、表达式规则等信息。在调试时用来确定变量或表达式的值和范围。</li>
<li><code>.debug_aranges</code>：存储简化版本的地址范围描述，允许调试器加速地定位代码和数据的位置。</li>
<li><code>.debug_ranges</code>：存储每个编译单元（CU）的地址范围，每个范围都是一个有限开区间。</li>
<li><code>.debug_line</code>：存储源代码行号信息，包括每行的文件、行号、是否为语句起始位置等信息。</li>
<li><code>.debug_str</code>：包含了所有字符串，如文件名、函数名等，由于每个调试信息的数据都是字符串，因此这是所有调试信息的基础。</li>
</ul>
<p>需要注意的是，这些 section 中的信息是根据编译器的配置和选项生成的，因此不同编译器可能会生成略有不同的调试信息。</p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><ul>
<li>在编译的过程中，哪个阶段 label会变成真实执行地址</li>
</ul>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/zuofaqi/articles/12853734.html">https://www.cnblogs.com/zuofaqi/articles/12853734.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/zuofaqi/articles/12853734.html">https://www.cnblogs.com/zuofaqi/articles/12853734.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-14T16:00:00.000Z" title="5/14/2023, 4:00:00 PM">2023-05-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.249Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Network/">Network</a></span><span class="level-item">12 minutes read (About 1862 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/14/OutOfWork/3-homepage/background/PersonalWebsiteBeginners/">Web Server: Nginx V.S. Apache2</a></p><div class="content"><h2 id="常见的web服务器"><a href="#常见的web服务器" class="headerlink" title="常见的web服务器"></a>常见的web服务器</h2><p>常见的web服务器有Apache、nginx、IIS</p>
<ol>
<li>Apache<ol>
<li>Apache音译为阿帕奇, 是全世界最受欢迎的web服务器，因其快速、可靠并且可通过简单的API扩充，能将Python\Perl等解释器部署在其上面等优势，受到广泛的关注与使用。</li>
<li>但是现在用的人少了，而且性能没nginx好</li>
</ol>
</li>
<li><strong>nginx</strong><ol>
<li>Apache的致命缺陷就是在同时处理大量的（一万个以上）请求时，显得有些吃力，所以“战斗民族”的人设计的一款轻量级的web服务器——nginx, 在高并发下nginx 能保持比Apache低资源低消耗高性能 ，</li>
</ol>
</li>
<li>IIS<ol>
<li>iis是Internet Information Services的缩写，意为互联网信息服务，是由微软公司提供的基于运行Microsoft Windows的互联网基本服务,</li>
</ol>
</li>
</ol>
<h2 id="查找网站服务"><a href="#查找网站服务" class="headerlink" title="查找网站服务"></a>查找网站服务</h2><h3 id="判断是nginx还是apach2"><a href="#判断是nginx还是apach2" class="headerlink" title="判断是nginx还是apach2"></a>判断是nginx还是apach2</h3><p>随便输出返回404页面显示 <code>nginx/1.14.0 (Ubuntu)</code></p>
<h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo service apache2 status</span><br><span class="line">sudo service nginx status</span><br><span class="line">sudo vim /etc/ssh/sshd_config</span><br><span class="line"><span class="comment">#PasswordAuthentication yes</span></span><br><span class="line">sudo service ssh restart</span><br></pre></td></tr></table></figure>

<h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><ol>
<li>&#x2F;etc&#x2F;nginx&#x2F;nginx.conf<ol>
<li>全局块、</li>
<li>events块</li>
<li>http块<ol>
<li>http全局块</li>
<li>多个server块<ol>
<li><strong>server全局块</strong></li>
<li>多个location块<ol>
<li>Nginx中location的作用是根据Url来决定怎么处理用户请求(转发请求给其他服务器处理或者查找本地文件进行处理)。location支持正则表达式，<a target="_blank" rel="noopener" href="https://www.cnblogs.com/wyy1234/p/10632108.html">配置十分灵活</a>。我们可以在一个虚拟主机(nginx中的一个server节点)下配置多个location以满足如动静分离，防盗链等需求。</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="全局块"><a href="#全局块" class="headerlink" title="全局块"></a>全局块</h3><p>全局块是默认配置文件从开始到events块之间的一部分内容，主要设置一些影响Nginx服务器整体运行的配置指令，因此，这些指令的作用域是Nginx服务器全局。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 指定可以运行nginx服务的用户和用户组，只能在全局块配置</span><br><span class="line">user www-data;</span><br><span class="line"># 指定工作线程数</span><br><span class="line">worker_processes auto;</span><br><span class="line"># 指定pid文件存放的路径，这个指令只能在全局块配置</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line"># include指令，用于包含其他的配置文件，可以放在配置文件的任何地方，但是要注意你包含进来的配置文件一定符合配置规范，比如说你include进来的配置是worker_processes指令的配置，而你将这个指令包含到了http块中，着肯定是不行的，上面已经介绍过worker_processes指令只能在全局块中。</span><br><span class="line">include /etc/nginx/modules-enabled/*.conf;</span><br></pre></td></tr></table></figure>


<h3 id="events块"><a href="#events块" class="headerlink" title="events块"></a>events块</h3><p>events 模块用于配置 Nginx 的事件处理机制。事件可以是网络连接、定时器等。一般来说，你不太需要直接修改 events 模块的配置，除非你对 Nginx 的事件处理机制有特殊的需求。默认的配置通常是适用于大多数情况的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">events &#123;</span><br><span class="line">    ; worker_connections 配置项定义每个 worker 进程可以同时处理的连接数</span><br><span class="line">    worker_connections  768;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="html块"><a href="#html块" class="headerlink" title="html块"></a>html块</h3><p>http 模块是配置 Nginx HTTP 服务器的主要部分。在这个模块中，你可以配置服务器的行为、代理、日志、gzip 压缩等等。这是你放置虚拟主机（<strong>server 块</strong>）配置的地方。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">        ##</span><br><span class="line">        # Virtual Host Configs</span><br><span class="line">        ##</span><br><span class="line"></span><br><span class="line">        include /etc/nginx/conf.d/*.conf;</span><br><span class="line">        include /etc/nginx/sites-enabled/*;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>include /etc/nginx/sites-enabled/*;</code>是最重要的。</p>
<h4 id="include-etc-nginx-sites-enabled"><a href="#include-etc-nginx-sites-enabled" class="headerlink" title="include &#x2F;etc&#x2F;nginx&#x2F;sites-enabled&#x2F;*"></a>include &#x2F;etc&#x2F;nginx&#x2F;sites-enabled&#x2F;*</h4><ul>
<li>在 Nginx 中，文件加载和生效的顺序是由 include 指令定义的。如果在这些文件中有重复的配置，后加载的配置将覆盖先加载的配置。因此，<strong>后加载的配置文件具有更高的优先级</strong>。</li>
<li>默认server块在<code>/etc/nginx/sites-enabled/default</code></li>
<li>默认填写了<code>root /var/www/html;</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 80 default_server;</span><br><span class="line"></span><br><span class="line">        root /var/www/html;</span><br><span class="line"></span><br><span class="line">        # Add index.php to the list if you are using PHP</span><br><span class="line">        index index.php index.html index.htm index.nginx-debian.html;</span><br><span class="line"></span><br><span class="line">        server_name _;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">                # First attempt to serve request as file, then</span><br><span class="line">                # as directory, then fall back to displaying a 404.</span><br><span class="line">                try_files $uri $uri/ =404;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="新配置"><a href="#新配置" class="headerlink" title="新配置"></a>新配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Virtual Host configuration for example.com</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># You can move that to a different file under sites-available/ and symlink that</span></span><br><span class="line"><span class="comment"># to sites-enabled/ to enable it.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">server &#123;</span><br><span class="line">      listen 80;</span><br><span class="line">      listen [::]:80;</span><br><span class="line"></span><br><span class="line">      server_name example.com;</span><br><span class="line"></span><br><span class="line">      root /var/www/example.com;</span><br><span class="line">      index index.html;</span><br><span class="line"></span><br><span class="line">      location / &#123;</span><br><span class="line">              try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ =404;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Ubuntu-18-04下-Apache2-web-服务器的安装-在node5测试"><a href="#Ubuntu-18-04下-Apache2-web-服务器的安装-在node5测试" class="headerlink" title="Ubuntu 18.04下 Apache2 web 服务器的安装 (在node5测试)"></a>Ubuntu 18.04下 Apache2 web 服务器的安装 (在node5测试)</h2><p>httpd是Apache超文本传输协议(HTTP)服务器的主程序。被设计为一个独立运行的后台进程，它会建立一个处理请求的子进程或线程的池。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install apache2 -y</span><br></pre></td></tr></table></figure>

<p>判断是否正常运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl status apache2</span><br><span class="line">service apache2 status</span><br></pre></td></tr></table></figure>

<p>开启、关闭和重启服务器,需要sudo</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/apache2 start    //启动Apache服务</span><br><span class="line">/etc/init.d/apache2 stop    //停止Apache服务 </span><br><span class="line">/etc/init.d/apache2 restart    //重启Apache服务</span><br></pre></td></tr></table></figure>

<p>修改根目录&#x2F;把文件传到根目录下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/apache2/sites-available/000-default.conf</span><br><span class="line">    DocumentRoot /var/www/html    // 默认</span><br><span class="line">    DocumentRoot /home/shaojiemike/Network/HUGO/shaojiemike/public //但是没有访问文件的权限，最后是把静态网页放到/var/www/html下</span><br><span class="line">sudo apache2ctl -k restart //重启</span><br></pre></td></tr></table></figure>

<h3 id="基础配置解释"><a href="#基础配置解释" class="headerlink" title="基础配置解释"></a>基础配置解释</h3><p><img src="https://pic.shaojiemike.top/img/20230510103819.png" alt="默认内网"></p>
<ul>
<li><p>You should replace this file (located at <code>/var/www/html/index.html</code>) before continuing to operate your HTTP server.</p>
</li>
<li><p>Configuration Overview</p>
<ul>
<li>Ubuntu’s Apache2 default configuration is different from the upstream default configuration, and split into several files optimized for interaction with Ubuntu tools.</li>
<li>The configuration system is fully documented in <code>/usr/share/doc/apache2/README.Debian.gz</code>. Refer to this for the full documentation. Documentation for the web server itself can be found by accessing the manual if the <code>apache2-doc</code> package was installed on this server.</li>
</ul>
</li>
<li><p>The <strong>configuration layout</strong> for an Apache2 web server installation on Ubuntu systems is as follows:</p>
</li>
<li><pre><code>  /etc/apache2/
  |-- apache2.conf
  |       `--  ports.conf
  |-- mods-enabled
  |       |-- *.load
  |       `-- *.conf
  |-- conf-enabled
  |       `-- *.conf
  |-- sites-enabled
  |       `-- *.conf
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  * **apache2.conf** is the main configuration file. It puts the pieces together by including all remaining configuration files when starting up the web server.</span><br><span class="line">  * **ports.conf** is always included from the main configuration file. It is used to determine the listening ports for incoming connections, and this file can be customized anytime.</span><br><span class="line">* Configuration files in the `mods-enabled/`, `conf-enabled/` and `sites-enabled/` directories contain particular configuration snippets which manage modules, global configuration fragments, or virtual host configurations, respectively.</span><br><span class="line">* They are activated by symlinking available configuration files from their respective `*-available/` counterparts. These should be managed by using our helpers a2enmod, a2dismod, a2ensite, a2dissite, and a2enconf, a2disconf . See their respective man pages for detailed information.</span><br><span class="line">* The binary is called apache2. Due to the use of environment variables, in the default configuration,</span><br><span class="line">  * apache2 needs to be started/stopped with `/etc/init.d/apache2` or `apache2ctl`.</span><br><span class="line">  * Calling `/usr/bin/apache2` directly will not work with the default configuration.</span><br><span class="line">* Document Roots</span><br><span class="line">  * By default, Ubuntu does not allow access through the web browser to any file apart of those located in `/var/www`, `public_html` directories (when enabled) and `/usr/share` (for web applications).</span><br><span class="line">  * If your site is using a web document root located elsewhere (such as in /srv) you may need to whitelist your document root directory in `/etc/apache2/apache2.conf`.</span><br><span class="line">    * 最简单实现`mount -t none -o bind,ro /targetPath /var/www/html`</span><br><span class="line">  * The default Ubuntu document root is `/var/www/html`. You can make your own virtual hosts under `/var/www`. This is different to previous releases which provides better security out of the box.</span><br><span class="line"></span><br><span class="line">## 遇到的问题</span><br><span class="line"></span><br><span class="line">把静态网页传上去</span><br><span class="line"></span><br></pre></td></tr></table></figure>
$ sudo apache2ctl -k restart
AH00558: apache2: Could not reliably determine the server&#39;s fully qualified domain name, using 127.0.1.1. Set the &#39;ServerName&#39; directive globally to suppress this message
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">没有访问权限</span><br><span class="line"></span><br></pre></td></tr></table></figure>
Forbidden
You don&#39;t have permission to access / on this server.
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这是因为没有修改运行访问的目录,而且能通过别名</span><br><span class="line"></span><br></pre></td></tr></table></figure>
sudo vim apache2.conf
  alias /testtsj/ &quot;/home/shaojiemike/Network/&quot;
  &lt;Directory &quot;/home/shaojiemike/Network/&quot;&gt;
      Options Indexes FollowSymLinks #首页不存在，允许访问当前目录下其它内容
      AllowOverride None
      Require all granted #允许访问所有
  &lt;/Directory&gt;
</code></pre>
</li>
</ul>
<pre><code>
![testtsj](https://link.jscdn.cn/sharepoint/aHR0cHM6Ly9tYWlsdXN0Y2VkdWNuLW15LnNoYXJlcG9pbnQuY29tLzppOi9nL3BlcnNvbmFsL3NoYW9qaWVtaWtlX21haWxfdXN0Y19lZHVfY24vRVZGMXhWcnUzUnBLb083VkFrdElodFlCdDRUTmVMYWp6NXkybE9WSTVnX25mUT9lPW5vUGx5Nw.png)

## 参考文献

&lt;https://blog.csdn.net/weixin_39212776/article/details/81192847&gt;

&lt;https://blog.csdn.net/weixin_41843699/article/details/90390562&gt;
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-12T16:00:00.000Z" title="5/12/2023, 4:00:00 PM">2023-05-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.253Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Tutorials/">Tutorials</a></span><span class="level-item">9 minutes read (About 1382 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/12/OutOfWork/6-games/6-SWITCH/">Switch emulator on PC</a></p><div class="content"><h2 id="合法使用"><a href="#合法使用" class="headerlink" title="合法使用"></a>合法使用</h2><p>虽然 Ryujinx 模拟器项目本身是开源免费且合法的，但它默认情况下并不能直接运行市面上发行的各种商业游戏，因为它并<strong>不包含 Switch 系统固件</strong>，也<strong>没有游戏 ROM</strong>。</p>
<p>而按照国外的法规，如果你用户购买了主机和游戏，将其内容 DUMP (提取) 出来自己使用是合法的。</p>
<p>所以，无论是 Ryujinx 还是 Yuzu 等模拟器，想要开玩都需要先完成</p>
<ul>
<li>安装系统固件和 </li>
<li>prod.keys 密钥等步骤。<ul>
<li>如果游戏要求最新的key和firmware你需要去更新</li>
</ul>
</li>
</ul>
<h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><ol>
<li>下载 Ryujinx 模拟器主程序</li>
<li>下载 <code>prod.keys</code> 密钥文件以及 Switch 的系统固件 (Firmware)</li>
<li>自行网上搜索下载你喜欢的任天堂游戏文件，支持 <code>.NSP</code> 或者 <code>.XCI</code> 格式</li>
</ol>
<h2 id="密钥文件以及-Switch-的系统固件"><a href="#密钥文件以及-Switch-的系统固件" class="headerlink" title="密钥文件以及 Switch 的系统固件"></a>密钥文件以及 Switch 的系统固件</h2><ul>
<li>通过<a target="_blank" rel="noopener" href="https://www.base64decode.org/">decode</a> 知道 <a target="_blank" rel="noopener" href="https://rentry.org/128bbkeys">网站中编码</a>的下载地址<ul>
<li>为<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/10c755wcDVn3sBb5LkxwWk-lIkZsnv40X">key</a></li>
</ul>
</li>
</ul>
<h2 id="Ryujinx-龙神-模拟器"><a href="#Ryujinx-龙神-模拟器" class="headerlink" title="Ryujinx (龙神)模拟器"></a>Ryujinx (龙神)模拟器</h2><p>率先支持了ARM和苹果 M 系列芯片</p>
<h3 id="简易步骤教程："><a href="#简易步骤教程：" class="headerlink" title="简易步骤教程："></a>简易步骤教程：</h3><ol>
<li>下载<a target="_blank" rel="noopener" href="https://ryujinx.org/download">模拟器</a>对应<a target="_blank" rel="noopener" href="https://github.com/Ryujinx/Ryujinx">github</a></li>
<li>将 Ryujinx 模拟器主程序解压到「不包含中文的路径」下。</li>
<li>首次启动 Ryujinx 模拟器后，会提示找不到 key 文件的错误<ol>
<li>点击菜单 文件 (File) → 打开 Ryujinx 文件夹 (Open Ryujinx Folder)，会弹出模拟器数据所在的目录。</li>
<li>将 <code>prod.keys</code> 文件放进到 Ryujinx 目录中的 <code>system</code> 文件夹里，重启模拟器</li>
</ol>
</li>
<li>放置好 keys 文件之后就开始安装固件 (Firmware) 了，<ol>
<li>点击菜单 工具 (Tools)→安装固件 (Install Firmware)→从 XCI 或 ZIP 安装固件 (Install a firmware from XCI or ZIP)，选择你下载到的 Firmware 压缩包(不需解压)，</li>
<li>模拟器就会开始安装，直到显示安装完成即可。</li>
</ol>
</li>
<li>此时已经可以运行 Switch 游戏了，<ol>
<li>点击菜单 选项 (Options) → 设置 (Settings)，在 用户界面 (General) → 游戏目录 (Game Directories) 下点击 添加 (Add) 来「添加一个游戏 ROM 文件存放目录」。</li>
<li>此后，模拟器会自动加载出存放在这些文件夹里的游戏列表。</li>
</ol>
</li>
</ol>
<h3 id="安装nsp-DLC文件"><a href="#安装nsp-DLC文件" class="headerlink" title="安装nsp DLC文件"></a>安装nsp DLC文件</h3><p>不是<br><img src="https://pic.shaojiemike.top/img/20221209151137.png"></p>
<p>而是<br><img src="https://pic.shaojiemike.top/img/20221209151349.png"></p>
<h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p><img src="https://pic.shaojiemike.top/img/20221209154239.png"></p>
<p><img src="https://pic.shaojiemike.top/img/20221209154454.png"></p>
<h2 id="YUZU-柚子-模拟器"><a href="#YUZU-柚子-模拟器" class="headerlink" title="YUZU(柚子)模拟器"></a>YUZU(柚子)模拟器</h2><p><a target="_blank" rel="noopener" href="https://github.com/yuzu-emu/yuzu-mainline">yuzu</a>，奶刃2好像都是用这个</p>
<h3 id="密钥缺失"><a href="#密钥缺失" class="headerlink" title="密钥缺失"></a>密钥缺失</h3><p>将你原来的User文件夹和ROM文件夹拖到新版模拟器文件夹的根目录即可。</p>
<p>将 <code>prod.keys</code> 文件放在<code>Yuzu\user\keys</code></p>
<h3 id="更新密钥和固件"><a href="#更新密钥和固件" class="headerlink" title="更新密钥和固件"></a>更新密钥和固件</h3><ul>
<li>下面两个目录的内容都可以删除，然后解压</li>
<li>keys解压到<code>Yuzu\user\keys</code></li>
<li>固件解压到<code>Yuzu\user\nand\system\Contents\registered</code></li>
</ul>
<h3 id="YUZU模拟器使用教程"><a href="#YUZU模拟器使用教程" class="headerlink" title="YUZU模拟器使用教程"></a>YUZU模拟器使用教程</h3><p><a target="_blank" rel="noopener" href="https://www.playdanji.com/yuzu">https://www.playdanji.com/yuzu</a></p>
<h3 id="YUZU金手指"><a href="#YUZU金手指" class="headerlink" title="YUZU金手指"></a>YUZU金手指</h3><p><a target="_blank" rel="noopener" href="https://www.playdanji.com/yuzujinshouzhi">https://www.playdanji.com/yuzujinshouzhi</a></p>
<h3 id="YUZU软件升级方法"><a href="#YUZU软件升级方法" class="headerlink" title="YUZU软件升级方法"></a>YUZU软件升级方法</h3><p>Early Access版本是需要花钱订阅才能下载的。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/yuzu-emu/yuzu-mainline">github</a>的release直接下载zip后解压替换即可。</p>
<h3 id="YUZU存档位置"><a href="#YUZU存档位置" class="headerlink" title="YUZU存档位置"></a>YUZU存档位置</h3><p>游戏右键，打开存档位置。</p>
<h3 id="退出全屏"><a href="#退出全屏" class="headerlink" title="退出全屏"></a>退出全屏</h3><p>F11</p>
<h3 id="YUZU-安装-nsp和xci文件"><a href="#YUZU-安装-nsp和xci文件" class="headerlink" title="YUZU 安装 nsp和xci文件"></a>YUZU 安装 nsp和xci文件</h3><p>key和中文的问题，建议用之前好的文件</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/406048136">https://zhuanlan.zhihu.com/p/406048136</a></p>
<h3 id="安装升级补丁nsp文件和DLC"><a href="#安装升级补丁nsp文件和DLC" class="headerlink" title="安装升级补丁nsp文件和DLC"></a>安装升级补丁nsp文件和DLC</h3><p><a target="_blank" rel="noopener" href="https://jingyan.baidu.com/article/39810a23e2ce82f737fda63d.html">导入NAND文件即可</a></p>
<h2 id="异度之刃2"><a href="#异度之刃2" class="headerlink" title="异度之刃2"></a>异度之刃2</h2><h3 id="打包本体1"><a href="#打包本体1" class="headerlink" title="打包本体1"></a>打包本体1</h3><p>30帧720P</p>
<p><a target="_blank" rel="noopener" href="https://switch520.com/23050.html">https://switch520.com/23050.html</a></p>
<h3 id="推荐OpenGL模式"><a href="#推荐OpenGL模式" class="headerlink" title="推荐OpenGL模式"></a>推荐OpenGL模式</h3><p>v模式，暗场景会过曝。</p>
<h3 id="画质补丁"><a href="#画质补丁" class="headerlink" title="画质补丁"></a>画质补丁</h3><p><a target="_blank" rel="noopener" href="https://tieba.baidu.com/p/6733982266">贴吧老哥的</a>放入目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E:\gamePojie\NaiRen2\A3285 v2.0.2_yuzuEA2077\user\sdmc\atmosphere\contents</span><br></pre></td></tr></table></figure>

<p>但是没什么用。</p>
<p>ini配置原理是，如下图<strong>对应</strong>配置目录<br><img src="https://pic.shaojiemike.top/img/20220620165029.png"></p>
<p>放入如下修改的ini文件来修改画质</p>
<p><img src="https://pic.shaojiemike.top/img/20220620165155.png"></p>
<p>如下图成功</p>
<p><img src="https://pic.shaojiemike.top/img/20220620165322.png"></p>
<p><a target="_blank" rel="noopener" href="https://tieba.baidu.com/p/7459891171">贴吧10楼</a>：刚试了下，我把属性的mod选项关掉，然后把0100F3400332C000的画质mod删掉，效果一样有，所以效果应该只能在0100F3400332D001\画质mod\romfs\monolib\shader下的lib_nx.ini里改，其他的都没用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">red_sclX=2.0</span><br><span class="line">red_sclY=2.0</span><br><span class="line">red_hdsclX=2.0</span><br><span class="line">red_hdsclY=2.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">red_Auto=on</span><br><span class="line">red_AtMaxX=2.0</span><br><span class="line">red_AtMaxY=2.0</span><br><span class="line">red_AtMinX=2.0</span><br><span class="line">red_AtMinY=2.0</span><br><span class="line">red_AtRate=100.0</span><br></pre></td></tr></table></figure>

<p>2.0就是1440p，1.0就是原版720p。你们可以试试改其他的</p>
<h3 id="帧数补丁"><a href="#帧数补丁" class="headerlink" title="帧数补丁"></a>帧数补丁</h3><p>60帧补丁实际效果远没有60帧而且一堆副作用，不用浪费时间了</p>
<h3 id="bug花屏"><a href="#bug花屏" class="headerlink" title="bug花屏"></a>bug花屏</h3><p>按照<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1h3411L7ay?spm_id_from=333.851.header_right.fav_list.click&vd_source=5bbdecb1838c6f684e0b823d0d4f6db3">B站设置</a>，主要改了GLSL</p>
<p><img src="https://pic.shaojiemike.top/img/20220622072520.png"></p>
<h2 id="塞尔达-旷野之息"><a href="#塞尔达-旷野之息" class="headerlink" title="塞尔达-旷野之息"></a>塞尔达-旷野之息</h2><p>游侠论坛的cemu模拟的效果就不错</p>
<h2 id="塞尔达-王国之泪"><a href="#塞尔达-王国之泪" class="headerlink" title="塞尔达-王国之泪"></a>塞尔达-王国之泪</h2><ul>
<li>yuzu 1414以上</li>
<li>keys firmware 16.0.2以上</li>
</ul>
<p>龙神模拟器，会经常闪退，暂时不知道解决办法(Cache PPTC rebuild?)。yuzu没有闪退的问题<br><img src="https://pic.shaojiemike.top/img/20230512210628.png"></p>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>暂无</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><p>之前买了正版的switch，游戏也入了两三千。旷&#x2F;荒野之息，奥德赛，奶刃2都通关了。可惜被妈妈没收了~</p>
<p>想研究一下，PC模拟，记录踩坑过程</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-11T16:00:00.000Z" title="5/11/2023, 4:00:00 PM">2023-05-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-15T13:31:32.273Z" title="12/15/2023, 1:31:32 PM">2023-12-15</time></span><span class="level-item"><a class="link-muted" href="/categories/toLearn/">toLearn</a></span><span class="level-item">23 minutes read (About 3401 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/11/Work/network/Protocol/BT/">BitTorrent</a></p><div class="content"><h2 id="BT简述"><a href="#BT简述" class="headerlink" title="BT简述"></a>BT简述</h2><p>BitTorrent (简称 BT) 协议是和点对点（point-to-point）的协议程序不同，它是用户群对用户群（peer-to-peer, 或简写为 P2P) 传输协议, 它被设计用来高效地分发文件 (尤其是对于大文件、多人同时下载时效率非常高)。该协议基于HTTP协议，属于TCP&#x2F;IP应用层。</p>
<p>将文件划分成多块(默认256Kb一块)，每块可以从网络中不同的用户的BT客户端处并行下载。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BT 下载的文件都是别人上传给你的。</span><br><span class="line">BT 下载速度均来自其他下载同一资源的用户上传速度。</span><br><span class="line">上传的用户越多，你的下载速度越快，相反没用户上传你就没有下载速度。</span><br></pre></td></tr></table></figure>

<p>比特彗星，包括其他 BT 软件（迅雷除外，迅雷不是会员会限速，高速通道下载提高的速度一部分就是接触限速后获得的）都不会限制下载速度。</p>
<h3 id="BT分享规则"><a href="#BT分享规则" class="headerlink" title="BT分享规则"></a>BT分享规则</h3><p>与迅雷不同，BT旨在“人人为我，我为人人”。用户和用户之间对等交换自己手中已有的资源。如果任何一方试图白嫖另外一方的资源，而自己不愿意上传自己的资源，那么那方就会被人视作吸血者而被踢出这个交换，下场是没有人会愿意和你交换数据，你的下载速度也就归零。</p>
<p>如果把上传速度限制为了10KB&#x2F;s，10KB&#x2F;s是BitComet上传最低限速，很大时候就这10KB会被包含DHT查询、向Tracker服务器注册，连接用户所产生的上传全部占满。在下载种子的时候，其他用户连上你是只能拿到1～2KB&#x2F;s甚至一点都没有的。</p>
<p>现在的BT下载客户端都可以做到智能反吸血，所以基本想和交换数据的用户都把你当作Leecher（吸血鬼）Ban（封禁）处理了，故没有下载速度不足为奇。</p>
<p>一般来说，只要预留50KB&#x2F;s的上传给其他网页浏览、聊天就可以了，在下载时应该尽量把上传留给那些和你交换资源的用户，这样才不会被他们视作你在吸血进而屏蔽你。</p>
<p>如果上传不足，就应该主动限制自己的下载速度，否则单位时间下载量远超过上传量反而会遭来更多的屏蔽，对下载速度提升更加不利。</p>
<h3 id="BT基本流程"><a href="#BT基本流程" class="headerlink" title="BT基本流程"></a>BT基本流程</h3><p><code>.torrent</code> 种子文件本质上是文本文件，包含Tracker信息和文件信息两部分。Tracker信息主要是BT下载中需要用到的Tracker服务器的地址和针对Tracker服务器的设置。</p>
<ol>
<li>下载时，BT客户端首先解析种子文件得到Tracker地址，然后连接Tracker服务器。</li>
<li>Tracker服务器回应下载者的请求，提供下载者其他下载者（包括发布者）的IP。</li>
<li>下载者再连接其他下载者，根据种子文件，两者分别告知对方自己已经有的块，然后交换对方所没有的数据。<ol>
<li>此时不需要其他服务器参与，分散了单个线路上的数据流量，因此减轻了服务器负担。</li>
</ol>
</li>
<li>下载者每得到一个块，需要算出下载块的Hash验证码与种子文件中的对比，如果一样则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容准确性的问题。</li>
</ol>
<h2 id="常规部署"><a href="#常规部署" class="headerlink" title="常规部署"></a>常规部署</h2><ul>
<li>安装<a target="_blank" rel="noopener" href="https://manpages.ubuntu.com/manpages/jammy/man1/qbittorrent-nox.1.html">qBittorrent-nox</a>, tmux下运行，在8080端口挂载WebUI</li>
<li>安装qbittorrent, 用户运行qbittorrent, x11弹出应用窗口<ul>
<li>问题：<ul>
<li>怎么维持窗口？<code>sudo XAUTHORITY=/home/qcjiang/.Xauthority qbittorrent</code></li>
<li>关于写文件权限，如何写网络硬盘</li>
<li>node5 上传很快, 网络原因？种子原因？(不是，是因为网络硬盘，所以下载多少要占用多少上传)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="docker部署"><a href="#docker部署" class="headerlink" title="docker部署"></a>docker部署</h2><p>以qBit的docker为例，参考<a target="_blank" rel="noopener" href="https://hub.docker.com/r/linuxserver/qbittorrent/#!">linuxsever</a>的docker-compose如下：(qBit相对于Transmission有多线程IO的优势) 也可以使用<a target="_blank" rel="noopener" href="https://github.com/SuperNG6/Docker-qBittorrent">其余docker镜像</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">version: &quot;2.1&quot;</span><br><span class="line">services:</span><br><span class="line">  qbittorrent:</span><br><span class="line">    image: lscr.io/linuxserver/qbittorrent:latest</span><br><span class="line">    container_name: qbittorrent</span><br><span class="line">    environment:</span><br><span class="line">      - PUID=0 # 这里是root 如果想以其他用戶A修改文件，可以改成其他用户的UID。通過id A 查看</span><br><span class="line">      - PGID=0</span><br><span class="line">      - TZ=Etc/UTC</span><br><span class="line">      - WEBUI_PORT=8080</span><br><span class="line">    volumes:</span><br><span class="line">      - /addDisk/DiskNo4/qBit:/config</span><br><span class="line">      - /addDisk/DiskNo4/bt:/downloads</span><br><span class="line"></span><br><span class="line">    network_mode: host</span><br><span class="line">    restart: unless-stopped</span><br></pre></td></tr></table></figure>

<p>默认账号 <code>admin</code> 默认密码 <code>adminadmin</code><br>然后通过webUI <code>http://222.195.72.218:8080/</code>管理。</p>
<p>如果不想网络通过wireguard，而是本地可以如下设置<br><img src="https://pic.shaojiemike.top/img/20230314193709.png"></p>
<h3 id="同一台机器实现两个账号做种"><a href="#同一台机器实现两个账号做种" class="headerlink" title="同一台机器实现两个账号做种"></a>同一台机器实现两个账号做种</h3><ul>
<li>思路：两个docker，同一个网络出口</li>
<li>問題：<ul>
<li>qBit要有权限写文件</li>
<li>两个docker兼容性：<ul>
<li>WebUI有bug，不一定会显示。重启刷新即可</li>
<li>其次有一个docker会没有网络。<ul>
<li>这是由于端口随机错误导致的，会导致下面连接状态显示火焰。换端口刷新即可解决。</li>
<li><img src="https://pic.shaojiemike.top/img/20230512090749.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>关于封号<ul>
<li>由于国内环境下载一般都是大内网。同一个网络出去应该没有问题。</li>
<li>大多数做种是通过ipv6，会被检测出同一个机器多个账户做种，导致封号</li>
<li>还有关于盒子刷上传，一方面通过速度，另一方面由于盒子的ip是固定的，所以会被检测出重复导致封号。</li>
</ul>
</li>
</ul>
<h2 id="测速"><a href="#测速" class="headerlink" title="测速"></a>测速</h2><ol>
<li>先用 <a target="_blank" rel="noopener" href="https://www.speedtest.net/">https://www.speedtest.net</a> 测速<ol>
<li><img src="https://pic.shaojiemike.top/img/20221117082208.png"></li>
</ol>
</li>
<li>考虑热门种子测试 <a target="_blank" rel="noopener" href="http://releases.ubuntu.com/19.10/ubuntu-19.10-desktop-amd64.iso.torrent">http://releases.ubuntu.com/19.10/ubuntu-19.10-desktop-amd64.iso.torrent</a><ol>
<li><img src="https://pic.shaojiemike.top/img/20221117084350.png"></li>
<li>没通过代理能找到的用户变少，速度也变慢了。</li>
</ol>
</li>
<li>如果跑不到网络上限，可能和<a target="_blank" rel="noopener" href="https://www.cometbbs.com/t/%E8%A2%AB%E9%99%90%E9%80%9F%E5%9C%A8109mbs/34309/13">软件设置有关</a></li>
</ol>
<h2 id="上传速度"><a href="#上传速度" class="headerlink" title="上传速度"></a>上传速度</h2><p>m站刷上传的时候，发现基本都是对方基本都是通过ipv6下载<br><img src="https://pic.shaojiemike.top/img/Snipaste_2023-03-06_18-17-07.png"><br>uTP是一种基于UDP的协议，它可以根据网络拥塞情况自动调节传输速度，从而减少对其他网络应用的影响。</p>
<p>BT连接是一种基于TCP的协议，它可以保证数据的完整性和可靠性，但是可能会占用较多的网络带宽和资源。</p>
<p>在qBittorrent中，标志U K E P分别表示以下含义：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">U：表示你正在上传数据给对方，或者对方正在从你那里下载数据。</span><br><span class="line">K：表示对方支持uTP协议，即基于UDP的传输协议。</span><br><span class="line">E：表示对方使用了加密连接，即通过加密算法保护数据的安全性。</span><br><span class="line">P：表示对方使用了代理服务器或VPN服务，即通过第三方网络隐藏自己的真实IP地址。</span><br></pre></td></tr></table></figure>

<h2 id="PT设置"><a href="#PT设置" class="headerlink" title="PT设置"></a>PT设置</h2><ul>
<li>虽然说PT下载，客户端要关闭DHT,PeX, LSD。</li>
<li>但是其实种子是默认关闭的，无序额外设置，北洋和M站一样。</li>
<li><img src="https://pic.shaojiemike.top/img/20230512091246.png"></li>
</ul>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Tracker"><a href="#Tracker" class="headerlink" title="Tracker"></a>Tracker</h3><p>收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。</p>
<h3 id="种子"><a href="#种子" class="headerlink" title="种子"></a>种子</h3><p>指一个下载任务中所有文件都被某下载者<strong>完整</strong>的下载，此时下载者成为一个种子。发布者本身发布的文件就是原始种子。</p>
<h3 id="做种"><a href="#做种" class="headerlink" title="做种"></a>做种</h3><p>发布者提供下载任务的<strong>全部</strong>内容的行为；下载者下载完成后继续提供给他人下载的行为。</p>
<h3 id="分享率"><a href="#分享率" class="headerlink" title="分享率"></a>分享率</h3><p>上傳資料量 &#x2F; 下傳資料量的比率,是一種BT的良心度,沒實際作用.(一般为了良心，至少大于1)</p>
<h3 id="长期种子"><a href="#长期种子" class="headerlink" title="长期种子"></a>长期种子</h3><p>BitComet的概念，相对于种子任务的上传能够控制。</p>
<p>长效种子就是你<strong>不开启</strong>任务做种，只要你启动了比特彗星，软件挂后台，当有其他用户也是用比特彗星下载你列表里的存在的文件时候就会被认为是长效种子 。</p>
<h3 id="DHT"><a href="#DHT" class="headerlink" title="DHT"></a>DHT</h3><p>.DHT全称叫分布式哈希表(Distributed Hash Table)，是一种分布式存储方法。在不需要服务器的情况下，每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。新版BitComet允许同行连接DHT网络和Tracker，也就是说在完全不连上Tracker服务器的情况下，也可以很好的下载，因为它可以在DHT网络中寻找下载同一文件的其他用户。</p>
<p>类似Tracker的根据种子特征码返回种子信息的网络。</p>
<p>在BitComet中，无须作任何设置即可自动连接并使用DHT网络，完全不需要用户干预。</p>
<h3 id="用户交换Pex"><a href="#用户交换Pex" class="headerlink" title="用户交换Pex"></a>用户交换Pex</h3><p>Peer Exchange (PEX)， 每个peer客户端的用户列表，可以互相交换通用。可以将其理解为“节点信息交换”。前面说到了 DHT 网络是没有中心服务器的，那么我们的客户端总不能满世界去喊：“我在下载这个文件，快来连我吧.”（很大声）。所以就通过各个 BT 客户端自带的节点去同步路由表实现 DHT 网络连接。</p>
<h3 id="本地用户发现"><a href="#本地用户发现" class="headerlink" title="本地用户发现"></a>本地用户发现</h3><p>LSD（LPD）就是本地网络资源，内网下载，没什么几把用的东西，可能学校等私有网络好使</p>
<h3 id="ISP"><a href="#ISP" class="headerlink" title="ISP"></a>ISP</h3><p>網絡業務提供商(Internet Service Provider，簡稱ISP)，互聯網服務提供商，即向廣大用户綜合提供互聯網接入業務、信息業務、和增值業務的電信運營商。</p>
<h2 id="反吸血机制"><a href="#反吸血机制" class="headerlink" title="反吸血机制"></a>反吸血机制</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><ol>
<li>根据<strong>流量</strong>： 默认设置为120秒，持续对某个peer产生上传，并且从该peer用户获取的下载流量没有超过1KB文件（1024字节）大小，即拉黑该peer，预警颜色为黄色，合法为绿色，红色为封禁。</li>
<li>可组合检测<strong>指定客户端</strong>进行反吸血，比如说指定屏蔽qbittorrent、utorrent等吸血客户端选择（可多选客户端，可对下载任务和做种任务生效）</li>
<li>可组合检测客户端<strong>连接端口号</strong>进行反吸血，比如说指定屏蔽15000迅雷X版本客户端等吸血端口（可多选端口号，可对下载任务和做种任务生效）</li>
<li>可组合检测客户端<strong>连接peer_id标志符</strong>进行反吸血屏蔽，例如屏蔽XL0018客户端等吸血标志符（可多选标志符，可对下载任务和做种任务生效）</li>
</ol>
<h3 id="高级设置"><a href="#高级设置" class="headerlink" title="高级设置"></a>高级设置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bittorrent.anti_leech_min_byte</span><br><span class="line">设定反吸血保护流量：要求对方在指定时间（秒）内需要上传的最少流量（byte）， 取值范围：1-10000。</span><br><span class="line"></span><br><span class="line">bittorrent.anti_leech_min_stable_sec</span><br><span class="line">设定反吸血保护时间：指定与对方连接多长时间（秒）后开始检查流量（byte），取值范围：1-10000。</span><br></pre></td></tr></table></figure>

<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="需要软件开着吗？"><a href="#需要软件开着吗？" class="headerlink" title="需要软件开着吗？"></a>需要软件开着吗？</h3><p>需要</p>
<h3 id="原文件改名或者移动，还会上传吗？"><a href="#原文件改名或者移动，还会上传吗？" class="headerlink" title="原文件改名或者移动，还会上传吗？"></a>原文件改名或者移动，还会上传吗？</h3><p>文件下载后不能移动，不能删除，不能重命名（但可以在软件内改）。 一但BT 软件找不到文件，或删除了任务，就无法做种上传了。</p>
<h3 id="晚上避免上传"><a href="#晚上避免上传" class="headerlink" title="晚上避免上传"></a>晚上避免上传</h3><p>可以在Bitcomet<strong>高级设置</strong>里设置<strong>时段限速</strong></p>
<h3 id="对硬盘损害大吗？"><a href="#对硬盘损害大吗？" class="headerlink" title="对硬盘损害大吗？"></a>对硬盘损害大吗？</h3><p>分享上传也需要频繁读取硬盘。</p>
<p>以Bitcomet为例，该软件就是通过磁盘缓存技术减小频繁随机读写对硬盘的损伤。</p>
<p>磁盘缓存就是利用物理内存作为缓冲，将下载下的数据先存放于内存中，然后定期的一次性写入硬盘，以减少对硬盘的写入操作，很大的程度上降低了磁盘碎片。</p>
<p>因为通常我们设置内存（磁盘缓存）为每任务XX兆，意味着，这个缓冲区可以存放数兆甚至几十兆的“块”，基本上可以杜绝碎片了。</p>
<p>现在BT软件都是自动设置缓存的，它是根据你物理内存的大小分配的。</p>
<h2 id="注意设置"><a href="#注意设置" class="headerlink" title="注意设置"></a>注意设置</h2><ol>
<li>设置了“反吸血”，应对迅雷</li>
<li>校园网设置9，不限制P2P<ol>
<li>国内各省份不同运营商限速策略（QOS）</li>
</ol>
</li>
</ol>
<h2 id="需要进一步的研究学习"><a href="#需要进一步的研究学习" class="headerlink" title="需要进一步的研究学习"></a>需要进一步的研究学习</h2><p>路由器下载？</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>暂无</p>
<h2 id="开题缘由、总结、反思、吐槽"><a href="#开题缘由、总结、反思、吐槽" class="headerlink" title="开题缘由、总结、反思、吐槽~~"></a>开题缘由、总结、反思、吐槽~~</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id='refer-anchor'></div>
无
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/18/">Previous</a></div><div class="pagination-next"><a href="/page/20/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/18/">18</a></li><li><a class="pagination-link is-current" href="/page/19/">19</a></li><li><a class="pagination-link" href="/page/20/">20</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/37/">37</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="Shaojie Tan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shaojie Tan</p><p class="is-size-6 is-block">𝘊𝘰𝘮𝘱𝘶𝘵𝘦𝘳 𝘈𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 &amp; 𝘏𝘗𝘊</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Anhui, Hefei, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">361</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">29</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">482</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kirrito-k423" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kirrito-k423"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithms/"><span class="level-start"><span class="level-item">Algorithms</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">36</span></span></a></li><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Databases/"><span class="level-start"><span class="level-item">Databases</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/HPC/"><span class="level-start"><span class="level-item">HPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Operating-system/"><span class="level-start"><span class="level-item">Operating system</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Software/"><span class="level-start"><span class="level-item">Software</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Treasure/"><span class="level-start"><span class="level-item">Treasure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tutorials/"><span class="level-start"><span class="level-item">Tutorials</span></span><span class="level-end"><span class="level-item tag">118</span></span></a></li><li><a class="level is-mobile" href="/categories/Values/"><span class="level-start"><span class="level-item">Values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/english/"><span class="level-start"><span class="level-item">english</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/hardware/"><span class="level-start"><span class="level-item">hardware</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/categories/operating-system/"><span class="level-start"><span class="level-item">operating system</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/software/"><span class="level-start"><span class="level-item">software</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/thinking/"><span class="level-start"><span class="level-item">thinking</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/thinking/OOW/"><span class="level-start"><span class="level-item">OOW</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/tips/"><span class="level-start"><span class="level-item">tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/toLearn/"><span class="level-start"><span class="level-item">toLearn</span></span><span class="level-end"><span class="level-item tag">50</span></span></a></li><li><a class="level is-mobile" href="/categories/values/"><span class="level-start"><span class="level-item">values</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://ibug.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ibugs</span></span><span class="level-right"><span class="level-item tag">ibug.io</span></span></a></li><li><a class="level is-mobile" href="https://jia.je/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">jiegec</span></span><span class="level-right"><span class="level-item tag">jia.je</span></span></a></li><li><a class="level is-mobile" href="https://leimao.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">leimao</span></span><span class="level-right"><span class="level-item tag">leimao.github.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-08T13:13:26.000Z">2023-12-08</time></p><p class="title"><a href="/2023/12/08/OutOfWork/5-VideoEntertainment/CalibreAndItsPuginsForEhentaiBooks/">Calibre and its Pugins for e-hentai Books</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-07T12:34:56.000Z">2023-12-07</time></p><p class="title"><a href="/2023/12/07/OutOfWork/3-homepage/blogWebsiteBuilderOrSSG/dokuwiki/">Dokuwiki</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-06T08:10:02.000Z">2023-12-06</time></p><p class="title"><a href="/2023/12/06/OutOfWork/4-devices/nas/UgreenNas/">Ugreen Nas</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-03T09:31:21.000Z">2023-12-03</time></p><p class="title"><a href="/2023/12/03/OutOfWork/3-homepage/deployment/webDesign4customizeMarkdownGrammarInSSG/">Web Design 4 : Customize Markdown Grammar In SSG</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-30T21:48:21.000Z">2023-11-30</time></p><p class="title"><a href="/2023/11/30/OutOfWork/3-homepage/deployment/webDesign3FutureFeatures/">Web Design 3 : Future Features</a></p><p class="categories"><a href="/categories/OOW/">OOW</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">222</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">67</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">72</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/5G/"><span class="tag">5G</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/64bits-vs-32bits/"><span class="tag">64bits vs 32bits</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMAT/"><span class="tag">AMAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AMD/"><span class="tag">AMD</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASPLOS/"><span class="tag">ASPLOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ATI/"><span class="tag">ATI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AVX/"><span class="tag">AVX</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Alpha/"><span class="tag">Alpha</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Analysis/"><span class="tag">Analysis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Apt/"><span class="tag">Apt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Assembly/"><span class="tag">Assembly</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BFS/"><span class="tag">BFS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BHive/"><span class="tag">BHive</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BT/"><span class="tag">BT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BTL/"><span class="tag">BTL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Baka-Mitai/"><span class="tag">Baka Mitai</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bash/"><span class="tag">Bash</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Endian/"><span class="tag">Big-Endian</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SHAOJIE&#039;S BOOK" height="28"></a><p class="is-size-7"><span>&copy; 2023 Shaojie Tan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Kirrito-k423/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>